
<!doctype html><html lang="en">
 <head>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
  <title>Web Neural Network API</title>
  <meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<style data-fill-with="stylesheet">/******************************************************************************
 *                   Style sheet for the W3C specifications                   *
 *
 * Special classes handled by this style sheet include:
 *
 * Indices
 *   - .toc for the Table of Contents (<ol class="toc">)
 *     + <span class="secno"> for the section numbers
 *   - #toc for the Table of Contents (<nav id="toc">)
 *   - ul.index for Indices (<a href="#ref">term</a><span>, in §N.M</span>)
 *   - table.index for Index Tables (e.g. for properties or elements)
 *
 * Structural Markup
 *   - table.data for general data tables
 *     -> use 'scope' attribute, <colgroup>, <thead>, and <tbody> for best results !
 *     -> use <table class='complex data'> for extra-complex tables
 *     -> use <td class='long'> for paragraph-length cell content
 *     -> use <td class='pre'> when manual line breaks/indentation would help readability
 *   - dl.switch for switch statements
 *   - ol.algorithm for algorithms (helps to visualize nesting)
 *   - .figure and .caption (HTML4) and figure and figcaption (HTML5)
 *     -> .sidefigure for right-floated figures
 *   - ins/del
 *
 * Code
 *   - pre and code
 *
 * Special Sections
 *   - .note       for informative notes             (div, p, span, aside, details)
 *   - .example    for informative examples          (div, p, pre, span)
 *   - .issue      for issues                        (div, p, span)
 *   - .assertion  for assertions                    (div, p, span)
 *   - .advisement for loud normative statements     (div, p, strong)
 *   - .annoying-warning for spec obsoletion notices (div, aside, details)
 *
 * Definition Boxes
 *   - pre.def   for WebIDL definitions
 *   - table.def for tables that define other entities (e.g. CSS properties)
 *   - dl.def    for definition lists that define other entitles (e.g. HTML elements)
 *
 * Numbering
 *   - .secno for section numbers in .toc and headings (<span class='secno'>3.2</span>)
 *   - .marker for source-inserted example/figure/issue numbers (<span class='marker'>Issue 4</span>)
 *   - ::before styled for CSS-generated issue/example/figure numbers:
 *     -> Documents wishing to use this only need to add
 *        figcaption::before,
 *        .caption::before { content: "Figure "  counter(figure) " ";  }
 *        .example::before { content: "Example " counter(example) " "; }
 *        .issue::before   { content: "Issue "   counter(issue) " ";   }
 *
 * Header Stuff (ignore, just don't conflict with these classes)
 *   - .head for the header
 *   - .copyright for the copyright
 *
 * Miscellaneous
 *   - .overlarge for things that should be as wide as possible, even if
 *     that overflows the body text area. This can be used on an item or
 *     on its container, depending on the effect desired.
 *     Note that this styling basically doesn't help at all when printing,
 *     since A4 paper isn't much wider than the max-width here.
 *     It's better to design things to fit into a narrower measure if possible.
 *   - js-added ToC jump links (see fixup.js)
 *
 ******************************************************************************/

/******************************************************************************/
/*                                   Body                                     */
/******************************************************************************/

	body {
		counter-reset: example figure issue;

		/* Layout */
		max-width: 50em;               /* limit line length to 50em for readability   */
		margin: 0 auto;                /* center text within page                     */
		padding: 1.6em 1.5em 2em 50px; /* assume 16px font size for downlevel clients */
		padding: 1.6em 1.5em 2em calc(26px + 1.5em); /* leave space for status flag     */

		/* Typography */
		line-height: 1.5;
		font-family: sans-serif;
		widows: 2;
		orphans: 2;
		word-wrap: break-word;
		overflow-wrap: break-word;
		hyphens: auto;

		/* Colors */
		color: black;
		background: white top left fixed no-repeat;
		background-size: 25px auto;
	}


/******************************************************************************/
/*                         Front Matter & Navigation                          */
/******************************************************************************/

/** Header ********************************************************************/

	div.head { margin-bottom: 1em }
	div.head hr { border-style: solid; }

	div.head h1 {
		font-weight: bold;
		margin: 0 0 .1em;
		font-size: 220%;
	}

	div.head h2 { margin-bottom: 1.5em;}

/** W3C Logo ******************************************************************/

	.head .logo {
		float: right;
		margin: 0.4rem 0 0.2rem .4rem;
	}

	.head img[src*="logos/W3C"] {
		display: block;
		border: solid #1a5e9a;
		border-width: .65rem .7rem .6rem;
		border-radius: .4rem;
		background: #1a5e9a;
		color: white;
		font-weight: bold;
	}

	.head a:hover > img[src*="logos/W3C"],
	.head a:focus > img[src*="logos/W3C"] {
		opacity: .8;
	}

	.head a:active > img[src*="logos/W3C"] {
		background: #c00;
		border-color: #c00;
	}

	/* see also additional rules in Link Styling section */

/** Copyright *****************************************************************/

	p.copyright,
	p.copyright small { font-size: small }

/** Back to Top / ToC Toggle **************************************************/

	@media print {
		#toc-nav {
			display: none;
		}
	}
	@media not print {
		#toc-nav {
			position: fixed;
			z-index: 2;
			bottom: 0; left: 0;
			margin: 0;
			min-width: 1.33em;
			border-top-right-radius: 2rem;
			box-shadow: 0 0 2px;
			font-size: 1.5em;
			color: black;
		}
		#toc-nav > a {
			display: block;
			white-space: nowrap;

			height: 1.33em;
			padding: .1em 0.3em;
			margin: 0;

			background: white;
			box-shadow: 0 0 2px;
			border: none;
			border-top-right-radius: 1.33em;
			background: white;
		}
		#toc-nav > #toc-jump {
			padding-bottom: 2em;
			margin-bottom: -1.9em;
		}

		#toc-nav > a:hover,
		#toc-nav > a:focus {
			background: #f8f8f8;
		}
		#toc-nav > a:not(:hover):not(:focus) {
			color: #707070;
		}

		/* statusbar gets in the way on keyboard focus; remove once browsers fix */
		#toc-nav > a[href="#toc"]:not(:hover):focus:last-child {
			padding-bottom: 1.5rem;
		}

		#toc-nav:not(:hover) > a:not(:focus) > span + span {
			/* Ideally this uses :focus-within on #toc-nav */
			display: none;
		}
		#toc-nav > a > span + span {
			padding-right: 0.2em;
		}

		#toc-toggle-inline {
			vertical-align: 0.05em;
			font-size: 80%;
			color: gray;
			color: hsla(203,20%,40%,.7);
			border-style: none;
			background: transparent;
			position: relative;
		}
		#toc-toggle-inline:hover:not(:active),
		#toc-toggle-inline:focus:not(:active) {
			text-shadow: 1px 1px silver;
			top: -1px;
			left: -1px;
		}

		#toc-nav :active {
			color: #C00;
		}
	}

/** ToC Sidebar ***************************************************************/

	/* Floating sidebar */
	@media screen {
		body.toc-sidebar #toc {
			position: fixed;
			top: 0; bottom: 0;
			left: 0;
			width: 23.5em;
			max-width: 80%;
			max-width: calc(100% - 2em - 26px);
			overflow: auto;
			padding: 0 1em;
			padding-left: 42px;
			padding-left: calc(1em + 26px);
			background: inherit;
			background-color: #f7f8f9;
			z-index: 1;
			box-shadow: -.1em 0 .25em rgba(0,0,0,.1) inset;
		}
		body.toc-sidebar #toc h2 {
			margin-top: .8rem;
			font-variant: small-caps;
			font-variant: all-small-caps;
			text-transform: lowercase;
			font-weight: bold;
			color: gray;
			color: hsla(203,20%,40%,.7);
		}
		body.toc-sidebar #toc-jump:not(:focus) {
			width: 0;
			height: 0;
			padding: 0;
			position: absolute;
			overflow: hidden;
		}
	}
	/* Hide main scroller when only the ToC is visible anyway */
	@media screen and (max-width: 28em) {
		body.toc-sidebar {
			overflow: hidden;
		}
	}

	/* Sidebar with its own space */
	@media screen and (min-width: 78em) {
		body:not(.toc-inline) #toc {
			position: fixed;
			top: 0; bottom: 0;
			left: 0;
			width: 23.5em;
			overflow: auto;
			padding: 0 1em;
			padding-left: 42px;
			padding-left: calc(1em + 26px);
			background: inherit;
			background-color: #f7f8f9;
			z-index: 1;
			box-shadow: -.1em 0 .25em rgba(0,0,0,.1) inset;
		}
		body:not(.toc-inline) #toc h2 {
			margin-top: .8rem;
			font-variant: small-caps;
			font-variant: all-small-caps;
			text-transform: lowercase;
			font-weight: bold;
			color: gray;
			color: hsla(203,20%,40%,.7);
		}

		body:not(.toc-inline) {
			padding-left: 29em;
		}
		/* See also Overflow section at the bottom */

		body:not(.toc-inline) #toc-jump:not(:focus) {
			width: 0;
			height: 0;
			padding: 0;
			position: absolute;
			overflow: hidden;
		}
	}
	@media screen and (min-width: 90em) {
		body:not(.toc-inline) {
			margin: 0 4em;
		}
	}

/******************************************************************************/
/*                                Sectioning                                  */
/******************************************************************************/

/** Headings ******************************************************************/

	h1, h2, h3, h4, h5, h6, dt {
		page-break-after: avoid;
		page-break-inside: avoid;
		font: 100% sans-serif;   /* Reset all font styling to clear out UA styles */
		font-family: inherit;    /* Inherit the font family. */
		line-height: 1.2;        /* Keep wrapped headings compact */
		hyphens: manual;         /* Hyphenated headings look weird */
	}

	h2, h3, h4, h5, h6 {
		margin-top: 3rem;
	}

	h1, h2, h3 {
		color: #005A9C;
		background: transparent;
	}

	h1 { font-size: 170%; }
	h2 { font-size: 140%; }
	h3 { font-size: 120%; }
	h4 { font-weight: bold; }
	h5 { font-style: italic; }
	h6 { font-variant: small-caps; }
	dt { font-weight: bold; }

/** Subheadings ***************************************************************/

	h1 + h2,
	#subtitle {
		/* #subtitle is a subtitle in an H2 under the H1 */
		margin-top: 0;
	}
	h2 + h3,
	h3 + h4,
	h4 + h5,
	h5 + h6 {
		margin-top: 1.2em; /* = 1 x line-height */
	}

/** Section divider ***********************************************************/

	:not(.head) > hr {
		font-size: 1.5em;
		text-align: center;
		margin: 1em auto;
		height: auto;
		border: transparent solid 0;
		background: transparent;
	}
	:not(.head) > hr::before {
		content: "\2727\2003\2003\2727\2003\2003\2727";
	}

/******************************************************************************/
/*                            Paragraphs and Lists                            */
/******************************************************************************/

	p {
		margin: 1em 0;
	}

	dd > p:first-child,
	li > p:first-child {
		margin-top: 0;
	}

	ul, ol {
		margin-left: 0;
		padding-left: 2em;
	}

	li {
		margin: 0.25em 0 0.5em;
		padding: 0;
	}

	dl dd {
		margin: 0 0 .5em 2em;
	}

	.head dd + dd { /* compact for header */
		margin-top: -.5em;
	}

	/* Style for algorithms */
	ol.algorithm ol:not(.algorithm),
	.algorithm > ol ol:not(.algorithm) {
	 border-left: 0.5em solid #DEF;
	}

	/* Put nice boxes around each algorithm. */
	[data-algorithm]:not(.heading) {
	  padding: .5em;
	  border: thin solid #ddd; border-radius: .5em;
	  margin: .5em calc(-0.5em - 1px);
	}
	[data-algorithm]:not(.heading) > :first-child {
	  margin-top: 0;
	}
	[data-algorithm]:not(.heading) > :last-child {
	  margin-bottom: 0;
	}

	/* Style for switch/case <dl>s */
	dl.switch > dd > ol.only,
	dl.switch > dd > .only > ol {
	 margin-left: 0;
	}
	dl.switch > dd > ol.algorithm,
	dl.switch > dd > .algorithm > ol {
	 margin-left: -2em;
	}
	dl.switch {
	 padding-left: 2em;
	}
	dl.switch > dt {
	 text-indent: -1.5em;
	 margin-top: 1em;
	}
	dl.switch > dt + dt {
	 margin-top: 0;
	}
	dl.switch > dt::before {
	 content: '\21AA';
	 padding: 0 0.5em 0 0;
	 display: inline-block;
	 width: 1em;
	 text-align: right;
	 line-height: 0.5em;
	}

/** Terminology Markup ********************************************************/


/******************************************************************************/
/*                                 Inline Markup                              */
/******************************************************************************/

/** Terminology Markup ********************************************************/
	dfn   { /* Defining instance */
		font-weight: bolder;
	}
	a > i { /* Instance of term */
		font-style: normal;
	}
	dt dfn code, code.idl {
		font-size: medium;
	}
	dfn var {
		font-style: normal;
	}

/** Change Marking ************************************************************/

	del { color: red;  text-decoration: line-through; }
	ins { color: #080; text-decoration: underline;    }

/** Miscellaneous improvements to inline formatting ***************************/

	sup {
		vertical-align: super;
		font-size: 80%
	}

/******************************************************************************/
/*                                    Code                                    */
/******************************************************************************/

/** General monospace/pre rules ***********************************************/

	pre, code, samp {
		font-family: Menlo, Consolas, "DejaVu Sans Mono", Monaco, monospace;
		font-size: .9em;
		page-break-inside: avoid;
		hyphens: none;
		text-transform: none;
	}
	pre code,
	code code {
		font-size: 100%;
	}

	pre {
		margin-top: 1em;
		margin-bottom: 1em;
		overflow: auto;
	}

/** Inline Code fragments *****************************************************/

  /* Do something nice. */

/******************************************************************************/
/*                                    Links                                   */
/******************************************************************************/

/** General Hyperlinks ********************************************************/

	/* We hyperlink a lot, so make it less intrusive */
	a[href] {
		color: #034575;
		text-decoration: none;
		border-bottom: 1px solid #707070;
		/* Need a bit of extending for it to look okay */
		padding: 0 1px 0;
		margin: 0 -1px 0;
	}
	a:visited {
		border-bottom-color: #BBB;
	}

	/* Use distinguishing colors when user is interacting with the link */
	a[href]:focus,
	a[href]:hover {
		background: #f8f8f8;
		background: rgba(75%, 75%, 75%, .25);
		border-bottom-width: 3px;
		margin-bottom: -2px;
	}
	a[href]:active {
		color: #C00;
		border-color: #C00;
	}

	/* Backout above styling for W3C logo */
	.head .logo,
	.head .logo a {
		border: none;
		text-decoration: none;
		background: transparent;
	}

/******************************************************************************/
/*                                    Images                                  */
/******************************************************************************/

	img {
		border-style: none;
	}

	/* For autogen numbers, add
	   .caption::before, figcaption::before { content: "Figure " counter(figure) ". "; }
	*/

	figure, .figure, .sidefigure {
		page-break-inside: avoid;
		text-align: center;
		margin: 2.5em 0;
	}
	.figure img,    .sidefigure img,    figure img,
	.figure object, .sidefigure object, figure object {
		max-width: 100%;
		margin: auto;
	}
	.figure pre, .sidefigure pre, figure pre {
		text-align: left;
		display: table;
		margin: 1em auto;
	}
	.figure table, figure table {
		margin: auto;
	}
	@media screen and (min-width: 20em) {
		.sidefigure {
			float: right;
			width: 50%;
			margin: 0 0 0.5em 0.5em
		}
	}
	.caption, figcaption, caption {
		font-style: italic;
		font-size: 90%;
	}
	.caption::before, figcaption::before, figcaption > .marker {
		font-weight: bold;
	}
	.caption, figcaption {
		counter-increment: figure;
	}

	/* DL list is indented 2em, but figure inside it is not */
	dd > .figure, dd > figure { margin-left: -2em }

/******************************************************************************/
/*                             Colored Boxes                                  */
/******************************************************************************/

	.issue, .note, .example, .assertion, .advisement, blockquote {
		padding: .5em;
		border: .5em;
		border-left-style: solid;
		page-break-inside: avoid;
	}
	span.issue, span.note {
		padding: .1em .5em .15em;
		border-right-style: solid;
	}

	.issue,
	.note,
	.example,
	.advisement,
	.assertion,
	blockquote {
		margin: 1em auto;
	}
	.note  > p:first-child,
	.issue > p:first-child,
	blockquote > :first-child {
		margin-top: 0;
	}
	blockquote > :last-child {
		margin-bottom: 0;
	}

/** Blockquotes ***************************************************************/

	blockquote {
		border-color: silver;
	}

/** Open issue ****************************************************************/

	.issue {
		border-color: #E05252;
		background: #FBE9E9;
		counter-increment: issue;
		overflow: auto;
	}
	.issue::before, .issue > .marker {
		text-transform: uppercase;
		color: #AE1E1E;
		padding-right: 1em;
		text-transform: uppercase;
	}
	/* Add .issue::before { content: "Issue " counter(issue) " "; } for autogen numbers,
	   or use class="marker" to mark up the issue number in source. */

/** Example *******************************************************************/

	.example {
		border-color: #E0CB52;
		background: #FCFAEE;
		counter-increment: example;
		overflow: auto;
		clear: both;
	}
	.example::before, .example > .marker {
		text-transform: uppercase;
		color: #827017;
		min-width: 7.5em;
		display: block;
	}
	/* Add .example::before { content: "Example " counter(example) " "; } for autogen numbers,
	   or use class="marker" to mark up the example number in source. */

/** Non-normative Note ********************************************************/

	.note {
		border-color: #52E052;
		background: #E9FBE9;
		overflow: auto;
	}

	.note::before, .note > .marker,
	details.note > summary::before,
	details.note > summary > .marker {
		text-transform: uppercase;
		display: block;
		color: hsl(120, 70%, 30%);
	}
	/* Add .note::before { content: "Note"; } for autogen label,
	   or use class="marker" to mark up the label in source. */

	details.note > summary {
		display: block;
		color: hsl(120, 70%, 30%);
	}
	details.note[open] > summary {
		border-bottom: 1px silver solid;
	}

/** Assertion Box *************************************************************/
	/*  for assertions in algorithms */

	.assertion {
		border-color: #AAA;
		background: #EEE;
	}

/** Advisement Box ************************************************************/
	/*  for attention-grabbing normative statements */

	.advisement {
		border-color: orange;
		border-style: none solid;
		background: #FFEECC;
	}
	strong.advisement {
		display: block;
		text-align: center;
	}
	.advisement > .marker {
		color: #B35F00;
	}

/** Spec Obsoletion Notice ****************************************************/
	/* obnoxious obsoletion notice for older/abandoned specs. */

	details {
		display: block;
	}
	summary {
		font-weight: bolder;
	}

	.annoying-warning:not(details),
	details.annoying-warning:not([open]) > summary,
	details.annoying-warning[open] {
		background: #fdd;
		color: red;
		font-weight: bold;
		padding: .75em 1em;
		border: thick red;
		border-style: solid;
		border-radius: 1em;
	}
	.annoying-warning :last-child {
		margin-bottom: 0;
	}

@media not print {
	details.annoying-warning[open] {
		position: fixed;
		left: 1em;
		right: 1em;
		bottom: 1em;
		z-index: 1000;
	}
}

	details.annoying-warning:not([open]) > summary {
		text-align: center;
	}

/** Entity Definition Boxes ***************************************************/

	.def {
		padding: .5em 1em;
		background: #DEF;
		margin: 1.2em 0;
		border-left: 0.5em solid #8CCBF2;
	}

/******************************************************************************/
/*                                    Tables                                  */
/******************************************************************************/

	th, td {
		text-align: left;
		text-align: start;
	}

/** Property/Descriptor Definition Tables *************************************/

	table.def {
		/* inherits .def box styling, see above */
		width: 100%;
		border-spacing: 0;
	}

	table.def td,
	table.def th {
		padding: 0.5em;
		vertical-align: baseline;
		border-bottom: 1px solid #bbd7e9;
	}

	table.def > tbody > tr:last-child th,
	table.def > tbody > tr:last-child td {
		border-bottom: 0;
	}

	table.def th {
		font-style: italic;
		font-weight: normal;
		padding-left: 1em;
		width: 3em;
	}

	/* For when values are extra-complex and need formatting for readability */
	table td.pre {
		white-space: pre-wrap;
	}

	/* A footnote at the bottom of a def table */
	table.def           td.footnote {
		padding-top: 0.6em;
	}
	table.def           td.footnote::before {
		content: " ";
		display: block;
		height: 0.6em;
		width: 4em;
		border-top: thin solid;
	}

/** Data tables (and properly marked-up index tables) *************************/
	/*
		 <table class="data"> highlights structural relationships in a table
		 when correct markup is used (e.g. thead/tbody, th vs. td, scope attribute)

		 Use class="complex data" for particularly complicated tables --
		 (This will draw more lines: busier, but clearer.)

		 Use class="long" on table cells with paragraph-like contents
		 (This will adjust text alignment accordingly.)
		 Alternately use class="longlastcol" on tables, to have the last column assume "long".
	*/

	table {
		word-wrap: normal;
		overflow-wrap: normal;
		hyphens: manual;
	}

	table.data,
	table.index {
		margin: 1em auto;
		border-collapse: collapse;
		border: hidden;
		width: 100%;
	}
	table.data caption,
	table.index caption {
		max-width: 50em;
		margin: 0 auto 1em;
	}

	table.data td,  table.data th,
	table.index td, table.index th {
		padding: 0.5em 1em;
		border-width: 1px;
		border-color: silver;
		border-top-style: solid;
	}

	table.data thead td:empty {
		padding: 0;
		border: 0;
	}

	table.data  thead,
	table.index thead,
	table.data  tbody,
	table.index tbody {
		border-bottom: 2px solid;
	}

	table.data colgroup,
	table.index colgroup {
		border-left: 2px solid;
	}

	table.data  tbody th:first-child,
	table.index tbody th:first-child  {
		border-right: 2px solid;
		border-top: 1px solid silver;
		padding-right: 1em;
	}

	table.data th[colspan],
	table.data td[colspan] {
		text-align: center;
	}

	table.complex.data th,
	table.complex.data td {
		border: 1px solid silver;
		text-align: center;
	}

	table.data.longlastcol td:last-child,
	table.data td.long {
	 vertical-align: baseline;
	 text-align: left;
	}

	table.data img {
		vertical-align: middle;
	}


/*
Alternate table alignment rules

	table.data,
	table.index {
		text-align: center;
	}

	table.data  thead th[scope="row"],
	table.index thead th[scope="row"] {
		text-align: right;
	}

	table.data  tbody th:first-child,
	table.index tbody th:first-child  {
		text-align: right;
	}

Possible extra rowspan handling

	table.data  tbody th[rowspan]:not([rowspan='1']),
	table.index tbody th[rowspan]:not([rowspan='1']),
	table.data  tbody td[rowspan]:not([rowspan='1']),
	table.index tbody td[rowspan]:not([rowspan='1']) {
		border-left: 1px solid silver;
	}

	table.data  tbody th[rowspan]:first-child,
	table.index tbody th[rowspan]:first-child,
	table.data  tbody td[rowspan]:first-child,
	table.index tbody td[rowspan]:first-child{
		border-left: 0;
		border-right: 1px solid silver;
	}
*/

/******************************************************************************/
/*                                  Indices                                   */
/******************************************************************************/


/** Table of Contents *********************************************************/

	.toc a {
		/* More spacing; use padding to make it part of the click target. */
		padding-top: 0.1rem;
		/* Larger, more consistently-sized click target */
		display: block;
		/* Reverse color scheme */
		color: black;
		border-color: #3980B5;
		border-bottom-width: 3px !important;
		margin-bottom: 0px !important;
	}
	.toc a:visited {
		border-color: #054572;
	}
	.toc a:not(:focus):not(:hover) {
		/* Allow colors to cascade through from link styling */
		border-bottom-color: transparent;
	}

	.toc, .toc ol, .toc ul, .toc li {
		list-style: none; /* Numbers must be inlined into source */
		/* because generated content isn't search/selectable and markers can't do multilevel yet */
		margin:  0;
		padding: 0;
		line-height: 1.1rem; /* consistent spacing */
	}

	/* ToC not indented until third level, but font style & margins show hierarchy */
	.toc > li             { font-weight: bold;   }
	.toc > li li          { font-weight: normal; }
	.toc > li li li       { font-size:   95%;    }
	.toc > li li li li    { font-size:   90%;    }
	.toc > li li li li .secno { font-size: 85%; }
	.toc > li li li li li { font-size:   85%;    }
	.toc > li li li li li .secno { font-size: 100%; }

	/* @supports not (display:grid) { */
		.toc > li             { margin: 1.5rem 0;    }
		.toc > li li          { margin: 0.3rem 0;    }
		.toc > li li li       { margin-left: 2rem;   }

		/* Section numbers in a column of their own */
		.toc .secno {
			float: left;
			width: 4rem;
			white-space: nowrap;
		}

		.toc li {
			clear: both;
		}

		:not(li) > .toc              { margin-left:  5rem; }
		.toc .secno                  { margin-left: -5rem; }
		.toc > li li li .secno       { margin-left: -7rem; }
		.toc > li li li li .secno    { margin-left: -9rem; }
		.toc > li li li li li .secno { margin-left: -11rem; }

		/* Tighten up indentation in narrow ToCs */
		@media (max-width: 30em) {
			:not(li) > .toc              { margin-left:  4rem; }
			.toc .secno                  { margin-left: -4rem; }
			.toc > li li li              { margin-left:  1rem; }
			.toc > li li li .secno       { margin-left: -5rem; }
			.toc > li li li li .secno    { margin-left: -6rem; }
			.toc > li li li li li .secno { margin-left: -7rem; }
		}
	/* } */

	@supports (display:grid) and (display:contents) {
		/* Use #toc over .toc to override non-@supports rules. */
		#toc {
			display: grid;
			align-content: start;
			grid-template-columns: auto 1fr;
			grid-column-gap: 1rem;
			column-gap: 1rem;
			grid-row-gap: .6rem;
			row-gap: .6rem;
		}
		#toc h2 {
			grid-column: 1 / -1;
			margin-bottom: 0;
		}
		#toc ol,
		#toc li,
		#toc a {
			display: contents;
			/* Switch <a> to subgrid when supported */
		}
		#toc span {
			margin: 0;
		}
		#toc > .toc > li > a > span {
			/* The spans of the top-level list,
			   comprising the first items of each top-level section. */
			margin-top: 1.1rem;
		}
		#toc#toc .secno { /* Ugh, need more specificity to override base.css */
			grid-column: 1;
			width: auto;
			margin-left: 0;
		}
		#toc .content {
			grid-column: 2;
			width: auto;
			margin-right: 1rem;
		}
		#toc .content:hover {
			background: rgba(75%, 75%, 75%, .25);
			border-bottom: 3px solid #054572;
			margin-bottom: -3px;
		}
		#toc li li li .content {
			margin-left: 1rem;
		}
		#toc li li li li .content {
			margin-left: 2rem;
		}
	}


/** Index *********************************************************************/

	/* Index Lists: Layout */
	ul.index       { margin-left: 0; columns: 15em; text-indent: 1em hanging; }
	ul.index li    { margin-left: 0; list-style: none; break-inside: avoid; }
	ul.index li li { margin-left: 1em }
	ul.index dl    { margin-top: 0; }
	ul.index dt    { margin: .2em 0 .2em 20px;}
	ul.index dd    { margin: .2em 0 .2em 40px;}
	/* Index Lists: Typography */
	ul.index ul,
	ul.index dl { font-size: smaller; }
	@media not print {
		ul.index li span {
			white-space: nowrap;
			color: transparent; }
		ul.index li a:hover + span,
		ul.index li a:focus + span {
			color: #707070;
		}
	}

/** Index Tables *****************************************************/
	/* See also the data table styling section, which this effectively subclasses */

	table.index {
		font-size: small;
		border-collapse: collapse;
		border-spacing: 0;
		text-align: left;
		margin: 1em 0;
	}

	table.index td,
	table.index th {
		padding: 0.4em;
	}

	table.index tr:hover td:not([rowspan]),
	table.index tr:hover th:not([rowspan]) {
		background: #f7f8f9;
	}

	/* The link in the first column in the property table (formerly a TD) */
	table.index th:first-child a {
		font-weight: bold;
	}

/******************************************************************************/
/*                                    Print                                   */
/******************************************************************************/

	@media print {
		/* Pages have their own margins. */
		html {
			margin: 0;
		}
		/* Serif for print. */
		body {
			font-family: serif;
		}
	}
	@page {
		margin: 1.5cm 1.1cm;
	}

/******************************************************************************/
/*                                    Legacy                                  */
/******************************************************************************/

	/* This rule is inherited from past style sheets. No idea what it's for. */
	.hide { display: none }



/******************************************************************************/
/*                             Overflow Control                               */
/******************************************************************************/

	.figure .caption, .sidefigure .caption, figcaption {
		/* in case figure is overlarge, limit caption to 50em */
		max-width: 50rem;
		margin-left: auto;
		margin-right: auto;
	}
	.overlarge {
		/* Magic to create good table positioning:
		   "content column" is 50ems wide at max; less on smaller screens.
		   Extra space (after ToC + content) is empty on the right.

		   1. When table < content column, centers table in column.
		   2. When content < table < available, left-aligns.
		   3. When table > available, fills available + scroll bar.
		*/
		display: grid;
		grid-template-columns: minmax(0, 50em);
	}
	.overlarge > table {
		/* limit preferred width of table */
		max-width: 50em;
		margin-left: auto;
		margin-right: auto;
	}

	@media (min-width: 55em) {
		.overlarge {
			margin-right: calc(13px + 26.5rem - 50vw);
			max-width: none;
		}
	}
	@media screen and (min-width: 78em) {
		body:not(.toc-inline) .overlarge {
			/* 30.5em body padding 50em content area */
			margin-right: calc(40em - 50vw) !important;
		}
	}
	@media screen and (min-width: 90em) {
		body:not(.toc-inline) .overlarge {
			/* 4em html margin 30.5em body padding 50em content area */
			margin-right: calc(84.5em - 100vw) !important;
		}
	}

	@media not print {
		.overlarge {
			overflow-x: auto;
			/* See Lea Verou's explanation background-attachment:
			 * http://lea.verou.me/2012/04/background-attachment-local/
			 *
			background: top left  / 4em 100% linear-gradient(to right,  #ffffff, rgba(255, 255, 255, 0)) local,
			            top right / 4em 100% linear-gradient(to left, #ffffff, rgba(255, 255, 255, 0)) local,
			            top left  / 1em 100% linear-gradient(to right,  #c3c3c5, rgba(195, 195, 197, 0)) scroll,
			            top right / 1em 100% linear-gradient(to left, #c3c3c5, rgba(195, 195, 197, 0)) scroll,
			            white;
			background-repeat: no-repeat;
			*/
		}
	}
</style>
  <meta content="Bikeshed version 6cf40e14, updated Fri Aug 14 17:42:41 2020 -0700" name="generator">
  <link href="https://webmachinelearning.github.io/webnn/" rel="canonical">
<style>/* style-autolinks */

.css.css, .property.property, .descriptor.descriptor {
    color: #005a9c;
    font-size: inherit;
    font-family: inherit;
}
.css::before, .property::before, .descriptor::before {
    content: "‘";
}
.css::after, .property::after, .descriptor::after {
    content: "’";
}
.property, .descriptor {
    /* Don't wrap property and descriptor names */
    white-space: nowrap;
}
.type { /* CSS value <type> */
    font-style: italic;
}
pre .property::before, pre .property::after {
    content: "";
}
[data-link-type="property"]::before,
[data-link-type="propdesc"]::before,
[data-link-type="descriptor"]::before,
[data-link-type="value"]::before,
[data-link-type="function"]::before,
[data-link-type="at-rule"]::before,
[data-link-type="selector"]::before,
[data-link-type="maybe"]::before {
    content: "‘";
}
[data-link-type="property"]::after,
[data-link-type="propdesc"]::after,
[data-link-type="descriptor"]::after,
[data-link-type="value"]::after,
[data-link-type="function"]::after,
[data-link-type="at-rule"]::after,
[data-link-type="selector"]::after,
[data-link-type="maybe"]::after {
    content: "’";
}

[data-link-type].production::before,
[data-link-type].production::after,
.prod [data-link-type]::before,
.prod [data-link-type]::after {
    content: "";
}

[data-link-type=element],
[data-link-type=element-attr] {
    font-family: Menlo, Consolas, "DejaVu Sans Mono", monospace;
    font-size: .9em;
}
[data-link-type=element]::before { content: "<" }
[data-link-type=element]::after  { content: ">" }

[data-link-type=biblio] {
    white-space: pre;
}</style>
<style>/* style-counters */

body {
    counter-reset: example figure issue;
}
.issue {
    counter-increment: issue;
}
.issue:not(.no-marker)::before {
    content: "Issue " counter(issue);
}

.example {
    counter-increment: example;
}
.example:not(.no-marker)::before {
    content: "Example " counter(example);
}
.invalid.example:not(.no-marker)::before,
.illegal.example:not(.no-marker)::before {
    content: "Invalid Example" counter(example);
}

figcaption {
    counter-increment: figure;
}
figcaption:not(.no-marker)::before {
    content: "Figure " counter(figure) " ";
}</style>
<style>/* style-dfn-panel */

.dfn-panel {
    position: absolute;
    z-index: 35;
    height: auto;
    width: -webkit-fit-content;
    width: fit-content;
    max-width: 300px;
    max-height: 500px;
    overflow: auto;
    padding: 0.5em 0.75em;
    font: small Helvetica Neue, sans-serif, Droid Sans Fallback;
    background: #DDDDDD;
    color: black;
    border: outset 0.2em;
}
.dfn-panel:not(.on) { display: none; }
.dfn-panel * { margin: 0; padding: 0; text-indent: 0; }
.dfn-panel > b { display: block; }
.dfn-panel a { color: black; }
.dfn-panel a:not(:hover) { text-decoration: none !important; border-bottom: none !important; }
.dfn-panel > b + b { margin-top: 0.25em; }
.dfn-panel ul { padding: 0; }
.dfn-panel li { list-style: inside; }
.dfn-panel.activated {
    display: inline-block;
    position: fixed;
    left: .5em;
    bottom: 2em;
    margin: 0 auto;
    max-width: calc(100vw - 1.5em - .4em - .5em);
    max-height: 30vh;
}

.dfn-paneled { cursor: pointer; }
</style>
<style>/* style-md-lists */

/* This is a weird hack for me not yet following the commonmark spec
   regarding paragraph and lists. */
[data-md] > :first-child {
    margin-top: 0;
}
[data-md] > :last-child {
    margin-bottom: 0;
}</style>
<style>/* style-selflinks */

.heading, .issue, .note, .example, li, dt {
    position: relative;
}
a.self-link {
    position: absolute;
    top: 0;
    left: calc(-1 * (3.5rem - 26px));
    width: calc(3.5rem - 26px);
    height: 2em;
    text-align: center;
    border: none;
    transition: opacity .2s;
    opacity: .5;
}
a.self-link:hover {
    opacity: 1;
}
.heading > a.self-link {
    font-size: 83%;
}
li > a.self-link {
    left: calc(-1 * (3.5rem - 26px) - 2em);
}
dfn > a.self-link {
    top: auto;
    left: auto;
    opacity: 0;
    width: 1.5em;
    height: 1.5em;
    background: gray;
    color: white;
    font-style: normal;
    transition: opacity .2s, background-color .2s, color .2s;
}
dfn:hover > a.self-link {
    opacity: 1;
}
dfn > a.self-link:hover {
    color: black;
}

a.self-link::before            { content: "¶"; }
.heading > a.self-link::before { content: "§"; }
dfn > a.self-link::before      { content: "#"; }</style>
<style>/* style-syntax-highlighting */
pre.idl.highlight { color: #708090; }
.highlight:not(.idl) { background: hsl(24, 20%, 95%); }
code.highlight { padding: .1em; border-radius: .3em; }
pre.highlight, pre > code.highlight { display: block; padding: 1em; margin: .5em 0; overflow: auto; border-radius: 0; }
c-[a] { color: #990055 } /* Keyword.Declaration */
c-[b] { color: #990055 } /* Keyword.Type */
c-[c] { color: #708090 } /* Comment */
c-[d] { color: #708090 } /* Comment.Multiline */
c-[e] { color: #0077aa } /* Name.Attribute */
c-[f] { color: #669900 } /* Name.Tag */
c-[g] { color: #222222 } /* Name.Variable */
c-[k] { color: #990055 } /* Keyword */
c-[l] { color: #000000 } /* Literal */
c-[m] { color: #000000 } /* Literal.Number */
c-[n] { color: #0077aa } /* Name */
c-[o] { color: #999999 } /* Operator */
c-[p] { color: #999999 } /* Punctuation */
c-[s] { color: #a67f59 } /* Literal.String */
c-[t] { color: #a67f59 } /* Literal.String.Single */
c-[u] { color: #a67f59 } /* Literal.String.Double */
c-[cp] { color: #708090 } /* Comment.Preproc */
c-[c1] { color: #708090 } /* Comment.Single */
c-[cs] { color: #708090 } /* Comment.Special */
c-[kc] { color: #990055 } /* Keyword.Constant */
c-[kn] { color: #990055 } /* Keyword.Namespace */
c-[kp] { color: #990055 } /* Keyword.Pseudo */
c-[kr] { color: #990055 } /* Keyword.Reserved */
c-[ld] { color: #000000 } /* Literal.Date */
c-[nc] { color: #0077aa } /* Name.Class */
c-[no] { color: #0077aa } /* Name.Constant */
c-[nd] { color: #0077aa } /* Name.Decorator */
c-[ni] { color: #0077aa } /* Name.Entity */
c-[ne] { color: #0077aa } /* Name.Exception */
c-[nf] { color: #0077aa } /* Name.Function */
c-[nl] { color: #0077aa } /* Name.Label */
c-[nn] { color: #0077aa } /* Name.Namespace */
c-[py] { color: #0077aa } /* Name.Property */
c-[ow] { color: #999999 } /* Operator.Word */
c-[mb] { color: #000000 } /* Literal.Number.Bin */
c-[mf] { color: #000000 } /* Literal.Number.Float */
c-[mh] { color: #000000 } /* Literal.Number.Hex */
c-[mi] { color: #000000 } /* Literal.Number.Integer */
c-[mo] { color: #000000 } /* Literal.Number.Oct */
c-[sb] { color: #a67f59 } /* Literal.String.Backtick */
c-[sc] { color: #a67f59 } /* Literal.String.Char */
c-[sd] { color: #a67f59 } /* Literal.String.Doc */
c-[se] { color: #a67f59 } /* Literal.String.Escape */
c-[sh] { color: #a67f59 } /* Literal.String.Heredoc */
c-[si] { color: #a67f59 } /* Literal.String.Interpol */
c-[sx] { color: #a67f59 } /* Literal.String.Other */
c-[sr] { color: #a67f59 } /* Literal.String.Regex */
c-[ss] { color: #a67f59 } /* Literal.String.Symbol */
c-[vc] { color: #0077aa } /* Name.Variable.Class */
c-[vg] { color: #0077aa } /* Name.Variable.Global */
c-[vi] { color: #0077aa } /* Name.Variable.Instance */
c-[il] { color: #000000 } /* Literal.Number.Integer.Long */
</style>
 <body class="h-entry">
  <div class="head">
   <p data-fill-with="logo"><a class="logo" href="https://webmachinelearning.github.io/"> <img alt="Logo" height="100" src="https://webmachinelearning.github.io/webmachinelearning-logo.png" width="100"> </a> </p>
   <h1 class="p-name no-ref" id="title">Web Neural Network API</h1>
   <h2 class="no-num no-toc no-ref heading settled" id="subtitle"><span class="content">Draft Community Group Report, <time class="dt-updated" datetime="2020-08-16">16 August 2020</time></span></h2>
   <div data-fill-with="spec-metadata">
    <dl>
     <dt>This version:
     <dd><a class="u-url" href="https://webmachinelearning.github.io/webnn/">https://webmachinelearning.github.io/webnn/</a>
     <dt>Issue Tracking:
     <dd><a href="https://github.com/webmachinelearning/webnn/issues/">GitHub</a>
     <dt class="editor">Editors:
     <dd class="editor p-author h-card vcard" data-editor-id="68202"><span class="p-name fn">Ningxin Hu</span> (<a class="p-org org" href="https://intel.com">Intel Corporation</a>)
     <dd class="editor p-author h-card vcard" data-editor-id="120203"><span class="p-name fn">Chai Chaoweeraprasit</span> (<a class="p-org org" href="https://microsoft.com">Microsoft Corporation</a>)
     <dt>Explainer:
     <dd><a href="https://github.com/webmachinelearning/webnn/blob/master/explainer.md">explainer.md</a>
    </dl>
   </div>
   <div data-fill-with="warning"></div>
   <p class="copyright" data-fill-with="copyright"><a href="http://www.w3.org/Consortium/Legal/ipr-notice#Copyright">Copyright</a> © 2020 the Contributors to the Web Neural Network API Specification, published by the <a href="https://www.w3.org/community/webmachinelearning/">Machine Learning for the Web Community Group</a> under the <a href="https://www.w3.org/community/about/agreements/cla/">W3C Community Contributor License Agreement (CLA)</a>.
A human-readable <a href="http://www.w3.org/community/about/agreements/cla-deed/">summary</a> is available. </p>
   <hr title="Separator for header">
  </div>
  <div class="p-summary" data-fill-with="abstract">
   <h2 class="no-num no-toc no-ref heading settled" id="abstract"><span class="content">Abstract</span></h2>
   <p>This document describes a dedicated low-level API for neural network inference hardware acceleration.</p>
  </div>
  <div data-fill-with="at-risk"></div>
  <h2 class="no-num no-toc no-ref heading settled" id="status"><span class="content">Status of this document</span></h2>
  <div data-fill-with="status">
   <p> This specification was published by the <a href="https://www.w3.org/community/webmachinelearning/">Machine Learning for the Web Community Group</a>.
  It is not a W3C Standard nor is it on the W3C Standards Track.

  Please note that under the <a href="https://www.w3.org/community/about/agreements/cla/">W3C Community Contributor License Agreement (CLA)</a> there is a limited opt-out and other conditions apply.

  Learn more about <a href="http://www.w3.org/community/">W3C Community and Business Groups</a>. </p>
   <p></p>
  </div>
  <div data-fill-with="at-risk"></div>
  <nav data-fill-with="table-of-contents" id="toc">
   <h2 class="no-num no-toc no-ref" id="contents">Table of Contents</h2>
   <ol class="toc" role="directory">
    <li><a href="#intro"><span class="secno">1</span> <span class="content">Introduction</span></a>
    <li>
     <a href="#usecases"><span class="secno">2</span> <span class="content">Use cases</span></a>
     <ol class="toc">
      <li>
       <a href="#usecases-application"><span class="secno">2.1</span> <span class="content">Application Use Cases</span></a>
       <ol class="toc">
        <li><a href="#usecase-person-detection"><span class="secno">2.1.1</span> <span class="content">Person Detection</span></a>
        <li><a href="#usecase-segmentation"><span class="secno">2.1.2</span> <span class="content">Semantic Segmentation</span></a>
        <li><a href="#usecase-skeleton-detection"><span class="secno">2.1.3</span> <span class="content">Skeleton Detection</span></a>
        <li><a href="#usecase-face-recognition"><span class="secno">2.1.4</span> <span class="content">Face Recognition</span></a>
        <li><a href="#usecase-facial-landmarks"><span class="secno">2.1.5</span> <span class="content">Facial Landmark Detection</span></a>
        <li><a href="#usecase-style-transfer"><span class="secno">2.1.6</span> <span class="content">Style Transfer</span></a>
        <li><a href="#usecase-super-resolution"><span class="secno">2.1.7</span> <span class="content">Super Resolution</span></a>
        <li><a href="#usecase-image-captioning"><span class="secno">2.1.8</span> <span class="content">Image Captioning</span></a>
        <li><a href="#usecase-translation"><span class="secno">2.1.9</span> <span class="content">Machine Translation</span></a>
        <li><a href="#usecase-emotion-analysis"><span class="secno">2.1.10</span> <span class="content">Emotion Analysis</span></a>
        <li><a href="#usecase-video-summalization"><span class="secno">2.1.11</span> <span class="content">Video Summarization</span></a>
        <li><a href="#usecase-noise-suppression"><span class="secno">2.1.12</span> <span class="content">Noise Suppression</span></a>
       </ol>
      <li>
       <a href="#usecases-framework"><span class="secno">2.2</span> <span class="content">Framework Use Cases</span></a>
       <ol class="toc">
        <li><a href="#usecase-custom-layer"><span class="secno">2.2.1</span> <span class="content">Custom Layer</span></a>
        <li><a href="#usecase-network-concat"><span class="secno">2.2.2</span> <span class="content">Network Concatenation</span></a>
        <li><a href="#usecase-perf-adapt"><span class="secno">2.2.3</span> <span class="content">Performance Adaptation</span></a>
       </ol>
     </ol>
    <li>
     <a href="#api"><span class="secno">3</span> <span class="content">API</span></a>
     <ol class="toc">
      <li><a href="#api-navigator"><span class="secno">3.1</span> <span class="content">Navigator</span></a>
      <li><a href="#api-ml"><span class="secno">3.2</span> <span class="content">ML</span></a>
      <li><a href="#api-operanddescriptor"><span class="secno">3.3</span> <span class="content">OperandDescriptor</span></a>
      <li><a href="#api-operand"><span class="secno">3.4</span> <span class="content">Operand</span></a>
      <li>
       <a href="#api-neuralnetworkcontext"><span class="secno">3.5</span> <span class="content">NeuralNetworkContext</span></a>
       <ol class="toc">
        <li><a href="#api-neuralnetworkcontext-batchnorm"><span class="secno">3.5.1</span> <span class="content">batchNormalization</span></a>
        <li><a href="#api-neuralnetworkcontext-concat"><span class="secno">3.5.2</span> <span class="content">concat</span></a>
        <li><a href="#api-neuralnetworkcontext-conv2d"><span class="secno">3.5.3</span> <span class="content">conv2d</span></a>
        <li><a href="#api-neuralnetworkcontext-binary"><span class="secno">3.5.4</span> <span class="content">element-wise binary operations</span></a>
        <li><a href="#api-neuralnetworkcontext-unary"><span class="secno">3.5.5</span> <span class="content">element-wise unary operations</span></a>
        <li><a href="#api-neuralnetworkcontext-gemm"><span class="secno">3.5.6</span> <span class="content">gemm</span></a>
        <li><a href="#api-neuralnetworkcontext-gru"><span class="secno">3.5.7</span> <span class="content">gru</span></a>
        <li><a href="#api-neuralnetworkcontext-grucell"><span class="secno">3.5.8</span> <span class="content">gruCell</span></a>
        <li><a href="#api-neuralnetworkcontext-leakyrelu"><span class="secno">3.5.9</span> <span class="content">leakyRelu</span></a>
        <li><a href="#api-neuralnetworkcontext-matmul"><span class="secno">3.5.10</span> <span class="content">matmul</span></a>
        <li><a href="#api-neuralnetworkcontext-pool2d"><span class="secno">3.5.11</span> <span class="content">pooling operations</span></a>
        <li><a href="#api-neuralnetworkcontext-reduce"><span class="secno">3.5.12</span> <span class="content">reduction operations</span></a>
        <li><a href="#api-neuralnetworkcontext-relu"><span class="secno">3.5.13</span> <span class="content">relu</span></a>
        <li><a href="#api-neuralnetworkcontext-reshape"><span class="secno">3.5.14</span> <span class="content">reshape</span></a>
        <li><a href="#api-neuralnetworkcontext-slice"><span class="secno">3.5.15</span> <span class="content">slice</span></a>
        <li><a href="#api-neuralnetworkcontext-softmax"><span class="secno">3.5.16</span> <span class="content">softmax</span></a>
        <li><a href="#api-neuralnetworkcontext-squeeze"><span class="secno">3.5.17</span> <span class="content">squeeze</span></a>
        <li><a href="#api-neuralnetworkcontext-transpose"><span class="secno">3.5.18</span> <span class="content">transpose</span></a>
       </ol>
      <li><a href="#api-model"><span class="secno">3.6</span> <span class="content">Model</span></a>
      <li><a href="#api-compilation"><span class="secno">3.7</span> <span class="content">Compilation</span></a>
      <li><a href="#api-execution"><span class="secno">3.8</span> <span class="content">Execution</span></a>
     </ol>
    <li><a href="#examples"><span class="secno">4</span> <span class="content">Examples</span></a>
    <li><a href="#acknowledgements"><span class="secno">5</span> <span class="content">Acknowledgements</span></a>
    <li><a href="#conformance"><span class="secno"></span> <span class="content"> Conformance</span></a>
    <li>
     <a href="#index"><span class="secno"></span> <span class="content">Index</span></a>
     <ol class="toc">
      <li><a href="#index-defined-here"><span class="secno"></span> <span class="content">Terms defined by this specification</span></a>
      <li><a href="#index-defined-elsewhere"><span class="secno"></span> <span class="content">Terms defined by reference</span></a>
     </ol>
    <li>
     <a href="#references"><span class="secno"></span> <span class="content">References</span></a>
     <ol class="toc">
      <li><a href="#normative"><span class="secno"></span> <span class="content">Normative References</span></a>
      <li><a href="#informative"><span class="secno"></span> <span class="content">Informative References</span></a>
     </ol>
    <li><a href="#idl-index"><span class="secno"></span> <span class="content">IDL Index</span></a>
   </ol>
  </nav>
  <main>
   <h2 class="heading settled" data-level="1" id="intro"><span class="secno">1. </span><span class="content">Introduction</span><a class="self-link" href="#intro"></a></h2>
   <p>We’re working on this section. Meanwhile, please take a look at the <a href="https://github.com/webmachinelearning/webnn/blob/master/explainer.md">explainer</a>.</p>
   <h2 class="heading settled" data-level="2" id="usecases"><span class="secno">2. </span><span class="content">Use cases</span><a class="self-link" href="#usecases"></a></h2>
   <h3 class="heading settled" data-level="2.1" id="usecases-application"><span class="secno">2.1. </span><span class="content">Application Use Cases</span><a class="self-link" href="#usecases-application"></a></h3>
   <p>This section illustrates application-level use cases for neural network
inference hardware acceleration. All applications in those use cases can be
built on top of pre-trained deep neural network (DNN) models.</p>
   <h4 class="heading settled" data-level="2.1.1" id="usecase-person-detection"><span class="secno">2.1.1. </span><span class="content">Person Detection</span><a class="self-link" href="#usecase-person-detection"></a></h4>
   <p>A user opens a web-based video conferencing application, but she temporarily
leaves from her room. The application is watching whether she is in front of her
PC by using object detection (for example, using object detection approaches
such as <a data-link-type="biblio" href="#biblio-ssd">[SSD]</a> or <a data-link-type="biblio" href="#biblio-yolo">[YOLO]</a> that use a single DNN) to detect regions in a camera
input frame that include persons.</p>
   <p>When she comes back, the application automatically detects her and notifies
other online users that she is active now.</p>
   <h4 class="heading settled" data-level="2.1.2" id="usecase-segmentation"><span class="secno">2.1.2. </span><span class="content">Semantic Segmentation</span><a class="self-link" href="#usecase-segmentation"></a></h4>
   <p>A user joins a teleconference via a web-based video conferencing application at
her desk since no meeting room in her office is available. During the
teleconference, she does not wish that her room and people in the background are
visible. To protect the privacy of the other people and the surroundings, the
application runs a machine learning model such as <a data-link-type="biblio" href="#biblio-deeplabv3">[DeepLabv3+]</a> or <a data-link-type="biblio" href="#biblio-maskr-cnn">[MaskR-CNN]</a> to semantically split an image into segments and replaces
segments that represent other people and background with another picture.</p>
   <h4 class="heading settled" data-level="2.1.3" id="usecase-skeleton-detection"><span class="secno">2.1.3. </span><span class="content">Skeleton Detection</span><a class="self-link" href="#usecase-skeleton-detection"></a></h4>
   <p>A web-based video conferencing application tracks a pose of user’s skeleton by
running a machine learning model, which allows for real-time human pose
estimation, such as <a data-link-type="biblio" href="#biblio-posenet">[PoseNet]</a> to recognize her gesture and body language. When
she raises her hand, her microphone is automatically unmuted and she can start
speaking on the teleconference.</p>
   <h4 class="heading settled" data-level="2.1.4" id="usecase-face-recognition"><span class="secno">2.1.4. </span><span class="content">Face Recognition</span><a class="self-link" href="#usecase-face-recognition"></a></h4>
   <p>There are multiple people in the conference room and they join an online meeting
using a web-based video conferencing application. The application detects faces
of participants by using object detection (for example, using object detection
approaches such as <a data-link-type="biblio" href="#biblio-ssd">[SSD]</a>) and checks whether each face was present at the
previous meeting or not by running a machine learning model such as <a data-link-type="biblio" href="#biblio-facenet">[FaceNet]</a>,
which verifies whether two faces would be identical or not.</p>
   <h4 class="heading settled" data-level="2.1.5" id="usecase-facial-landmarks"><span class="secno">2.1.5. </span><span class="content">Facial Landmark Detection</span><a class="self-link" href="#usecase-facial-landmarks"></a></h4>
   <p>A user wants to find new glasses that beautifully fits her on an online glasses
store. The online store offers web-based try-on simulator that runs a machine
learning model such as Face Alignment Network <a data-link-type="biblio" href="#biblio-fan">[FAN]</a> to detect facial landmarks
like eyes, nose, mouth, etc. When she chooses a pair of glasses, the simulator
properly render the selected glasses on the detected position of eyes on her
facial image.</p>
   <h4 class="heading settled" data-level="2.1.6" id="usecase-style-transfer"><span class="secno">2.1.6. </span><span class="content">Style Transfer</span><a class="self-link" href="#usecase-style-transfer"></a></h4>
   <p>A user is looking for cosmetics on an online store and wondering which color may
fit her face. The online store shows sample facial makeup images of cosmetics,
and offers makeup simulator that runs a machine learning model like <a data-link-type="biblio" href="#biblio-contextualloss">[ContextualLoss]</a> or <a data-link-type="biblio" href="#biblio-pairedcyclegan">[PairedCycleGAN]</a> to transfer the makeup style of the
sample makeup image to her facial image. She can check how the selected makeup
looks like on her face by the simulator.</p>
   <h4 class="heading settled" data-level="2.1.7" id="usecase-super-resolution"><span class="secno">2.1.7. </span><span class="content">Super Resolution</span><a class="self-link" href="#usecase-super-resolution"></a></h4>
   <p>A web-based video conferencing is receiving a video stream from its peer, but
the resolution of the video becomes lower due to network congestion. To prevent
degradation of the perceived video quality, the application runs a machine
learning model for super-resolution such as <a data-link-type="biblio" href="#biblio-srgan">[SRGAN]</a> to generate
higher-resolution video frames.</p>
   <h4 class="heading settled" data-level="2.1.8" id="usecase-image-captioning"><span class="secno">2.1.8. </span><span class="content">Image Captioning</span><a class="self-link" href="#usecase-image-captioning"></a></h4>
   <p>For better accessibility, a web-based presentation application provides
automatic image captioning by running a machine learning model such as <a data-link-type="biblio" href="#biblio-im2txt">[im2txt]</a> which predicts explanatory words of the presentation slides.</p>
   <h4 class="heading settled" data-level="2.1.9" id="usecase-translation"><span class="secno">2.1.9. </span><span class="content">Machine Translation</span><a class="self-link" href="#usecase-translation"></a></h4>
   <p>Multiple people from various countries are talking via a web-based real-time
text chat application. The application translates their conversation by using a
machine learning model such as <a data-link-type="biblio" href="#biblio-gnmt">[GNMT]</a> or <a data-link-type="biblio" href="#biblio-opennmt">[OpenNMT]</a>, which translates every
text into different language.</p>
   <h4 class="heading settled" data-level="2.1.10" id="usecase-emotion-analysis"><span class="secno">2.1.10. </span><span class="content">Emotion Analysis</span><a class="self-link" href="#usecase-emotion-analysis"></a></h4>
   <p>A user is talking to her friend via a web-based real-time text chat application,
and she is wondering how the friend feels because she cannot see the friend’s
face. The application analyses the friend’s emotion by using a machine learning
model such as <a data-link-type="biblio" href="#biblio-deepmoji">[DeepMoji]</a>, which infers emotion from input texts, and displays
an emoji that represents the estimated emotion.</p>
   <h4 class="heading settled" data-level="2.1.11" id="usecase-video-summalization"><span class="secno">2.1.11. </span><span class="content">Video Summarization</span><a class="self-link" href="#usecase-video-summalization"></a></h4>
   <p>A web-based video conferencing application records received video streams, and
it needs to reduce recorded video data to be stored. The application generates
the short version of the recorded video by using a machine learning model for
video summarization such as <a data-link-type="biblio" href="#biblio-video-summarization-with-lstm">[Video-Summarization-with-LSTM]</a>.</p>
   <h4 class="heading settled" data-level="2.1.12" id="usecase-noise-suppression"><span class="secno">2.1.12. </span><span class="content">Noise Suppression</span><a class="self-link" href="#usecase-noise-suppression"></a></h4>
   <p>A web-based video conferencing application records received audio streams, but
usually the background noise is everywhere. The application leverages real-time 
noise suppression using Recurrent Neural Network such as <a data-link-type="biblio" href="#biblio-rnnoise">[RNNoise]</a> for 
suppressing background dynamic noise like baby cry or dog barking to improve 
audio experiences in video conferences.</p>
   <h3 class="heading settled" data-level="2.2" id="usecases-framework"><span class="secno">2.2. </span><span class="content">Framework Use Cases</span><a class="self-link" href="#usecases-framework"></a></h3>
   <p>This section collects framework-level use cases for a dedicated low-level API
for neural network inference hardware acceleration. It is expected that Machine
Learning frameworks will be key consumers of the Web Neural Network API (WebNN
API) and the low-level details exposed through the WebNN API are abstracted out
from typical web developers. However, it is also expected that web developers
with specific interest and competence in Machine Learning will want to interface
with the WebNN API directly instead of a higher-level ML framework.</p>
   <h4 class="heading settled" data-level="2.2.1" id="usecase-custom-layer"><span class="secno">2.2.1. </span><span class="content">Custom Layer</span><a class="self-link" href="#usecase-custom-layer"></a></h4>
   <p>A web application developer wants to run a DNN model on the WebNN API. However,
she has found that some of activation functions like <a data-link-type="biblio" href="#biblio-leakyrelu">[LeakyReLU]</a>, <a data-link-type="biblio" href="#biblio-elu">[ELU]</a>,
etc. are not included in the WebNN API. To address this issue, she constructs
custom layers of the additional activation functions on top of the WebNN API.
Note that the scope of custom layers may include convolution, normalization,
etc. as well as activation.</p>
   <h4 class="heading settled" data-level="2.2.2" id="usecase-network-concat"><span class="secno">2.2.2. </span><span class="content">Network Concatenation</span><a class="self-link" href="#usecase-network-concat"></a></h4>
   <p>A web application uses a DNN model, and its model data of upper convolutional
layers and lower fully-connected layers are stored in separate files, since
model data of the fully-connected layers are periodically updated due to fine
tuning at the server side.</p>
   <p>Therefore, the application downloads both partial model files at first and
concatenates them into a single model. When the model is updated, the
application downloads fine-tuned part of the model and replace only the
fully-connected layers with it.</p>
   <h4 class="heading settled" data-level="2.2.3" id="usecase-perf-adapt"><span class="secno">2.2.3. </span><span class="content">Performance Adaptation</span><a class="self-link" href="#usecase-perf-adapt"></a></h4>
   <p>A web application developer has a concern about performance of her DNN model on
mobile devices. She has confirmed that it may run too slow on mobile devices
which do not have GPU acceleration. To address this issue, her web application
refers to the WebNN API to confirm whether acceleration is available or not, so
that the application can display the warning for devices without acceleration.</p>
   <p>After several weeks, she has developed a tiny DNN model that can even run on
CPU. In order to accommodate CPU execution, she modifies the application
so that the application loads the tiny model in the case of CPU-only devices.</p>
   <h2 class="heading settled" data-level="3" id="api"><span class="secno">3. </span><span class="content">API</span><a class="self-link" href="#api"></a></h2>
   <h3 class="heading settled" data-level="3.1" id="api-navigator"><span class="secno">3.1. </span><span class="content">Navigator</span><a class="self-link" href="#api-navigator"></a></h3>
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="https://html.spec.whatwg.org/multipage/system-state.html#navigator" id="ref-for-navigator"><c- g>Navigator</c-></a> {
  <c- b>readonly</c-> <c- b>attribute</c-> <a class="n" data-link-type="idl-name" href="#ml" id="ref-for-ml"><c- n>ML</c-></a> <dfn class="idl-code" data-dfn-for="Navigator" data-dfn-type="attribute" data-export data-readonly data-type="ML" id="dom-navigator-ml"><code><c- g>ml</c-></code><a class="self-link" href="#dom-navigator-ml"></a></dfn>;
};
</pre>
   <h3 class="heading settled" data-level="3.2" id="api-ml"><span class="secno">3.2. </span><span class="content">ML</span><a class="self-link" href="#api-ml"></a></h3>
<pre class="idl highlight def"><c- b>interface</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="interface" data-export id="ml"><code><c- g>ML</c-></code></dfn> {
  <a class="n" data-link-type="idl-name" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext"><c- n>NeuralNetworkContext</c-></a> <dfn class="idl-code" data-dfn-for="ML" data-dfn-type="method" data-export data-lt="getNeuralNetworkContext()" id="dom-ml-getneuralnetworkcontext"><code><c- g>getNeuralNetworkContext</c-></code><a class="self-link" href="#dom-ml-getneuralnetworkcontext"></a></dfn>();
};
</pre>
   <h3 class="heading settled" data-level="3.3" id="api-operanddescriptor"><span class="secno">3.3. </span><span class="content">OperandDescriptor</span><a class="self-link" href="#api-operanddescriptor"></a></h3>
<pre class="idl highlight def"><c- b>enum</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="enum" data-export id="enumdef-operandlayout"><code><c- g>OperandLayout</c-></code></dfn> {
  <dfn class="idl-code" data-dfn-for="OperandLayout" data-dfn-type="enum-value" data-export id="dom-operandlayout-nchw"><code><c- s>"nchw"</c-></code><a class="self-link" href="#dom-operandlayout-nchw"></a></dfn>,
  <dfn class="idl-code" data-dfn-for="OperandLayout" data-dfn-type="enum-value" data-export id="dom-operandlayout-nhwc"><code><c- s>"nhwc"</c-></code><a class="self-link" href="#dom-operandlayout-nhwc"></a></dfn>
};

<c- b>enum</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="enum" data-export id="enumdef-operandtype"><code><c- g>OperandType</c-></code></dfn> {
  <dfn class="idl-code" data-dfn-for="OperandType" data-dfn-type="enum-value" data-export id="dom-operandtype-float32"><code><c- s>"float32"</c-></code><a class="self-link" href="#dom-operandtype-float32"></a></dfn>,
  <dfn class="idl-code" data-dfn-for="OperandType" data-dfn-type="enum-value" data-export id="dom-operandtype-float16"><code><c- s>"float16"</c-></code><a class="self-link" href="#dom-operandtype-float16"></a></dfn>,
  <dfn class="idl-code" data-dfn-for="OperandType" data-dfn-type="enum-value" data-export id="dom-operandtype-int32"><code><c- s>"int32"</c-></code><a class="self-link" href="#dom-operandtype-int32"></a></dfn>,
  <dfn class="idl-code" data-dfn-for="OperandType" data-dfn-type="enum-value" data-export id="dom-operandtype-uint32"><code><c- s>"uint32"</c-></code><a class="self-link" href="#dom-operandtype-uint32"></a></dfn>,
  <dfn class="idl-code" data-dfn-for="OperandType" data-dfn-type="enum-value" data-export id="dom-operandtype-tensor-float32"><code><c- s>"tensor-float32"</c-></code><a class="self-link" href="#dom-operandtype-tensor-float32"></a></dfn>,
  <dfn class="idl-code" data-dfn-for="OperandType" data-dfn-type="enum-value" data-export id="dom-operandtype-tensor-float16"><code><c- s>"tensor-float16"</c-></code><a class="self-link" href="#dom-operandtype-tensor-float16"></a></dfn>,
  <dfn class="idl-code" data-dfn-for="OperandType" data-dfn-type="enum-value" data-export id="dom-operandtype-tensor-int32"><code><c- s>"tensor-int32"</c-></code><a class="self-link" href="#dom-operandtype-tensor-int32"></a></dfn>,
  <dfn class="idl-code" data-dfn-for="OperandType" data-dfn-type="enum-value" data-export id="dom-operandtype-tensor-quant8-asymm"><code><c- s>"tensor-quant8-asymm"</c-></code><a class="self-link" href="#dom-operandtype-tensor-quant8-asymm"></a></dfn>
};

<c- b>dictionary</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="dictionary" data-export id="dictdef-operanddescriptor"><code><c- g>OperandDescriptor</c-></code></dfn> {
  // The operand type.
  <c- b>required</c-> <a class="n" data-link-type="idl-name" href="#enumdef-operandtype" id="ref-for-enumdef-operandtype"><c- n>OperandType</c-></a> <dfn class="idl-code" data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export data-type="OperandType " id="dom-operanddescriptor-type"><code><c- g>type</c-></code><a class="self-link" href="#dom-operanddescriptor-type"></a></dfn>;

  // The dimensions field is only required for tensor operands.
  // The negative value means an unknown dimension.
  <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export data-type="sequence<long> " id="dom-operanddescriptor-dimensions"><code><c- g>dimensions</c-></code><a class="self-link" href="#dom-operanddescriptor-dimensions"></a></dfn>;

  // The following two fields are only required for quantized operand.
  // scale: an non-negative floating point value
  // zeroPoint: an integer, in range [0, 255]
  // The real value is (value - zeroPoint) * scale
  <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float"><c- b>float</c-></a> <dfn class="idl-code" data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export data-type="float " id="dom-operanddescriptor-scale"><code><c- g>scale</c-></code><a class="self-link" href="#dom-operanddescriptor-scale"></a></dfn>;
  <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①"><c- b>long</c-></a> <dfn class="idl-code" data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export data-type="long " id="dom-operanddescriptor-zeropoint"><code><c- g>zeroPoint</c-></code><a class="self-link" href="#dom-operanddescriptor-zeropoint"></a></dfn>;
};
</pre>
   <h3 class="heading settled" data-level="3.4" id="api-operand"><span class="secno">3.4. </span><span class="content">Operand</span><a class="self-link" href="#api-operand"></a></h3>
<pre class="idl highlight def"><c- b>interface</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="interface" data-export id="operand"><code><c- g>Operand</c-></code></dfn> {};
</pre>
   <h3 class="heading settled" data-level="3.5" id="api-neuralnetworkcontext"><span class="secno">3.5. </span><span class="content">NeuralNetworkContext</span><a class="self-link" href="#api-neuralnetworkcontext"></a></h3>
   <p>The <code class="idl"><a data-link-type="idl" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①">NeuralNetworkContext</a></code> defines a set of operations derived from the first-wave models <a data-link-type="biblio" href="#biblio-models">[Models]</a> that address identified <a href="#usecases">§ 2 Use cases</a>.</p>
<pre class="idl highlight def"><c- b>typedef</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-double" id="ref-for-idl-double"><c- b>double</c-></a> <dfn class="dfn-paneled idl-code" data-dfn-type="typedef" data-export id="typedefdef-number"><code><c- g>number</c-></code></dfn>;

<c- b>dictionary</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="dictionary" data-export id="dictdef-namedoperand"><code><c- g>NamedOperand</c-></code></dfn> {
  <c- b>required</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString"><c- b>DOMString</c-></a> <dfn class="idl-code" data-dfn-for="NamedOperand" data-dfn-type="dict-member" data-export data-type="DOMString " id="dom-namedoperand-name"><code><c- g>name</c-></code><a class="self-link" href="#dom-namedoperand-name"></a></dfn>;
  <c- b>required</c-> <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NamedOperand" data-dfn-type="dict-member" data-export data-type="Operand " id="dom-namedoperand-operand"><code><c- g>operand</c-></code><a class="self-link" href="#dom-namedoperand-operand"></a></dfn>;
};

<c- b>interface</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="interface" data-export id="neuralnetworkcontext"><code><c- g>NeuralNetworkContext</c-></code></dfn> {
  // Create an Operand object that represents a model input.
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="input(name, desc)" id="dom-neuralnetworkcontext-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-input"></a></dfn>(<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString①"><c- b>DOMString</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/input(name, desc)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-input-name-desc-name"><code><c- g>name</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-input-name-desc-name"></a></dfn>, <a class="n" data-link-type="idl-name" href="#dictdef-operanddescriptor" id="ref-for-dictdef-operanddescriptor"><c- n>OperandDescriptor</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/input(name, desc)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-input-name-desc-desc"><code><c- g>desc</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-input-name-desc-desc"></a></dfn>);

  // Create an Operand object that represents a model constant.
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand②"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="constant(desc, value)" id="dom-neuralnetworkcontext-constant"><code><c- g>constant</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-constant"></a></dfn>(<a class="n" data-link-type="idl-name" href="#dictdef-operanddescriptor" id="ref-for-dictdef-operanddescriptor①"><c- n>OperandDescriptor</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/constant(desc, value)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-constant-desc-value-desc"><code><c- g>desc</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-constant-desc-value-desc"></a></dfn>, <a class="n" data-link-type="idl-name" href="https://heycam.github.io/webidl/#ArrayBufferView" id="ref-for-ArrayBufferView"><c- n>ArrayBufferView</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/constant(desc, value)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-constant-desc-value-value"><code><c- g>value</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-constant-desc-value-value"></a></dfn>);

  // Create a single-value tensor from the specified number of the specified type.
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand③"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="constant(value, type)|constant(value)" id="dom-neuralnetworkcontext-constant-value-type"><code><c- g>constant</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-constant-value-type"></a></dfn>(<a class="n" data-link-type="idl-name" href="#typedefdef-number" id="ref-for-typedefdef-number"><c- n>number</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/constant(value, type), NeuralNetworkContext/constant(value)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-constant-value-type-value"><code><c- g>value</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-constant-value-type-value"></a></dfn>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-operandtype" id="ref-for-enumdef-operandtype①"><c- n>OperandType</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/constant(value, type), NeuralNetworkContext/constant(value)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-constant-value-type-type"><code><c- g>type</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-constant-value-type-type"></a></dfn> = "float32");

  // Create a Model object by identifying output operands.
  <c- b>Promise</c->&lt;<a class="n" data-link-type="idl-name" href="#model" id="ref-for-model"><c- n>Model</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="createModel(outputs)" id="dom-neuralnetworkcontext-createmodel"><code><c- g>createModel</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-createmodel"></a></dfn>(<c- b>sequence</c->&lt;<a class="n" data-link-type="idl-name" href="#dictdef-namedoperand" id="ref-for-dictdef-namedoperand"><c- n>NamedOperand</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/createModel(outputs)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-createmodel-outputs-outputs"><code><c- g>outputs</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-createmodel-outputs-outputs"></a></dfn>);
};
</pre>
   <h4 class="heading settled" data-level="3.5.1" id="api-neuralnetworkcontext-batchnorm"><span class="secno">3.5.1. </span><span class="content">batchNormalization</span><a class="self-link" href="#api-neuralnetworkcontext-batchnorm"></a></h4>
    Normalize the tensor values across dimensions in a batch through a specialized <a href="https://en.wikipedia.org/wiki/Batch_normalization#Batch_Normalizing_Transform">transform</a> introduced in this <a href="https://arxiv.org/abs/1502.03167">paper</a>. The <em>mean</em> and <em>variance</em> tensors are previously calculated during model training pass. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext②"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand④"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="batchNormalization(input, mean, variance, scale, bias, axis, epsilon)|batchNormalization(input, mean, variance, scale, bias, axis)|batchNormalization(input, mean, variance, scale, bias)|batchNormalization(input, mean, variance, scale)|batchNormalization(input, mean, variance)" id="dom-neuralnetworkcontext-batchnormalization"><code><c- g>batchNormalization</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-batchnormalization"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑤"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑥"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"><code><c- g>mean</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑦"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"><code><c- g>variance</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"></a></dfn>, 
                             <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑧"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"><code><c- g>scale</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"></a></dfn>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑨"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"><code><c- g>bias</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"></a></dfn>, 
                             <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②"><c- b>long</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"><code><c- g>axis</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"></a></dfn> = 1, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float①"><c- b>float</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"><code><c- g>epsilon</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"></a></dfn> = 1e-5);
};
</pre>
   <div class="algorithm" data-algorithm="batchnorm">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>input</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⓪">Operand</a></code>. The input N-D tensor.</p>
     <li data-md>
      <p><em>mean</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①①">Operand</a></code>. The 1-D tensor of the batch mean values
whose length is equal to the size of the input dimension denoted by <em>axis</em>.</p>
     <li data-md>
      <p><em>variance</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①②">Operand</a></code>. The 1-D tensor of the batch variance values
whose length is equal to the size of the input dimension denoted by <em>axis</em>.</p>
     <li data-md>
      <p><em>scale</em>: an optional <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①③">Operand</a></code>. The 1-D tensor of the scaling values
whose length is equal to the size of the input dimension denoted by <em>axis</em>.</p>
     <li data-md>
      <p><em>bias</em>: an optional <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①④">Operand</a></code>. The 1-D tensor of the bias values
whose length is equal to the size of the input dimension denoted by <em>axis</em>.</p>
     <li data-md>
      <p><em>axis</em>: an optional <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long③">long</a></code>. The index for the feature dimension of the input shape for which
the normalizing batch is defined and that the mean and variance values are computed. 
When it’s not specified, the default value is 1.</p>
     <li data-md>
      <p><em>epsilon</em>: an optional <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float②">float</a></code>. The Epsilon value to prevent computational error due to divide-by-zero.
The default value is 0.00001 when not specified.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑤">Operand</a></code>. The batch normalized N-D tensor of the same shape as the input tensor.</p>
    <p>When <em>input</em> is a 4-D tensor of the "nchw" or "nhwc" layout, <em>axis</em> should be set to 1 or 3 respectively,
    to designate the feature dimension of the input tensor.</p>
    <div class="note" role="note">
      The behavior of this operation when the input tensor is 4-D of the "nchw" layout can be generically emulated from 
    the usage of other operations as follow. However, user agents typically have a more efficient implementation for it, 
    therefore its usage is encouraged from the performance standpoint. 
<pre class="highlight"><c- a>let</c-> shape <c- o>=</c-> <c- p>[</c-><c- mi>1</c-><c- p>,</c-><c- o>-</c-><c- mi>1</c-><c- p>,</c-><c- mi>1</c-><c- p>,</c-><c- mi>1</c-><c- p>];</c->
<c- k>return</c-> nn<c- p>.</c->add<c- p>(</c->
    nn<c- p>.</c->mul<c- p>(</c->
      nn<c- p>.</c->reshape<c- p>(</c->scale<c- p>,</c-> shape<c- p>),</c->
      nn<c- p>.</c->div<c- p>(</c->
        nn<c- p>.</c->sub<c- p>(</c->input<c- p>,</c-> reshape<c- p>(</c->mean<c- p>,</c-> shape<c- p>)),</c->
        nn<c- p>.</c->sqrt<c- p>(</c->nn<c- p>.</c->add<c- p>(</c->nn<c- p>.</c->reshape<c- p>(</c->variance<c- p>,</c-> shape<c- p>),</c-> nn<c- p>.</c->constant<c- p>(</c->epsilon<c- p>)))</c->
        <c- p>)</c->
      <c- p>),</c->
    nn<c- p>.</c->reshape<c- p>(</c->bias<c- p>,</c-> shape<c- p>)</c->
  <c- p>);</c->
</pre>
    </div>
   </div>
   <h4 class="heading settled" data-level="3.5.2" id="api-neuralnetworkcontext-concat"><span class="secno">3.5.2. </span><span class="content">concat</span><a class="self-link" href="#api-neuralnetworkcontext-concat"></a></h4>
    Concatenates the input tensors along a given axis. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext③"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⑥"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="concat(inputs, axis)" id="dom-neuralnetworkcontext-concat"><code><c- g>concat</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-concat"></a></dfn>(<c- b>sequence</c->&lt;<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⑦"><c- n>Operand</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/concat(inputs, axis)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-concat-inputs-axis-inputs"><code><c- g>inputs</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-concat-inputs-axis-inputs"></a></dfn>, <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long④"><c- b>long</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/concat(inputs, axis)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-concat-inputs-axis-axis"><code><c- g>axis</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-concat-inputs-axis-axis"></a></dfn>);
};
</pre>
   <div class="algorithm" data-algorithm="concat">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>inputs</em>: a sequence of <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑧">Operand</a></code>. All input tensors must have the
same shape, except for the size of the dimension to concatenate on.</p>
     <li data-md>
      <p><em>axis</em>: a <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long⑤">long</a></code>. The axis that the inputs concatenate along, with
the value in the interval [0, N) where N is the rank of all the
inputs.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑨">Operand</a></code>. The concatenated tensor of all the inputs along
    the <em>axis</em>. The output tensor has the same shape except on the dimension
    that all the inputs concatenated along. The size of that dimension is
    computed as the sum of all the input sizes of the same dimension.</p>
   </div>
   <h4 class="heading settled" data-level="3.5.3" id="api-neuralnetworkcontext-conv2d"><span class="secno">3.5.3. </span><span class="content">conv2d</span><a class="self-link" href="#api-neuralnetworkcontext-conv2d"></a></h4>
    Compute a 2-D convolution given 4-D input and filter tensors 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext④"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand②⓪"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="conv2d(input, filter, padding, strides, dilations, groups, layout)|conv2d(input, filter, padding, strides, dilations, groups)|conv2d(input, filter, padding, strides, dilations)|conv2d(input, filter, padding, strides)|conv2d(input, filter, padding)|conv2d(input, filter)" id="dom-neuralnetworkcontext-conv2d"><code><c- g>conv2d</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-conv2d"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand②①"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations, groups, layout), NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations, groups), NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations), NeuralNetworkContext/conv2d(input, filter, padding, strides), NeuralNetworkContext/conv2d(input, filter, padding), NeuralNetworkContext/conv2d(input, filter)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-input"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand②②"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations, groups, layout), NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations, groups), NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations), NeuralNetworkContext/conv2d(input, filter, padding, strides), NeuralNetworkContext/conv2d(input, filter, padding), NeuralNetworkContext/conv2d(input, filter)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-filter"><code><c- g>filter</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-filter"></a></dfn>,
                 <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long⑥"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations, groups, layout), NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations, groups), NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations), NeuralNetworkContext/conv2d(input, filter, padding, strides), NeuralNetworkContext/conv2d(input, filter, padding), NeuralNetworkContext/conv2d(input, filter)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-padding"><code><c- g>padding</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-padding"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long⑦"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations, groups, layout), NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations, groups), NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations), NeuralNetworkContext/conv2d(input, filter, padding, strides), NeuralNetworkContext/conv2d(input, filter, padding), NeuralNetworkContext/conv2d(input, filter)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-strides"><code><c- g>strides</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-strides"></a></dfn>, 
                 <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long⑧"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations, groups, layout), NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations, groups), NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations), NeuralNetworkContext/conv2d(input, filter, padding, strides), NeuralNetworkContext/conv2d(input, filter, padding), NeuralNetworkContext/conv2d(input, filter)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-dilations"><code><c- g>dilations</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-dilations"></a></dfn>, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long⑨"><c- b>long</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations, groups, layout), NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations, groups), NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations), NeuralNetworkContext/conv2d(input, filter, padding, strides), NeuralNetworkContext/conv2d(input, filter, padding), NeuralNetworkContext/conv2d(input, filter)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-groups"><code><c- g>groups</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-groups"></a></dfn> = 1,
                 <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-operandlayout" id="ref-for-enumdef-operandlayout"><c- n>OperandLayout</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations, groups, layout), NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations, groups), NeuralNetworkContext/conv2d(input, filter, padding, strides, dilations), NeuralNetworkContext/conv2d(input, filter, padding, strides), NeuralNetworkContext/conv2d(input, filter, padding), NeuralNetworkContext/conv2d(input, filter)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-layout"><code><c- g>layout</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-layout"></a></dfn> = "nchw");
};
</pre>
   <div class="algorithm" data-algorithm="conv2d">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>input</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand②③">Operand</a></code>. The input 4-D tensor. The logical shape
is interpreted according to the value of <em>layout</em>.</p>
     <li data-md>
      <p><em>filter</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand②④">Operand</a></code>. The filter 4-D tensor. The logical shape is
interpreted according to the value of <em>layout</em> and <em>groups</em>.</p>
     <li data-md>
      <p><em>padding</em>: an optional sequence of <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①⓪">long</a></code> of length 4. The padding for the
beginning and ending along each spatial dimension of <em>input</em>,
[beginning_height, ending_height, beginning_width, ending_width]. 
If not present, the values are assumed to be [0,0,0,0].</p>
     <li data-md>
      <p><em>strides</em>: an optional sequence of <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①①">long</a></code> of length 2. The stride of the
sliding window for each spatial dimension of <em>input</em>, [stride_height, stride_width]. 
If not present, the values are assumed to be [1,1].</p>
     <li data-md>
      <p><em>dilations</em>: an optional sequence of <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①②">long</a></code> of length 2. The dilation factor
for each spatial dimension of <em>input</em>, [dilation_height, dilation_width]. 
If not present, the values are assumed to be [1,1].</p>
     <li data-md>
      <p><em>groups</em>: an optional <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①③">long</a></code>. The number of groups that input
channels and output channels are divided into, default to 1.</p>
     <li data-md>
      <p><em>layout</em>: an optional <code class="idl"><a data-link-type="idl" href="#enumdef-operandlayout" id="ref-for-enumdef-operandlayout①">OperandLayout</a></code> with value as "nchw" or
"nhwc". The default value is "nchw". This argument specifies the
layout format of the input, output and filter tensor.
Specifically,</p>
      <p>"nchw":</p>
      <ul>
       <li data-md>
        <p>input tensor: [batches, input_channels, height, width]</p>
       <li data-md>
        <p>filter tensor: [output_channels, input_channels/groups,
height, width]</p>
       <li data-md>
        <p>output tensor: [batches, output_channels, height, width]</p>
      </ul>
      "nhwc": 
      <ul>
       <li data-md>
        <p>input tensor: [batches, height, width, input_channels]</p>
       <li data-md>
        <p>filter tensor: [height, width, input_channels/groups,
output_channels]</p>
       <li data-md>
        <p>output tensor: [batches, height, width, output_channels]</p>
      </ul>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand②⑤">Operand</a></code>. The output 4-D tensor that contains the
    result of the convolution. The logical shape is interpreted according to the
    value of <em>layout</em>.</p>
    <div class="note" role="note"> A <em>depthwise</em> conv2d operation is a variant of grouped conv2d, used in
    models like the MobileNet, where the <em>groups</em> = input_channels =
    output_channels and the shape of filter tensor is [groups, 1, height, width]
    for "nchw" layout or [height, width, 1, groups] for "nhwc" layout. </div>
   </div>
   <h4 class="heading settled" data-level="3.5.4" id="api-neuralnetworkcontext-binary"><span class="secno">3.5.4. </span><span class="content">element-wise binary operations</span><a class="self-link" href="#api-neuralnetworkcontext-binary"></a></h4>
    Compute the element-wise binary addition, subtraction, multiplication, division,
maximum and minimum of the two input tensors. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext⑤"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand②⑥"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="add(a, b)" id="dom-neuralnetworkcontext-add"><code><c- g>add</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-add"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand②⑦"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/add(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-add-a-b-a"><code><c- g>a</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-add-a-b-a"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand②⑧"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/add(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-add-a-b-b"><code><c- g>b</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-add-a-b-b"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand②⑨"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="sub(a, b)" id="dom-neuralnetworkcontext-sub"><code><c- g>sub</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-sub"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand③⓪"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/sub(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-sub-a-b-a"><code><c- g>a</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-sub-a-b-a"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand③①"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/sub(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-sub-a-b-b"><code><c- g>b</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-sub-a-b-b"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand③②"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="mul(a, b)" id="dom-neuralnetworkcontext-mul"><code><c- g>mul</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-mul"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand③③"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/mul(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-mul-a-b-a"><code><c- g>a</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-mul-a-b-a"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand③④"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/mul(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-mul-a-b-b"><code><c- g>b</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-mul-a-b-b"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand③⑤"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="div(a, b)" id="dom-neuralnetworkcontext-div"><code><c- g>div</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-div"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand③⑥"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/div(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-div-a-b-a"><code><c- g>a</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-div-a-b-a"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand③⑦"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/div(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-div-a-b-b"><code><c- g>b</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-div-a-b-b"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand③⑧"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="max(a, b)" id="dom-neuralnetworkcontext-max"><code><c- g>max</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-max"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand③⑨"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/max(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-max-a-b-a"><code><c- g>a</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-max-a-b-a"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand④⓪"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/max(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-max-a-b-b"><code><c- g>b</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-max-a-b-b"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand④①"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="min(a, b)" id="dom-neuralnetworkcontext-min"><code><c- g>min</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-min"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand④②"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/min(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-min-a-b-a"><code><c- g>a</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-min-a-b-a"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand④③"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/min(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-min-a-b-b"><code><c- g>b</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-min-a-b-b"></a></dfn>);
};
</pre>
   <div class="algorithm" data-algorithm="binary">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>a</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand④④">Operand</a></code>. The first input tensor.</p>
     <li data-md>
      <p><em>b</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand④⑤">Operand</a></code>. The second input tensor.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand④⑥">Operand</a></code>. The output tensor that contains the result of
    element-wise binary operation of the two input tensors.</p>
    <p>The element-wise binary operation will be broadcasted according to <a data-link-type="biblio" href="#biblio-numpy-broadcasting-rule">[numpy-broadcasting-rule]</a>. The rank of the output tensor is the maximum
    rank of the input tensors. For each dimension of the output tensor, its size
    is the maximum size along that dimension of the input tensors.</p>
   </div>
   <h4 class="heading settled" data-level="3.5.5" id="api-neuralnetworkcontext-unary"><span class="secno">3.5.5. </span><span class="content">element-wise unary operations</span><a class="self-link" href="#api-neuralnetworkcontext-unary"></a></h4>
    Compute the element-wise unary operation for input tensor. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext⑥"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand④⑦"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="abs(x)" id="dom-neuralnetworkcontext-abs"><code><c- g>abs</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-abs"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand④⑧"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/abs(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-abs-x-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-abs-x-x"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand④⑨"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="ceil(x)" id="dom-neuralnetworkcontext-ceil"><code><c- g>ceil</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-ceil"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑤⓪"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/ceil(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-ceil-x-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-ceil-x-x"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑤①"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="cos(x)" id="dom-neuralnetworkcontext-cos"><code><c- g>cos</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-cos"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑤②"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/cos(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-cos-x-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-cos-x-x"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑤③"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="exp(x)" id="dom-neuralnetworkcontext-exp"><code><c- g>exp</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-exp"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑤④"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/exp(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-exp-x-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-exp-x-x"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑤⑤"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="floor(x)" id="dom-neuralnetworkcontext-floor"><code><c- g>floor</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-floor"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑤⑥"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/floor(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-floor-x-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-floor-x-x"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑤⑦"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="log(x)" id="dom-neuralnetworkcontext-log"><code><c- g>log</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-log"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑤⑧"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/log(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-log-x-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-log-x-x"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑤⑨"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="neg(x)" id="dom-neuralnetworkcontext-neg"><code><c- g>neg</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-neg"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑥⓪"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/neg(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-neg-x-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-neg-x-x"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑥①"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="sigmoid(x)" id="dom-neuralnetworkcontext-sigmoid"><code><c- g>sigmoid</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-sigmoid"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑥②"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/sigmoid(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-sigmoid-x-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-sigmoid-x-x"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑥③"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="sin(x)" id="dom-neuralnetworkcontext-sin"><code><c- g>sin</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-sin"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑥④"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/sin(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-sin-x-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-sin-x-x"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑥⑤"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="sqrt(x)" id="dom-neuralnetworkcontext-sqrt"><code><c- g>sqrt</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-sqrt"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑥⑥"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/sqrt(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-sqrt-x-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-sqrt-x-x"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑥⑦"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="tan(x)" id="dom-neuralnetworkcontext-tan"><code><c- g>tan</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-tan"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑥⑧"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/tan(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-tan-x-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-tan-x-x"></a></dfn>);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑥⑨"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="tanh(x)" id="dom-neuralnetworkcontext-tanh"><code><c- g>tanh</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-tanh"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑦⓪"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/tanh(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-tanh-x-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-tanh-x-x"></a></dfn>);
};
</pre>
   <div class="algorithm" data-algorithm="unary">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>x</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand⑦①">Operand</a></code>. The input tensor.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand⑦②">Operand</a></code>. The output tensor that contains the result of
    element-wise unary operation of the input tensor. The shape of the output
    tensor is the same as the shape of input tensor.</p>
    <p><strong>Operation types:</strong></p>
    <ul>
     <li data-md>
      <p><em>abs</em>: Compute the absolute value of the input tensor, element-wise.</p>
     <li data-md>
      <p><em>ceil</em>: Compute the ceiling of the input tensor, element-wise.</p>
     <li data-md>
      <p><em>cos</em>: Compute the cosine of the input tensor, element-wise.</p>
     <li data-md>
      <p><em>exp</em>: Compute the exponential of the input tensor, element-wise.</p>
     <li data-md>
      <p><em>floor</em>: Compute the floor of the input tensor, element-wise.</p>
     <li data-md>
      <p><em>log</em>: Compute the natural logarithm of the input tensor, element-wise.</p>
     <li data-md>
      <p><em>neg</em>: Compute the numerical negative value of the input tensor, element-wise.</p>
     <li data-md>
      <p><em>sigmoid</em>: Compute the sigmoid function of the input tensor, element-wise.</p>
     <li data-md>
      <p><em>sin</em>: Compute the sine of the input tensor, element-wise.</p>
     <li data-md>
      <p><em>sqrt</em>: Compute the square root of the input tensor, element-wise.</p>
     <li data-md>
      <p><em>tan</em>: Compute the tangent of the input tensor, element-wise.</p>
     <li data-md>
      <p><em>tanh</em>: Compute the hyperbolic tangent of the input tensor, element-wise.</p>
    </ul>
   </div>
   <h4 class="heading settled" data-level="3.5.6" id="api-neuralnetworkcontext-gemm"><span class="secno">3.5.6. </span><span class="content">gemm</span><a class="self-link" href="#api-neuralnetworkcontext-gemm"></a></h4>
    Calculate the <a href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3">general matrixmultiplication of the Basic Liner Algebra Subprograms</a>. The calculation follows the expression <code>alpha * A * B + beta *C</code>, where <code>A</code>, <code>B</code>, and <code>C</code> are matrices, and <code>A</code> and <code>B</code> may optionally be transposed prior to the calculation. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext⑦"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑦③"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="gemm(a, b, c, alpha, beta, aTranspose, bTranspose)|gemm(a, b, c, alpha, beta, aTranspose)|gemm(a, b, c, alpha, beta)|gemm(a, b, c, alpha)|gemm(a, b, c)|gemm(a, b)" id="dom-neuralnetworkcontext-gemm"><code><c- g>gemm</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gemm"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑦④"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gemm(a, b, c, alpha, beta, aTranspose, bTranspose), NeuralNetworkContext/gemm(a, b, c, alpha, beta, aTranspose), NeuralNetworkContext/gemm(a, b, c, alpha, beta), NeuralNetworkContext/gemm(a, b, c, alpha), NeuralNetworkContext/gemm(a, b, c), NeuralNetworkContext/gemm(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-a"><code><c- g>a</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-a"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑦⑤"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gemm(a, b, c, alpha, beta, aTranspose, bTranspose), NeuralNetworkContext/gemm(a, b, c, alpha, beta, aTranspose), NeuralNetworkContext/gemm(a, b, c, alpha, beta), NeuralNetworkContext/gemm(a, b, c, alpha), NeuralNetworkContext/gemm(a, b, c), NeuralNetworkContext/gemm(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-b"><code><c- g>b</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-b"></a></dfn>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑦⑥"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gemm(a, b, c, alpha, beta, aTranspose, bTranspose), NeuralNetworkContext/gemm(a, b, c, alpha, beta, aTranspose), NeuralNetworkContext/gemm(a, b, c, alpha, beta), NeuralNetworkContext/gemm(a, b, c, alpha), NeuralNetworkContext/gemm(a, b, c), NeuralNetworkContext/gemm(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-c"><code><c- g>c</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-c"></a></dfn>, 
               <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float③"><c- b>float</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gemm(a, b, c, alpha, beta, aTranspose, bTranspose), NeuralNetworkContext/gemm(a, b, c, alpha, beta, aTranspose), NeuralNetworkContext/gemm(a, b, c, alpha, beta), NeuralNetworkContext/gemm(a, b, c, alpha), NeuralNetworkContext/gemm(a, b, c), NeuralNetworkContext/gemm(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-alpha"><code><c- g>alpha</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-alpha"></a></dfn> = 1.0, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float④"><c- b>float</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gemm(a, b, c, alpha, beta, aTranspose, bTranspose), NeuralNetworkContext/gemm(a, b, c, alpha, beta, aTranspose), NeuralNetworkContext/gemm(a, b, c, alpha, beta), NeuralNetworkContext/gemm(a, b, c, alpha), NeuralNetworkContext/gemm(a, b, c), NeuralNetworkContext/gemm(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-beta"><code><c- g>beta</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-beta"></a></dfn> = 1.0, 
               <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gemm(a, b, c, alpha, beta, aTranspose, bTranspose), NeuralNetworkContext/gemm(a, b, c, alpha, beta, aTranspose), NeuralNetworkContext/gemm(a, b, c, alpha, beta), NeuralNetworkContext/gemm(a, b, c, alpha), NeuralNetworkContext/gemm(a, b, c), NeuralNetworkContext/gemm(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-atranspose"><code><c- g>aTranspose</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-atranspose"></a></dfn> = <c- b>false</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean①"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gemm(a, b, c, alpha, beta, aTranspose, bTranspose), NeuralNetworkContext/gemm(a, b, c, alpha, beta, aTranspose), NeuralNetworkContext/gemm(a, b, c, alpha, beta), NeuralNetworkContext/gemm(a, b, c, alpha), NeuralNetworkContext/gemm(a, b, c), NeuralNetworkContext/gemm(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-btranspose"><code><c- g>bTranspose</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-btranspose"></a></dfn> = <c- b>false</c->);
};
</pre>
   <div class="algorithm" data-algorithm="gemm">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>a</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand⑦⑦">Operand</a></code>. The first input 2-D tensor.</p>
     <li data-md>
      <p><em>b</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand⑦⑧">Operand</a></code>. The second input 2-D tensor.</p>
     <li data-md>
      <p><em>c</em>: an optional <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand⑦⑨">Operand</a></code>. The third input 2-D tensor.</p>
     <li data-md>
      <p><em>alpha</em>: an optional <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float⑤">float</a></code> scalar multiplier for the first input, default to 1.0.</p>
     <li data-md>
      <p><em>beta</em>: an optional <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float⑥">float</a></code> scalar multiplier for the third input, default to 1.0.</p>
     <li data-md>
      <p><em>aTranspose</em>: an optional <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean②">boolean</a></code> indicating if the first input should be transposed prior to calculating the output, default to false.</p>
     <li data-md>
      <p><em>bTranspose</em>: an optional <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean③">boolean</a></code> indicating if the second input should be transposed prior to calculating the output, default to false.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand⑧⓪">Operand</a></code>. The output 2-D tensor that contains the calculated product of all the inputs.</p>
    <div class="note" role="note">
      The behavior of this operation can be generically emulated from the usage of other operations as follow. However, user agents typically have a more efficient implementation for it, therefore its usage is encouraged from the performance standpoint. 
<pre class="highlight"><c- k>if</c-> <c- p>(</c->aTranspose<c- p>)</c->
  a <c- o>=</c-> nn<c- p>.</c->transpose<c- p>(</c->a<c- p>);</c->

<c- k>if</c-> <c- p>(</c->bTranspose<c- p>)</c->
  b <c- o>=</c-> nn<c- p>.</c->transpose<c- p>(</c->b<c- p>);</c->

<c- a>let</c-> ab <c- o>=</c-> nn<c- p>.</c->matmul<c- p>(</c->nn<c- p>.</c->mul<c- p>(</c->nn<c- p>.</c->constant<c- p>(</c->alpha<c- p>),</c-> a<c- p>),</c-> b<c- p>);</c->
<c- k>return</c-> <c- p>(</c->c <c- o>?</c-> nn<c- p>.</c->add<c- p>(</c->ab<c- p>,</c-> nn<c- p>.</c->mul<c- p>(</c->nn<c- p>.</c->constant<c- p>(</c->beta<c- p>),</c-> c<c- p>))</c-> <c- o>:</c-> ab<c- p>);</c->
</pre>
    </div>
   </div>
   <h4 class="heading settled" data-level="3.5.7" id="api-neuralnetworkcontext-gru"><span class="secno">3.5.7. </span><span class="content">gru</span><a class="self-link" href="#api-neuralnetworkcontext-gru"></a></h4>
    Gated Recurrent Unit (GRU) recurrent network using an update gate and a reset gate to compute the hidden state that rolls into the output across the temporal sequence of the network, as outlined in this <a href="https://arxiv.org/pdf/1406.1078.pdf">paper</a>. 
<pre class="idl highlight def"><c- b>enum</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="enum" data-export id="enumdef-recurrentnetworkdirection"><code><c- g>RecurrentNetworkDirection</c-></code></dfn> {
  <dfn class="idl-code" data-dfn-for="RecurrentNetworkDirection" data-dfn-type="enum-value" data-export id="dom-recurrentnetworkdirection-forward"><code><c- s>"forward"</c-></code><a class="self-link" href="#dom-recurrentnetworkdirection-forward"></a></dfn>,
  <dfn class="idl-code" data-dfn-for="RecurrentNetworkDirection" data-dfn-type="enum-value" data-export id="dom-recurrentnetworkdirection-backward"><code><c- s>"backward"</c-></code><a class="self-link" href="#dom-recurrentnetworkdirection-backward"></a></dfn>,
  <dfn class="idl-code" data-dfn-for="RecurrentNetworkDirection" data-dfn-type="enum-value" data-export id="dom-recurrentnetworkdirection-both"><code><c- s>"both"</c-></code><a class="self-link" href="#dom-recurrentnetworkdirection-both"></a></dfn>
};

<c- b>enum</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="enum" data-export id="enumdef-recurrentnetworkweightlayout"><code><c- g>RecurrentNetworkWeightLayout</c-></code></dfn> {
  <dfn class="idl-code" data-dfn-for="RecurrentNetworkWeightLayout" data-dfn-type="enum-value" data-export id="dom-recurrentnetworkweightlayout-zrn"><code><c- s>"zrn"</c-></code><a class="self-link" href="#dom-recurrentnetworkweightlayout-zrn"></a></dfn>,  // update-reset-new gate ordering
  <dfn class="idl-code" data-dfn-for="RecurrentNetworkWeightLayout" data-dfn-type="enum-value" data-export id="dom-recurrentnetworkweightlayout-rzn"><code><c- s>"rzn"</c-></code><a class="self-link" href="#dom-recurrentnetworkweightlayout-rzn"></a></dfn>   // reset-update-new gate ordering
};

<c- b>enum</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="enum" data-export id="enumdef-recurrentnetworkactivation"><code><c- g>RecurrentNetworkActivation</c-></code></dfn> {
  <dfn class="idl-code" data-dfn-for="RecurrentNetworkActivation" data-dfn-type="enum-value" data-export id="dom-recurrentnetworkactivation-relu"><code><c- s>"relu"</c-></code><a class="self-link" href="#dom-recurrentnetworkactivation-relu"></a></dfn>,
  <dfn class="idl-code" data-dfn-for="RecurrentNetworkActivation" data-dfn-type="enum-value" data-export id="dom-recurrentnetworkactivation-sigmoid"><code><c- s>"sigmoid"</c-></code><a class="self-link" href="#dom-recurrentnetworkactivation-sigmoid"></a></dfn>,
  <dfn class="idl-code" data-dfn-for="RecurrentNetworkActivation" data-dfn-type="enum-value" data-export id="dom-recurrentnetworkactivation-tanh"><code><c- s>"tanh"</c-></code><a class="self-link" href="#dom-recurrentnetworkactivation-tanh"></a></dfn>
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext⑧"><c- g>NeuralNetworkContext</c-></a> {
  <c- b>sequence</c->&lt;<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑧①"><c- n>Operand</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations)|gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout)|gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction)|gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence)|gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter)|gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias)|gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias)|gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)" id="dom-neuralnetworkcontext-gru"><code><c- g>gru</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gru"></a></dfn>(<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①④"><c- b>long</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-hiddensize"><code><c- g>hiddenSize</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-hiddensize"></a></dfn>, <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①⑤"><c- b>long</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-steps"><code><c- g>steps</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-steps"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑧②"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-input"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑧③"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-weight"><code><c- g>weight</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-weight"></a></dfn>, 
                        <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑧④"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-recurrentweight"><code><c- g>recurrentWeight</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-recurrentweight"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑧⑤"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-initialhidden"><code><c- g>initialHidden</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-initialhidden"></a></dfn>,
                        <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑧⑥"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-bias"><code><c- g>bias</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-bias"></a></dfn>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑧⑦"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-recurrentbias"><code><c- g>recurrentBias</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-recurrentbias"></a></dfn>,
                        <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean④"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-resetafter"><code><c- g>resetAfter</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-resetafter"></a></dfn> = <c- b>true</c->,
                        <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean⑤"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-returnsequence"><code><c- g>returnSequence</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-returnsequence"></a></dfn> = <c- b>false</c->,
                        <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-recurrentnetworkdirection" id="ref-for-enumdef-recurrentnetworkdirection"><c- n>RecurrentNetworkDirection</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-direction"><code><c- g>direction</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-direction"></a></dfn> = "forward",
                        <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-recurrentnetworkweightlayout" id="ref-for-enumdef-recurrentnetworkweightlayout"><c- n>RecurrentNetworkWeightLayout</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-layout"><code><c- g>layout</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-layout"></a></dfn> = "zrn",
                        <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="n" data-link-type="idl-name" href="#enumdef-recurrentnetworkactivation" id="ref-for-enumdef-recurrentnetworkactivation"><c- n>RecurrentNetworkActivation</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias), NeuralNetworkContext/gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-activations"><code><c- g>activations</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-activations"></a></dfn>);
};
</pre>
   <div class="algorithm" data-algorithm="gru">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>hiddenSize</em>: a <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①⑥">long</a></code> scalar. The value of the third dimension of the cell output tensor shape. It indicates the number of features in the hidden state.</p>
     <li data-md>
      <p><em>steps</em>: a <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①⑦">long</a></code> scalar. The number of time steps in the recurrent network.</p>
     <li data-md>
      <p><em>input</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand⑧⑧">Operand</a></code>. The input 3-D tensor of shape [steps, batch_size, input_size].</p>
     <li data-md>
      <p><em>weight</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand⑧⑨">Operand</a></code>. The 3-D input weight tensor of shape [num_directions, 3 * hidden_size, input_size]. The ordering of the weight vectors in the second dimension of the tensor shape is specified according to the <em>layout</em> argument.</p>
     <li data-md>
      <p><em>recurrentWeight</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand⑨⓪">Operand</a></code>. The 3-D recurrent weight tensor of shape [num_directions, 3 * hidden_size, hidden_size]. The ordering of the weight vectors in the second dimension of the tensor shape is specified according to the <em>layout</em> argument.</p>
     <li data-md>
      <p><em>initialHidden</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand⑨①">Operand</a></code>. The 3-D initial hidden state tensor of shape [num_directions, batch_size, hidden_size].</p>
     <li data-md>
      <p><em>bias</em>: an optional <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand⑨②">Operand</a></code>. The 2-D input bias tensor of shape [num_directions, 3 * hidden_size]. The ordering of the bias vectors in the second dimension of the tensor shape is specified according to the <em>layout</em> argument.</p>
     <li data-md>
      <p><em>recurrentBias</em>: an optional <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand⑨③">Operand</a></code>. The 2-D recurrent bias tensor of shape [num_directions, 3 * hidden_size]. The ordering of the bias vectors in the second dimension of the tensor shape is specified according to the <em>layout</em> argument.</p>
     <li data-md>
      <p><em>resetAfter</em>: an optional <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean⑥">boolean</a></code> indicating whether to apply the reset gate after or before matrix multilication. Default to true.</p>
     <li data-md>
      <p><em>returnSequence</em>: an optional <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean⑦">boolean</a></code> indicating whether to also return the entire sequence with every cell outputs from each time step in it in addition to the cell output of the last time step. Default to false.</p>
     <li data-md>
      <p><em>direction</em>: an optional <code class="idl"><a data-link-type="idl" href="#enumdef-recurrentnetworkdirection" id="ref-for-enumdef-recurrentnetworkdirection①">RecurrentNetworkDirection</a></code>. The processing direction of the input sequence. When set to <em>"both"</em>, the size of the first dimension of the weight and the bias tensor shapes must be 2, and the input is processed in both directions.</p>
     <li data-md>
      <p><em>layout</em>: an optional <code class="idl"><a data-link-type="idl" href="#enumdef-recurrentnetworkweightlayout" id="ref-for-enumdef-recurrentnetworkweightlayout①">RecurrentNetworkWeightLayout</a></code>. The ordering of the weight and bias vectors for the internal gates of GRU, specifically the <em>update (z)</em>, <em>reset (r)</em>, and <em>new (n)</em> gate, as indicated in the second dimension of the weight and bias tensor shape. When not specified, the default layout is <em>"zrn"</em>.</p>
     <li data-md>
      <p><em>activations</em>: an optional sequence of <code class="idl"><a data-link-type="idl" href="#enumdef-recurrentnetworkactivation" id="ref-for-enumdef-recurrentnetworkactivation①">RecurrentNetworkActivation</a></code>. A pair of activation functions with the first function used for the update and reset gate, and the second used for the new gate. When not specified, it’s default to the sigmoid ("sigmoid") and the hyperbolic tangent ("tanh") function respectively.</p>
    </ul>
    <p><strong>Returns:</strong> a sequence of <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand⑨④">Operand</a></code>. The first element of the sequence is a 3-D tensor of shape [num_directions, batch_size, hidden_size], the cell output from the last time step of the network. Additionally, if <em>returnSequence</em> is set to true, the second element is the 4-D output tensor of shape [steps, num_directions, batch_size, hidden_size] containing every cell outputs from each time step in the temporal sequence.</p>
    <div class="note" role="note">
      The behavior of this operation with default argument values can be generically emulated from the usage of other operations as follow. However, user agents typically have a more efficient implementation for it, therefore its usage is encouraged from the performance standpoint. 
<pre class="highlight"><c- a>let</c-> hidden <c- o>=</c-> initialHidden<c- p>;</c->
<c- a>let</c-> slots <c- o>=</c-> <c- p>(</c->direction <c- o>==</c-> <c- u>"both"</c-> <c- o>?</c-> <c- mi>2</c-> <c- o>:</c-> <c- mi>1</c-><c- p>);</c->
<c- a>let</c-> sequence <c- o>=</c-> <c- kc>null</c-><c- p>;</c->

<c- a>let</c-> cellWeight <c- o>=</c-> <c- p>[];</c->
<c- a>let</c-> cellRecurrentWeight <c- o>=</c-> <c- p>[];</c->
<c- a>let</c-> cellBias <c- o>=</c-> <c- p>[];</c->
<c- a>let</c-> cellRecurrentBias <c- o>=</c-> <c- p>[];</c->

<c- k>for</c-> <c- p>(</c-><c- a>let</c-> slot <c- o>=</c-> <c- mi>0</c-><c- p>;</c-> slot <c- o>&lt;</c-> slots<c- p>;</c-> <c- o>++</c->slot<c- p>)</c-> <c- p>{</c->
  cellWeight<c- p>.</c->push<c- p>(</c->nn<c- p>.</c->squeeze<c- p>(</c->nn<c- p>.</c->slice<c- p>(</c->weight<c- p>,</c-> <c- p>[</c->slot<c- p>,</c-> <c- mi>0</c-><c- p>,</c-> <c- mi>0</c-><c- p>],</c-> <c- p>[</c->slot <c- o>+</c-> <c- mi>1</c-><c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>])),</c-> <c- p>[</c-><c- mi>0</c-><c- p>]);</c->
  cellRecurrentWeight<c- p>.</c->push<c- p>(</c->nn<c- p>.</c->squeeze<c- p>(</c->nn<c- p>.</c->slice<c- p>(</c->recurrentWeight<c- p>,</c-> <c- p>[</c->slot<c- p>,</c-> <c- mi>0</c-><c- p>,</c-> <c- mi>0</c-><c- p>],</c-> <c- p>[</c->slot <c- o>+</c-> <c- mi>1</c-><c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>])),</c-> <c- p>[</c-><c- mi>0</c-><c- p>]);</c->
  cellBias<c- p>.</c->push<c- p>(</c->bias <c- o>?</c-> <c- p>(</c->nn<c- p>.</c->squeeze<c- p>(</c->nn<c- p>.</c->slice<c- p>(</c->bias<c- p>,</c-> <c- p>[</c->slot<c- p>,</c-> <c- mi>0</c-><c- p>],</c-> <c- p>[</c->slot <c- o>+</c-> <c- mi>1</c-><c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>]),</c-> <c- p>[</c-><c- mi>0</c-><c- p>]))</c-> <c- o>:</c-> <c- kc>null</c-><c- p>);</c->
  cellRecurrentBias<c- p>.</c->push<c- p>(</c->recurrentBias <c- o>?</c-> <c- p>(</c->nn<c- p>.</c->squeeze<c- p>(</c->nn<c- p>.</c->slice<c- p>(</c->recurrentBias<c- p>,</c-> <c- p>[</c->slot<c- p>,</c-> <c- mi>0</c-><c- p>],</c-> <c- p>[</c->slot <c- o>+</c-> <c- mi>1</c-><c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>]),</c-> <c- p>[</c-><c- mi>0</c-><c- p>]))</c-> <c- o>:</c-> <c- kc>null</c-><c- p>);</c->
<c- p>}</c->

<c- k>for</c-> <c- p>(</c-><c- a>let</c-> step <c- o>=</c-> <c- mi>0</c-><c- p>;</c-> step <c- o>&lt;</c-> steps<c- p>;</c-> <c- o>++</c->step<c- p>)</c-> <c- p>{</c->
  <c- a>let</c-> cellHidden <c- o>=</c-> <c- p>[];</c->
  <c- a>let</c-> cellOutput <c- o>=</c-> <c- kc>null</c-><c- p>;</c->

  <c- k>for</c-> <c- p>(</c-><c- a>let</c-> slot <c- o>=</c-> <c- mi>0</c-><c- p>;</c-> slot <c- o>&lt;</c-> slots<c- p>;</c-> <c- o>++</c->slot<c- p>)</c-> <c- p>{</c->
    cellHidden<c- p>.</c->push<c- p>(</c->nn<c- p>.</c->squeeze<c- p>(</c->nn<c- p>.</c->slice<c- p>(</c->hidden<c- p>,</c-> <c- p>[</c->slot<c- p>,</c-> <c- mi>0</c-><c- p>,</c-> <c- mi>0</c-><c- p>],</c-> <c- p>[</c->slot <c- o>+</c-> <c- mi>1</c-><c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>]),</c-> <c- p>[</c-><c- mi>0</c-><c- p>]));</c->
  <c- p>}</c->

  <c- k>for</c-> <c- p>(</c-><c- a>let</c-> slot <c- o>=</c-> <c- mi>0</c-><c- p>;</c-> slot <c- o>&lt;</c-> slots<c- p>;</c-> <c- o>++</c->slot<c- p>)</c-> <c- p>{</c->
    <c- a>let</c-> slice <c- o>=</c-> <c- p>(</c->slot <c- o>==</c-> <c- mi>1</c-> <c- o>||</c-> direction <c- o>==</c-> <c- u>"backward"</c-> <c- o>?</c-> steps <c- o>-</c-> step <c- o>-</c-> <c- mi>1</c-> <c- o>:</c-> step<c- p>);</c->
    <c- a>let</c-> cellInput <c- o>=</c-> nn<c- p>.</c->squeeze<c- p>(</c->nn<c- p>.</c->slice<c- p>(</c->input<c- p>,</c-> <c- p>[</c->slice<c- p>,</c-> <c- mi>0</c-><c- p>,</c-> <c- mi>0</c-><c- p>],</c-> <c- p>[</c->slice <c- o>+</c-> <c- mi>1</c-><c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>]),</c-> <c- p>[</c-><c- mi>0</c-><c- p>]);</c->

    <c- a>let</c-> result <c- o>=</c-> nn<c- p>.</c->gruCell<c- p>(</c->
      hiddenSize<c- p>,</c-> cellInput<c- p>,</c-> cellWeight<c- p>[</c->slot<c- p>],</c-> cellRecurrentWeight<c- p>[</c->slot<c- p>],</c->
      cellHidden<c- p>[</c->slot<c- p>],</c-> cellBias<c- p>[</c->slot<c- p>],</c-> cellRecurrentBias<c- p>[</c->slot<c- p>],</c-> 
      resetAfter<c- p>,</c-> layout<c- p>,</c-> activations<c- p>);</c->

    cellOutput <c- o>=</c-> <c- p>(</c->cellOutput <c- o>?</c-> nn<c- p>.</c->concat<c- p>([</c->cellOutput<c- p>,</c-> result<c- p>],</c-> <c- mi>0</c-><c- p>)</c-> <c- o>:</c-> result<c- p>);</c->
  <c- p>}</c->

  hidden <c- o>=</c-> cellOutput<c- p>;</c->

  <c- k>if</c-> <c- p>(</c->returnSequence<c- p>)</c-> <c- p>{</c->
    cellOutput <c- o>=</c-> nn<c- p>.</c->reshape<c- p>(</c->cellOutput<c- p>,</c-> <c- p>[</c-><c- mi>1</c-><c- p>,</c-> slots<c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>,</c-> hiddenSize<c- p>]);</c->
    sequence <c- o>=</c-> <c- p>(</c->sequence <c- o>?</c-> nn<c- p>.</c->concat<c- p>([</c->sequence<c- p>,</c-> cellOutput<c- p>],</c-> <c- mi>0</c-><c- p>)</c-> <c- o>:</c-> cellOutput<c- p>);</c->
  <c- p>}</c->
<c- p>}</c->

<c- k>return</c-> <c- p>(</c->sequence <c- o>?</c-> <c- p>[</c->hidden<c- p>,</c-> sequence<c- p>]</c-> <c- o>:</c-> <c- p>[</c->hidden<c- p>]);</c->
</pre>
    </div>
   </div>
   <h4 class="heading settled" data-level="3.5.8" id="api-neuralnetworkcontext-grucell"><span class="secno">3.5.8. </span><span class="content">gruCell</span><a class="self-link" href="#api-neuralnetworkcontext-grucell"></a></h4>
    A single time step of the Gated Recurrent Unit (GRU) recurrent network using an update gate and a reset gate to compute the hidden state that rolls into the output across the temporal sequence of a recurrent network. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext⑨"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑨⑤"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout, activations)|gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout)|gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter)|gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias)|gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias)|gruCell(hiddenSize, input, weight, recurrentWeight, hidden)" id="dom-neuralnetworkcontext-grucell"><code><c- g>gruCell</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-grucell"></a></dfn>(<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①⑧"><c- b>long</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout, activations), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-hiddensize"><code><c- g>hiddenSize</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-hiddensize"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑨⑥"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout, activations), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-input"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑨⑦"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout, activations), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-weight"><code><c- g>weight</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-weight"></a></dfn>, 
                  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑨⑧"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout, activations), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-recurrentweight"><code><c- g>recurrentWeight</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-recurrentweight"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand⑨⑨"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout, activations), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-hidden"><code><c- g>hidden</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-hidden"></a></dfn>,
                  <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⓪⓪"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout, activations), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-bias"><code><c- g>bias</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-bias"></a></dfn>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⓪①"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout, activations), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-recurrentbias"><code><c- g>recurrentBias</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-recurrentbias"></a></dfn>,
                  <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean⑧"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout, activations), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-resetafter"><code><c- g>resetAfter</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-resetafter"></a></dfn> = <c- b>true</c->,
                  <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-recurrentnetworkweightlayout" id="ref-for-enumdef-recurrentnetworkweightlayout②"><c- n>RecurrentNetworkWeightLayout</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout, activations), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-layout"><code><c- g>layout</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-layout"></a></dfn> = "zrn",
                  <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="n" data-link-type="idl-name" href="#enumdef-recurrentnetworkactivation" id="ref-for-enumdef-recurrentnetworkactivation②"><c- n>RecurrentNetworkActivation</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout, activations), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias), NeuralNetworkContext/gruCell(hiddenSize, input, weight, recurrentWeight, hidden)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-activations"><code><c- g>activations</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-activations"></a></dfn>);
};
</pre>
   <div class="algorithm" data-algorithm="grucell">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>hiddenSize</em>: a <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①⑨">long</a></code> scalar. The value of the second dimension of the output tensor shape. It indicates the number of features in the hidden state.</p>
     <li data-md>
      <p><em>input</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⓪②">Operand</a></code>. The input 2-D tensor of shape [batch_size, input_size].</p>
     <li data-md>
      <p><em>weight</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⓪③">Operand</a></code>. The 2-D input weight tensor of shape [3 * hidden_size, input_size]. The ordering of the weight vectors in the first dimension of the tensor shape is specified according to the <em>layout</em> argument.</p>
     <li data-md>
      <p><em>recurrentWeight</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⓪④">Operand</a></code>. The 2-D recurrent weight tensor of shape [3 * hidden_size, hidden_size]. The ordering of the weight vectors in the first dimension of the tensor shape is specified according to the <em>layout</em> argument.</p>
     <li data-md>
      <p><em>hidden</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⓪⑤">Operand</a></code>. The 2-D input hidden state tensor of shape [batch_size, hidden_size].</p>
     <li data-md>
      <p><em>bias</em>: an optional <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⓪⑥">Operand</a></code>. The 1-D input bias tensor of shape [3 * hidden_size]. The ordering of the bias vectors in the first dimension of the tensor shape is specified according to the <em>layout</em> argument.</p>
     <li data-md>
      <p><em>recurrentBias</em>: an optional <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⓪⑦">Operand</a></code>. The 1-D recurrent bias tensor of shape [3 * hidden_size]. The ordering of the bias vectors in the first dimension of the tensor shape is specified according to the <em>layout</em> argument.</p>
     <li data-md>
      <p><em>resetAfter</em>: an optional <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean⑨">boolean</a></code> indicating whether to apply the reset gate after or before matrix multilication. Default to true.</p>
     <li data-md>
      <p><em>layout</em>: an optional <code class="idl"><a data-link-type="idl" href="#enumdef-recurrentnetworkweightlayout" id="ref-for-enumdef-recurrentnetworkweightlayout③">RecurrentNetworkWeightLayout</a></code>. The ordering of the weight and bias vectors for the internal gates of GRU, specifically the <em>update (z)</em>, <em>reset (r)</em>, and <em>new (n)</em> gate, as indicated in the first dimension of the weight and bias tensor shapes. When not specified, the default layout is <em>"zrn"</em>.</p>
     <li data-md>
      <p><em>activations</em>: an optional sequence of <code class="idl"><a data-link-type="idl" href="#enumdef-recurrentnetworkactivation" id="ref-for-enumdef-recurrentnetworkactivation③">RecurrentNetworkActivation</a></code>. A pair of activation functions with the first function used for the update and reset gate, and the second used for the new gate. When not specified, it’s default to the sigmoid ("sigmoid") and the hyperbolic tangent ("tanh") function respectively.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⓪⑧">Operand</a></code>. The 2-D tensor of shape [batch_size, hidden_size], the cell output of a single time step of the recurrent network.</p>
    <div class="note" role="note">
      The behavior of this operation with default argument values can be generically emulated from the usage of other operations as follow. However, user agents typically have a more efficient implementation for it, therefore its usage is encouraged from the performance standpoint. 
<pre class="highlight"><c- a>let</c-> one <c- o>=</c-> nn<c- p>.</c->constant<c- p>(</c-><c- mi>1</c-><c- p>);</c->
<c- a>let</c-> zero <c- o>=</c-> nn<c- p>.</c->constant<c- p>(</c-><c- mi>0</c-><c- p>);</c->

<c- c1>// update gate</c->
<c- a>let</c-> z <c- o>=</c-> nn<c- p>.</c->sigmoid<c- p>(</c->
  nn<c- p>.</c->add<c- p>(</c->
    nn<c- p>.</c->add<c- p>(</c->
      <c- p>(</c->bias <c- o>?</c-> nn<c- p>.</c->slice<c- p>(</c->bias<c- p>,</c-> <c- p>[</c-><c- mi>0</c-><c- p>],</c-> <c- p>[</c->hiddenSize<c- p>])</c-> <c- o>:</c-> zero<c- p>),</c-> 
      <c- p>(</c->recurrentBias <c- o>?</c-> nn<c- p>.</c->slice<c- p>(</c->recurrentBias<c- p>,</c-> <c- p>[</c-><c- mi>0</c-><c- p>],</c-> <c- p>[</c->hiddenSize<c- p>])</c-> <c- o>:</c-> zero<c- p>)</c->
      <c- p>),</c->
    nn<c- p>.</c->add<c- p>(</c->
      nn<c- p>.</c->matmul<c- p>(</c->
        input<c- p>,</c-> 
        nn<c- p>.</c->transpose<c- p>(</c->nn<c- p>.</c->slice<c- p>(</c->weight<c- p>,</c-> <c- p>[</c-><c- mi>0</c-><c- p>,</c-> <c- mi>0</c-><c- p>],</c-> <c- p>[</c->hiddenSize<c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>]))</c->
        <c- p>),</c->
      nn<c- p>.</c->matmul<c- p>(</c->
        hidden<c- p>,</c->
        nn<c- p>.</c->transpose<c- p>(</c->nn<c- p>.</c->slice<c- p>(</c->recurrentweight<c- p>,</c-> <c- p>[</c-><c- mi>0</c-><c- p>,</c-> <c- mi>0</c-><c- p>],</c-> <c- p>[</c->hiddenSize<c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>]))</c->
        <c- p>)</c->
      <c- p>)</c->
    <c- p>)</c->
  <c- p>);</c->

<c- c1>// reset gate</c->
<c- a>let</c-> r <c- o>=</c-> nn<c- p>.</c->sigmoid<c- p>(</c->
  nn<c- p>.</c->add<c- p>(</c->
    nn<c- p>.</c->add<c- p>(</c->
      <c- p>(</c->bias <c- o>?</c-> nn<c- p>.</c->slice<c- p>(</c->bias<c- p>,</c-> <c- p>[</c->hiddenSize<c- p>],</c-> <c- p>[</c-><c- mi>2</c-> <c- o>*</c-> hiddenSize<c- p>])</c-> <c- o>:</c-> zero<c- p>),</c->
      <c- p>(</c->recurrentBias <c- o>?</c-> nn<c- p>.</c->slice<c- p>(</c->recurrentBias<c- p>,</c-> <c- p>[</c->hiddenSize<c- p>],</c-> <c- p>[</c-><c- mi>2</c-> <c- o>*</c-> hiddenSize<c- p>])</c-> <c- o>:</c-> zero<c- p>)</c->
      <c- p>),</c->
    nn<c- p>.</c->add<c- p>(</c->
      nn<c- p>.</c->matmul<c- p>(</c->
        input<c- p>,</c-> 
        nn<c- p>.</c->transpose<c- p>(</c->nn<c- p>.</c->slice<c- p>(</c->weight<c- p>,</c-> <c- p>[</c->hiddenSize<c- p>,</c-> <c- mi>0</c-><c- p>],</c-> <c- p>[</c-><c- mi>2</c-> <c- o>*</c-> hiddenSize<c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>]))</c->
        <c- p>),</c->
      nn<c- p>.</c->matmul<c- p>(</c->
        hidden<c- p>,</c-> 
        nn<c- p>.</c->transpose<c- p>(</c->nn<c- p>.</c->slice<c- p>(</c->recurrentweight<c- p>,</c-> <c- p>[</c->hiddenSize<c- p>,</c-> <c- mi>0</c-><c- p>],</c-> <c- p>[</c-><c- mi>2</c-> <c- o>*</c-> hiddenSize<c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>]))</c->
        <c- p>)</c->
      <c- p>)</c->
    <c- p>)</c->
  <c- p>);</c->

<c- c1>// new gate</c->
<c- a>let</c-> n<c- p>;</c->
<c- k>if</c-> <c- p>(</c->resetAfter<c- p>)</c-> <c- p>{</c->
  n <c- o>=</c-> nn<c- p>.</c->tanh<c- p>(</c->
    nn<c- p>.</c->add<c- p>(</c->
      <c- p>(</c->bias <c- o>?</c-> nn<c- p>.</c->slice<c- p>(</c->bias<c- p>,</c-> <c- p>[</c-><c- mi>2</c-> <c- o>*</c-> hiddenSize<c- p>],</c-> <c- p>[</c-><c- mi>3</c-> <c- o>*</c-> hiddenSize<c- p>])</c-> <c- o>:</c-> zero<c- p>),</c->
      nn<c- p>.</c->add<c- p>(</c->
        nn<c- p>.</c->matmul<c- p>(</c->
          input<c- p>,</c-> 
          nn<c- p>.</c->transpose<c- p>(</c->nn<c- p>.</c->slice<c- p>(</c->weight<c- p>,</c-> <c- p>[</c-><c- mi>2</c-> <c- o>*</c-> hiddenSize<c- p>,</c-> <c- mi>0</c-><c- p>],</c-> <c- p>[</c-><c- mi>3</c-> <c- o>*</c-> hiddenSize<c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>]))</c->
          <c- p>),</c->
        nn<c- p>.</c->mul<c- p>(</c->
          r<c- p>,</c->
          nn<c- p>.</c->add<c- p>(</c->
            <c- p>(</c->recurrentBias <c- o>?</c-> nn<c- p>.</c->slice<c- p>(</c->recurrentBias<c- p>,</c-> <c- p>[</c-><c- mi>2</c-> <c- o>*</c-> hiddenSize<c- p>],</c-> <c- p>[</c-><c- mi>3</c-> <c- o>*</c-> hiddenSize<c- p>])</c-> <c- o>:</c-> zero<c- p>),</c->
            nn<c- p>.</c->matmul<c- p>(</c->
              hidden<c- p>,</c-> 
              nn<c- p>.</c->transpose<c- p>(</c->nn<c- p>.</c->slice<c- p>(</c->recurrentweight<c- p>,</c-> <c- p>[</c-><c- mi>2</c-> <c- o>*</c-> hiddenSize<c- p>,</c-> <c- mi>0</c-><c- p>],</c-> <c- p>[</c-><c- mi>3</c-> <c- o>*</c-> hiddenSize<c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>]))</c->
              <c- p>)</c->
            <c- p>)</c->
          <c- p>)</c->
        <c- p>)</c->
      <c- p>)</c->
    <c- p>);</c->
<c- p>}</c->
<c- k>else</c-> <c- p>{</c->
  n <c- o>=</c-> nn<c- p>.</c->tanh<c- p>(</c->
    nn<c- p>.</c->add<c- p>(</c->
      nn<c- p>.</c->add<c- p>(</c->
        <c- p>(</c->bias <c- o>?</c-> nn<c- p>.</c->slice<c- p>(</c->bias<c- p>,</c-> <c- p>[</c-><c- mi>2</c-> <c- o>*</c-> hiddenSize<c- p>],</c-> <c- p>[</c-><c- mi>3</c-> <c- o>*</c-> hiddenSize<c- p>])</c-> <c- o>:</c-> zero<c- p>),</c->
        <c- p>(</c->recurrentBias <c- o>?</c-> nn<c- p>.</c->slice<c- p>(</c->recurrentBias<c- p>,</c-> <c- p>[</c-><c- mi>2</c-> <c- o>*</c-> hiddenSize<c- p>],</c-> <c- p>[</c-><c- mi>3</c-> <c- o>*</c-> hiddenSize<c- p>])</c-> <c- o>:</c-> zero<c- p>)</c->
        <c- p>),</c->
      nn<c- p>.</c->add<c- p>(</c->
        nn<c- p>.</c->matmul<c- p>(</c->
          input<c- p>,</c-> 
          nn<c- p>.</c->transpose<c- p>(</c->nn<c- p>.</c->slice<c- p>(</c->weight<c- p>,</c-> <c- p>[</c-><c- mi>2</c-> <c- o>*</c-> hiddenSize<c- p>,</c-> <c- mi>0</c-><c- p>],</c-> <c- p>[</c-><c- mi>3</c-> <c- o>*</c-> hiddenSize<c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>]))</c->
          <c- p>),</c->
        nn<c- p>.</c->matmul<c- p>(</c->
          nn<c- p>.</c->mul<c- p>(</c->r<c- p>,</c-> hidden<c- p>),</c->
          nn<c- p>.</c->transpose<c- p>(</c->nn<c- p>.</c->slice<c- p>(</c->recurrentweight<c- p>,</c-> <c- p>[</c-><c- mi>2</c-> <c- o>*</c-> hiddenSize<c- p>,</c-> <c- mi>0</c-><c- p>],</c-> <c- p>[</c-><c- mi>3</c-> <c- o>*</c-> hiddenSize<c- p>,</c-> <c- o>-</c-><c- mi>1</c-><c- p>]))</c->
          <c- p>)</c->
        <c- p>)</c->
      <c- p>)</c->
    <c- p>);</c->
<c- p>}</c->

<c- c1>// compute the new hidden state</c->
<c- k>return</c-> nn<c- p>.</c->add<c- p>(</c->nn<c- p>.</c->mul<c- p>(</c->z<c- p>,</c-> hidden<c- p>),</c-> nn<c- p>.</c->mul<c- p>(</c->n<c- p>,</c-> nn<c- p>.</c->sub<c- p>(</c->one<c- p>,</c-> z<c- p>)));</c->
</pre>
    </div>
   </div>
   <h4 class="heading settled" data-level="3.5.9" id="api-neuralnetworkcontext-leakyrelu"><span class="secno">3.5.9. </span><span class="content">leakyRelu</span><a class="self-link" href="#api-neuralnetworkcontext-leakyrelu"></a></h4>
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①⓪"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⓪⑨"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="leakyRelu(x, alpha)|leakyRelu(x)" id="dom-neuralnetworkcontext-leakyrelu"><code><c- g>leakyRelu</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-leakyrelu"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①①⓪"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/leakyRelu(x, alpha), NeuralNetworkContext/leakyRelu(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-leakyrelu-x-alpha-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-leakyrelu-x-alpha-x"></a></dfn>, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float⑦"><c- b>float</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/leakyRelu(x, alpha), NeuralNetworkContext/leakyRelu(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-leakyrelu-x-alpha-alpha"><code><c- g>alpha</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-leakyrelu-x-alpha-alpha"></a></dfn> = 0.01);
};
</pre>
   <div class="algorithm" data-algorithm="leakyrelu">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>x</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①①①">Operand</a></code>. The input tensor.</p>
     <li data-md>
      <p><em>alpha</em>: an optional <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float⑧">float</a></code> scalar multiplier, default to 0.01.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①①②">Operand</a></code>. The output tensor of the same shape as <em>x</em>.</p>
    <p>Calculate the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Leaky_ReLU"> leaky version of rectified linear function</a> on the input tensor
    element-wise. The calculation follows the expression <code>max(0, x) + alpha ∗ min(0, x)</code>.</p>
    <div class="note" role="note">
      The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint. 
<pre class="highlight"><c- k>return</c-> nn<c- p>.</c->add<c- p>(</c->nn<c- p>.</c->max<c- p>(</c->nn<c- p>.</c->constant<c- p>(</c-><c- mi>0</c-><c- p>),</c-> x<c- p>),</c->
              nn<c- p>.</c->mul<c- p>(</c->nn<c- p>.</c->constant<c- p>(</c->alpha<c- p>),</c-> nn<c- p>.</c->min<c- p>(</c->nn<c- p>.</c->constant<c- p>(</c-><c- mi>0</c-><c- p>),</c-> x<c- p>)));</c->
</pre>
    </div>
   </div>
   <h4 class="heading settled" data-level="3.5.10" id="api-neuralnetworkcontext-matmul"><span class="secno">3.5.10. </span><span class="content">matmul</span><a class="self-link" href="#api-neuralnetworkcontext-matmul"></a></h4>
    Compute the matrix product of two input tensors. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①①"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①①③"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="matmul(a, b)" id="dom-neuralnetworkcontext-matmul"><code><c- g>matmul</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-matmul"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①①④"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/matmul(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-matmul-a-b-a"><code><c- g>a</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-matmul-a-b-a"></a></dfn>, <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①①⑤"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/matmul(a, b)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-matmul-a-b-b"><code><c- g>b</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-matmul-a-b-b"></a></dfn>);
};
</pre>
   <div class="algorithm" data-algorithm="matmul">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>a</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①①⑥">Operand</a></code>. The first input N-D tensor.</p>
     <li data-md>
      <p><em>b</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①①⑦">Operand</a></code>. The second input N-D tensor.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①①⑧">Operand</a></code>. The output N-D tensor that contains the matrix
    product of two input tensors.</p>
    <p>Compute the matrix product of two input tensors. It behaves as following:</p>
    <ul>
     <li data-md>
      <p>If both <em>a</em> and <em>b</em> are 2-D, they are multiplied like conventional
matrices and produce a 2-D tensor as the output.</p>
     <li data-md>
      <p>If either <em>a</em> or <em>b</em> is N-D, N > 2, it is treated as a stack of
matrices with dimensions corresponding to the last two indices. The
matrix multiplication will be broadcasted accordingly by following <a data-link-type="biblio" href="#biblio-numpy-broadcasting-rule">[numpy-broadcasting-rule]</a>. The output is a N-D tensor whose rank
is the maximum rank of the input tensors. For each dimension, except
the last two, of the output tensor, its size is the maximum size
along that dimension of the input tensors.</p>
     <li data-md>
      <p>If <em>a</em> is 1-D, it is converted to a 2-D tensor by prepending a 1 to
its dimensions.</p>
     <li data-md>
      <p>If <em>b</em> is 1-D, it is converted to a 2-D tensor by by appending a 1 to
its dimensions.</p>
     <li data-md>
      <p>If both <em>a</em> and <em>b</em> are 1-D, the operation is a vector dot-product,
which produces a scalar output.</p>
    </ul>
   </div>
   <h4 class="heading settled" data-level="3.5.11" id="api-neuralnetworkcontext-pool2d"><span class="secno">3.5.11. </span><span class="content">pooling operations</span><a class="self-link" href="#api-neuralnetworkcontext-pool2d"></a></h4>
    Compute a <em>mean</em>, <em>L2 norm</em>, or <em>max</em> reduction operation across all the elements within the moving window over the input tensor. See the description of each type of reduction in <a href="#api-neuralnetworkcontext-reduce">§ 3.5.12 reduction operations</a>. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①②"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①①⑨"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="averagePool2d(input, windowDimensions, padding, strides, dilations, layout)|averagePool2d(input, windowDimensions, padding, strides, dilations)|averagePool2d(input, windowDimensions, padding, strides)|averagePool2d(input, windowDimensions, padding)|averagePool2d(input, windowDimensions)|averagePool2d(input)" id="dom-neuralnetworkcontext-averagepool2d"><code><c- g>averagePool2d</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-averagepool2d"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①②⓪"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding), NeuralNetworkContext/averagePool2d(input, windowDimensions), NeuralNetworkContext/averagePool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②⓪"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding), NeuralNetworkContext/averagePool2d(input, windowDimensions), NeuralNetworkContext/averagePool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-windowdimensions"><code><c- g>windowDimensions</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-windowdimensions"></a></dfn>,
                        <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②①"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding), NeuralNetworkContext/averagePool2d(input, windowDimensions), NeuralNetworkContext/averagePool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-padding"><code><c- g>padding</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-padding"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②②"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding), NeuralNetworkContext/averagePool2d(input, windowDimensions), NeuralNetworkContext/averagePool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-strides"><code><c- g>strides</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-strides"></a></dfn>,
                        <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②③"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding), NeuralNetworkContext/averagePool2d(input, windowDimensions), NeuralNetworkContext/averagePool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-dilations"><code><c- g>dilations</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-dilations"></a></dfn>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-operandlayout" id="ref-for-enumdef-operandlayout②"><c- n>OperandLayout</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/averagePool2d(input, windowDimensions, padding), NeuralNetworkContext/averagePool2d(input, windowDimensions), NeuralNetworkContext/averagePool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-layout"><code><c- g>layout</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-layout"></a></dfn> = "nchw");
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①②①"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="l2Pool2d(input, windowDimensions, padding, strides, dilations, layout)|l2Pool2d(input, windowDimensions, padding, strides, dilations)|l2Pool2d(input, windowDimensions, padding, strides)|l2Pool2d(input, windowDimensions, padding)|l2Pool2d(input, windowDimensions)|l2Pool2d(input)" id="dom-neuralnetworkcontext-l2pool2d"><code><c- g>l2Pool2d</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-l2pool2d"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①②②"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding), NeuralNetworkContext/l2Pool2d(input, windowDimensions), NeuralNetworkContext/l2Pool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②④"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding), NeuralNetworkContext/l2Pool2d(input, windowDimensions), NeuralNetworkContext/l2Pool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-windowdimensions"><code><c- g>windowDimensions</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-windowdimensions"></a></dfn>,
                  <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②⑤"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding), NeuralNetworkContext/l2Pool2d(input, windowDimensions), NeuralNetworkContext/l2Pool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-padding"><code><c- g>padding</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-padding"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②⑥"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding), NeuralNetworkContext/l2Pool2d(input, windowDimensions), NeuralNetworkContext/l2Pool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-strides"><code><c- g>strides</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-strides"></a></dfn>,
                  <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②⑦"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding), NeuralNetworkContext/l2Pool2d(input, windowDimensions), NeuralNetworkContext/l2Pool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-dilations"><code><c- g>dilations</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-dilations"></a></dfn>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-operandlayout" id="ref-for-enumdef-operandlayout③"><c- n>OperandLayout</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/l2Pool2d(input, windowDimensions, padding), NeuralNetworkContext/l2Pool2d(input, windowDimensions), NeuralNetworkContext/l2Pool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-layout"><code><c- g>layout</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-layout"></a></dfn> = "nchw");
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①②③"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="maxPool2d(input, windowDimensions, padding, strides, dilations, layout)|maxPool2d(input, windowDimensions, padding, strides, dilations)|maxPool2d(input, windowDimensions, padding, strides)|maxPool2d(input, windowDimensions, padding)|maxPool2d(input, windowDimensions)|maxPool2d(input)" id="dom-neuralnetworkcontext-maxpool2d"><code><c- g>maxPool2d</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-maxpool2d"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①②④"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding), NeuralNetworkContext/maxPool2d(input, windowDimensions), NeuralNetworkContext/maxPool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②⑧"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding), NeuralNetworkContext/maxPool2d(input, windowDimensions), NeuralNetworkContext/maxPool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-windowdimensions"><code><c- g>windowDimensions</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-windowdimensions"></a></dfn>,
                    <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②⑨"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding), NeuralNetworkContext/maxPool2d(input, windowDimensions), NeuralNetworkContext/maxPool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-padding"><code><c- g>padding</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-padding"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long③⓪"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding), NeuralNetworkContext/maxPool2d(input, windowDimensions), NeuralNetworkContext/maxPool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-strides"><code><c- g>strides</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-strides"></a></dfn>,
                    <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long③①"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding), NeuralNetworkContext/maxPool2d(input, windowDimensions), NeuralNetworkContext/maxPool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-dilations"><code><c- g>dilations</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-dilations"></a></dfn>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-operandlayout" id="ref-for-enumdef-operandlayout④"><c- n>OperandLayout</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides, dilations, layout), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides, dilations), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding, strides), NeuralNetworkContext/maxPool2d(input, windowDimensions, padding), NeuralNetworkContext/maxPool2d(input, windowDimensions), NeuralNetworkContext/maxPool2d(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-layout"><code><c- g>layout</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-layout"></a></dfn> = "nchw");
};
</pre>
   <div class="algorithm" data-algorithm="pool2d">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>input</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①②⑤">Operand</a></code>. The input 4-D tensor. The logical shape
is interpreted according to the value of <em>layout</em>.</p>
     <li data-md>
      <p><em>windowDimensions</em>: an optional sequence of <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long③②">long</a></code> of length 2. The dimensions of the sliding window,
[window_height, window_width]. If not present, the window dimensions are assumed to be the height  
and width dimensions of the input shape.</p>
     <li data-md>
      <p><em>padding</em>: an optional sequence of <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long③③">long</a></code> of length 4. The padding for the
beginning and ending along each spatial dimension of <em>input</em>,
[beginning_height, ending_height, beginning_width, ending_width].
If not present, the values are assumed to be [0,0,0,0].</p>
     <li data-md>
      <p><em>strides</em>: an optional sequence of <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long③④">long</a></code> of length 2. The stride of the
sliding window for each spatial dimension of <em>input</em>,
[stride_height, stride_width]. If not present, the values are assumed to be [1,1].</p>
     <li data-md>
      <p><em>dilations</em>: an optional sequence of <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long③⑤">long</a></code> of length 2. The dilation factor
for each spatial dimension of <em>input</em>, [dilation_height, dilation_width].
If not present, the values are assumed to be [1,1].</p>
     <li data-md>
      <p><em>layout</em>: an optional <code class="idl"><a data-link-type="idl" href="#enumdef-operandlayout" id="ref-for-enumdef-operandlayout⑤">OperandLayout</a></code> with value as "nchw" or
"nhwc". The default value is "nchw". This argument specifies the
layout format of the input and output.</p>
      <p>"nchw":</p>
      <ul>
       <li data-md>
        <p>input tensor: [batches, channels, height, width]</p>
       <li data-md>
        <p>output tensor: [batches, channels, height, width]</p>
      </ul>
      "nhwc": 
      <ul>
       <li data-md>
        <p>input tensor: [batches, height, width, channels]</p>
       <li data-md>
        <p>output tensor: [batches, height, width, channels]</p>
      </ul>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①②⑥">Operand</a></code>. The output 4-D tensor that contains the
    result of the reduction. The logical shape is interpreted according to the
    value of <em>layout</em>.</p>
    <div class="note" role="note">
      A <em>global</em> pooling operation such as one for the max pooling operation is a variant of pooling where the window dimensions is the spatial dimensions (last two dimensions) of the input shape, as follow. 
<pre class="highlight"><c- c1>// 'global' max pooling</c->
maxPool2d<c- p>(</c->input<c- p>);</c->
</pre>
    </div>
   </div>
   <h4 class="heading settled" data-level="3.5.12" id="api-neuralnetworkcontext-reduce"><span class="secno">3.5.12. </span><span class="content">reduction operations</span><a class="self-link" href="#api-neuralnetworkcontext-reduce"></a></h4>
    Reduce the input along the dimensions given in <em>axes</em>. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①③"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①②⑦"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="reduceL1(input, axes, keepDimensions)|reduceL1(input, axes)|reduceL1(input)" id="dom-neuralnetworkcontext-reducel1"><code><c- g>reduceL1</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducel1"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①②⑧"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceL1(input, axes, keepDimensions), NeuralNetworkContext/reduceL1(input, axes), NeuralNetworkContext/reduceL1(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducel1-input-axes-keepdimensions-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducel1-input-axes-keepdimensions-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long③⑥"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceL1(input, axes, keepDimensions), NeuralNetworkContext/reduceL1(input, axes), NeuralNetworkContext/reduceL1(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducel1-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducel1-input-axes-keepdimensions-axes"></a></dfn> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean①⓪"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceL1(input, axes, keepDimensions), NeuralNetworkContext/reduceL1(input, axes), NeuralNetworkContext/reduceL1(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducel1-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducel1-input-axes-keepdimensions-keepdimensions"></a></dfn> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①②⑨"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="reduceL2(input, axes, keepDimensions)|reduceL2(input, axes)|reduceL2(input)" id="dom-neuralnetworkcontext-reducel2"><code><c- g>reduceL2</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducel2"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①③⓪"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceL2(input, axes, keepDimensions), NeuralNetworkContext/reduceL2(input, axes), NeuralNetworkContext/reduceL2(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducel2-input-axes-keepdimensions-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducel2-input-axes-keepdimensions-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long③⑦"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceL2(input, axes, keepDimensions), NeuralNetworkContext/reduceL2(input, axes), NeuralNetworkContext/reduceL2(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducel2-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducel2-input-axes-keepdimensions-axes"></a></dfn> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean①①"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceL2(input, axes, keepDimensions), NeuralNetworkContext/reduceL2(input, axes), NeuralNetworkContext/reduceL2(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducel2-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducel2-input-axes-keepdimensions-keepdimensions"></a></dfn> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①③①"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="reduceLogSum(input, axes, keepDimensions)|reduceLogSum(input, axes)|reduceLogSum(input)" id="dom-neuralnetworkcontext-reducelogsum"><code><c- g>reduceLogSum</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducelogsum"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①③②"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceLogSum(input, axes, keepDimensions), NeuralNetworkContext/reduceLogSum(input, axes), NeuralNetworkContext/reduceLogSum(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducelogsum-input-axes-keepdimensions-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducelogsum-input-axes-keepdimensions-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long③⑧"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceLogSum(input, axes, keepDimensions), NeuralNetworkContext/reduceLogSum(input, axes), NeuralNetworkContext/reduceLogSum(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducelogsum-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducelogsum-input-axes-keepdimensions-axes"></a></dfn> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean①②"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceLogSum(input, axes, keepDimensions), NeuralNetworkContext/reduceLogSum(input, axes), NeuralNetworkContext/reduceLogSum(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducelogsum-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducelogsum-input-axes-keepdimensions-keepdimensions"></a></dfn> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①③③"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="reduceLogSumExp(input, axes, keepDimensions)|reduceLogSumExp(input, axes)|reduceLogSumExp(input)" id="dom-neuralnetworkcontext-reducelogsumexp"><code><c- g>reduceLogSumExp</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducelogsumexp"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①③④"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceLogSumExp(input, axes, keepDimensions), NeuralNetworkContext/reduceLogSumExp(input, axes), NeuralNetworkContext/reduceLogSumExp(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducelogsumexp-input-axes-keepdimensions-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducelogsumexp-input-axes-keepdimensions-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long③⑨"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceLogSumExp(input, axes, keepDimensions), NeuralNetworkContext/reduceLogSumExp(input, axes), NeuralNetworkContext/reduceLogSumExp(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducelogsumexp-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducelogsumexp-input-axes-keepdimensions-axes"></a></dfn> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean①③"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceLogSumExp(input, axes, keepDimensions), NeuralNetworkContext/reduceLogSumExp(input, axes), NeuralNetworkContext/reduceLogSumExp(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducelogsumexp-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducelogsumexp-input-axes-keepdimensions-keepdimensions"></a></dfn> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①③⑤"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="reduceMax(input, axes, keepDimensions)|reduceMax(input, axes)|reduceMax(input)" id="dom-neuralnetworkcontext-reducemax"><code><c- g>reduceMax</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducemax"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①③⑥"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceMax(input, axes, keepDimensions), NeuralNetworkContext/reduceMax(input, axes), NeuralNetworkContext/reduceMax(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducemax-input-axes-keepdimensions-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducemax-input-axes-keepdimensions-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long④⓪"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceMax(input, axes, keepDimensions), NeuralNetworkContext/reduceMax(input, axes), NeuralNetworkContext/reduceMax(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducemax-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducemax-input-axes-keepdimensions-axes"></a></dfn> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean①④"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceMax(input, axes, keepDimensions), NeuralNetworkContext/reduceMax(input, axes), NeuralNetworkContext/reduceMax(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducemax-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducemax-input-axes-keepdimensions-keepdimensions"></a></dfn> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①③⑦"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="reduceMean(input, axes, keepDimensions)|reduceMean(input, axes)|reduceMean(input)" id="dom-neuralnetworkcontext-reducemean"><code><c- g>reduceMean</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducemean"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①③⑧"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceMean(input, axes, keepDimensions), NeuralNetworkContext/reduceMean(input, axes), NeuralNetworkContext/reduceMean(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducemean-input-axes-keepdimensions-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducemean-input-axes-keepdimensions-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long④①"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceMean(input, axes, keepDimensions), NeuralNetworkContext/reduceMean(input, axes), NeuralNetworkContext/reduceMean(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducemean-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducemean-input-axes-keepdimensions-axes"></a></dfn> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean①⑤"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceMean(input, axes, keepDimensions), NeuralNetworkContext/reduceMean(input, axes), NeuralNetworkContext/reduceMean(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducemean-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducemean-input-axes-keepdimensions-keepdimensions"></a></dfn> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①③⑨"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="reduceMin(input, axe, keepDimensions)|reduceMin(input, axe)|reduceMin(input)" id="dom-neuralnetworkcontext-reducemin"><code><c- g>reduceMin</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducemin"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①④⓪"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceMin(input, axe, keepDimensions), NeuralNetworkContext/reduceMin(input, axe), NeuralNetworkContext/reduceMin(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducemin-input-axe-keepdimensions-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducemin-input-axe-keepdimensions-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long④②"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceMin(input, axe, keepDimensions), NeuralNetworkContext/reduceMin(input, axe), NeuralNetworkContext/reduceMin(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducemin-input-axe-keepdimensions-axe"><code><c- g>axe</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducemin-input-axe-keepdimensions-axe"></a></dfn> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean①⑥"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceMin(input, axe, keepDimensions), NeuralNetworkContext/reduceMin(input, axe), NeuralNetworkContext/reduceMin(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducemin-input-axe-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducemin-input-axe-keepdimensions-keepdimensions"></a></dfn> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①④①"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="reduceProduct(input, axes, keepDimensions)|reduceProduct(input, axes)|reduceProduct(input)" id="dom-neuralnetworkcontext-reduceproduct"><code><c- g>reduceProduct</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reduceproduct"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①④②"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceProduct(input, axes, keepDimensions), NeuralNetworkContext/reduceProduct(input, axes), NeuralNetworkContext/reduceProduct(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reduceproduct-input-axes-keepdimensions-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reduceproduct-input-axes-keepdimensions-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long④③"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceProduct(input, axes, keepDimensions), NeuralNetworkContext/reduceProduct(input, axes), NeuralNetworkContext/reduceProduct(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reduceproduct-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reduceproduct-input-axes-keepdimensions-axes"></a></dfn> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean①⑦"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceProduct(input, axes, keepDimensions), NeuralNetworkContext/reduceProduct(input, axes), NeuralNetworkContext/reduceProduct(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reduceproduct-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reduceproduct-input-axes-keepdimensions-keepdimensions"></a></dfn> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①④③"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="reduceSum(input, axes, keepDimensions)|reduceSum(input, axes)|reduceSum(input)" id="dom-neuralnetworkcontext-reducesum"><code><c- g>reduceSum</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducesum"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①④④"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceSum(input, axes, keepDimensions), NeuralNetworkContext/reduceSum(input, axes), NeuralNetworkContext/reduceSum(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducesum-input-axes-keepdimensions-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducesum-input-axes-keepdimensions-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long④④"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceSum(input, axes, keepDimensions), NeuralNetworkContext/reduceSum(input, axes), NeuralNetworkContext/reduceSum(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducesum-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducesum-input-axes-keepdimensions-axes"></a></dfn> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean①⑧"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceSum(input, axes, keepDimensions), NeuralNetworkContext/reduceSum(input, axes), NeuralNetworkContext/reduceSum(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducesum-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducesum-input-axes-keepdimensions-keepdimensions"></a></dfn> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①④⑤"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="reduceSumSquare(input, axes, keepDimensions)|reduceSumSquare(input, axes)|reduceSumSquare(input)" id="dom-neuralnetworkcontext-reducesumsquare"><code><c- g>reduceSumSquare</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducesumsquare"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①④⑥"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceSumSquare(input, axes, keepDimensions), NeuralNetworkContext/reduceSumSquare(input, axes), NeuralNetworkContext/reduceSumSquare(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducesumsquare-input-axes-keepdimensions-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducesumsquare-input-axes-keepdimensions-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long④⑤"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceSumSquare(input, axes, keepDimensions), NeuralNetworkContext/reduceSumSquare(input, axes), NeuralNetworkContext/reduceSumSquare(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducesumsquare-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducesumsquare-input-axes-keepdimensions-axes"></a></dfn> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean①⑨"><c- b>boolean</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reduceSumSquare(input, axes, keepDimensions), NeuralNetworkContext/reduceSumSquare(input, axes), NeuralNetworkContext/reduceSumSquare(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reducesumsquare-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reducesumsquare-input-axes-keepdimensions-keepdimensions"></a></dfn> = <c- b>false</c->);
};
</pre>
   <div class="algorithm" data-algorithm="reduce">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>input</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①④⑦">Operand</a></code>. The input tensor.</p>
     <li data-md>
      <p><em>axes</em>: an optional sequence of <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long④⑥">long</a></code>. The dimensions to reduce where -1 means the last dimension.
If not present, all dimensions are reduced.</p>
     <li data-md>
      <p><em>keepDimensions</em>: an optional <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-boolean" id="ref-for-idl-boolean②⓪">boolean</a></code>. If true, retains reduced dimensions with size of 1.
The default value is false.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①④⑧">Operand</a></code>. The reduced output tensor.</p>
    <p><strong>Reduction types:</strong></p>
    <ul>
     <li data-md>
      <p><em>L1</em>: Compute the <a href="https://mathworld.wolfram.com/L1-Norm.html">L1 norm</a> of all the input values along the axes.</p>
     <li data-md>
      <p><em>L2</em>: Compute the <a href="https://mathworld.wolfram.com/L2-Norm.html">L2 norm</a> of all the input values along the axes.</p>
     <li data-md>
      <p><em>LogSum</em>: Compute the log value of the sum of all the input values along the axes.</p>
     <li data-md>
      <p><em>LogSumExp</em>: Compute the log value of the sum of the exponent of all the input values along the axes.</p>
     <li data-md>
      <p><em>Max</em>: Compute the maximum value of all the input values along the axes.</p>
     <li data-md>
      <p><em>Mean</em>: Compute the average value of all the input values along the axes.</p>
     <li data-md>
      <p><em>Min</em>: Compute the minimum value of all the input values along the axes.</p>
     <li data-md>
      <p><em>Product</em>: Compute the product of all the input values along the axes.</p>
     <li data-md>
      <p><em>Sum</em>: Compute the sum of all the input values along the axes.</p>
     <li data-md>
      <p><em>SumSquare</em>: Compute the sum of the square of all the input values along the axes.</p>
    </ul>
   </div>
   <h4 class="heading settled" data-level="3.5.13" id="api-neuralnetworkcontext-relu"><span class="secno">3.5.13. </span><span class="content">relu</span><a class="self-link" href="#api-neuralnetworkcontext-relu"></a></h4>
    Calculate the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks">rectified linear</a> function on the input tensor element-wise. The calculation follows the expression <code>max(0, x)</code>. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①④"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①④⑨"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="relu(x)" id="dom-neuralnetworkcontext-relu"><code><c- g>relu</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-relu"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⑤⓪"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/relu(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-relu-x-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-relu-x-x"></a></dfn>);
};
</pre>
   <div class="algorithm" data-algorithm="relu">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>x</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑤①">Operand</a></code>. The input tensor.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑤②">Operand</a></code>. The output tensor of the same shape as <em>x</em>.</p>
    <p>Calculate the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">rectified
    linear function</a> on the input tensor element-wise. The calculation
    follows the expression <code>max(0, x)</code>.</p>
    <div class="note" role="note">
      The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint. 
<pre class="highlight"><c- k>return</c-> nn<c- p>.</c->max<c- p>(</c->nn<c- p>.</c->constant<c- p>(</c-><c- mi>0</c-><c- p>),</c-> x<c- p>);</c->
</pre>
    </div>
   </div>
   <h4 class="heading settled" data-level="3.5.14" id="api-neuralnetworkcontext-reshape"><span class="secno">3.5.14. </span><span class="content">reshape</span><a class="self-link" href="#api-neuralnetworkcontext-reshape"></a></h4>
    Reshapes a tensor to a given new shape. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①⑤"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⑤③"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="reshape(input, newShape)" id="dom-neuralnetworkcontext-reshape"><code><c- g>reshape</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reshape"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⑤④"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reshape(input, newShape)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reshape-input-newshape-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reshape-input-newshape-input"></a></dfn>, <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long④⑦"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/reshape(input, newShape)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-reshape-input-newshape-newshape"><code><c- g>newShape</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-reshape-input-newshape-newshape"></a></dfn>);
};
</pre>
   <div class="algorithm" data-algorithm="reshape">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>input</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑤⑤">Operand</a></code>. The input tensor.</p>
     <li data-md>
      <p><em>newShape</em>: a sequence of <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long④⑧">long</a></code>. The shape of the output tensor.
The number of elements implied by <em>newShape</em> must be the same as the
number of elements in the input tensor. Only one component of <em>newShape</em> can be the special value of -1. The size of the dimension
with the value -1 is computed so that the total size remains
constant.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑤⑥">Operand</a></code>. The output tensor. The values of the output
    tensor are the same as values of the input tensor. The shape of the output
    tensor is specified by the <em>newShape</em> argument.</p>
   </div>
   <h4 class="heading settled" data-level="3.5.15" id="api-neuralnetworkcontext-slice"><span class="secno">3.5.15. </span><span class="content">slice</span><a class="self-link" href="#api-neuralnetworkcontext-slice"></a></h4>
    Produce a slice of the input tensor. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①⑥"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⑤⑦"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="slice(input, starts, ends)" id="dom-neuralnetworkcontext-slice"><code><c- g>slice</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-slice"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⑤⑧"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/slice(input, starts, ends)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-slice-input-starts-ends-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-slice-input-starts-ends-input"></a></dfn>, <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long④⑨"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/slice(input, starts, ends)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-slice-input-starts-ends-starts"><code><c- g>starts</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-slice-input-starts-ends-starts"></a></dfn>, <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long⑤⓪"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/slice(input, starts, ends)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-slice-input-starts-ends-ends"><code><c- g>ends</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-slice-input-starts-ends-ends"></a></dfn>);
};
</pre>
   <div class="algorithm" data-algorithm="slice">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>input</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑤⑨">Operand</a></code>. The input tensor.</p>
     <li data-md>
      <p><em>starts</em>: a sequence of <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long⑤①">long</a></code>. The starting indices of the corresponding axes of the input shape.</p>
     <li data-md>
      <p><em>ends</em>: a sequence of <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long⑤②">long</a></code>. The ending indices of the corresponding axes of the input shape.
The ending index value of -1 selects all the remaining tensor values from the starting index of the given axis.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑥⓪">Operand</a></code>. The output tensor of the same rank as the input tensor with tensor values stripped to the specified starting and ending indices in each dimension.</p>
   </div>
   <h4 class="heading settled" data-level="3.5.16" id="api-neuralnetworkcontext-softmax"><span class="secno">3.5.16. </span><span class="content">softmax</span><a class="self-link" href="#api-neuralnetworkcontext-softmax"></a></h4>
    Compute the <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a> values of
the 2-D input tensor along axis 1. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①⑦"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⑥①"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="softmax(x)" id="dom-neuralnetworkcontext-softmax"><code><c- g>softmax</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-softmax"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⑥②"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/softmax(x)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-softmax-x-x"><code><c- g>x</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-softmax-x-x"></a></dfn>);
};
</pre>
   <div class="algorithm" data-algorithm="softmax">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>x</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑥③">Operand</a></code>. The input 2-D tensor.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑥④">Operand</a></code>. The output 2-D tensor that contains the softmax
    results, of the same shape as the input tensor.</p>
    <div class="note" role="note">
      The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint. 
<pre class="highlight"><c- c1>// This sample deploys a well-known implementation trick [1] to compute the</c->
<c- c1>// exponentials of the distances to the max value, instead of the exponentials</c->
<c- c1>// of the input values itself, in order to increase the numerical stability of</c->
<c- c1>// the result.</c->
<c- c1>// [1]: https://cs231n.github.io/linear-classify/#softmax</c->
<c- kr>const</c-> max_x <c- o>=</c-> nn<c- p>.</c->reduceMax<c- p>(</c->x<c- p>,</c-> <c- d>/* axes = */</c-> <c- p>[</c-><c- mi>1</c-><c- p>],</c-> <c- d>/* keepDimensions = */</c-> <c- kc>true</c-><c- p>);</c->
<c- kr>const</c-> exp_x <c- o>=</c-> nn<c- p>.</c->exp<c- p>(</c->nn<c- p>.</c->sub<c- p>(</c->x<c- p>,</c-> max<c- p>));</c->
<c- k>return</c-> nn<c- p>.</c->div<c- p>(</c->exp_x<c- p>,</c-> nn<c- p>.</c->reduceSum<c- p>(</c->exp_x<c- p>,</c-> <c- d>/* axes = */</c-> <c- p>[</c-><c- mi>1</c-><c- p>],</c-> <c- d>/* keepDimensions = */</c-> <c- kc>true</c-><c- p>));</c->
</pre>
    </div>
   </div>
   <h4 class="heading settled" data-level="3.5.17" id="api-neuralnetworkcontext-squeeze"><span class="secno">3.5.17. </span><span class="content">squeeze</span><a class="self-link" href="#api-neuralnetworkcontext-squeeze"></a></h4>
    Reduce the rank of a tensor without affecting its values by eliminating dimensions with size 1 of the tensor shape. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①⑧"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⑥⑤"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="squeeze(input, axes)|squeeze(input)" id="dom-neuralnetworkcontext-squeeze"><code><c- g>squeeze</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-squeeze"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⑥⑥"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/squeeze(input, axes), NeuralNetworkContext/squeeze(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-squeeze-input-axes-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-squeeze-input-axes-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long⑤③"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/squeeze(input, axes), NeuralNetworkContext/squeeze(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-squeeze-input-axes-axes"><code><c- g>axes</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-squeeze-input-axes-axes"></a></dfn>);
};
</pre>
   <div class="algorithm" data-algorithm="squeeze">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>input</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑥⑦">Operand</a></code>. The input tensor.</p>
     <li data-md>
      <p><em>axes</em>: an optional sequence of <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long⑤④">long</a></code>. Indices to the shape dimensions of size 1 to eliminate. When not specified, every shape dimensions of size 1 in the tensor are eliminated.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑥⑧">Operand</a></code>. The output tensor of the same or reduced rank with the shape dimensions of size 1 eliminated.</p>
   </div>
   <h4 class="heading settled" data-level="3.5.18" id="api-neuralnetworkcontext-transpose"><span class="secno">3.5.18. </span><span class="content">transpose</span><a class="self-link" href="#api-neuralnetworkcontext-transpose"></a></h4>
    Permute the dimensions of the input tensor according to the <em>permutation</em> argument. 
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①⑨"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⑥⑨"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export data-lt="transpose(input, permutation)|transpose(input)" id="dom-neuralnetworkcontext-transpose"><code><c- g>transpose</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-transpose"></a></dfn>(<a class="n" data-link-type="idl-name" href="#operand" id="ref-for-operand①⑦⓪"><c- n>Operand</c-></a> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/transpose(input, permutation), NeuralNetworkContext/transpose(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-transpose-input-permutation-input"><code><c- g>input</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-transpose-input-permutation-input"></a></dfn>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long⑤⑤"><c- b>long</c-></a>> <dfn class="idl-code" data-dfn-for="NeuralNetworkContext/transpose(input, permutation), NeuralNetworkContext/transpose(input)" data-dfn-type="argument" data-export id="dom-neuralnetworkcontext-transpose-input-permutation-permutation"><code><c- g>permutation</c-></code><a class="self-link" href="#dom-neuralnetworkcontext-transpose-input-permutation-permutation"></a></dfn>);
};
</pre>
   <div class="algorithm" data-algorithm="transpose">
     <strong>Arguments:</strong> 
    <ul>
     <li data-md>
      <p><em>input</em>: an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑦①">Operand</a></code>. The input N-D tensor.</p>
     <li data-md>
      <p><em>permutation</em>: an optional sequence of <code class="idl"><a data-link-type="idl" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long⑤⑥">long</a></code> values. The values used to permute the output shape. When it’s not specified, it’s set to <code>[N-1...0]</code>, where <code>N</code> is the rank of the input tensor. These default values cause the output to become a transposed tensor of the input. When specified, the number of values in the sequence must be the same as the rank of the input tensor, and the values in the sequence must be within the range from 0 to N-1 with no two or more same values found in the sequence.</p>
    </ul>
    <p><strong>Returns:</strong> an <code class="idl"><a data-link-type="idl" href="#operand" id="ref-for-operand①⑦②">Operand</a></code>. The permuted or transposed N-D tensor.</p>
   </div>
   <h3 class="heading settled" data-level="3.6" id="api-model"><span class="secno">3.6. </span><span class="content">Model</span><a class="self-link" href="#api-model"></a></h3>
<pre class="idl highlight def"><c- b>enum</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="enum" data-export id="enumdef-powerpreference"><code><c- g>PowerPreference</c-></code></dfn> {
  // Let the user agent decide the most suitable behavior. This is the default value.
  <dfn class="idl-code" data-dfn-for="PowerPreference" data-dfn-type="enum-value" data-export id="dom-powerpreference-default"><code><c- s>"default"</c-></code><a class="self-link" href="#dom-powerpreference-default"></a></dfn>,
  // Prioritizes execution speed over other considerations e.g. power consumption
  <dfn class="idl-code" data-dfn-for="PowerPreference" data-dfn-type="enum-value" data-export id="dom-powerpreference-high-performance"><code><c- s>"high-performance"</c-></code><a class="self-link" href="#dom-powerpreference-high-performance"></a></dfn>,
  // Prioritizes power consumption over other considerations e.g. execution speed
  <dfn class="idl-code" data-dfn-for="PowerPreference" data-dfn-type="enum-value" data-export id="dom-powerpreference-low-power"><code><c- s>"low-power"</c-></code><a class="self-link" href="#dom-powerpreference-low-power"></a></dfn>
};

<c- b>dictionary</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="dictionary" data-export id="dictdef-compilationoptions"><code><c- g>CompilationOptions</c-></code></dfn> {
  // Compilation preference as related to power consumption level
  <a class="n" data-link-type="idl-name" href="#enumdef-powerpreference" id="ref-for-enumdef-powerpreference"><c- n>PowerPreference</c-></a> <dfn class="idl-code" data-default="&quot;default&quot;" data-dfn-for="CompilationOptions" data-dfn-type="dict-member" data-export data-type="PowerPreference " id="dom-compilationoptions-powerpreference"><code><c- g>powerPreference</c-></code><a class="self-link" href="#dom-compilationoptions-powerpreference"></a></dfn> = "default";
};

<c- b>interface</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="interface" data-export id="model"><code><c- g>Model</c-></code></dfn> {
  <c- b>Promise</c->&lt;<a class="n" data-link-type="idl-name" href="#compilation" id="ref-for-compilation"><c- n>Compilation</c-></a>> <dfn class="idl-code" data-dfn-for="Model" data-dfn-type="method" data-export data-lt="createCompilation(options)|createCompilation()" id="dom-model-createcompilation"><code><c- g>createCompilation</c-></code><a class="self-link" href="#dom-model-createcompilation"></a></dfn>(<c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#dictdef-compilationoptions" id="ref-for-dictdef-compilationoptions"><c- n>CompilationOptions</c-></a> <dfn class="idl-code" data-dfn-for="Model/createCompilation(options), Model/createCompilation()" data-dfn-type="argument" data-export id="dom-model-createcompilation-options-options"><code><c- g>options</c-></code><a class="self-link" href="#dom-model-createcompilation-options-options"></a></dfn> = {});
};
</pre>
   <h3 class="heading settled" data-level="3.7" id="api-compilation"><span class="secno">3.7. </span><span class="content">Compilation</span><a class="self-link" href="#api-compilation"></a></h3>
<pre class="idl highlight def"><c- b>interface</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="interface" data-export id="compilation"><code><c- g>Compilation</c-></code></dfn> {
  <c- b>Promise</c->&lt;<a class="n" data-link-type="idl-name" href="#execution" id="ref-for-execution"><c- n>Execution</c-></a>> <dfn class="idl-code" data-dfn-for="Compilation" data-dfn-type="method" data-export data-lt="createExecution()" id="dom-compilation-createexecution"><code><c- g>createExecution</c-></code><a class="self-link" href="#dom-compilation-createexecution"></a></dfn>();
};
</pre>
   <h3 class="heading settled" data-level="3.8" id="api-execution"><span class="secno">3.8. </span><span class="content">Execution</span><a class="self-link" href="#api-execution"></a></h3>
<pre class="idl highlight def"><c- b>interface</c-> <dfn class="dfn-paneled idl-code" data-dfn-type="interface" data-export id="execution"><code><c- g>Execution</c-></code></dfn> {
  <c- b>void</c-> <dfn class="idl-code" data-dfn-for="Execution" data-dfn-type="method" data-export data-lt="setInput(name, data)" id="dom-execution-setinput"><code><c- g>setInput</c-></code><a class="self-link" href="#dom-execution-setinput"></a></dfn>(<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString②"><c- b>DOMString</c-></a> <dfn class="idl-code" data-dfn-for="Execution/setInput(name, data)" data-dfn-type="argument" data-export id="dom-execution-setinput-name-data-name"><code><c- g>name</c-></code><a class="self-link" href="#dom-execution-setinput-name-data-name"></a></dfn>, <a class="n" data-link-type="idl-name" href="https://heycam.github.io/webidl/#ArrayBufferView" id="ref-for-ArrayBufferView①"><c- n>ArrayBufferView</c-></a> <dfn class="idl-code" data-dfn-for="Execution/setInput(name, data)" data-dfn-type="argument" data-export id="dom-execution-setinput-name-data-data"><code><c- g>data</c-></code><a class="self-link" href="#dom-execution-setinput-name-data-data"></a></dfn>);
  <c- b>void</c-> <dfn class="idl-code" data-dfn-for="Execution" data-dfn-type="method" data-export data-lt="setOutput(name, data)" id="dom-execution-setoutput"><code><c- g>setOutput</c-></code><a class="self-link" href="#dom-execution-setoutput"></a></dfn>(<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString③"><c- b>DOMString</c-></a> <dfn class="idl-code" data-dfn-for="Execution/setOutput(name, data)" data-dfn-type="argument" data-export id="dom-execution-setoutput-name-data-name"><code><c- g>name</c-></code><a class="self-link" href="#dom-execution-setoutput-name-data-name"></a></dfn>, <a class="n" data-link-type="idl-name" href="https://heycam.github.io/webidl/#ArrayBufferView" id="ref-for-ArrayBufferView②"><c- n>ArrayBufferView</c-></a> <dfn class="idl-code" data-dfn-for="Execution/setOutput(name, data)" data-dfn-type="argument" data-export id="dom-execution-setoutput-name-data-data"><code><c- g>data</c-></code><a class="self-link" href="#dom-execution-setoutput-name-data-data"></a></dfn>);
  <c- b>Promise</c->&lt;<c- b>void</c->> <dfn class="idl-code" data-dfn-for="Execution" data-dfn-type="method" data-export data-lt="startCompute()" id="dom-execution-startcompute"><code><c- g>startCompute</c-></code><a class="self-link" href="#dom-execution-startcompute"></a></dfn>();
};
</pre>
   <h2 class="heading settled" data-level="4" id="examples"><span class="secno">4. </span><span class="content">Examples</span><a class="self-link" href="#examples"></a></h2>
   <div class="example" id="example-36ed72d9">
    <a class="self-link" href="#example-36ed72d9"></a> The following code gets the NeuralNetworkContext object. 
<pre class="highlight"><c- kr>const</c-> nn <c- o>=</c-> navigator<c- p>.</c->ml<c- p>.</c->getNeuralNetworkContext<c- p>();</c->
</pre>
   </div>
   <div class="example" id="example-3b065651">
    <a class="self-link" href="#example-3b065651"></a> The following code builds a graph as: 
<pre>constant1 ---+
             +--- Add ---> intermediateOutput1 ---+
input1    ---+                                    |
                                                  +--- Mul---> output
constant2 ---+                                    |
             +--- Add ---> intermediateOutput2 ---+
input2    ---+
</pre>
<pre class="highlight"><c- c1>// Use tensors in 4 dimensions.</c->
<c- kr>const</c-> TENSOR_DIMS <c- o>=</c-> <c- p>[</c-><c- mi>2</c-><c- p>,</c-> <c- mi>2</c-><c- p>,</c-> <c- mi>2</c-><c- p>,</c-> <c- mi>2</c-><c- p>];</c->
<c- kr>const</c-> TENSOR_SIZE <c- o>=</c-> <c- mi>16</c-><c- p>;</c->

<c- c1>// Create OperandDescriptor object.</c->
<c- kr>const</c-> float32TensorType <c- o>=</c-> <c- p>{</c->type<c- o>:</c-> <c- t>'tensor-float32'</c-><c- p>,</c-> dimensions<c- o>:</c-> TENSOR_DIMS<c- p>};</c->

<c- c1>// constant1 is a constant tensor with the value 0.5.</c->
<c- kr>const</c-> constantBuffer1 <c- o>=</c-> <c- k>new</c-> Float32Array<c- p>(</c->TENSOR_SIZE<c- p>).</c->fill<c- p>(</c-><c- mf>0.5</c-><c- p>);</c->
<c- kr>const</c-> constant1 <c- o>=</c-> nn<c- p>.</c->constant<c- p>(</c->float32TensorType<c- p>,</c-> constantBuffer1<c- p>);</c->

<c- c1>// input1 is one of the input tensors. Its value will be set before execution.</c->
<c- kr>const</c-> input1 <c- o>=</c-> nn<c- p>.</c->input<c- p>(</c-><c- t>'input1'</c-><c- p>,</c-> float32TensorType<c- p>);</c->

<c- c1>// constant2 is another constant tensor with the value 0.5.</c->
<c- kr>const</c-> constantBuffer2 <c- o>=</c-> <c- k>new</c-> Float32Array<c- p>(</c->TENSOR_SIZE<c- p>).</c->fill<c- p>(</c-><c- mf>0.5</c-><c- p>);</c->
<c- kr>const</c-> constant2 <c- o>=</c-> nn<c- p>.</c->constant<c- p>(</c->float32TensorType<c- p>,</c-> constantBuffer2<c- p>);</c->

<c- c1>// input2 is another input tensor. Its value will be set before execution.</c->
<c- kr>const</c-> input2 <c- o>=</c-> nn<c- p>.</c->input<c- p>(</c-><c- t>'input2'</c-><c- p>,</c-> float32TensorType<c- p>);</c->

<c- c1>// intermediateOutput1 is the output of the first Add operation.</c->
<c- kr>const</c-> intermediateOutput1 <c- o>=</c-> nn<c- p>.</c->add<c- p>(</c->constant1<c- p>,</c-> input1<c- p>);</c->

<c- c1>// intermediateOutput2 is the output of the second Add operation.</c->
<c- kr>const</c-> intermediateOutput2 <c- o>=</c-> nn<c- p>.</c->add<c- p>(</c->constant2<c- p>,</c-> input2<c- p>);</c->

<c- c1>// output is the output tensor of the Mul operation.</c->
<c- kr>const</c-> output <c- o>=</c-> nn<c- p>.</c->mul<c- p>(</c->intermediateOutput1<c- p>,</c-> intermediateOutput2<c- p>);</c->

<c- c1>// Create the model by identifying the outputs.</c->
<c- kr>const</c-> model <c- o>=</c-> await nn<c- p>.</c->createModel<c- p>([{</c->name<c- o>:</c-> <c- t>'output'</c-><c- p>,</c-> operand<c- o>:</c-> output<c- p>}]);</c->
</pre>
   </div>
   <div class="example" id="example-02335b34">
    <a class="self-link" href="#example-02335b34"></a> The following code compiles the model by prioritizing lower level of power consumption
over time. This option could be particularly useful for long-running models. 
<pre class="highlight"><c- c1>// Create a Compilation object for the constructed model.</c->
<c- kr>const</c-> options <c- o>=</c-> <c- p>{</c-> powerPreference<c- o>:</c-> <c- t>'low-power'</c-> <c- p>};</c->
<c- kr>const</c-> compilation <c- o>=</c-> await model<c- p>.</c->createCompilation<c- p>(</c->options<c- p>);</c->
</pre>
   </div>
   <div class="example" id="example-68ac6d9e">
    <a class="self-link" href="#example-68ac6d9e"></a> The following code executes the compiled graph. 
<pre class="highlight"><c- c1>// Create an Execution object for the compiled model.</c->
<c- kr>const</c-> execution <c- o>=</c-> await compilation<c- p>.</c->createExecution<c- p>();</c->

<c- c1>// Setup the input buffers with value 1.</c->
<c- kr>const</c-> inputBuffer1 <c- o>=</c-> <c- k>new</c-> Float32Array<c- p>(</c->TENSOR_SIZE<c- p>).</c->fill<c- p>(</c-><c- mi>1</c-><c- p>);</c->
<c- kr>const</c-> inputBuffer2 <c- o>=</c-> <c- k>new</c-> Float32Array<c- p>(</c->TENSOR_SIZE<c- p>).</c->fill<c- p>(</c-><c- mi>1</c-><c- p>);</c->

<c- c1>// Associate the input buffers to model’s inputs.</c->
execution<c- p>.</c->setInput<c- p>(</c-><c- t>'input1'</c-><c- p>,</c-> inputBuffer1<c- p>);</c->
execution<c- p>.</c->setInput<c- p>(</c-><c- t>'input2'</c-><c- p>,</c-> inputBuffer2<c- p>);</c->

<c- c1>// Associate the output buffer to model’s output.</c->
<c- a>let</c-> outputBuffer <c- o>=</c-> <c- k>new</c-> Float32Array<c- p>(</c->TENSOR_SIZE<c- p>);</c->
execution<c- p>.</c->setOutput<c- p>(</c-><c- t>'output'</c-><c- p>,</c-> outputBuffer<c- p>);</c->

<c- c1>// Start the asynchronous computation.</c->
await execution<c- p>.</c->startCompute<c- p>();</c->
<c- c1>// The computed result is now in outputBuffer.</c->
console<c- p>.</c->log<c- p>(</c->outputBuffer<c- p>);</c->
</pre>
   </div>
   <h2 class="heading settled" data-level="5" id="acknowledgements"><span class="secno">5. </span><span class="content">Acknowledgements</span><a class="self-link" href="#acknowledgements"></a></h2>
   <p>This specification follows the concepts of the Android Neural Networks API C
API.</p>
   <p>Thanks to Tomoyuki Shimizu, Ningxin Hu, Zhiqiang Yu and Belem Zhang for the use
cases.</p>
   <p>Thanks to Nikhil Thorat, Daniel Smilkov, Ganesan Ramalingam, Rafael Cintron and
Benjamin Poulain for their contributions to the API specification.</p>
  </main>
  <div data-fill-with="conformance">
   <h2 class="no-ref no-num heading settled" id="conformance"><span class="content"> Conformance</span><a class="self-link" href="#conformance"></a></h2>
   <p> Conformance requirements are expressed with a combination of descriptive assertions and RFC 2119 terminology.
            The key words “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “MAY”, and “OPTIONAL”
            in the normative parts of this document
            are to be interpreted as described in RFC 2119.
            However, for readability,
            these words do not appear in all uppercase letters in this specification. </p>
   <p> All of the text of this specification is normative
            except sections explicitly marked as non-normative, examples, and notes. <a data-link-type="biblio" href="#biblio-rfc2119">[RFC2119]</a> </p>
   <p> Examples in this specification are introduced with the words “for example”
            or are set apart from the normative text with <code>class="example"</code>, like this: </p>
   <div class="example" id="example-example"><a class="self-link" href="#example-example"></a> This is an example of an informative example. </div>
   <p> Informative notes begin with the word “Note”
            and are set apart from the normative text with <code>class="note"</code>, like this: </p>
   <p class="note" role="note"> Note, this is an informative note. </p>
  </div>
<script>
(function() {
  "use strict";
  var collapseSidebarText = '<span aria-hidden="true">←</span> '
                          + '<span>Collapse Sidebar</span>';
  var expandSidebarText   = '<span aria-hidden="true">→</span> '
                          + '<span>Pop Out Sidebar</span>';
  var tocJumpText         = '<span aria-hidden="true">↑</span> '
                          + '<span>Jump to Table of Contents</span>';

  var sidebarMedia = window.matchMedia('screen and (min-width: 78em)');
  var autoToggle   = function(e){ toggleSidebar(e.matches) };
  if(sidebarMedia.addListener) {
    sidebarMedia.addListener(autoToggle);
  }

  function toggleSidebar(on) {
    if (on == undefined) {
      on = !document.body.classList.contains('toc-sidebar');
    }

    /* Don’t scroll to compensate for the ToC if we’re above it already. */
    var headY = 0;
    var head = document.querySelector('.head');
    if (head) {
      // terrible approx of "top of ToC"
      headY += head.offsetTop + head.offsetHeight;
    }
    var skipScroll = window.scrollY < headY;

    var toggle = document.getElementById('toc-toggle');
    var tocNav = document.getElementById('toc');
    if (on) {
      var tocHeight = tocNav.offsetHeight;
      document.body.classList.add('toc-sidebar');
      document.body.classList.remove('toc-inline');
      toggle.innerHTML = collapseSidebarText;
      if (!skipScroll) {
        window.scrollBy(0, 0 - tocHeight);
      }
      tocNav.focus();
      sidebarMedia.addListener(autoToggle); // auto-collapse when out of room
    }
    else {
      document.body.classList.add('toc-inline');
      document.body.classList.remove('toc-sidebar');
      toggle.innerHTML = expandSidebarText;
      if (!skipScroll) {
        window.scrollBy(0, tocNav.offsetHeight);
      }
      if (toggle.matches(':hover')) {
        /* Unfocus button when not using keyboard navigation,
           because I don’t know where else to send the focus. */
        toggle.blur();
      }
    }
  }

  function createSidebarToggle() {
    /* Create the sidebar toggle in JS; it shouldn’t exist when JS is off. */
    var toggle = document.createElement('a');
      /* This should probably be a button, but appearance isn’t standards-track.*/
    toggle.id = 'toc-toggle';
    toggle.class = 'toc-toggle';
    toggle.href = '#toc';
    toggle.innerHTML = collapseSidebarText;

    sidebarMedia.addListener(autoToggle);
    var toggler = function(e) {
      e.preventDefault();
      sidebarMedia.removeListener(autoToggle); // persist explicit off states
      toggleSidebar();
      return false;
    }
    toggle.addEventListener('click', toggler, false);


    /* Get <nav id=toc-nav>, or make it if we don’t have one. */
    var tocNav = document.getElementById('toc-nav');
    if (!tocNav) {
      tocNav = document.createElement('p');
      tocNav.id = 'toc-nav';
      /* Prepend for better keyboard navigation */
      document.body.insertBefore(tocNav, document.body.firstChild);
    }
    /* While we’re at it, make sure we have a Jump to Toc link. */
    var tocJump = document.getElementById('toc-jump');
    if (!tocJump) {
      tocJump = document.createElement('a');
      tocJump.id = 'toc-jump';
      tocJump.href = '#toc';
      tocJump.innerHTML = tocJumpText;
      tocNav.appendChild(tocJump);
    }

    tocNav.appendChild(toggle);
  }

  var toc = document.getElementById('toc');
  if (toc) {
    createSidebarToggle();
    toggleSidebar(sidebarMedia.matches);

    /* If the sidebar has been manually opened and is currently overlaying the text
       (window too small for the MQ to add the margin to body),
       then auto-close the sidebar once you click on something in there. */
    toc.addEventListener('click', function(e) {
      if(e.target.tagName.toLowerCase() == "a" && document.body.classList.contains('toc-sidebar') && !sidebarMedia.matches) {
        toggleSidebar(false);
      }
    }, false);
  }
  else {
    console.warn("Can’t find Table of Contents. Please use <nav id='toc'> around the ToC.");
  }

  /* Wrap tables in case they overflow */
  var tables = document.querySelectorAll(':not(.overlarge) > table.data, :not(.overlarge) > table.index');
  var numTables = tables.length;
  for (var i = 0; i < numTables; i++) {
    var table = tables[i];
    var wrapper = document.createElement('div');
    wrapper.className = 'overlarge';
    table.parentNode.insertBefore(wrapper, table);
    wrapper.appendChild(table);
  }

})();
</script>
  <h2 class="no-num no-ref heading settled" id="index"><span class="content">Index</span><a class="self-link" href="#index"></a></h2>
  <h3 class="no-num no-ref heading settled" id="index-defined-here"><span class="content">Terms defined by this specification</span><a class="self-link" href="#index-defined-here"></a></h3>
  <ul class="index">
   <li><a href="#dom-neuralnetworkcontext-abs">abs(x)</a><span>, in §3.5.5</span>
   <li><a href="#dom-neuralnetworkcontext-add">add(a, b)</a><span>, in §3.5.4</span>
   <li><a href="#dom-neuralnetworkcontext-averagepool2d">averagePool2d(input)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-averagepool2d">averagePool2d(input, windowDimensions)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-averagepool2d">averagePool2d(input, windowDimensions, padding)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-averagepool2d">averagePool2d(input, windowDimensions, padding, strides)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-averagepool2d">averagePool2d(input, windowDimensions, padding, strides, dilations)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-averagepool2d">averagePool2d(input, windowDimensions, padding, strides, dilations, layout)</a><span>, in §3.5.11</span>
   <li><a href="#dom-recurrentnetworkdirection-backward">"backward"</a><span>, in §3.5.7</span>
   <li><a href="#dom-neuralnetworkcontext-batchnormalization">batchNormalization(input, mean, variance)</a><span>, in §3.5.1</span>
   <li><a href="#dom-neuralnetworkcontext-batchnormalization">batchNormalization(input, mean, variance, scale)</a><span>, in §3.5.1</span>
   <li><a href="#dom-neuralnetworkcontext-batchnormalization">batchNormalization(input, mean, variance, scale, bias)</a><span>, in §3.5.1</span>
   <li><a href="#dom-neuralnetworkcontext-batchnormalization">batchNormalization(input, mean, variance, scale, bias, axis)</a><span>, in §3.5.1</span>
   <li><a href="#dom-neuralnetworkcontext-batchnormalization">batchNormalization(input, mean, variance, scale, bias, axis, epsilon)</a><span>, in §3.5.1</span>
   <li><a href="#dom-recurrentnetworkdirection-both">"both"</a><span>, in §3.5.7</span>
   <li><a href="#dom-neuralnetworkcontext-ceil">ceil(x)</a><span>, in §3.5.5</span>
   <li><a href="#compilation">Compilation</a><span>, in §3.7</span>
   <li><a href="#dictdef-compilationoptions">CompilationOptions</a><span>, in §3.6</span>
   <li><a href="#dom-neuralnetworkcontext-concat">concat(inputs, axis)</a><span>, in §3.5.2</span>
   <li><a href="#dom-neuralnetworkcontext-constant">constant(desc, value)</a><span>, in §3.5</span>
   <li><a href="#dom-neuralnetworkcontext-constant-value-type">constant(value)</a><span>, in §3.5</span>
   <li><a href="#dom-neuralnetworkcontext-constant-value-type">constant(value, type)</a><span>, in §3.5</span>
   <li><a href="#dom-neuralnetworkcontext-conv2d">conv2d(input, filter)</a><span>, in §3.5.3</span>
   <li><a href="#dom-neuralnetworkcontext-conv2d">conv2d(input, filter, padding)</a><span>, in §3.5.3</span>
   <li><a href="#dom-neuralnetworkcontext-conv2d">conv2d(input, filter, padding, strides)</a><span>, in §3.5.3</span>
   <li><a href="#dom-neuralnetworkcontext-conv2d">conv2d(input, filter, padding, strides, dilations)</a><span>, in §3.5.3</span>
   <li><a href="#dom-neuralnetworkcontext-conv2d">conv2d(input, filter, padding, strides, dilations, groups)</a><span>, in §3.5.3</span>
   <li><a href="#dom-neuralnetworkcontext-conv2d">conv2d(input, filter, padding, strides, dilations, groups, layout)</a><span>, in §3.5.3</span>
   <li><a href="#dom-neuralnetworkcontext-cos">cos(x)</a><span>, in §3.5.5</span>
   <li><a href="#dom-model-createcompilation">createCompilation()</a><span>, in §3.6</span>
   <li><a href="#dom-model-createcompilation">createCompilation(options)</a><span>, in §3.6</span>
   <li><a href="#dom-compilation-createexecution">createExecution()</a><span>, in §3.7</span>
   <li><a href="#dom-neuralnetworkcontext-createmodel">createModel(outputs)</a><span>, in §3.5</span>
   <li><a href="#dom-powerpreference-default">"default"</a><span>, in §3.6</span>
   <li><a href="#dom-operanddescriptor-dimensions">dimensions</a><span>, in §3.3</span>
   <li><a href="#dom-neuralnetworkcontext-div">div(a, b)</a><span>, in §3.5.4</span>
   <li><a href="#execution">Execution</a><span>, in §3.8</span>
   <li><a href="#dom-neuralnetworkcontext-exp">exp(x)</a><span>, in §3.5.5</span>
   <li><a href="#dom-operandtype-float16">"float16"</a><span>, in §3.3</span>
   <li><a href="#dom-operandtype-float32">"float32"</a><span>, in §3.3</span>
   <li><a href="#dom-neuralnetworkcontext-floor">floor(x)</a><span>, in §3.5.5</span>
   <li><a href="#dom-recurrentnetworkdirection-forward">"forward"</a><span>, in §3.5.7</span>
   <li><a href="#dom-neuralnetworkcontext-gemm">gemm(a, b)</a><span>, in §3.5.6</span>
   <li><a href="#dom-neuralnetworkcontext-gemm">gemm(a, b, c)</a><span>, in §3.5.6</span>
   <li><a href="#dom-neuralnetworkcontext-gemm">gemm(a, b, c, alpha)</a><span>, in §3.5.6</span>
   <li><a href="#dom-neuralnetworkcontext-gemm">gemm(a, b, c, alpha, beta)</a><span>, in §3.5.6</span>
   <li><a href="#dom-neuralnetworkcontext-gemm">gemm(a, b, c, alpha, beta, aTranspose)</a><span>, in §3.5.6</span>
   <li><a href="#dom-neuralnetworkcontext-gemm">gemm(a, b, c, alpha, beta, aTranspose, bTranspose)</a><span>, in §3.5.6</span>
   <li><a href="#dom-ml-getneuralnetworkcontext">getNeuralNetworkContext()</a><span>, in §3.2</span>
   <li><a href="#dom-neuralnetworkcontext-grucell">gruCell(hiddenSize, input, weight, recurrentWeight, hidden)</a><span>, in §3.5.8</span>
   <li><a href="#dom-neuralnetworkcontext-grucell">gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias)</a><span>, in §3.5.8</span>
   <li><a href="#dom-neuralnetworkcontext-grucell">gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias)</a><span>, in §3.5.8</span>
   <li><a href="#dom-neuralnetworkcontext-grucell">gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter)</a><span>, in §3.5.8</span>
   <li><a href="#dom-neuralnetworkcontext-grucell">gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout)</a><span>, in §3.5.8</span>
   <li><a href="#dom-neuralnetworkcontext-grucell">gruCell(hiddenSize, input, weight, recurrentWeight, hidden, bias, recurrentBias, resetAfter, layout, activations)</a><span>, in §3.5.8</span>
   <li><a href="#dom-neuralnetworkcontext-gru">gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden)</a><span>, in §3.5.7</span>
   <li><a href="#dom-neuralnetworkcontext-gru">gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias)</a><span>, in §3.5.7</span>
   <li><a href="#dom-neuralnetworkcontext-gru">gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias)</a><span>, in §3.5.7</span>
   <li><a href="#dom-neuralnetworkcontext-gru">gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter)</a><span>, in §3.5.7</span>
   <li><a href="#dom-neuralnetworkcontext-gru">gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence)</a><span>, in §3.5.7</span>
   <li><a href="#dom-neuralnetworkcontext-gru">gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction)</a><span>, in §3.5.7</span>
   <li><a href="#dom-neuralnetworkcontext-gru">gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout)</a><span>, in §3.5.7</span>
   <li><a href="#dom-neuralnetworkcontext-gru">gru(hiddenSize, steps, input, weight, recurrentWeight, initialHidden, bias, recurrentBias, resetAfter, returnSequence, direction, layout, activations)</a><span>, in §3.5.7</span>
   <li><a href="#dom-powerpreference-high-performance">"high-performance"</a><span>, in §3.6</span>
   <li><a href="#dom-neuralnetworkcontext-input">input(name, desc)</a><span>, in §3.5</span>
   <li><a href="#dom-operandtype-int32">"int32"</a><span>, in §3.3</span>
   <li><a href="#dom-neuralnetworkcontext-l2pool2d">l2Pool2d(input)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-l2pool2d">l2Pool2d(input, windowDimensions)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-l2pool2d">l2Pool2d(input, windowDimensions, padding)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-l2pool2d">l2Pool2d(input, windowDimensions, padding, strides)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-l2pool2d">l2Pool2d(input, windowDimensions, padding, strides, dilations)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-l2pool2d">l2Pool2d(input, windowDimensions, padding, strides, dilations, layout)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-leakyrelu">leakyRelu(x)</a><span>, in §3.5.9</span>
   <li><a href="#dom-neuralnetworkcontext-leakyrelu">leakyRelu(x, alpha)</a><span>, in §3.5.9</span>
   <li><a href="#dom-neuralnetworkcontext-log">log(x)</a><span>, in §3.5.5</span>
   <li><a href="#dom-powerpreference-low-power">"low-power"</a><span>, in §3.6</span>
   <li><a href="#dom-neuralnetworkcontext-matmul">matmul(a, b)</a><span>, in §3.5.10</span>
   <li><a href="#dom-neuralnetworkcontext-max">max(a, b)</a><span>, in §3.5.4</span>
   <li><a href="#dom-neuralnetworkcontext-maxpool2d">maxPool2d(input)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-maxpool2d">maxPool2d(input, windowDimensions)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-maxpool2d">maxPool2d(input, windowDimensions, padding)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-maxpool2d">maxPool2d(input, windowDimensions, padding, strides)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-maxpool2d">maxPool2d(input, windowDimensions, padding, strides, dilations)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-maxpool2d">maxPool2d(input, windowDimensions, padding, strides, dilations, layout)</a><span>, in §3.5.11</span>
   <li><a href="#dom-neuralnetworkcontext-min">min(a, b)</a><span>, in §3.5.4</span>
   <li><a href="#ml">ML</a><span>, in §3.2</span>
   <li><a href="#dom-navigator-ml">ml</a><span>, in §3.1</span>
   <li><a href="#model">Model</a><span>, in §3.6</span>
   <li><a href="#dom-neuralnetworkcontext-mul">mul(a, b)</a><span>, in §3.5.4</span>
   <li><a href="#dom-namedoperand-name">name</a><span>, in §3.5</span>
   <li><a href="#dictdef-namedoperand">NamedOperand</a><span>, in §3.5</span>
   <li><a href="#dom-operandlayout-nchw">"nchw"</a><span>, in §3.3</span>
   <li><a href="#dom-neuralnetworkcontext-neg">neg(x)</a><span>, in §3.5.5</span>
   <li><a href="#neuralnetworkcontext">NeuralNetworkContext</a><span>, in §3.5</span>
   <li><a href="#dom-operandlayout-nhwc">"nhwc"</a><span>, in §3.3</span>
   <li><a href="#typedefdef-number">number</a><span>, in §3.5</span>
   <li><a href="#operand">Operand</a><span>, in §3.4</span>
   <li><a href="#dom-namedoperand-operand">operand</a><span>, in §3.5</span>
   <li><a href="#dictdef-operanddescriptor">OperandDescriptor</a><span>, in §3.3</span>
   <li><a href="#enumdef-operandlayout">OperandLayout</a><span>, in §3.3</span>
   <li><a href="#enumdef-operandtype">OperandType</a><span>, in §3.3</span>
   <li><a href="#enumdef-powerpreference">PowerPreference</a><span>, in §3.6</span>
   <li><a href="#dom-compilationoptions-powerpreference">powerPreference</a><span>, in §3.6</span>
   <li><a href="#enumdef-recurrentnetworkactivation">RecurrentNetworkActivation</a><span>, in §3.5.7</span>
   <li><a href="#enumdef-recurrentnetworkdirection">RecurrentNetworkDirection</a><span>, in §3.5.7</span>
   <li><a href="#enumdef-recurrentnetworkweightlayout">RecurrentNetworkWeightLayout</a><span>, in §3.5.7</span>
   <li><a href="#dom-neuralnetworkcontext-reducel1">reduceL1(input)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducel1">reduceL1(input, axes)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducel1">reduceL1(input, axes, keepDimensions)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducel2">reduceL2(input)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducel2">reduceL2(input, axes)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducel2">reduceL2(input, axes, keepDimensions)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducelogsumexp">reduceLogSumExp(input)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducelogsumexp">reduceLogSumExp(input, axes)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducelogsumexp">reduceLogSumExp(input, axes, keepDimensions)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducelogsum">reduceLogSum(input)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducelogsum">reduceLogSum(input, axes)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducelogsum">reduceLogSum(input, axes, keepDimensions)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducemax">reduceMax(input)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducemax">reduceMax(input, axes)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducemax">reduceMax(input, axes, keepDimensions)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducemean">reduceMean(input)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducemean">reduceMean(input, axes)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducemean">reduceMean(input, axes, keepDimensions)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducemin">reduceMin(input)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducemin">reduceMin(input, axe)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducemin">reduceMin(input, axe, keepDimensions)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reduceproduct">reduceProduct(input)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reduceproduct">reduceProduct(input, axes)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reduceproduct">reduceProduct(input, axes, keepDimensions)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducesum">reduceSum(input)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducesum">reduceSum(input, axes)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducesum">reduceSum(input, axes, keepDimensions)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducesumsquare">reduceSumSquare(input)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducesumsquare">reduceSumSquare(input, axes)</a><span>, in §3.5.12</span>
   <li><a href="#dom-neuralnetworkcontext-reducesumsquare">reduceSumSquare(input, axes, keepDimensions)</a><span>, in §3.5.12</span>
   <li><a href="#dom-recurrentnetworkactivation-relu">"relu"</a><span>, in §3.5.7</span>
   <li><a href="#dom-neuralnetworkcontext-relu">relu(x)</a><span>, in §3.5.13</span>
   <li><a href="#dom-neuralnetworkcontext-reshape">reshape(input, newShape)</a><span>, in §3.5.14</span>
   <li><a href="#dom-recurrentnetworkweightlayout-rzn">"rzn"</a><span>, in §3.5.7</span>
   <li><a href="#dom-operanddescriptor-scale">scale</a><span>, in §3.3</span>
   <li><a href="#dom-execution-setinput">setInput(name, data)</a><span>, in §3.8</span>
   <li><a href="#dom-execution-setoutput">setOutput(name, data)</a><span>, in §3.8</span>
   <li><a href="#dom-recurrentnetworkactivation-sigmoid">"sigmoid"</a><span>, in §3.5.7</span>
   <li><a href="#dom-neuralnetworkcontext-sigmoid">sigmoid(x)</a><span>, in §3.5.5</span>
   <li><a href="#dom-neuralnetworkcontext-sin">sin(x)</a><span>, in §3.5.5</span>
   <li><a href="#dom-neuralnetworkcontext-slice">slice(input, starts, ends)</a><span>, in §3.5.15</span>
   <li><a href="#dom-neuralnetworkcontext-softmax">softmax(x)</a><span>, in §3.5.16</span>
   <li><a href="#dom-neuralnetworkcontext-sqrt">sqrt(x)</a><span>, in §3.5.5</span>
   <li><a href="#dom-neuralnetworkcontext-squeeze">squeeze(input)</a><span>, in §3.5.17</span>
   <li><a href="#dom-neuralnetworkcontext-squeeze">squeeze(input, axes)</a><span>, in §3.5.17</span>
   <li><a href="#dom-execution-startcompute">startCompute()</a><span>, in §3.8</span>
   <li><a href="#dom-neuralnetworkcontext-sub">sub(a, b)</a><span>, in §3.5.4</span>
   <li><a href="#dom-recurrentnetworkactivation-tanh">"tanh"</a><span>, in §3.5.7</span>
   <li><a href="#dom-neuralnetworkcontext-tanh">tanh(x)</a><span>, in §3.5.5</span>
   <li><a href="#dom-neuralnetworkcontext-tan">tan(x)</a><span>, in §3.5.5</span>
   <li><a href="#dom-operandtype-tensor-float16">"tensor-float16"</a><span>, in §3.3</span>
   <li><a href="#dom-operandtype-tensor-float32">"tensor-float32"</a><span>, in §3.3</span>
   <li><a href="#dom-operandtype-tensor-int32">"tensor-int32"</a><span>, in §3.3</span>
   <li><a href="#dom-operandtype-tensor-quant8-asymm">"tensor-quant8-asymm"</a><span>, in §3.3</span>
   <li><a href="#dom-neuralnetworkcontext-transpose">transpose(input)</a><span>, in §3.5.18</span>
   <li><a href="#dom-neuralnetworkcontext-transpose">transpose(input, permutation)</a><span>, in §3.5.18</span>
   <li><a href="#dom-operanddescriptor-type">type</a><span>, in §3.3</span>
   <li><a href="#dom-operandtype-uint32">"uint32"</a><span>, in §3.3</span>
   <li><a href="#dom-operanddescriptor-zeropoint">zeroPoint</a><span>, in §3.3</span>
   <li><a href="#dom-recurrentnetworkweightlayout-zrn">"zrn"</a><span>, in §3.5.7</span>
  </ul>
  <aside class="dfn-panel" data-for="term-for-navigator">
   <a href="https://html.spec.whatwg.org/multipage/system-state.html#navigator">https://html.spec.whatwg.org/multipage/system-state.html#navigator</a><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-navigator">3.1. Navigator</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="term-for-ArrayBufferView">
   <a href="https://heycam.github.io/webidl/#ArrayBufferView">https://heycam.github.io/webidl/#ArrayBufferView</a><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-ArrayBufferView">3.5. NeuralNetworkContext</a>
    <li><a href="#ref-for-ArrayBufferView①">3.8. Execution</a> <a href="#ref-for-ArrayBufferView②">(2)</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="term-for-idl-DOMString">
   <a href="https://heycam.github.io/webidl/#idl-DOMString">https://heycam.github.io/webidl/#idl-DOMString</a><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-idl-DOMString">3.5. NeuralNetworkContext</a> <a href="#ref-for-idl-DOMString①">(2)</a>
    <li><a href="#ref-for-idl-DOMString②">3.8. Execution</a> <a href="#ref-for-idl-DOMString③">(2)</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="term-for-idl-boolean">
   <a href="https://heycam.github.io/webidl/#idl-boolean">https://heycam.github.io/webidl/#idl-boolean</a><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-idl-boolean">3.5.6. gemm</a> <a href="#ref-for-idl-boolean①">(2)</a> <a href="#ref-for-idl-boolean②">(3)</a> <a href="#ref-for-idl-boolean③">(4)</a>
    <li><a href="#ref-for-idl-boolean④">3.5.7. gru</a> <a href="#ref-for-idl-boolean⑤">(2)</a> <a href="#ref-for-idl-boolean⑥">(3)</a> <a href="#ref-for-idl-boolean⑦">(4)</a>
    <li><a href="#ref-for-idl-boolean⑧">3.5.8. gruCell</a> <a href="#ref-for-idl-boolean⑨">(2)</a>
    <li><a href="#ref-for-idl-boolean①⓪">3.5.12. reduction operations</a> <a href="#ref-for-idl-boolean①①">(2)</a> <a href="#ref-for-idl-boolean①②">(3)</a> <a href="#ref-for-idl-boolean①③">(4)</a> <a href="#ref-for-idl-boolean①④">(5)</a> <a href="#ref-for-idl-boolean①⑤">(6)</a> <a href="#ref-for-idl-boolean①⑥">(7)</a> <a href="#ref-for-idl-boolean①⑦">(8)</a> <a href="#ref-for-idl-boolean①⑧">(9)</a> <a href="#ref-for-idl-boolean①⑨">(10)</a> <a href="#ref-for-idl-boolean②⓪">(11)</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="term-for-idl-double">
   <a href="https://heycam.github.io/webidl/#idl-double">https://heycam.github.io/webidl/#idl-double</a><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-idl-double">3.5. NeuralNetworkContext</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="term-for-idl-float">
   <a href="https://heycam.github.io/webidl/#idl-float">https://heycam.github.io/webidl/#idl-float</a><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-idl-float">3.3. OperandDescriptor</a>
    <li><a href="#ref-for-idl-float①">3.5.1. batchNormalization</a> <a href="#ref-for-idl-float②">(2)</a>
    <li><a href="#ref-for-idl-float③">3.5.6. gemm</a> <a href="#ref-for-idl-float④">(2)</a> <a href="#ref-for-idl-float⑤">(3)</a> <a href="#ref-for-idl-float⑥">(4)</a>
    <li><a href="#ref-for-idl-float⑦">3.5.9. leakyRelu</a> <a href="#ref-for-idl-float⑧">(2)</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="term-for-idl-long">
   <a href="https://heycam.github.io/webidl/#idl-long">https://heycam.github.io/webidl/#idl-long</a><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-idl-long">3.3. OperandDescriptor</a> <a href="#ref-for-idl-long①">(2)</a>
    <li><a href="#ref-for-idl-long②">3.5.1. batchNormalization</a> <a href="#ref-for-idl-long③">(2)</a>
    <li><a href="#ref-for-idl-long④">3.5.2. concat</a> <a href="#ref-for-idl-long⑤">(2)</a>
    <li><a href="#ref-for-idl-long⑥">3.5.3. conv2d</a> <a href="#ref-for-idl-long⑦">(2)</a> <a href="#ref-for-idl-long⑧">(3)</a> <a href="#ref-for-idl-long⑨">(4)</a> <a href="#ref-for-idl-long①⓪">(5)</a> <a href="#ref-for-idl-long①①">(6)</a> <a href="#ref-for-idl-long①②">(7)</a> <a href="#ref-for-idl-long①③">(8)</a>
    <li><a href="#ref-for-idl-long①④">3.5.7. gru</a> <a href="#ref-for-idl-long①⑤">(2)</a> <a href="#ref-for-idl-long①⑥">(3)</a> <a href="#ref-for-idl-long①⑦">(4)</a>
    <li><a href="#ref-for-idl-long①⑧">3.5.8. gruCell</a> <a href="#ref-for-idl-long①⑨">(2)</a>
    <li><a href="#ref-for-idl-long②⓪">3.5.11. pooling operations</a> <a href="#ref-for-idl-long②①">(2)</a> <a href="#ref-for-idl-long②②">(3)</a> <a href="#ref-for-idl-long②③">(4)</a> <a href="#ref-for-idl-long②④">(5)</a> <a href="#ref-for-idl-long②⑤">(6)</a> <a href="#ref-for-idl-long②⑥">(7)</a> <a href="#ref-for-idl-long②⑦">(8)</a> <a href="#ref-for-idl-long②⑧">(9)</a> <a href="#ref-for-idl-long②⑨">(10)</a> <a href="#ref-for-idl-long③⓪">(11)</a> <a href="#ref-for-idl-long③①">(12)</a> <a href="#ref-for-idl-long③②">(13)</a> <a href="#ref-for-idl-long③③">(14)</a> <a href="#ref-for-idl-long③④">(15)</a> <a href="#ref-for-idl-long③⑤">(16)</a>
    <li><a href="#ref-for-idl-long③⑥">3.5.12. reduction operations</a> <a href="#ref-for-idl-long③⑦">(2)</a> <a href="#ref-for-idl-long③⑧">(3)</a> <a href="#ref-for-idl-long③⑨">(4)</a> <a href="#ref-for-idl-long④⓪">(5)</a> <a href="#ref-for-idl-long④①">(6)</a> <a href="#ref-for-idl-long④②">(7)</a> <a href="#ref-for-idl-long④③">(8)</a> <a href="#ref-for-idl-long④④">(9)</a> <a href="#ref-for-idl-long④⑤">(10)</a> <a href="#ref-for-idl-long④⑥">(11)</a>
    <li><a href="#ref-for-idl-long④⑦">3.5.14. reshape</a> <a href="#ref-for-idl-long④⑧">(2)</a>
    <li><a href="#ref-for-idl-long④⑨">3.5.15. slice</a> <a href="#ref-for-idl-long⑤⓪">(2)</a> <a href="#ref-for-idl-long⑤①">(3)</a> <a href="#ref-for-idl-long⑤②">(4)</a>
    <li><a href="#ref-for-idl-long⑤③">3.5.17. squeeze</a> <a href="#ref-for-idl-long⑤④">(2)</a>
    <li><a href="#ref-for-idl-long⑤⑤">3.5.18. transpose</a> <a href="#ref-for-idl-long⑤⑥">(2)</a>
   </ul>
  </aside>
  <h3 class="no-num no-ref heading settled" id="index-defined-elsewhere"><span class="content">Terms defined by reference</span><a class="self-link" href="#index-defined-elsewhere"></a></h3>
  <ul class="index">
   <li>
    <a data-link-type="biblio">[HTML]</a> defines the following terms:
    <ul>
     <li><span class="dfn-paneled" id="term-for-navigator" style="color:initial">Navigator</span>
    </ul>
   <li>
    <a data-link-type="biblio">[WebIDL]</a> defines the following terms:
    <ul>
     <li><span class="dfn-paneled" id="term-for-ArrayBufferView" style="color:initial">ArrayBufferView</span>
     <li><span class="dfn-paneled" id="term-for-idl-DOMString" style="color:initial">DOMString</span>
     <li><span class="dfn-paneled" id="term-for-idl-boolean" style="color:initial">boolean</span>
     <li><span class="dfn-paneled" id="term-for-idl-double" style="color:initial">double</span>
     <li><span class="dfn-paneled" id="term-for-idl-float" style="color:initial">float</span>
     <li><span class="dfn-paneled" id="term-for-idl-long" style="color:initial">long</span>
    </ul>
  </ul>
  <h2 class="no-num no-ref heading settled" id="references"><span class="content">References</span><a class="self-link" href="#references"></a></h2>
  <h3 class="no-num no-ref heading settled" id="normative"><span class="content">Normative References</span><a class="self-link" href="#normative"></a></h3>
  <dl>
   <dt id="biblio-html">[HTML]
   <dd>Anne van Kesteren; et al. <a href="https://html.spec.whatwg.org/multipage/">HTML Standard</a>. Living Standard. URL: <a href="https://html.spec.whatwg.org/multipage/">https://html.spec.whatwg.org/multipage/</a>
   <dt id="biblio-numpy-broadcasting-rule">[NUMPY-BROADCASTING-RULE]
   <dd>The SciPy community. <a href="https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html#general-broadcasting-rules">General Broadcasting Rules of NumPy</a>. July 2019. URL: <a href="https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html#general-broadcasting-rules">https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html#general-broadcasting-rules</a>
   <dt id="biblio-rfc2119">[RFC2119]
   <dd>S. Bradner. <a href="https://tools.ietf.org/html/rfc2119">Key words for use in RFCs to Indicate Requirement Levels</a>. March 1997. Best Current Practice. URL: <a href="https://tools.ietf.org/html/rfc2119">https://tools.ietf.org/html/rfc2119</a>
   <dt id="biblio-webidl">[WebIDL]
   <dd>Boris Zbarsky. <a href="https://heycam.github.io/webidl/">Web IDL</a>. 15 December 2016. ED. URL: <a href="https://heycam.github.io/webidl/">https://heycam.github.io/webidl/</a>
  </dl>
  <h3 class="no-num no-ref heading settled" id="informative"><span class="content">Informative References</span><a class="self-link" href="#informative"></a></h3>
  <dl>
   <dt id="biblio-contextualloss">[ContextualLoss]
   <dd>Roey Mechrez; Itamar Talmi; Lihi Zelnik-Manor. <a href="https://arxiv.org/abs/1803.02077">The Contextual Loss for Image Transformation with Non-Aligned Data</a>. July 2018. URL: <a href="https://arxiv.org/abs/1803.02077">https://arxiv.org/abs/1803.02077</a>
   <dt id="biblio-deeplabv3">[DeepLabv3+]
   <dd>Liang-Chieh Chen; et al. <a href="https://arxiv.org/abs/1802.02611">Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation</a>. August 2018. URL: <a href="https://arxiv.org/abs/1802.02611">https://arxiv.org/abs/1802.02611</a>
   <dt id="biblio-deepmoji">[DeepMoji]
   <dd>Bjarke Felbo; et al. <a href="https://arxiv.org/abs/1708.00524">Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm</a>. October 2017. URL: <a href="https://arxiv.org/abs/1708.00524">https://arxiv.org/abs/1708.00524</a>
   <dt id="biblio-elu">[ELU]
   <dd>Djork-Arné Clevert; Thomas Unterthiner; Sepp Hochreiter. <a href="https://arxiv.org/abs/1511.07289">Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)</a>. February 2016. URL: <a href="https://arxiv.org/abs/1511.07289">https://arxiv.org/abs/1511.07289</a>
   <dt id="biblio-facenet">[FaceNet]
   <dd>Florian Schroff; Dmitry Kalenichenko; James Philbin. <a href="https://arxiv.org/abs/1503.03832">FaceNet: A Unified Embedding for Face Recognition and Clustering</a>. June 2015. URL: <a href="https://arxiv.org/abs/1503.03832">https://arxiv.org/abs/1503.03832</a>
   <dt id="biblio-fan">[FAN]
   <dd>Adrian Bulat; Georgios Tzimiropoulos. <a href="https://arxiv.org/abs/1703.07332">How far are we from solving the 2D &amp; 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks)</a>. September 2017. URL: <a href="https://arxiv.org/abs/1703.07332">https://arxiv.org/abs/1703.07332</a>
   <dt id="biblio-gnmt">[GNMT]
   <dd>Minh-Thang Luong; Eugene Brevdo; Rui Zhao. <a href="https://github.com/tensorflow/nmt">Neural Machine Translation (seq2seq) Tutorial</a>. May 2017. URL: <a href="https://github.com/tensorflow/nmt">https://github.com/tensorflow/nmt</a>
   <dt id="biblio-im2txt">[IM2TXT]
   <dd>Oriol Vinyals; et al. <a href="https://arxiv.org/abs/1609.06647">Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge</a>. September 2016. URL: <a href="https://arxiv.org/abs/1609.06647">https://arxiv.org/abs/1609.06647</a>
   <dt id="biblio-leakyrelu">[LeakyReLU]
   <dd>Andrew L. Maas; Awni Y. Hannun; Andrew Y. Ng. <a href="https://pdfs.semanticscholar.org/367f/2c63a6f6a10b3b64b8729d601e69337ee3cc.pdf">Rectifier Nonlinearities Improve Neural Network Acoustic Models</a>. June 2013. URL: <a href="https://pdfs.semanticscholar.org/367f/2c63a6f6a10b3b64b8729d601e69337ee3cc.pdf">https://pdfs.semanticscholar.org/367f/2c63a6f6a10b3b64b8729d601e69337ee3cc.pdf</a>
   <dt id="biblio-maskr-cnn">[MaskR-CNN]
   <dd>Kaiming He; et al. <a href="https://arxiv.org/abs/1703.06870">Mask R-CNN</a>. January 2018. URL: <a href="https://arxiv.org/abs/1703.06870">https://arxiv.org/abs/1703.06870</a>
   <dt id="biblio-models">[Models]
   <dd>Machine Learning for the Web Community Group. <a href="https://github.com/webmachinelearning/webnn/blob/master/op_compatibility/first_wave_models.md">The first-wave models</a>. 2020. URL: <a href="https://github.com/webmachinelearning/webnn/blob/master/op_compatibility/first_wave_models.md">https://github.com/webmachinelearning/webnn/blob/master/op_compatibility/first_wave_models.md</a>
   <dt id="biblio-opennmt">[OpenNMT]
   <dd>Guillaume Klein; et al. <a href="https://arxiv.org/abs/1701.02810">OpenNMT: Open-Source Toolkit for Neural Machine Translation</a>. March 2017. URL: <a href="https://arxiv.org/abs/1701.02810">https://arxiv.org/abs/1701.02810</a>
   <dt id="biblio-pairedcyclegan">[PairedCycleGAN]
   <dd>Huiwen Chang; et al. <a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Chang_PairedCycleGAN_Asymmetric_Style_CVPR_2018_paper.html">PairedCycleGAN: Asymmetric Style Transfer for Applying and Removing Makeup</a>. June 2018. URL: <a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Chang_PairedCycleGAN_Asymmetric_Style_CVPR_2018_paper.html">http://openaccess.thecvf.com/content_cvpr_2018/html/Chang_PairedCycleGAN_Asymmetric_Style_CVPR_2018_paper.html</a>
   <dt id="biblio-posenet">[PoseNet]
   <dd>Dan Oved. <a href="https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5">Real-time Human Pose Estimation in the Browser with TensorFlow.js</a>. May 2018. URL: <a href="https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5">https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5</a>
   <dt id="biblio-rnnoise">[RNNoise]
   <dd>Jean-Marc Valin. <a href="https://github.com/xiph/rnnoise">Recurrent neural network for audio noise reduction</a>. September 2017. URL: <a href="https://github.com/xiph/rnnoise">https://github.com/xiph/rnnoise</a>
   <dt id="biblio-srgan">[SRGAN]
   <dd>Christian Ledig; et al. <a href="https://arxiv.org/abs/1609.04802">Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network</a>. May 2017. URL: <a href="https://arxiv.org/abs/1609.04802">https://arxiv.org/abs/1609.04802</a>
   <dt id="biblio-ssd">[SSD]
   <dd>Wei Liu; et al. <a href="https://arxiv.org/abs/1512.02325">SSD: Single Shot MultiBox Detector</a>. December 2016. URL: <a href="https://arxiv.org/abs/1512.02325">https://arxiv.org/abs/1512.02325</a>
   <dt id="biblio-video-summarization-with-lstm">[Video-Summarization-with-LSTM]
   <dd>Ke Zhang; et al. <a href="http://www-scf.usc.edu/~zhan355/ke_eccv2016.pdf">Video summarization with long short-term memory</a>. October 2016. URL: <a href="http://www-scf.usc.edu/~zhan355/ke_eccv2016.pdf">http://www-scf.usc.edu/~zhan355/ke_eccv2016.pdf</a>
   <dt id="biblio-yolo">[YOLO]
   <dd>Joseph Redmon; et al. <a href="https://arxiv.org/abs/1506.02640">You Only Look Once: Unified, Real-Time Object Detection</a>. May 2016. URL: <a href="https://arxiv.org/abs/1506.02640">https://arxiv.org/abs/1506.02640</a>
  </dl>
  <h2 class="no-num no-ref heading settled" id="idl-index"><span class="content">IDL Index</span><a class="self-link" href="#idl-index"></a></h2>
<pre class="idl highlight def"><c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="https://html.spec.whatwg.org/multipage/system-state.html#navigator"><c- g>Navigator</c-></a> {
  <c- b>readonly</c-> <c- b>attribute</c-> <a class="n" data-link-type="idl-name" href="#ml"><c- n>ML</c-></a> <a data-readonly data-type="ML" href="#dom-navigator-ml"><code><c- g>ml</c-></code></a>;
};

<c- b>interface</c-> <a href="#ml"><code><c- g>ML</c-></code></a> {
  <a class="n" data-link-type="idl-name" href="#neuralnetworkcontext"><c- n>NeuralNetworkContext</c-></a> <a href="#dom-ml-getneuralnetworkcontext"><code><c- g>getNeuralNetworkContext</c-></code></a>();
};

<c- b>enum</c-> <a href="#enumdef-operandlayout"><code><c- g>OperandLayout</c-></code></a> {
  <a href="#dom-operandlayout-nchw"><code><c- s>"nchw"</c-></code></a>,
  <a href="#dom-operandlayout-nhwc"><code><c- s>"nhwc"</c-></code></a>
};

<c- b>enum</c-> <a href="#enumdef-operandtype"><code><c- g>OperandType</c-></code></a> {
  <a href="#dom-operandtype-float32"><code><c- s>"float32"</c-></code></a>,
  <a href="#dom-operandtype-float16"><code><c- s>"float16"</c-></code></a>,
  <a href="#dom-operandtype-int32"><code><c- s>"int32"</c-></code></a>,
  <a href="#dom-operandtype-uint32"><code><c- s>"uint32"</c-></code></a>,
  <a href="#dom-operandtype-tensor-float32"><code><c- s>"tensor-float32"</c-></code></a>,
  <a href="#dom-operandtype-tensor-float16"><code><c- s>"tensor-float16"</c-></code></a>,
  <a href="#dom-operandtype-tensor-int32"><code><c- s>"tensor-int32"</c-></code></a>,
  <a href="#dom-operandtype-tensor-quant8-asymm"><code><c- s>"tensor-quant8-asymm"</c-></code></a>
};

<c- b>dictionary</c-> <a href="#dictdef-operanddescriptor"><code><c- g>OperandDescriptor</c-></code></a> {
  // The operand type.
  <c- b>required</c-> <a class="n" data-link-type="idl-name" href="#enumdef-operandtype"><c- n>OperandType</c-></a> <a data-type="OperandType " href="#dom-operanddescriptor-type"><code><c- g>type</c-></code></a>;

  // The dimensions field is only required for tensor operands.
  // The negative value means an unknown dimension.
  <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a data-type="sequence<long> " href="#dom-operanddescriptor-dimensions"><code><c- g>dimensions</c-></code></a>;

  // The following two fields are only required for quantized operand.
  // scale: an non-negative floating point value
  // zeroPoint: an integer, in range [0, 255]
  // The real value is (value - zeroPoint) * scale
  <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float"><c- b>float</c-></a> <a data-type="float " href="#dom-operanddescriptor-scale"><code><c- g>scale</c-></code></a>;
  <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a> <a data-type="long " href="#dom-operanddescriptor-zeropoint"><code><c- g>zeroPoint</c-></code></a>;
};

<c- b>interface</c-> <a href="#operand"><code><c- g>Operand</c-></code></a> {};

<c- b>typedef</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-double"><c- b>double</c-></a> <a href="#typedefdef-number"><code><c- g>number</c-></code></a>;

<c- b>dictionary</c-> <a href="#dictdef-namedoperand"><code><c- g>NamedOperand</c-></code></a> {
  <c- b>required</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString"><c- b>DOMString</c-></a> <a data-type="DOMString " href="#dom-namedoperand-name"><code><c- g>name</c-></code></a>;
  <c- b>required</c-> <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a data-type="Operand " href="#dom-namedoperand-operand"><code><c- g>operand</c-></code></a>;
};

<c- b>interface</c-> <a href="#neuralnetworkcontext"><code><c- g>NeuralNetworkContext</c-></code></a> {
  // Create an Operand object that represents a model input.
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-input"><code><c- g>input</c-></code></a>(<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString"><c- b>DOMString</c-></a> <a href="#dom-neuralnetworkcontext-input-name-desc-name"><code><c- g>name</c-></code></a>, <a class="n" data-link-type="idl-name" href="#dictdef-operanddescriptor"><c- n>OperandDescriptor</c-></a> <a href="#dom-neuralnetworkcontext-input-name-desc-desc"><code><c- g>desc</c-></code></a>);

  // Create an Operand object that represents a model constant.
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-constant"><code><c- g>constant</c-></code></a>(<a class="n" data-link-type="idl-name" href="#dictdef-operanddescriptor"><c- n>OperandDescriptor</c-></a> <a href="#dom-neuralnetworkcontext-constant-desc-value-desc"><code><c- g>desc</c-></code></a>, <a class="n" data-link-type="idl-name" href="https://heycam.github.io/webidl/#ArrayBufferView"><c- n>ArrayBufferView</c-></a> <a href="#dom-neuralnetworkcontext-constant-desc-value-value"><code><c- g>value</c-></code></a>);

  // Create a single-value tensor from the specified number of the specified type.
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-constant-value-type"><code><c- g>constant</c-></code></a>(<a class="n" data-link-type="idl-name" href="#typedefdef-number"><c- n>number</c-></a> <a href="#dom-neuralnetworkcontext-constant-value-type-value"><code><c- g>value</c-></code></a>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-operandtype"><c- n>OperandType</c-></a> <a href="#dom-neuralnetworkcontext-constant-value-type-type"><code><c- g>type</c-></code></a> = "float32");

  // Create a Model object by identifying output operands.
  <c- b>Promise</c->&lt;<a class="n" data-link-type="idl-name" href="#model"><c- n>Model</c-></a>> <a href="#dom-neuralnetworkcontext-createmodel"><code><c- g>createModel</c-></code></a>(<c- b>sequence</c->&lt;<a class="n" data-link-type="idl-name" href="#dictdef-namedoperand"><c- n>NamedOperand</c-></a>> <a href="#dom-neuralnetworkcontext-createmodel-outputs-outputs"><code><c- g>outputs</c-></code></a>);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-batchnormalization"><code><c- g>batchNormalization</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"><code><c- g>input</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"><code><c- g>mean</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"><code><c- g>variance</c-></code></a>, 
                             <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"><code><c- g>scale</c-></code></a>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"><code><c- g>bias</c-></code></a>, 
                             <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a> <a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"><code><c- g>axis</c-></code></a> = 1, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float"><c- b>float</c-></a> <a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"><code><c- g>epsilon</c-></code></a> = 1e-5);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-concat"><code><c- g>concat</c-></code></a>(<c- b>sequence</c->&lt;<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a>> <a href="#dom-neuralnetworkcontext-concat-inputs-axis-inputs"><code><c- g>inputs</c-></code></a>, <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a> <a href="#dom-neuralnetworkcontext-concat-inputs-axis-axis"><code><c- g>axis</c-></code></a>);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-conv2d"><code><c- g>conv2d</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-input"><code><c- g>input</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-filter"><code><c- g>filter</c-></code></a>,
                 <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-padding"><code><c- g>padding</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-strides"><code><c- g>strides</c-></code></a>, 
                 <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-dilations"><code><c- g>dilations</c-></code></a>, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a> <a href="#dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-groups"><code><c- g>groups</c-></code></a> = 1,
                 <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-operandlayout"><c- n>OperandLayout</c-></a> <a href="#dom-neuralnetworkcontext-conv2d-input-filter-padding-strides-dilations-groups-layout-layout"><code><c- g>layout</c-></code></a> = "nchw");
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-add"><code><c- g>add</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-add-a-b-a"><code><c- g>a</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-add-a-b-b"><code><c- g>b</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-sub"><code><c- g>sub</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-sub-a-b-a"><code><c- g>a</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-sub-a-b-b"><code><c- g>b</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-mul"><code><c- g>mul</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-mul-a-b-a"><code><c- g>a</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-mul-a-b-b"><code><c- g>b</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-div"><code><c- g>div</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-div-a-b-a"><code><c- g>a</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-div-a-b-b"><code><c- g>b</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-max"><code><c- g>max</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-max-a-b-a"><code><c- g>a</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-max-a-b-b"><code><c- g>b</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-min"><code><c- g>min</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-min-a-b-a"><code><c- g>a</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-min-a-b-b"><code><c- g>b</c-></code></a>);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-abs"><code><c- g>abs</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-abs-x-x"><code><c- g>x</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-ceil"><code><c- g>ceil</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-ceil-x-x"><code><c- g>x</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-cos"><code><c- g>cos</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-cos-x-x"><code><c- g>x</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-exp"><code><c- g>exp</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-exp-x-x"><code><c- g>x</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-floor"><code><c- g>floor</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-floor-x-x"><code><c- g>x</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-log"><code><c- g>log</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-log-x-x"><code><c- g>x</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-neg"><code><c- g>neg</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-neg-x-x"><code><c- g>x</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-sigmoid"><code><c- g>sigmoid</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-sigmoid-x-x"><code><c- g>x</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-sin"><code><c- g>sin</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-sin-x-x"><code><c- g>x</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-sqrt"><code><c- g>sqrt</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-sqrt-x-x"><code><c- g>x</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-tan"><code><c- g>tan</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-tan-x-x"><code><c- g>x</c-></code></a>);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-tanh"><code><c- g>tanh</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-tanh-x-x"><code><c- g>x</c-></code></a>);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-gemm"><code><c- g>gemm</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-a"><code><c- g>a</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-b"><code><c- g>b</c-></code></a>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-c"><code><c- g>c</c-></code></a>, 
               <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float"><c- b>float</c-></a> <a href="#dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-alpha"><code><c- g>alpha</c-></code></a> = 1.0, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float"><c- b>float</c-></a> <a href="#dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-beta"><code><c- g>beta</c-></code></a> = 1.0, 
               <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-atranspose"><code><c- g>aTranspose</c-></code></a> = <c- b>false</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-gemm-a-b-c-alpha-beta-atranspose-btranspose-btranspose"><code><c- g>bTranspose</c-></code></a> = <c- b>false</c->);
};

<c- b>enum</c-> <a href="#enumdef-recurrentnetworkdirection"><code><c- g>RecurrentNetworkDirection</c-></code></a> {
  <a href="#dom-recurrentnetworkdirection-forward"><code><c- s>"forward"</c-></code></a>,
  <a href="#dom-recurrentnetworkdirection-backward"><code><c- s>"backward"</c-></code></a>,
  <a href="#dom-recurrentnetworkdirection-both"><code><c- s>"both"</c-></code></a>
};

<c- b>enum</c-> <a href="#enumdef-recurrentnetworkweightlayout"><code><c- g>RecurrentNetworkWeightLayout</c-></code></a> {
  <a href="#dom-recurrentnetworkweightlayout-zrn"><code><c- s>"zrn"</c-></code></a>,  // update-reset-new gate ordering
  <a href="#dom-recurrentnetworkweightlayout-rzn"><code><c- s>"rzn"</c-></code></a>   // reset-update-new gate ordering
};

<c- b>enum</c-> <a href="#enumdef-recurrentnetworkactivation"><code><c- g>RecurrentNetworkActivation</c-></code></a> {
  <a href="#dom-recurrentnetworkactivation-relu"><code><c- s>"relu"</c-></code></a>,
  <a href="#dom-recurrentnetworkactivation-sigmoid"><code><c- s>"sigmoid"</c-></code></a>,
  <a href="#dom-recurrentnetworkactivation-tanh"><code><c- s>"tanh"</c-></code></a>
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <c- b>sequence</c->&lt;<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a>> <a href="#dom-neuralnetworkcontext-gru"><code><c- g>gru</c-></code></a>(<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a> <a href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-hiddensize"><code><c- g>hiddenSize</c-></code></a>, <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a> <a href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-steps"><code><c- g>steps</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-input"><code><c- g>input</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-weight"><code><c- g>weight</c-></code></a>, 
                        <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-recurrentweight"><code><c- g>recurrentWeight</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-initialhidden"><code><c- g>initialHidden</c-></code></a>,
                        <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-bias"><code><c- g>bias</c-></code></a>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-recurrentbias"><code><c- g>recurrentBias</c-></code></a>,
                        <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-resetafter"><code><c- g>resetAfter</c-></code></a> = <c- b>true</c->,
                        <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-returnsequence"><code><c- g>returnSequence</c-></code></a> = <c- b>false</c->,
                        <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-recurrentnetworkdirection"><c- n>RecurrentNetworkDirection</c-></a> <a href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-direction"><code><c- g>direction</c-></code></a> = "forward",
                        <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-recurrentnetworkweightlayout"><c- n>RecurrentNetworkWeightLayout</c-></a> <a href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-layout"><code><c- g>layout</c-></code></a> = "zrn",
                        <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="n" data-link-type="idl-name" href="#enumdef-recurrentnetworkactivation"><c- n>RecurrentNetworkActivation</c-></a>> <a href="#dom-neuralnetworkcontext-gru-hiddensize-steps-input-weight-recurrentweight-initialhidden-bias-recurrentbias-resetafter-returnsequence-direction-layout-activations-activations"><code><c- g>activations</c-></code></a>);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-grucell"><code><c- g>gruCell</c-></code></a>(<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a> <a href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-hiddensize"><code><c- g>hiddenSize</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-input"><code><c- g>input</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-weight"><code><c- g>weight</c-></code></a>, 
                  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-recurrentweight"><code><c- g>recurrentWeight</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-hidden"><code><c- g>hidden</c-></code></a>,
                  <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-bias"><code><c- g>bias</c-></code></a>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-recurrentbias"><code><c- g>recurrentBias</c-></code></a>,
                  <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-resetafter"><code><c- g>resetAfter</c-></code></a> = <c- b>true</c->,
                  <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-recurrentnetworkweightlayout"><c- n>RecurrentNetworkWeightLayout</c-></a> <a href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-layout"><code><c- g>layout</c-></code></a> = "zrn",
                  <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="n" data-link-type="idl-name" href="#enumdef-recurrentnetworkactivation"><c- n>RecurrentNetworkActivation</c-></a>> <a href="#dom-neuralnetworkcontext-grucell-hiddensize-input-weight-recurrentweight-hidden-bias-recurrentbias-resetafter-layout-activations-activations"><code><c- g>activations</c-></code></a>);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-leakyrelu"><code><c- g>leakyRelu</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-leakyrelu-x-alpha-x"><code><c- g>x</c-></code></a>, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float"><c- b>float</c-></a> <a href="#dom-neuralnetworkcontext-leakyrelu-x-alpha-alpha"><code><c- g>alpha</c-></code></a> = 0.01);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-matmul"><code><c- g>matmul</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-matmul-a-b-a"><code><c- g>a</c-></code></a>, <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-matmul-a-b-b"><code><c- g>b</c-></code></a>);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-averagepool2d"><code><c- g>averagePool2d</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-windowdimensions"><code><c- g>windowDimensions</c-></code></a>,
                        <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-padding"><code><c- g>padding</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-strides"><code><c- g>strides</c-></code></a>,
                        <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-dilations"><code><c- g>dilations</c-></code></a>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-operandlayout"><c- n>OperandLayout</c-></a> <a href="#dom-neuralnetworkcontext-averagepool2d-input-windowdimensions-padding-strides-dilations-layout-layout"><code><c- g>layout</c-></code></a> = "nchw");
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-l2pool2d"><code><c- g>l2Pool2d</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-windowdimensions"><code><c- g>windowDimensions</c-></code></a>,
                  <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-padding"><code><c- g>padding</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-strides"><code><c- g>strides</c-></code></a>,
                  <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-dilations"><code><c- g>dilations</c-></code></a>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-operandlayout"><c- n>OperandLayout</c-></a> <a href="#dom-neuralnetworkcontext-l2pool2d-input-windowdimensions-padding-strides-dilations-layout-layout"><code><c- g>layout</c-></code></a> = "nchw");
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-maxpool2d"><code><c- g>maxPool2d</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-windowdimensions"><code><c- g>windowDimensions</c-></code></a>,
                    <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-padding"><code><c- g>padding</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-strides"><code><c- g>strides</c-></code></a>,
                    <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-dilations"><code><c- g>dilations</c-></code></a>, <c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#enumdef-operandlayout"><c- n>OperandLayout</c-></a> <a href="#dom-neuralnetworkcontext-maxpool2d-input-windowdimensions-padding-strides-dilations-layout-layout"><code><c- g>layout</c-></code></a> = "nchw");
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducel1"><code><c- g>reduceL1</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducel1-input-axes-keepdimensions-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-reducel1-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code></a> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-reducel1-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code></a> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducel2"><code><c- g>reduceL2</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducel2-input-axes-keepdimensions-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-reducel2-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code></a> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-reducel2-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code></a> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducelogsum"><code><c- g>reduceLogSum</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducelogsum-input-axes-keepdimensions-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-reducelogsum-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code></a> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-reducelogsum-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code></a> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducelogsumexp"><code><c- g>reduceLogSumExp</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducelogsumexp-input-axes-keepdimensions-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-reducelogsumexp-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code></a> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-reducelogsumexp-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code></a> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducemax"><code><c- g>reduceMax</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducemax-input-axes-keepdimensions-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-reducemax-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code></a> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-reducemax-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code></a> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducemean"><code><c- g>reduceMean</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducemean-input-axes-keepdimensions-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-reducemean-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code></a> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-reducemean-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code></a> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducemin"><code><c- g>reduceMin</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducemin-input-axe-keepdimensions-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-reducemin-input-axe-keepdimensions-axe"><code><c- g>axe</c-></code></a> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-reducemin-input-axe-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code></a> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reduceproduct"><code><c- g>reduceProduct</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reduceproduct-input-axes-keepdimensions-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-reduceproduct-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code></a> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-reduceproduct-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code></a> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducesum"><code><c- g>reduceSum</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducesum-input-axes-keepdimensions-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-reducesum-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code></a> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-reducesum-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code></a> = <c- b>false</c->);
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducesumsquare"><code><c- g>reduceSumSquare</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reducesumsquare-input-axes-keepdimensions-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-reducesumsquare-input-axes-keepdimensions-axes"><code><c- g>axes</c-></code></a> = <c- b>null</c->, <c- b>optional</c-> <a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-boolean"><c- b>boolean</c-></a> <a href="#dom-neuralnetworkcontext-reducesumsquare-input-axes-keepdimensions-keepdimensions"><code><c- g>keepDimensions</c-></code></a> = <c- b>false</c->);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-relu"><code><c- g>relu</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-relu-x-x"><code><c- g>x</c-></code></a>);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reshape"><code><c- g>reshape</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-reshape-input-newshape-input"><code><c- g>input</c-></code></a>, <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-reshape-input-newshape-newshape"><code><c- g>newShape</c-></code></a>);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-slice"><code><c- g>slice</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-slice-input-starts-ends-input"><code><c- g>input</c-></code></a>, <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-slice-input-starts-ends-starts"><code><c- g>starts</c-></code></a>, <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-slice-input-starts-ends-ends"><code><c- g>ends</c-></code></a>);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-softmax"><code><c- g>softmax</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-softmax-x-x"><code><c- g>x</c-></code></a>);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-squeeze"><code><c- g>squeeze</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-squeeze-input-axes-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-squeeze-input-axes-axes"><code><c- g>axes</c-></code></a>);
};

<c- b>partial</c-> <c- b>interface</c-> <a class="idl-code" data-link-type="interface" href="#neuralnetworkcontext"><c- g>NeuralNetworkContext</c-></a> {
  <a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-transpose"><code><c- g>transpose</c-></code></a>(<a class="n" data-link-type="idl-name" href="#operand"><c- n>Operand</c-></a> <a href="#dom-neuralnetworkcontext-transpose-input-permutation-input"><code><c- g>input</c-></code></a>, <c- b>optional</c-> <c- b>sequence</c->&lt;<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long"><c- b>long</c-></a>> <a href="#dom-neuralnetworkcontext-transpose-input-permutation-permutation"><code><c- g>permutation</c-></code></a>);
};

<c- b>enum</c-> <a href="#enumdef-powerpreference"><code><c- g>PowerPreference</c-></code></a> {
  // Let the user agent decide the most suitable behavior. This is the default value.
  <a href="#dom-powerpreference-default"><code><c- s>"default"</c-></code></a>,
  // Prioritizes execution speed over other considerations e.g. power consumption
  <a href="#dom-powerpreference-high-performance"><code><c- s>"high-performance"</c-></code></a>,
  // Prioritizes power consumption over other considerations e.g. execution speed
  <a href="#dom-powerpreference-low-power"><code><c- s>"low-power"</c-></code></a>
};

<c- b>dictionary</c-> <a href="#dictdef-compilationoptions"><code><c- g>CompilationOptions</c-></code></a> {
  // Compilation preference as related to power consumption level
  <a class="n" data-link-type="idl-name" href="#enumdef-powerpreference"><c- n>PowerPreference</c-></a> <a data-default="&quot;default&quot;" data-type="PowerPreference " href="#dom-compilationoptions-powerpreference"><code><c- g>powerPreference</c-></code></a> = "default";
};

<c- b>interface</c-> <a href="#model"><code><c- g>Model</c-></code></a> {
  <c- b>Promise</c->&lt;<a class="n" data-link-type="idl-name" href="#compilation"><c- n>Compilation</c-></a>> <a href="#dom-model-createcompilation"><code><c- g>createCompilation</c-></code></a>(<c- b>optional</c-> <a class="n" data-link-type="idl-name" href="#dictdef-compilationoptions"><c- n>CompilationOptions</c-></a> <a href="#dom-model-createcompilation-options-options"><code><c- g>options</c-></code></a> = {});
};

<c- b>interface</c-> <a href="#compilation"><code><c- g>Compilation</c-></code></a> {
  <c- b>Promise</c->&lt;<a class="n" data-link-type="idl-name" href="#execution"><c- n>Execution</c-></a>> <a href="#dom-compilation-createexecution"><code><c- g>createExecution</c-></code></a>();
};

<c- b>interface</c-> <a href="#execution"><code><c- g>Execution</c-></code></a> {
  <c- b>void</c-> <a href="#dom-execution-setinput"><code><c- g>setInput</c-></code></a>(<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString"><c- b>DOMString</c-></a> <a href="#dom-execution-setinput-name-data-name"><code><c- g>name</c-></code></a>, <a class="n" data-link-type="idl-name" href="https://heycam.github.io/webidl/#ArrayBufferView"><c- n>ArrayBufferView</c-></a> <a href="#dom-execution-setinput-name-data-data"><code><c- g>data</c-></code></a>);
  <c- b>void</c-> <a href="#dom-execution-setoutput"><code><c- g>setOutput</c-></code></a>(<a class="idl-code" data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString"><c- b>DOMString</c-></a> <a href="#dom-execution-setoutput-name-data-name"><code><c- g>name</c-></code></a>, <a class="n" data-link-type="idl-name" href="https://heycam.github.io/webidl/#ArrayBufferView"><c- n>ArrayBufferView</c-></a> <a href="#dom-execution-setoutput-name-data-data"><code><c- g>data</c-></code></a>);
  <c- b>Promise</c->&lt;<c- b>void</c->> <a href="#dom-execution-startcompute"><code><c- g>startCompute</c-></code></a>();
};

</pre>
  <aside class="dfn-panel" data-for="ml">
   <b><a href="#ml">#ml</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-ml">3.1. Navigator</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="enumdef-operandlayout">
   <b><a href="#enumdef-operandlayout">#enumdef-operandlayout</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-enumdef-operandlayout">3.5.3. conv2d</a> <a href="#ref-for-enumdef-operandlayout①">(2)</a>
    <li><a href="#ref-for-enumdef-operandlayout②">3.5.11. pooling operations</a> <a href="#ref-for-enumdef-operandlayout③">(2)</a> <a href="#ref-for-enumdef-operandlayout④">(3)</a> <a href="#ref-for-enumdef-operandlayout⑤">(4)</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="enumdef-operandtype">
   <b><a href="#enumdef-operandtype">#enumdef-operandtype</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-enumdef-operandtype">3.3. OperandDescriptor</a>
    <li><a href="#ref-for-enumdef-operandtype①">3.5. NeuralNetworkContext</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="dictdef-operanddescriptor">
   <b><a href="#dictdef-operanddescriptor">#dictdef-operanddescriptor</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-dictdef-operanddescriptor">3.5. NeuralNetworkContext</a> <a href="#ref-for-dictdef-operanddescriptor①">(2)</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="operand">
   <b><a href="#operand">#operand</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-operand">3.5. NeuralNetworkContext</a> <a href="#ref-for-operand①">(2)</a> <a href="#ref-for-operand②">(3)</a> <a href="#ref-for-operand③">(4)</a>
    <li><a href="#ref-for-operand④">3.5.1. batchNormalization</a> <a href="#ref-for-operand⑤">(2)</a> <a href="#ref-for-operand⑥">(3)</a> <a href="#ref-for-operand⑦">(4)</a> <a href="#ref-for-operand⑧">(5)</a> <a href="#ref-for-operand⑨">(6)</a> <a href="#ref-for-operand①⓪">(7)</a> <a href="#ref-for-operand①①">(8)</a> <a href="#ref-for-operand①②">(9)</a> <a href="#ref-for-operand①③">(10)</a> <a href="#ref-for-operand①④">(11)</a> <a href="#ref-for-operand①⑤">(12)</a>
    <li><a href="#ref-for-operand①⑥">3.5.2. concat</a> <a href="#ref-for-operand①⑦">(2)</a> <a href="#ref-for-operand①⑧">(3)</a> <a href="#ref-for-operand①⑨">(4)</a>
    <li><a href="#ref-for-operand②⓪">3.5.3. conv2d</a> <a href="#ref-for-operand②①">(2)</a> <a href="#ref-for-operand②②">(3)</a> <a href="#ref-for-operand②③">(4)</a> <a href="#ref-for-operand②④">(5)</a> <a href="#ref-for-operand②⑤">(6)</a>
    <li><a href="#ref-for-operand②⑥">3.5.4. element-wise binary operations</a> <a href="#ref-for-operand②⑦">(2)</a> <a href="#ref-for-operand②⑧">(3)</a> <a href="#ref-for-operand②⑨">(4)</a> <a href="#ref-for-operand③⓪">(5)</a> <a href="#ref-for-operand③①">(6)</a> <a href="#ref-for-operand③②">(7)</a> <a href="#ref-for-operand③③">(8)</a> <a href="#ref-for-operand③④">(9)</a> <a href="#ref-for-operand③⑤">(10)</a> <a href="#ref-for-operand③⑥">(11)</a> <a href="#ref-for-operand③⑦">(12)</a> <a href="#ref-for-operand③⑧">(13)</a> <a href="#ref-for-operand③⑨">(14)</a> <a href="#ref-for-operand④⓪">(15)</a> <a href="#ref-for-operand④①">(16)</a> <a href="#ref-for-operand④②">(17)</a> <a href="#ref-for-operand④③">(18)</a> <a href="#ref-for-operand④④">(19)</a> <a href="#ref-for-operand④⑤">(20)</a> <a href="#ref-for-operand④⑥">(21)</a>
    <li><a href="#ref-for-operand④⑦">3.5.5. element-wise unary operations</a> <a href="#ref-for-operand④⑧">(2)</a> <a href="#ref-for-operand④⑨">(3)</a> <a href="#ref-for-operand⑤⓪">(4)</a> <a href="#ref-for-operand⑤①">(5)</a> <a href="#ref-for-operand⑤②">(6)</a> <a href="#ref-for-operand⑤③">(7)</a> <a href="#ref-for-operand⑤④">(8)</a> <a href="#ref-for-operand⑤⑤">(9)</a> <a href="#ref-for-operand⑤⑥">(10)</a> <a href="#ref-for-operand⑤⑦">(11)</a> <a href="#ref-for-operand⑤⑧">(12)</a> <a href="#ref-for-operand⑤⑨">(13)</a> <a href="#ref-for-operand⑥⓪">(14)</a> <a href="#ref-for-operand⑥①">(15)</a> <a href="#ref-for-operand⑥②">(16)</a> <a href="#ref-for-operand⑥③">(17)</a> <a href="#ref-for-operand⑥④">(18)</a> <a href="#ref-for-operand⑥⑤">(19)</a> <a href="#ref-for-operand⑥⑥">(20)</a> <a href="#ref-for-operand⑥⑦">(21)</a> <a href="#ref-for-operand⑥⑧">(22)</a> <a href="#ref-for-operand⑥⑨">(23)</a> <a href="#ref-for-operand⑦⓪">(24)</a> <a href="#ref-for-operand⑦①">(25)</a> <a href="#ref-for-operand⑦②">(26)</a>
    <li><a href="#ref-for-operand⑦③">3.5.6. gemm</a> <a href="#ref-for-operand⑦④">(2)</a> <a href="#ref-for-operand⑦⑤">(3)</a> <a href="#ref-for-operand⑦⑥">(4)</a> <a href="#ref-for-operand⑦⑦">(5)</a> <a href="#ref-for-operand⑦⑧">(6)</a> <a href="#ref-for-operand⑦⑨">(7)</a> <a href="#ref-for-operand⑧⓪">(8)</a>
    <li><a href="#ref-for-operand⑧①">3.5.7. gru</a> <a href="#ref-for-operand⑧②">(2)</a> <a href="#ref-for-operand⑧③">(3)</a> <a href="#ref-for-operand⑧④">(4)</a> <a href="#ref-for-operand⑧⑤">(5)</a> <a href="#ref-for-operand⑧⑥">(6)</a> <a href="#ref-for-operand⑧⑦">(7)</a> <a href="#ref-for-operand⑧⑧">(8)</a> <a href="#ref-for-operand⑧⑨">(9)</a> <a href="#ref-for-operand⑨⓪">(10)</a> <a href="#ref-for-operand⑨①">(11)</a> <a href="#ref-for-operand⑨②">(12)</a> <a href="#ref-for-operand⑨③">(13)</a> <a href="#ref-for-operand⑨④">(14)</a>
    <li><a href="#ref-for-operand⑨⑤">3.5.8. gruCell</a> <a href="#ref-for-operand⑨⑥">(2)</a> <a href="#ref-for-operand⑨⑦">(3)</a> <a href="#ref-for-operand⑨⑧">(4)</a> <a href="#ref-for-operand⑨⑨">(5)</a> <a href="#ref-for-operand①⓪⓪">(6)</a> <a href="#ref-for-operand①⓪①">(7)</a> <a href="#ref-for-operand①⓪②">(8)</a> <a href="#ref-for-operand①⓪③">(9)</a> <a href="#ref-for-operand①⓪④">(10)</a> <a href="#ref-for-operand①⓪⑤">(11)</a> <a href="#ref-for-operand①⓪⑥">(12)</a> <a href="#ref-for-operand①⓪⑦">(13)</a> <a href="#ref-for-operand①⓪⑧">(14)</a>
    <li><a href="#ref-for-operand①⓪⑨">3.5.9. leakyRelu</a> <a href="#ref-for-operand①①⓪">(2)</a> <a href="#ref-for-operand①①①">(3)</a> <a href="#ref-for-operand①①②">(4)</a>
    <li><a href="#ref-for-operand①①③">3.5.10. matmul</a> <a href="#ref-for-operand①①④">(2)</a> <a href="#ref-for-operand①①⑤">(3)</a> <a href="#ref-for-operand①①⑥">(4)</a> <a href="#ref-for-operand①①⑦">(5)</a> <a href="#ref-for-operand①①⑧">(6)</a>
    <li><a href="#ref-for-operand①①⑨">3.5.11. pooling operations</a> <a href="#ref-for-operand①②⓪">(2)</a> <a href="#ref-for-operand①②①">(3)</a> <a href="#ref-for-operand①②②">(4)</a> <a href="#ref-for-operand①②③">(5)</a> <a href="#ref-for-operand①②④">(6)</a> <a href="#ref-for-operand①②⑤">(7)</a> <a href="#ref-for-operand①②⑥">(8)</a>
    <li><a href="#ref-for-operand①②⑦">3.5.12. reduction operations</a> <a href="#ref-for-operand①②⑧">(2)</a> <a href="#ref-for-operand①②⑨">(3)</a> <a href="#ref-for-operand①③⓪">(4)</a> <a href="#ref-for-operand①③①">(5)</a> <a href="#ref-for-operand①③②">(6)</a> <a href="#ref-for-operand①③③">(7)</a> <a href="#ref-for-operand①③④">(8)</a> <a href="#ref-for-operand①③⑤">(9)</a> <a href="#ref-for-operand①③⑥">(10)</a> <a href="#ref-for-operand①③⑦">(11)</a> <a href="#ref-for-operand①③⑧">(12)</a> <a href="#ref-for-operand①③⑨">(13)</a> <a href="#ref-for-operand①④⓪">(14)</a> <a href="#ref-for-operand①④①">(15)</a> <a href="#ref-for-operand①④②">(16)</a> <a href="#ref-for-operand①④③">(17)</a> <a href="#ref-for-operand①④④">(18)</a> <a href="#ref-for-operand①④⑤">(19)</a> <a href="#ref-for-operand①④⑥">(20)</a> <a href="#ref-for-operand①④⑦">(21)</a> <a href="#ref-for-operand①④⑧">(22)</a>
    <li><a href="#ref-for-operand①④⑨">3.5.13. relu</a> <a href="#ref-for-operand①⑤⓪">(2)</a> <a href="#ref-for-operand①⑤①">(3)</a> <a href="#ref-for-operand①⑤②">(4)</a>
    <li><a href="#ref-for-operand①⑤③">3.5.14. reshape</a> <a href="#ref-for-operand①⑤④">(2)</a> <a href="#ref-for-operand①⑤⑤">(3)</a> <a href="#ref-for-operand①⑤⑥">(4)</a>
    <li><a href="#ref-for-operand①⑤⑦">3.5.15. slice</a> <a href="#ref-for-operand①⑤⑧">(2)</a> <a href="#ref-for-operand①⑤⑨">(3)</a> <a href="#ref-for-operand①⑥⓪">(4)</a>
    <li><a href="#ref-for-operand①⑥①">3.5.16. softmax</a> <a href="#ref-for-operand①⑥②">(2)</a> <a href="#ref-for-operand①⑥③">(3)</a> <a href="#ref-for-operand①⑥④">(4)</a>
    <li><a href="#ref-for-operand①⑥⑤">3.5.17. squeeze</a> <a href="#ref-for-operand①⑥⑥">(2)</a> <a href="#ref-for-operand①⑥⑦">(3)</a> <a href="#ref-for-operand①⑥⑧">(4)</a>
    <li><a href="#ref-for-operand①⑥⑨">3.5.18. transpose</a> <a href="#ref-for-operand①⑦⓪">(2)</a> <a href="#ref-for-operand①⑦①">(3)</a> <a href="#ref-for-operand①⑦②">(4)</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="typedefdef-number">
   <b><a href="#typedefdef-number">#typedefdef-number</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-typedefdef-number">3.5. NeuralNetworkContext</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="dictdef-namedoperand">
   <b><a href="#dictdef-namedoperand">#dictdef-namedoperand</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-dictdef-namedoperand">3.5. NeuralNetworkContext</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="neuralnetworkcontext">
   <b><a href="#neuralnetworkcontext">#neuralnetworkcontext</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-neuralnetworkcontext">3.2. ML</a>
    <li><a href="#ref-for-neuralnetworkcontext①">3.5. NeuralNetworkContext</a>
    <li><a href="#ref-for-neuralnetworkcontext②">3.5.1. batchNormalization</a>
    <li><a href="#ref-for-neuralnetworkcontext③">3.5.2. concat</a>
    <li><a href="#ref-for-neuralnetworkcontext④">3.5.3. conv2d</a>
    <li><a href="#ref-for-neuralnetworkcontext⑤">3.5.4. element-wise binary operations</a>
    <li><a href="#ref-for-neuralnetworkcontext⑥">3.5.5. element-wise unary operations</a>
    <li><a href="#ref-for-neuralnetworkcontext⑦">3.5.6. gemm</a>
    <li><a href="#ref-for-neuralnetworkcontext⑧">3.5.7. gru</a>
    <li><a href="#ref-for-neuralnetworkcontext⑨">3.5.8. gruCell</a>
    <li><a href="#ref-for-neuralnetworkcontext①⓪">3.5.9. leakyRelu</a>
    <li><a href="#ref-for-neuralnetworkcontext①①">3.5.10. matmul</a>
    <li><a href="#ref-for-neuralnetworkcontext①②">3.5.11. pooling operations</a>
    <li><a href="#ref-for-neuralnetworkcontext①③">3.5.12. reduction operations</a>
    <li><a href="#ref-for-neuralnetworkcontext①④">3.5.13. relu</a>
    <li><a href="#ref-for-neuralnetworkcontext①⑤">3.5.14. reshape</a>
    <li><a href="#ref-for-neuralnetworkcontext①⑥">3.5.15. slice</a>
    <li><a href="#ref-for-neuralnetworkcontext①⑦">3.5.16. softmax</a>
    <li><a href="#ref-for-neuralnetworkcontext①⑧">3.5.17. squeeze</a>
    <li><a href="#ref-for-neuralnetworkcontext①⑨">3.5.18. transpose</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="enumdef-recurrentnetworkdirection">
   <b><a href="#enumdef-recurrentnetworkdirection">#enumdef-recurrentnetworkdirection</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-enumdef-recurrentnetworkdirection">3.5.7. gru</a> <a href="#ref-for-enumdef-recurrentnetworkdirection①">(2)</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="enumdef-recurrentnetworkweightlayout">
   <b><a href="#enumdef-recurrentnetworkweightlayout">#enumdef-recurrentnetworkweightlayout</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-enumdef-recurrentnetworkweightlayout">3.5.7. gru</a> <a href="#ref-for-enumdef-recurrentnetworkweightlayout①">(2)</a>
    <li><a href="#ref-for-enumdef-recurrentnetworkweightlayout②">3.5.8. gruCell</a> <a href="#ref-for-enumdef-recurrentnetworkweightlayout③">(2)</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="enumdef-recurrentnetworkactivation">
   <b><a href="#enumdef-recurrentnetworkactivation">#enumdef-recurrentnetworkactivation</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-enumdef-recurrentnetworkactivation">3.5.7. gru</a> <a href="#ref-for-enumdef-recurrentnetworkactivation①">(2)</a>
    <li><a href="#ref-for-enumdef-recurrentnetworkactivation②">3.5.8. gruCell</a> <a href="#ref-for-enumdef-recurrentnetworkactivation③">(2)</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="enumdef-powerpreference">
   <b><a href="#enumdef-powerpreference">#enumdef-powerpreference</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-enumdef-powerpreference">3.6. Model</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="dictdef-compilationoptions">
   <b><a href="#dictdef-compilationoptions">#dictdef-compilationoptions</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-dictdef-compilationoptions">3.6. Model</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="model">
   <b><a href="#model">#model</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-model">3.5. NeuralNetworkContext</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="compilation">
   <b><a href="#compilation">#compilation</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-compilation">3.6. Model</a>
   </ul>
  </aside>
  <aside class="dfn-panel" data-for="execution">
   <b><a href="#execution">#execution</a></b><b>Referenced in:</b>
   <ul>
    <li><a href="#ref-for-execution">3.7. Compilation</a>
   </ul>
  </aside>
<script>/* script-dfn-panel */

document.body.addEventListener("click", function(e) {
    var queryAll = function(sel) { return [].slice.call(document.querySelectorAll(sel)); }
    // Find the dfn element or panel, if any, that was clicked on.
    var el = e.target;
    var target;
    var hitALink = false;
    while(el.parentElement) {
        if(el.tagName == "A") {
            // Clicking on a link in a <dfn> shouldn't summon the panel
            hitALink = true;
        }
        if(el.classList.contains("dfn-paneled")) {
            target = "dfn";
            break;
        }
        if(el.classList.contains("dfn-panel")) {
            target = "dfn-panel";
            break;
        }
        el = el.parentElement;
    }
    if(target != "dfn-panel") {
        // Turn off any currently "on" or "activated" panels.
        queryAll(".dfn-panel.on, .dfn-panel.activated").forEach(function(el){
            el.classList.remove("on");
            el.classList.remove("activated");
        });
    }
    if(target == "dfn" && !hitALink) {
        // open the panel
        var dfnPanel = document.querySelector(".dfn-panel[data-for='" + el.id + "']");
        if(dfnPanel) {
            dfnPanel.classList.add("on");
            var rect = el.getBoundingClientRect();
            dfnPanel.style.left = window.scrollX + rect.right + 5 + "px";
            dfnPanel.style.top = window.scrollY + rect.top + "px";
            var panelRect = dfnPanel.getBoundingClientRect();
            var panelWidth = panelRect.right - panelRect.left;
            if(panelRect.right > document.body.scrollWidth && (rect.left - (panelWidth + 5)) > 0) {
                // Reposition, because the panel is overflowing
                dfnPanel.style.left = window.scrollX + rect.left - (panelWidth + 5) + "px";
            }
        } else {
            console.log("Couldn't find .dfn-panel[data-for='" + el.id + "']");
        }
    } else if(target == "dfn-panel") {
        // Switch it to "activated" state, which pins it.
        el.classList.add("activated");
        el.style.left = null;
        el.style.top = null;
    }

});
</script>