<pre class='metadata'>
Title: Web Neural Network API
Shortname: webnn
Level: None
Status: w3c/ED
Group: webmlwg
TR: https://www.w3.org/TR/webnn/
URL: https://webmachinelearning.github.io/webnn/
Editor: Ningxin Hu 68202, Intel Corporation https://intel.com
Editor: Chai Chaoweeraprasit 120203, Microsoft Corporation https://microsoft.com
Abstract: This document describes a dedicated low-level API for neural network inference hardware acceleration.
Repository: https://github.com/webmachinelearning/webnn
Test Suite: https://github.com/web-platform-tests/wpt/tree/master/webnn
Implementation Report: https://wpt.fyi/results/webnn?label=master&label=experimental&aligned&q=webnn
!Explainer: <a href="https://github.com/webmachinelearning/webnn/blob/master/explainer.md">explainer.md</a>
!Polyfill: <a href="https://github.com/webmachinelearning/webnn-polyfill">webnn-polyfill</a> / <a href="https://github.com/webmachinelearning/webnn-samples">webnn-samples</a>
Markup Shorthands: markdown yes
Markup Shorthands: dfn yes
Markup Shorthands: idl yes
Markup Shorthands: css no
Logo: https://webmachinelearning.github.io/webmachinelearning-logo.png
Deadline: 2023-10-01
Status Text: <p>
  Further implementation experience and user feedback is being gathered for the
  {{MLCommandEncoder}} interface that proposes to enable more efficient WebGPU
  integration. A proposal to
  <a href="https://github.com/webmachinelearning/webnn/pull/322">simplify
  MLContext creation</a> is being discussed. This document is maintained and
  updated at any time. Some parts of this document are work in progress and
  further improvements are expected to be reflected in revised Candidate
  Recommendation Drafts and Snaphots.
  </p>
  <p>Before requesting transition to <a href="https://www.w3.org/standards/types#PR">Proposed Recommendation</a>, the Working Group will seek to demonstrate that:</p>
  <ul>
  <li>the API is implementable on top of existing APIs of major platforms, such as Android, Windows and macOS/iOS;</li>
  <li>it has at least two independent, interoperable implementations of every feature defined in the specification, where interoperability can be verified by passing open test suites, and two or more implementations interoperating with each other;</li>
  <li>it has an open test suite of every feature defined in the specification.</li>
  </ul>

</pre>
<pre class="anchors">
urlPrefix: https://gpuweb.github.io/gpuweb/; spec: WEBGPU
    type: interface
        text: GPUDevice; url: gpu-device
        text: GPUBuffer; url: buffer-interface
        for: GPUBuffer; text: size; url: dom-gpubuffer-size
        text: GPUTexture; url: texture-interface
        text: GPUQueue; url: queues
        text: GPUCommandBuffer; url: command-buffers
        text: GPUCommandBufferDescriptor; url: dictdef-gpucommandbufferdescriptor
urlPrefix: https://tc39.es/ecma262/; spec: ECMA-262
    type: dfn
        text: element size; url: table-the-typedarray-constructors
        text: element type; url: table-the-typedarray-constructors
        text: view constructor; url: table-the-typedarray-constructors
        text: Construct; url: sec-construct
urlPrefix: https://webidl.spec.whatwg.org/; spec: WEBIDL
    type: interface
        text: Promise; url: idl-promise
        text: nullable; url: idl-nullable-type
    type: dfn
        text: underlying buffer; url: buffersource-underlying-buffer
        text: buffer byte length; url: buffersource-byte-length
urlPrefix: https://tc39.es/proposal-float16array/; spec: float16array
    type: interface
        text: Float16Array; url: sec-float16array
</pre>
<pre class="biblio">
{
    "WEBGPU": {
        "authors": [
            "Dzmitry Malyshau",
            "Kai Ninomiya"
        ],
        "href": "https://gpuweb.github.io/gpuweb/",
        "title": "WebGPU",
        "status": "ED",
        "publisher": "W3C",
        "deliveredBy": [
            "https://www.w3.org/2020/gpu/"
        ]
    }
}
</pre>

<pre class="link-defaults">
spec:html;
    type:interface; text:Navigator
spec:webidl;
    type:dfn; text:record
    type:dfn; text:resolve
</pre>

<style>
/* Make <dl> blocks more distinct from their surroundings. */
main dl:not(.switch) {
    border-left: thin solid #f3e48c;
    padding-left: .5em;
}

/* <p> by default has these margins. Update ul/ol/dl to match,
 * since they are also put in places where paragraphs go. */
p, ul, ol, dl {
    margin: 1em 0;
}

/*
 * Stylistic labels, for clarity of presentation of these blocks.
 *
 * NOTE: This text is non-accessible and non-selectable; surrounding
 * text must also explain the context.
 */

/* Box for Valid Usage requirements. */
div.validusage {
    padding: .5em;
    border: thin solid #88e !important;
    border-radius: .5em;
}
.validusage {
    position: relative;
}
.validusage::before {
    font-weight: bold;
    font-style: italic;
    font-size: 130%;
    color: rgba(0, 0, 0, 0.15);
    color: var(--watermark-text);
    position: absolute;
    right: .3em;
    top: -.1em;
}
.validusage::before {
    content: "Valid Usage";
}

details {
    padding: .5em;
    border: thin solid #88e !important;
    border-radius: .5em;
}

summary {
    font-weight: bold;
    margin: -0.5em -0.5em 0;
    padding: 0.5em;
}

/* Box for algorithm steps. */

div.algorithm-steps {
    padding: .5em;
    background-color: ghostwhite;
}

.algorithm-steps {
    position: relative;
    overflow: hidden;
}
.algorithm-steps::after {
    font-weight: bold;
    font-style: italic;
    font-size: 130%;
    color: rgba(0, 0, 0, 0.15);
    color: var(--watermark-text);
    position: absolute;
    right: .3em;
    bottom: .1em;
}
.algorithm-steps::after {
    content: "Algorithm";
}

/* Informal steps */
div.informalsteps {
    padding: .5em;
    border: thin solid #88e !important;
    border-radius: .5em;
    background-color: ghostwhite;
}

.informalsteps {
    position: relative;
}
.informalsteps::after {
    font-weight: bold;
    font-style: italic;
    font-size: 130%;
    color: rgba(0, 0, 0, 0.15);
    color: var(--watermark-text);
    position: absolute;
    right: .3em;
    bottom: .1em;
}
.informalsteps::after {
    content: "Non-normative";
}

/* Internal slots */
div.internal-slots {
    padding: .5em;
    border: thin solid #88e !important;
    border-radius: .5em;
    background-color: aliceblue;
}

.internal-slots {
    position: relative;
}
.internal-slots::after {
    font-weight: bold;
    font-style: italic;
    font-size: 130%;
    color: rgba(0, 0, 0, 0.15);
    color: var(--watermark-text);
    position: absolute;
    right: .3em;
    bottom: .1em;
}

/*
 * Ensure that argumentdef blocks don't overflow algorithm section borders. This is made far harder
 * than it needs to be because the top-level W3C stylesheet has several @media + min-width variants
 * that mark themselves as !important and then proceed to do the wrong thing.
 */
@media screen and (min-width: 78em) {
    body:not(.toc-inline) .algorithm .overlarge {
        margin-right: auto !important;
    }
}
@media screen and (min-width: 90em) {
    body:not(.toc-inline) .algorithm .overlarge {
        margin-right: auto !important;
    }
}
.algorithm .overlarge {
    margin-right: auto !important;
}

/*
 * The default algorithm style has a caption that doesn't suit this spec's
 * formatting particularly well. Hide it.
 */
.algorithm .argumentdef {
    margin-top: 0;
}
.algorithm .argumentdef>caption {
    display: none;
}

/*
 * Add vertical lines to demarcate multi-column cells.
 */
table.data td[colspan] {
    border-left-style: dotted;
    border-right-style: dotted;
}

table.data.no-colspan-center td[colspan],
table.data.no-colspan-center th[colspan] {
    text-align: unset;
}

table.data tr.row-continuation td,
table.data tr.row-continuation th {
    border-top: none;
}

/*
 * Sticky table headers.
 */
.overlarge {
    /* position: sticky doesn't work inside scrollable elements. */
    overflow-x: unset;
}
thead.stickyheader th, th.stickyheader {
    position: sticky;
    top: 0;
    background: #f8f8f8;
    background: var(--stickyheader-background);
}

/*
 * Generic table format.
 */
th {
  text-align: left;
}

th, td {
  border-bottom: 1px solid black;
  border-collapse: collapse;
  padding-left: 5px;
  padding-right: 5px;
}

/*
 * Darkmode colors
 */
:root {
    --watermark-text: rgba(0, 0, 0, 15%);
    --stickyheader-background: #f8f8f8;
    --tint-red: rgba(255, 0, 0, 6%);
    --tint-green: rgba(0, 255, 0, 10%);
    --tint-blue: rgba(0, 0, 255, 5%);
    --tint-purple: rgba(255, 0, 255, 5%);
}
@media (prefers-color-scheme:dark) {
    :root {
        --watermark-text: rgba(255, 255, 255, 25%);
        --stickyheader-background: #181818;
        --tint-red: rgba(255, 0, 0, 20%);
        --tint-green: rgba(0, 255, 0, 18%);
        --tint-blue: rgba(0, 130, 255, 24%);
        --tint-purple: rgba(255, 0, 255, 22%);
    }
}


/* Floating button for collapse/expand all details elements */

.collapse-expand-button {
  position: fixed;
  bottom: 40px;
  right: 40px;
  width: 40px;
  height: 40px;
  border: none;
  border-radius: 50%;
  background-color: green;
  color: ghostwhite;
  font-size: 32px;
  text-align: center;
  align-items:center;
  justify-content:center;
  cursor: pointer;
}

.collapse-expand-button:hover {
  background-color: green;
}

.collapse-expand-button.expand {
  background-color: red;
}

.collapse-expand-button.expand::before {
  content: "+";
}

.collapse-expand-button.collapse {
  background-color: green;
}

.collapse-expand-button.collapse::before {
  content: "-";
}

.collapse-expand-button .tooltiptext {
  visibility: hidden;
  bottom: 20px;
  right: 20px;
  width: 120px;
  background-color: ghostwhite;
  color: black;
  font-size: 18px;
  text-align: center;
  align-items:center;
  justify-content:center;
  padding: 5px 0;
  border-radius: 5px;

  /* position */
  position: absolute;
  z-index: 1;
  bottom: 100%;
  left: 50%;
  margin-left: -60px;
      /* Use half of the width (120/2 = 60), to center the tooltip */
}

.collapse-expand-button:hover .tooltiptext {
  visibility: visible;
  opacity: 0.75;
}

/* end of floating collapse/expand button */

</style>

<button class="collapse-expand-button" onclick="toggleCE()">
    <span class="tooltiptext">Collapse all</span>
</button>

<script>
    var ceButton = document.querySelector(".collapse-expand-button");
    ceButton.classList.add("collapse");  // All details are expanded by default.
    var scrollY = window.scrollY;
    window.addEventListener('scroll', function() {
        scrollY = window.scrollY;
        ceButton.style.top = scrollY + window.innerHeight - 60 + 'px';
    });

    function toggleCE() {
        var button = document.querySelector(".collapse-expand-button");
        var tip = document.querySelector(".tooltiptext");
        var allDetails = document.querySelectorAll('details');

        Array.from(allDetails).forEach(function(detail, index) {
            if (button.classList.contains("expand")) {
                detail.open = true;
            } else {
                detail.removeAttribute('open');
            }
        });

        if (button.classList.contains("expand")) {
            button.classList.remove("expand");
            button.classList.add("collapse");
            tip.innerHTML = "Collapse all";
        } else {
            button.classList.remove("collapse");
            button.classList.add("expand");
            tip.innerHTML = "Expand all";
        }
    }
</script>

Introduction {#intro}
=====================

The Web Neural Network API defines a web-friendly hardware-agnostic abstraction layer that makes use of Machine Learning capabilities of operating systems and underlying hardware platforms without being tied to platform-specific capabilities. The abstraction layer addresses the requirements of key Machine Learning JavaScript frameworks and also allows web developers familiar with the ML domain to write custom code without the help of libraries. A complementary <a href="https://webmachinelearning.github.io/model-loader/">Model Loader API</a> defines a higher-level abstraction targeting primarily web developers.

For an illustrated introduction, please see the <a href="https://github.com/webmachinelearning/webnn/blob/master/explainer.md">explainer</a>.

Use cases {#usecases}
=====================

## Application Use Cases ## {#usecases-application}

This section illustrates application-level use cases for neural network
inference hardware acceleration. All applications in those use cases can be
built on top of pre-trained deep neural network (DNN) [[models]].

Note: Please be aware that some of the use cases described here, are by their very nature, privacy-invasive. Developers who are planning to use the API for such use cases should ensure that the API is being used to benefit users, for purposes that users understand, and approve. They should apply the Ethical Principles for Web Machine Learning [[webmachinelearning-ethics]] and implement appropriate privacy risk mitigations such as transparency, data minimisation, and users controls.

### Person Detection ### {#usecase-person-detection}

A user opens a web-based video conferencing application, but she temporarily
leaves from her room. The application is watching whether she is in front of her
PC by using object detection (for example, using object detection approaches
such as [[SSD]] or [[YOLO]] that use a single DNN) to detect regions in a camera
input frame that include persons.

When she comes back, the application automatically detects her and notifies
other online users that she is active now.

### Semantic Segmentation ### {#usecase-segmentation}

A user joins a teleconference via a web-based video conferencing application at
her desk since no meeting room in her office is available. During the
teleconference, she does not wish that her room and people in the background are
visible. To protect the privacy of the other people and the surroundings, the
application runs a machine learning model such as [[DeepLabv3+]] or
[[MaskR-CNN]] to semantically split an image into segments and replaces
segments that represent other people and background with another picture.

### Skeleton Detection ### {#usecase-skeleton-detection}

A web-based video conferencing application tracks a pose of user's skeleton by
running a machine learning model, which allows for real-time human pose
estimation, such as [[PoseNet]] to recognize her gesture and body language. When
she raises her hand, her microphone is automatically unmuted and she can start
speaking on the teleconference.

### Face Recognition ### {#usecase-face-recognition}

There are multiple people in the conference room and they join an online meeting
using a web-based video conferencing application. The application detects faces
of participants by using object detection (for example, using object detection
approaches such as [[SSD]]) and checks whether each face was present at the
previous meeting or not by running a machine learning model such as [[FaceNet]],
which verifies whether two faces would be identical or not.

### Facial Landmark Detection ### {#usecase-facial-landmarks}

A user wants to find new glasses that beautifully fits her on an online glasses
store. The online store offers web-based try-on simulator that runs a machine
learning model such as Face Alignment Network [[FAN]] to detect facial landmarks
like eyes, nose, mouth, etc. When she chooses a pair of glasses, the simulator
properly renders the selected glasses on the detected position of eyes on her
facial image.

### Style Transfer ### {#usecase-style-transfer}

A user is looking for cosmetics on an online store and wondering which color may
fit her face. The online store shows sample facial makeup images of cosmetics,
and offers makeup simulator that runs a machine learning model like
[[ContextualLoss]] or [[PairedCycleGAN]] to transfer the makeup style of the
sample makeup image to her facial image. She can check how the selected makeup
looks like on her face by the simulator.

### Super Resolution ### {#usecase-super-resolution}

A web-based video conferencing is receiving a video stream from its peer, but
the resolution of the video becomes lower due to network congestion. To prevent
degradation of the perceived video quality, the application runs a machine
learning model for super-resolution such as [[SRGAN]] to generate
higher-resolution video frames.

### Image Captioning ### {#usecase-image-captioning}

For better accessibility, a web-based presentation application provides
automatic image captioning by running a machine learning model such as
[[im2txt]] which predicts explanatory words of the presentation slides.

### Machine Translation ### {#usecase-translation}

Multiple people from various countries are talking via a web-based real-time
text chat application. The application translates their conversation by using a
machine learning model such as [[GNMT]] or [[OpenNMT]], which translates every
text into different language.

### Emotion Analysis ### {#usecase-emotion-analysis}

A user is talking to her friend via a web-based real-time text chat application,
and she is wondering how the friend feels because she cannot see the friend's
face. The application analyses the friend's emotion by using a machine learning
model such as [[DeepMoji]], which infers emotion from input texts, and displays
an emoji that represents the estimated emotion.

### Video Summarization ### {#usecase-video-summalization}

A web-based video conferencing application records received video streams, and
it needs to reduce recorded video data to be stored. The application generates
the short version of the recorded video by using a machine learning model for
video summarization such as [[Video-Summarization-with-LSTM]].

### Noise Suppression ### {#usecase-noise-suppression}

A web-based video conferencing application records received audio streams, but
usually the background noise is everywhere. The application leverages real-time
noise suppression using Recurrent Neural Network such as [[RNNoise]] for
suppressing background dynamic noise like baby cry or dog barking to improve
audio experiences in video conferences.

### Detecting fake video ### {#usecase-detecting-fake-video}

A user is exposed to realistic fake videos generated by ‘deepfake’ on the web.
The fake video can swap the speaker’s face into the president’s face to incite
a user politically or to manipulate user’s opinion. The deepfake detection
applications such as [[FaceForensics++]] analyze the videos and protect a user against
the fake videos or images. When she watches a fake video on the web, the
detection application alerts her of the fraud video in real-time.

## Framework Use Cases ## {#usecases-framework}

This section collects framework-level use cases for a dedicated low-level API
for neural network inference hardware acceleration. It is expected that Machine
Learning frameworks will be key consumers of the Web Neural Network API (WebNN
API) and the low-level details exposed through the WebNN API are abstracted out
from typical web developers. However, it is also expected that web developers
with specific interest and competence in Machine Learning will want to interface
with the WebNN API directly instead of a higher-level ML framework.

### Custom Layer ### {#usecase-custom-layer}

A web application developer wants to run a DNN model on the WebNN API. However,
she has found that some of activation functions like [[LeakyReLU]], [[ELU]],
etc. are not included in the WebNN API. To address this issue, she constructs
custom layers of the additional activation functions on top of the WebNN API.
Note that the scope of custom layers may include convolution, normalization,
etc. as well as activation.

### Network Concatenation ### {#usecase-network-concat}

A web application uses a DNN model, and its model data of upper convolutional
layers and lower fully-connected layers are stored in separate files, since
model data of the fully-connected layers are periodically updated due to fine
tuning at the server side.

Therefore, the application downloads both partial model files at first and
concatenates them into a single model. When the model is updated, the
application downloads fine-tuned part of the model and replace only the
fully-connected layers with it.

### Performance Adaptation ### {#usecase-perf-adapt}

A web application developer has a concern about performance of her DNN model on
mobile devices. She has confirmed that it may run too slow on mobile devices
which do not have GPU acceleration. To address this issue, her web application
refers to the WebNN API to confirm whether acceleration is available or not, so
that the application can display the warning for devices without acceleration.

After several weeks, she has developed a tiny DNN model that can even run on
CPU. In order to accommodate CPU execution, she modifies the application
so that the application loads the tiny model in the case of CPU-only devices.

### Operation Level Execution ### {#usecase-op-level-exec}

A JavaScript ML framework is responsible for loading, interpreting and executing a ML model. During the model execution phase, the framework iterates through the operations of the model and executes each operation on the hardware device, like CPU, GPU or ML accelerator. To avoid the unnecessary data copying across devices, the framework selects the same device to execute the operations. For a compute intensive operation, such as convolution 2D or matrix multiplication, the framework uses WebNN API to execute it with the ML-specific acceleration available on that selected device.

### Integration with real-time video processing ### {#usecase-real-time-video-processing}

The user experience of WebRTC-based video conferencing is enhanced using real-time video processing. For example, background blur implemented using a [[#usecase-segmentation]] model blurs the background in the user's live camera feed. To satisfy the performance requirements of this use case, the WebNN API integrates with primitives from other Web APIs that make up the media pipeline to allow WebNN API-based transformation of real-time video streams.

Security Considerations {#security}
===================================
This specification defines a low-level API for neural network inference hardware acceleration. This API is considered a powerful feature [[POWERFUL-FEATURES]] because it grants low-level access to a user's computer. To meet the authentication and confidentiality expectations of a powerful feature and to prevent man-in-the-middle attacks, all interfaces defined by this specification are only available in a secure context.

This API is disabled by default in all cross-origin frames using the [[#permissions-policy-integration]]. This prevents third-party content from using this API unless the embedding page explicitly sets a policy that grants permission.

This API allows creation of an {{MLContext}} from a {{GPUDevice}} defined by WebGPU specification. See <a href="https://gpuweb.github.io/gpuweb/#security-considerations">WebGPU Security Considerations</a> for more information regarding security characteristics of this context.

Once the graph is fully constructed and compiled, the input shapes into each of the operations in the graph are inferred and finalized. The bounds checking occurs when the compute method is invoked that executes the graph against the actual data. No actual data is bound to the compiled graph before this stage. It is the implementation's responsibility to make sure proper bounds checking occurs against the shapes of the data already inferred by that time.

Issue: Document operations susceptible to out-of-bounds access as a guidance to implementers.

As a future-proofing measure, the API design allows certain operations that can be generically emulated to be deprecated for security, performance, or other reasons without breaking compatibility. This is made possible by high-level functions that are defined in terms of smaller primitive operations defined in this specifications. This enables a native implementation of a high-level function to be replaced with a polyfill implementation.

Issue: Investigate side channel attack feasibility considering the current state where CPU is shared between processes running renderers.

In order to not allow an attacker to target a specific implementation that may contain a flaw, the [[#programming-model-device-selection]] mechanism is a hint only, and the concrete device selection is left to the implementation - a user agent could for instance choose never to run a model on a device with known vulnerabilities. As a further mitigation, no device enumeration mechanism is defined.

Issue: Hinting partially mitigates the concern. Investigate additional mitigations.

The API design minimizes the attack surface for the compiled computational graph. The {{MLGraphBuilder}} interface that hosts the various operations is a data definition API and as such doesn't execute anything, only constructs data. What follows, is that the potential for an attack is limited to when binding the data to the graph before executing it by invoking the {{MLContext}}.{{MLContext/compute()}} method. This enables implementers to focus on hardening the {{MLContext}}.{{MLContext/compute()}} method. For example, by making sure it honors the boundary of data and fails appropriately when the bounds are not respected.

Purpose-built Web APIs for measuring high-resolution time mitigate against timing attacks using techniques such as resolution reduction, adding jitter, detection of abuse and API call throttling [[hr-time-3]]. The practical deployment of WebNN implementations are likely to bring enough jitter to make timing attacks impractical (e.g. because they would use IPC) but implementers are advised to consider and test their implementations against timing attacks.

## Guidelines for new operations ## {#security-new-ops}

To ensure operations defined in this specification are shaped in a way they can be implemented securely, this section includes guidelines on how operations are expected to be defined to reduce potential for implementation problems. These guidelines are expected to evolve over time to align with industry best practices:

- Prefer simplicity of arguments
- Don't use parsers for complex data formats
- If an operation can be decomposed to low level primitives:
    - Add an informative emulation path
    - Prefer primitives over new high level operations but consider performance consequences
- Operations should follow a consistent style for inputs and attributes
- Operation families such as pooling and reduction should share API shape and options
- Formalize failure cases into test cases whenever possible
- When in doubt, leave it out: API surface should be as small as possible required to satisfy the use cases, but no smaller
- Try to keep the API free of implementation details that might inhibit future evolution, do not overspecify
- Fail fast: the sooner the web developer is informed of an issue, the better

In general, always consider the security and privacy implications as documented in [[security-privacy-questionnaire]] by the Technical Architecture Group and the Privacy Interest Group when adding new features.

Privacy Considerations {#privacy}
===================================

This API enhances privacy compared to cloud-based inference, since input data such as locally sourced images or video streams stay within the browser's sandbox.

This API exposes the minimum amount of information necessary to address the identified [[#usecases]] for the best performance and reliability of results.

No information from the underlying platform is exposed directly. An execution time analysis may reveal indirectly the performance of the underlying platform's neural network hardware acceleration capabilities relative to another underlying platform.

Note: The group is <a href="https://github.com/webmachinelearning/webnn/issues/85">soliciting further input</a> on the proposed execution time analysis fingerprinting vector and will augment this section with more information and mitigations to inform the implementers of this API.

Unlike WebGPU, this API does not intrinsically support custom shader authoring; and as a result is not prone to timing attacks that rely on shader caches, or other persistent data. The API builds upon pre-existing shaders and lower level primitives of the browser or the underlying OS. Web developers who interface with {{GPUDevice}} are expected to be aware of <a href="https://gpuweb.github.io/gpuweb/#privacy-user-agent-state">WebGPU compilation cache considerations</a>.

The WebGPU API identifies <a href="https://gpuweb.github.io/gpuweb/#privacy-machine-artifacts">machine-specific artifacts</a> as a privacy consideration. Given the WebNN API defines means to record an ML workload onto a WebGPU-compatible {{GPUCommandBuffer}}, compute unit scheduling may under certain circumstances introduce a fingerprint. However, similarly to WebGPU, such fingerprints are identical across most or all of the devices of each vendor, mitigating the concern. Furthermore, software implementations can be used to further eliminate such artifacts.

The WebNN API defines two developer-settable preferences to help inform [[#programming-model-device-selection]] and allow the implementation to better select the most appropriate underlying execution device for the workload. [=Device type=] normatively indicates the kind of device and is either "cpu" or "gpu". If this type cannot be satisfied, an "{{OperationError}}" {{DOMException}} is thrown, thus this type can in some cases add two bits of entropy to the fingerprint. [=Power preference=] indicates preference as related to the power consumption and is considered a hint only and as such does not increase entropy of the fingerprint.

If a future version of this specification introduces support for new a  [=device type=] that can only support a subset of {{MLOperandType}}s, that may introduce a new fingerprint.

In general, implementers of this API are expected to apply <a href="https://gpuweb.github.io/gpuweb/#privacy-considerations">WebGPU Privacy Considerations</a> to their implementations where applicable.


Ethical Considerations {#ethics}
===================================

The Working Group has started documenting ethical issues associated with using Machine Learning on the Web, to help identify what mitigations its normative specifications should take into account. The Working Group publishes and maintains an Ethical Principles for Web Machine Learning document [[webmachinelearning-ethics]] open to contributions from the wider community via a dedicated <a href="https://github.com/webmachinelearning/webmachinelearning-ethics">GitHub repository</a>.

# Programming Model # {#programming-model}
## Overview ## {#programming-model-overview}

At the heart of neural networks is a computational graph of mathematical operations.
These operations are the building blocks of modern machine learning technologies in
computer vision, natural language processing, and robotics.
The WebNN API is a specification for constructing, compiling, and executing computational
graphs of neural networks.

The {{MLGraph}} interface represents a compiled computational graph that is immutable (that is, a model).

The {{MLGraphBuilder}} interface serves as a builder (factory) to create an {{MLGraph}}.
An {{MLOperand}} is a representation of data that flows within the computational graph,
which include input-values for inference, constants (including trained weights)
used for inference, intermediate values (often referred to as activations) computed
during inference, as well as the output values of inference.
At inference time, every {{MLOperand}} will be bound to a tensor (the actual data).

The {{MLGraphBuilder}} interface enables the creation of {{MLOperand}}s.
A key part of the {{MLGraphBuilder}} interface are the operations (such as
{{MLGraphBuilder}}.{{MLGraphBuilder/gemm()}} and {{MLGraphBuilder}}.{{MLGraphBuilder/softmax()}}). The operations have a functional
semantics, with no side effects.
Each operation invocation conceptually returns a distinct new value, without
changing the value of any other {{MLOperand}}.

The runtime values (of {{MLOperand}}s) are tensors, which are essentially multidimensional
arrays. The representation of the tensors is implementation dependent, but it typically
includes the array data stored in some buffer (memory) and some metadata describing the
array data (such as its shape).

As mentioned above, the operations have a functional semantics. This allows the implementation
to potentially share the array data between multiple tensors. For example, the implementation
of operations such as reshape, or slice, or squeeze may return a view of its input tensor
that shares the same buffer as the input tensor. (In the case of reshape or squeeze,
the entire data is shared, while in the case of slice, a part of the input data is shared.)
The implementation may use views, as above, for intermediate values.

Before the execution, the computation graph that is used to compute one or more specified outputs needs to be compiled and optimized. The key purpose of the compilation step is to enable optimizations that span two or more operations, such as operation or loop fusion.

There are multiple ways by which the graph may be compiled. The {{MLGraphBuilder}}.{{MLGraphBuilder/build()}} method compiles the graph in the background without blocking the calling thread, and returns a {{Promise}} that resolves to an {{MLGraph}}. The {{MLGraphBuilder}}.{{MLGraphBuilder/buildSync()}} method compiles the graph immediately on the calling thread, which must be a worker thread running on CPU or GPU device, and returns an {{MLGraph}}. Both compilation methods produce an {{MLGraph}} that represents a compiled graph for optimal execution.

Once the {{MLGraph}} is constructed, there are multiple ways by which the graph may be executed. The
{{MLContext}}.{{MLContext/computeSync()}} method represents a way the execution of the graph is carried out immediately
on the calling thread, which must also be a worker thread, either on a CPU or GPU device. The execution
produces the results of the computation from all the inputs bound to the graph.

The {{MLContext}}.{{MLContext/compute()}} method represents a way the execution of the graph is performed asynchronously
either on a parallel timeline in a separate worker thread for the CPU execution or on a GPU timeline in a GPU
command queue. This method returns immediately without blocking the calling thread while the actual execution is
offloaded to a different timeline. This type of execution is appropriate when the responsiveness of the calling
thread is critical to good user experience. The computation results will be placed at the bound outputs at the
time the operation is successfully completed on the offloaded timeline at which time the calling thread is
signaled. This type of execution supports both the CPU and GPU device.

In both the {{MLContext}}.{{MLContext/compute()}} and {{MLContext}}.{{MLContext/computeSync()}} execution methods, the caller supplies
the input values using {{MLNamedArrayBufferViews}}, binding the input {{MLOperand}}s to their values. The caller
then supplies pre-allocated buffers for output {{MLOperand}}s using {{MLNamedArrayBufferViews}}.

The {{MLCommandEncoder}} interface created by the {{MLContext}}.{{MLContext/createCommandEncoder()}} method supports
a graph execution method that provides the maximum flexibility to callers that also utilize WebGPU in their
application. It does this by placing the workload required to initialize and compute the results of the
operations in the graph onto a {{GPUCommandBuffer}}. The callers are responsible for the eventual submission
of this workload on the {{GPUQueue}} through the WebGPU queue submission mechanism. Once the submitted workload
is completely executed, the result is avaialble in the bound output buffers.

## Device Selection ## {#programming-model-device-selection}

An {{MLContext}} interface represents a global state of neural network execution. One of the important context states is the underlying execution device that manages the resources and facilitates the compilation and the eventual execution of the neural network graph. In addition to the default method of creation with {{MLContextOptions}}, an {{MLContext}} could also be created from a specific {{GPUDevice}} that is already in use by the application, in which case the corresponding {{GPUBuffer}} resources used as graph constants, as well as the {{GPUTexture}} as graph inputs must also be created from the same device. In a multi-adapter configuration, the device used for {{MLContext}} must be created from the same adapter as the device used to allocate the resources referenced in the graph.

In a situation when a GPU context executes a graph with a constant or an input in the system memory as an {{ArrayBufferView}}, the input content is automatically uploaded from the system memory to the GPU memory, and downloaded back to the system memory of an {{ArrayBufferView}} output buffer at the end of the graph execution. This data upload and download cycles will only occur whenever the execution device requires the data to be copied out of and back into the system memory, such as in the case of the GPU. It doesn't occur when the device is a CPU device. Additionally, the result of the graph execution is in a known layout format. While the execution may be optimized for a native memory access pattern in an intermediate result within the graph, the output of the last operation of the graph must convert the content back to a known layout format at the end of the graph in order to maintain the expected behavior from the caller's perspective.

When an {{MLContext}} is created with {{MLContextOptions}}, the user agent selects and creates the underlying execution device by taking into account the application's [=power preference=] and [=device type=] specified in the {{MLPowerPreference}} and {{MLDeviceType}} options.

The following table summarizes the types of resource supported by the context created through different method of creation:

<div class="note">
<table>
  <tr><th>Creation method<th>ArrayBufferView<th>GPUBuffer<th>GPUTexture
  <tr><td>MLContextOptions<td>Yes<td>No<td>No
  <tr><td>GPUDevice<td>Yes<td>Yes<td>Yes
</table>
</div>

API {#api}
=====================

## The navigator.ml interface ## {#api-navigator-ml}

An {{ML}} object is available in the {{Window}} and {{DedicatedWorkerGlobalScope}} contexts through the {{Navigator}}
and {{WorkerNavigator}} interfaces respectively and is exposed via `navigator.ml`.

<script type=idl>
interface mixin NavigatorML {
  [SecureContext, SameObject] readonly attribute ML ml;
};
Navigator includes NavigatorML;
WorkerNavigator includes NavigatorML;
</script>

## The ML interface ## {#api-ml}
<script type=idl>
enum MLDeviceType {
  "cpu",
  "gpu"
};

enum MLPowerPreference {
  "default",
  "high-performance",
  "low-power"
};

dictionary MLContextOptions {
  MLDeviceType deviceType = "cpu";
  MLPowerPreference powerPreference = "default";
};

[SecureContext, Exposed=(Window, DedicatedWorker)]
interface ML {
  Promise<MLContext> createContext(optional MLContextOptions options = {});
  Promise<MLContext> createContext(GPUDevice gpuDevice);

  [Exposed=(DedicatedWorker)]
  MLContext createContextSync(optional MLContextOptions options = {});
  [Exposed=(DedicatedWorker)]
  MLContext createContextSync(GPUDevice gpuDevice);
};
</script>

### Permissions Policy Integration ### {#permissions-policy-integration}

This specification defines a <a>policy-controlled feature</a> identified by the
string "<code><dfn data-lt="webnn-feature">webnn</dfn></code>".
Its <a>default allowlist</a> is <code>'self'</code>.

### The {{ML/createContext()}} method ### {#api-ml-createcontext}
<details open>
<summary>
    The {{ML/createContext()}} method steps are:
</summary>
<div algorithm=createcontext class=algorithm-steps>
    1. If [=this=]'s [=relevant global object=]'s [=associated Document=] is not [=allowed to use=] the [=webnn-feature|webnn=] feature, return [=a new promise=] [=rejected=] with a "{{SecurityError}}" {{DOMException}} and abort these steps.
    1. Let |promise| be [=a new promise=].
    1. Return |promise| and run the following steps [=in parallel=].
    1. Let |options| be the first argument.
    1. Run the <dfn>create context</dfn> steps given |options|:
        1. Let |context| be a new {{MLContext}} object.
        1. If |options| is a {{GPUDevice}} object,
            1. Set |context|.{{[[contextType]]}} to "[=webgpu-context|webgpu=]".
            1. Set |context|.{{[[deviceType]]}} to "[=device-type-gpu|gpu=]".
            1. Set |context|.{{[[powerPreference]]}} to "[=power-preference-default|default=]".
        1. Otherwise,
            1. Set |context|.{{[[contextType]]}} to "[=default-context|default=]".
            1. If |options|["{{deviceType}}"] [=map/exists=], then set |context|.{{[[deviceType]]}} to |options|["{{deviceType}}"]. Otherwise, set |context|.{{[[deviceType]]}} to "[=device-type-cpu|cpu=]".
            1. If |options|["{{powerPreference}}"] [=map/exists=], then set |context|.{{[[powerPreference]]}} to |options|["{{powerPreference}}"]. Otherwise, set |context|.{{[[powerPreference]]}} to "[=power-preference-default|default=]".
    1. If the <a>validate MLContext</a> steps given |context| return `false`, [=reject=] |promise| with a "{{NotSupportedError}}" {{DOMException}} and abort these steps.
    1. [=Resolve=] |promise| with |context|.
</div>
</details>

### The {{ML/createContextSync()}} method ### {#api-ml-createcontextsync}
<details open>
  <summary>
    The {{ML/createContextSync()}} method steps are:
  </summary>
  <div algorithm=createcontextsync class=algorithm-steps>
    1. If [=this=]'s [=relevant global object=]'s [=associated Document=] is not [=allowed to use=] the [=webnn-feature|webnn=] feature, throw a "{{SecurityError}}" {{DOMException}} and abort these steps.
    1. Let |options| be the first argument.
    1. Let |context| be the result of running the <a>create context</a> steps given |options|.
    1. If the <a>validate MLContext</a> steps given |context| return `false`, throw a "{{NotSupportedError}}" {{DOMException}} and abort these steps.
    1. Return |context|.
  </div>
</details>

## The MLGraph interface ## {#api-mlgraph}
The {{MLGraph}} interface represents a compiled computational graph. A compiled graph once constructed is immutable and cannot be subsequently changed.

<script type=idl>
[SecureContext, Exposed=(Window, DedicatedWorker)]
interface MLGraph {};
</script>

<div class=internal-slots>
{{MLGraph}} has the following internal slots:
  <dl dfn-type=attribute dfn-for="MLGraph">
    : <dfn>\[[context]]</dfn> of type {{MLContext}}
    ::
        The context of type {{MLContext}} associated with this {{MLGraph}}.

    : <dfn>\[[inputDescriptors]]</dfn> of type [=record=]&lt;{{DOMString}}, {{MLOperandDescriptor}}&gt;
    ::
        Maps the name of an input {{MLOperand}} to its {{MLOperandDescriptor}} for all input {{MLOperand}}s of this {{MLGraph}}.

    : <dfn>\[[outputDescriptors]]</dfn> of type [=record=]&lt;{{DOMString}}, {{MLOperandDescriptor}}&gt;
    ::
        Maps the name of an output {{MLOperand}} to its {{MLOperandDescriptor}} for all output {{MLOperand}}s of this {{MLGraph}}.

    : <dfn>\[[implementation]]</dfn>
    ::
        The underlying implementation provided by the User Agent.
  </dl>
</div>

### The MLOperandDescriptor dictionary ### {#api-mloperanddescriptor}
<script type=idl>
enum MLInputOperandLayout {
  "nchw",
  "nhwc"
};

enum MLOperandType {
  "float32",
  "float16",
  "int32",
  "uint32",
  "int8",
  "uint8"
};

dictionary MLOperandDescriptor {
  // The operand type.
  required MLOperandType type;

  // The dimensions field is only required for tensor operands.
  sequence<unsigned long> dimensions;
};
</script>

<details open>
  <summary>
    The <dfn for="MLOperandDescriptor">byte length</dfn> of an {{MLOperandDescriptor}} |desc| is the value returned by the following steps:
  </summary>
  <div class=algorithm-steps>
    1. Let |elementLength| be 1.
    1. For each |dimension| of |desc|.{{MLOperandDescriptor/dimensions}}:
        1. Set |elementLength| to |elementLength| × |dimension|.
    1. Let |elementSize| be the [=element size=] of one of the {{ArrayBufferView}} types that matches |desc|.{{MLOperandDescriptor/type}} according to [this table](#appendices-mloperandtype-arraybufferview-compatibility).
    1. Return |elementLength| × |elementSize|.
  </div>
</details>

### The MLOperand interface ### {#api-mloperand}

An {{MLOperand}} represents an intermediary graph being constructed as a result of compositing parts of an operation into a fully composed operation.

For instance, an {{MLOperand}} may represent a constant feeding to an operation or the result from combining multiple constants together into an operation. See also [[#programming-model]].

<script type=idl>
[SecureContext, Exposed=(Window, DedicatedWorker)]
interface MLOperand {};
</script>

<div class=internal-slots>
{{MLOperand}} has the following internal slots:
  <dl dfn-type=attribute dfn-for="MLOperand">
    : <dfn>\[[builder]]</dfn> of type {{MLGraphBuilder}}
    ::
        The {{MLOperand}}'s associated builder object.

    : <dfn>\[[descriptor]]</dfn> of type {{MLOperandDescriptor}}
    ::
        The {{MLOperand}}'s descriptor.

    : <dfn>\[[name]]</dfn> of type [=string=]
    ::
        The {{MLOperand}}'s name (only for input operands).

    : <dfn>\[[operand]]</dfn> of type [=object=]
    ::
        Reference to {{MLOperand}}'s corresponding [=implementation-defined=] platform operand object.

    : <dfn>\[[operator]]</dfn> of type [=object=]
    ::
        Reference to {{MLOperand}}'s corresponding [=implementation-defined=] platform operator object.
  </dl>
</div>

To get the <dfn for="MLOperand">rank</dfn> of an {{MLOperand}} |operand|, run the following steps:
<div algorithm=rank class=algorithm-steps>
    1. Return the size of |operand|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}.
</div>

Since the {{MLOperand/[[builder]]}} object is bound by the {{MLGraphBuilder/constructor()}} constructor to an {{MLContext}} object, an {{MLOperand}} is also always bound to the same {{MLContext}} object.

#### Creating {{MLOperand}} #### {#api-mloperand-create}
The {{MLOperand}} objects are created by the methods of {{MLGraphBuilder}}, internally using the following algorithms.

<details open>
  <summary>
    To <dfn>create MLOperand</dfn> given |builder| and |desc|, run the following steps:
  </summary>
  <div class=algorithm-steps>
    1. If |builder| is not an instance of {{MLGraphBuilder}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |desc| is not an [=object=] that [=implements=] {{MLOperandDescriptor}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |operand| be a new [=object=].
    1. Set |operand|.{{MLOperand/[[builder]]}} to |builder|.
    1. Set |operand|.{{MLOperand/[[descriptor]]}} to |desc|.
    1. Return |operand|.
  </div>
</details>

<details open>
  <summary>
    To <dfn>copy MLOperand</dfn> given |operand|, run the following steps:
  </summary>
  <div class=algorithm-steps>
    1. If |operand| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" and stop.
    1. Let |result| be a new [=object=].
    1. Set |result|.{{MLOperand/[[builder]]}} to |operand|.{{MLOperand/[[builder]]}}.
    1. Set |result|.{{MLOperand/[[descriptor]]}} to |operand|.{{MLOperand/[[descriptor]]}}.
    1. If |operand|.{{MLOperand/[[name]]}} [=map/exists=], then set |result|.{{MLOperand/[[name]]}} to |operand|.{{MLOperand/[[name]]}}.
    1. Return |result|.
  </div>
</details>

<details open>
  <summary>
    To <dfn>check dimensions</dfn> given |dimensions| and |type|, run the following steps:
  </summary>
  <div class=algorithm-steps>
    1. If |dimensions| is not an array of positive numbers, return `false`;
    1. If |dimensions|.length is 0, return `false`.
    1. If |dimensions|.length is too large to be supported by the implementation, return `false`.
    1. If any element of |dimensions| is not a positive number, or it is too large to be supported by the implementation given |type|, return `false`.
    1. Return `true`.
  </div>
</details>

<details open>
  <summary>
    To <dfn for="MLOperand">validate MLOperand</dfn> given |operand| and |builder|, run the following steps:
  </summary>
  <div class=algorithm-steps>
    1. If |operand|.{{MLOperand/[[builder]]}} is not an instance of {{MLGraphBuilder}}, return `false`.
    1. If |builder| is not `undefined` and is not equal to |operand|.{{MLOperand/[[builder]]}}, return `false`.
    1. Let |desc| be |operand|.{{MLOperand/[[descriptor]]}}.
    1. If |desc| is not an [=object=] that [=implements=] {{MLOperandDescriptor}}, return `false`.
    1. If |desc|.{{MLOperandDescriptor/dimensions}} [=map/exists=] and invoking <a>check dimensions</a> given |desc|.{{MLOperandDescriptor/dimensions}} and |desc|.{{MLOperandDescriptor/type}} returns `false`, then return `false`.
    1. Return `true`.
  </div>
</details>

### The MLActivation interface ### {#api-mlactivation}

Objects implementing the {{MLActivation}} interface represent activation function types.

<script type=idl>
[SecureContext, Exposed=(Window, DedicatedWorker)]
interface MLActivation {
};
</script>

<div class="internal-slots">
{{MLActivation}} has the following internal slots:
  <dl dfn-type=attribute dfn-for="MLActivation">
    : <dfn>\[[name]]</dfn> of type [=string=]
    ::
        The {{MLActivation}}'s name.
    : <dfn>\[[builder]]</dfn> of type {{MLGraphBuilder}}
    ::
        The graph builder object this {{MLActivation}} belongs to.
    : <dfn>\[[options]]</dfn> of type [=object=]
    ::
        A dictionary containing {{MLActivation}} options.
    : <dfn>\[[operator]]</dfn> of type [=object=]
    ::
        Reference to {{MLActivation}}'s corresponding [=implementation-defined=] platform operator object.
  </dl>
</div>

<div class="note">
These activations function types are used to create other operations. One such use of this interface is for when an activation function is fused into another operation such as [[#api-mlgraphbuilder-conv2d]] or [[#api-mlgraphbuilder-batchnorm]] during a graph construction session. Such fused activation functions can provide a significant performance improvement when supported natively by the underlying implementation. This is intended as an optimization opportunity for implementers.
</div>

#### Creating {{MLActivation}} #### {#api-mlactivation-create}
<div class="note">
The {{MLActivation}} objects (including the ones passed as input to methods) are created by the methods of {{MLGraphBuilder}} and are identified by their name. The |options| dictionary is defined by those methods. The actual creation of the activation function e.g. a [[#api-mlgraphbuilder-sigmoid]] or [[#api-mlgraphbuilder-relu]] can then be deferred until when the rest of the graph is ready to connect with it such as during the construction of [[#api-mlgraphbuilder-conv2d]] for example.
</div>

<details open>
  <summary>
    To <dfn>create MLActivation</dfn> given |builder|, |name|, |options| and |init-steps|, run the following steps:
  </summary>
  <div class=algorithm-steps>
    1. If |builder| is not an instance of {{MLGraphBuilder}}, throw a "{{TypeError}}" and abort these steps.
    1. If |name| is `undefined` or `null`,  throw a "{{TypeError}}" and abort these steps.
    1. Let |activation| be a new [=object=].
    1. Set |activation|.{{MLActivation/[[builder]]}} to |builder|.
    1. Set |activation|.{{MLActivation/[[name]]}} to |name|.
    1. If |options| is an [=object=], set |activation|.{{MLActivation/[[options]]}} to |options|.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Make a request to the underlying platform to:
            1. Create an [=implementation-defined=] platform operator |opImpl| for the given |name| operation.
            1. Store a reference of |opImpl| in |activation|.{{MLActivation/[[operator]]}}.
        1. If |init-steps| are defined, run |init-steps| with |options|.
            1. Otherwise, initialize |activation|.{{MLActivation/[[operator]]}} given |options| in an [=implementation-defined=] way for the given |name| operation.
    1. Return |activation|.
  </div>
</details>

## The MLContext interface ## {#api-mlcontext}
The {{MLContext}} interface represents a global state of neural network compute workload and execution processes. Each {{MLContext}} object has associated [=context type=], [=device type=] and [=power preference=].

The <dfn>context type</dfn> is the type of the execution context that manages the resources and facilitates the compilation and execution of the neural network graph:
<dl>
<dt>"<code><dfn data-lt="default-context">default</dfn></code>"</dt>
<dd>Context created per user preference options.</dd>
<dt>"<code><dfn data-lt="webgpu-context">webgpu</dfn></code>"</dt>
<dd>Context created from WebGPU device.</dd>
</dl>

The <dfn>device type</dfn> indicates the kind of device used for the context. It is one of the following:
<dl>
<dt>"<code><dfn data-lt="device-type-cpu">cpu</dfn></code>"</dt>
<dd>Provides the broadest compatibility and usability across all client devices with varying degrees of performance.</dd>
<dt>"<code><dfn data-lt="device-type-gpu">gpu</dfn></code>"</dt>
<dd>Provides the broadest range of achievable performance across graphics hardware platforms from consumer devices to professional workstations.</dd>
</dl>

The <dfn>power preference</dfn> indicates preference as related to power consumption. It is one of the following:
<dl>
<dt>"<code><dfn data-lt="power-preference-default">default</dfn></code>"</dt>
<dd>Let the user agent select the most suitable behavior.</dd>
<dt>"<code><dfn data-lt="power-preference-high-performance">high-performance</dfn></code>"</dt>
<dd>Prioritizes execution speed over power consumption.</dd>
<dt>"<code><dfn data-lt="power-preference-low-power">low-power</dfn></code>"</dt>
<dd>Prioritizes power consumption over other considerations such as execution speed.</dd>
</dl>

<script type=idl>
typedef record<DOMString, ArrayBufferView> MLNamedArrayBufferViews;

[SecureContext, Exposed=(Window, DedicatedWorker)]
interface MLContext {};
</script>

<div class=internal-slots>
{{MLContext}} has the following internal slots:
  <dl dfn-type=attribute dfn-for="MLContext">
    : <dfn>\[[contextType]]</dfn> of type [=context type=]
    ::
        The {{MLContext}}'s [=context type=].
    : <dfn>\[[deviceType]]</dfn> of type [=device type=]
    ::
        The {{MLContext}}'s [=device type=].
    : <dfn>\[[powerPreference]]</dfn> of type [=power preference=]
    ::
        The {{MLContext}}'s [=power preference=].
  </dl>
</div>

<div class="note">
When the {{[[contextType]]}} is set to [=default-context|default=] with the {{MLContextOptions}}.{{deviceType}} set to [=device-type-gpu|gpu=], the user agent is responsible for creating an internal GPU device that operates within the context and is capable of ML workload submission on behalf of the calling application. In this setting however, only {{ArrayBufferView}} inputs and outputs are allowed in and out of the graph execution since the application has no way to know what type of internal GPU device is being created on their behalf. In this case, the user agent is responsible for automatic uploads and downloads of the inputs and outputs to and from the GPU memory using this said internal device.
</div>

### The {{MLContext}} validation algorithm ### {#api-mlcontext-validate}
<details open>
  <summary>
    To <dfn lt="validate MLContext">validate {{MLContext}}</dfn>, given |context|, run these steps:
  </summary>
  <div class=algorithm-steps>
    1. If |context|.{{[[contextType]]}} is not "[=webgpu-context|webgpu=]" or "[=default-context|default=], return `false`.
    1. If |context|.{{[[deviceType]]}} is not "[=device-type-cpu|cpu=]" or "[=device-type-gpu|gpu=]", return `false`.
    1. If |context|.{{[[powerPreference]]}} is not "[=power-preference-default|default=]" or "[=power-preference-high-performance|high-performance=]" or "[=power-preference-low-power|low-power=]", return `false`.
    1. If the user agent cannot support |context|.{{[[contextType]]}}, |context|.{{[[deviceType]]}} and |context|.{{[[powerPreference]]}}, return `false`.
    1. Return `true`;
  </div>
</details>

### Synchronous Execution ### {#api-mlcontext-sync-execution}
Synchronously carries out the computational workload of a compiled graph {{MLGraph}} on the calling thread, which must be a worker thread, to produce results as defined by the operations in the graph. This method of execution requires an {{MLContext}} created with {{MLContextOptions}}. Otherwise, it throws an "{{OperationError}}" {{DOMException}}.

<script type=idl>
partial interface MLContext {
  [Exposed=(DedicatedWorker)]
  undefined computeSync(
      MLGraph graph, MLNamedArrayBufferViews inputs, MLNamedArrayBufferViews outputs);
};
</script>

<div algorithm=mlcontext.computesync>

    **Arguments:**
      - *graph*: an {{MLGraph}}. The compiled graph to be executed.
      - *inputs*: an {{MLNamedArrayBufferViews}}. The resources of inputs.
      - *outputs*: an {{MLNamedArrayBufferViews}}. The pre-allocated resources of required outputs.

    **Returns:** {{undefined}}.

    1. If any of the following requirements are unmet, then throw a "{{DataError}}" {{DOMException}} and stop.
        <div class=validusage>
            1. For each |key| -> |value| of |inputs|:
                1. |graph|.{{MLGraph/[[inputDescriptors]]}}[|key|] must [=map/exist=].
                1. Let |inputDesc| be |graph|.{{MLGraph/[[inputDescriptors]]}}[|key|].
                1. The type of {{ArrayBufferView}} |value| must match |inputDesc|.{{MLOperandDescriptor/type}} according to [this table](#appendices-mloperandtype-arraybufferview-compatibility).
                1. |value|.\[[ByteLength]] must equal to [=byte length=] of |inputDesc|.
            1. For each |key| -> |value| of |outputs|:
                1. |graph|.{{MLGraph/[[outputDescriptors]]}}[|key|] must [=map/exist=].
                1. Let |outputDesc| be |graph|.{{MLGraph/[[outputDescriptors]]}}[|key|].
                1. The type of {{ArrayBufferView}} |value| must match |outputDesc|.{{MLOperandDescriptor/type}} according to [this table](#appendices-mloperandtype-arraybufferview-compatibility).
                1. |value|.\[[ByteLength]] must equal to [=byte length=] of |outputDesc|.
        </div>
    1. For each |key| -> |value| of |inputs|:
        1. Let |inputDesc| be |graph|.{{MLGraph/[[inputDescriptors]]}}[|key|].
        1. Let |inputTensor| be a new tensor for |graph|.{{MLGraph/[[implementation]]}}.
        1. Set the data type of |inputTensor| to the one that matches the [=element type=] of {{ArrayBufferView}} |value|.
        1. Set the dimensions of |inputTensor| to |inputDesc|.{{MLOperandDescriptor/dimensions}}.
        1. Set the values of |inputTensor| to the values of |value|.
        1. Set the input of |graph|.{{MLGraph/[[implementation]]}} that is associated with |key| to |inputTensor|.
    1. For each |key| -> |value| of |outputs|:
        1. Issue a compute request for output of |graph|.{{MLGraph/[[implementation]]}} that is associated with |key|.
        1. Wait for the compute request to be completed.
        1. If there is an error returned by |graph|.{{MLGraph/[[implementation]]}}, then:
            1. Throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Else:
            1. Let |outputTensor| be the output tensor returned by |graph|.{{MLGraph/[[implementation]]}}.
            1. If the data type of |outputTensor| doesn't match the [=element type=] of {{ArrayBufferView}} |value|, then throw a "{{DataError}}" {{DOMException}} and stop.
            1. If the byte length of |outputTensor| is not equal to |value|.\[[ByteLength]], then:
                1. Throw a "{{DataError}}" {{DOMException}} and stop.
            1. Else:
                1. Set the values of |value| to the values of |outputTensor|.
    1. Return {{undefined}}.
</div>

<div class=algorithm-steps>
To <dfn>validate buffer with descriptor</dfn> given |bufferView| and |descriptor|, run the following steps:
    1. If |bufferView| is not an {{MLBufferView}}, return `false`.
    1. If |bufferView|'s [=element type=] does not match to |descriptor|.{{MLOperandDescriptor/type}}  according to [this table](#appendices-mloperandtype-arraybufferview-compatibility), return `false`.
    1. If |bufferView|.\[[ByteLength]] is not equal to the [=byte length=] of |descriptor|, return `false`.
</div>

#### Examples #### {#api-mlcontext-sync-execution-examples}

<div class="example">
<details open>
  <summary>
    The following code showcases the synchronous computation with optional outputs in a worker.
  </summary>
  <pre highlight="js">
    const context = navigator.ml.createContextSync();

    // Build a graph with two outputs.
    const builder = new MLGraphBuilder(context);
    const descA = {type: 'float32', dimensions: [3, 4]};
    const a = builder.input('a', descA);
    const descB = {type: 'float32', dimensions: [4, 3]};
    const bufferB = new Float32Array(sizeOfShape(descB.dimensions)).fill(0.5);
    const b = builder.constant(descB, bufferB);
    const descC = {type: 'float32', dimensions: [3, 3]};
    const bufferC = new Float32Array(sizeOfShape(descC.dimensions)).fill(1);
    const c = builder.constant(descC, bufferC);
    const d = builder.matmul(a, b);
    const e = builder.add(d, c);
    const graph = builder.buildSync({'d': d, 'e': e});

    const bufferA = new Float32Array(sizeOfShape(descA.dimensions)).fill(0.5);
    const inputs = {'a': bufferA};

    // Compute d.
    const bufferD = new Float32Array(sizeOfShape([3, 3]));
    context.computeSync(graph, inputs, {'d': bufferD});
    console.log(&#96;values: ${bufferD}&#96;);

    // Compute e.
    const bufferE = new Float32Array(sizeOfShape([3, 3]));
    context.computeSync(graph, inputs, {'e': bufferE});
    console.log(&#96;values: ${bufferE}&#96;);
  </pre>
</details>
</div>

### The {{MLNamedArrayBufferViews}} transfer algorithm ### {#mlnamedarraybufferviews-transfer-alg}
<details open>
  <summary>
    To <dfn for="MLNamedArrayBufferViews">transfer</dfn> an {{MLNamedArrayBufferViews}} |views|:
  </summary>
  <div class=algorithm-steps>
    1. Let |transferredViews| be a new {{MLNamedArrayBufferViews}}.
    1. For each |key| -> |value| of |views|:
        1. Let |transferredBuffer| be the result of [=ArrayBuffer/transfer|transferring=] the [=underlying buffer=] of |value|.
        1. Let |constructor| be the appropriate [=view constructor=] for the type of {{ArrayBufferView}} |value|.
        1. Let |elementsNumber| be the result of the [=buffer byte length|byte length=] of |value| ÷ [=element size=] of |value|.
        1. Let |transferredView| be [=Construct=](|constructor|, |transferredBuffer|, |value|.\[[ByteOffset]], |elementsNumber|).
        1. Set |transferredViews|[|key|] to |transferredView|.
    1. Return |transferredViews|.
  </div>
</details>

### Asynchronous Execution ### {#api-mlcontext-async-execution}
Asynchronously carries out the computational workload of a compiled graph {{MLGraph}} on a separate timeline, either on a worker thread for the CPU execution, or on a GPU timeline for the submission of GPU workload on the command queue. The asynchronous nature of this call avoids blocking the calling thread while the computation for result is ongoing. This method of execution requires an {{MLContext}} created with {{MLContextOptions}}. Otherwise, it throws an "{{OperationError}}" {{DOMException}}.

<div class="note">
In accordance with the [=ArrayBufferView/write|Web IDL warning=], to prevent the calling thread from modifying the input and output resources while the computation is ongoing, this method [=MLNamedArrayBufferViews/transfer|transfers=] the input and output {{MLNamedArrayBufferViews}} to new views that share the same backing memory allocations. The transferred views are returned to the caller via the promise fulfillment with the computation result written into the backing memory of the output views.
</div>

<script type=idl>
dictionary MLComputeResult {
  MLNamedArrayBufferViews inputs;
  MLNamedArrayBufferViews outputs;
};

partial interface MLContext {
  Promise<MLComputeResult> compute(
      MLGraph graph, MLNamedArrayBufferViews inputs, MLNamedArrayBufferViews outputs);
};
</script>

<div algorithm=mlcontext.compute>

    **Arguments:**
      - *graph*: an {{MLGraph}}. The compiled graph to be executed.
      - *inputs*: an {{MLNamedArrayBufferViews}}. The resources of inputs. Will be [=MLNamedArrayBufferViews/transfer|transferred=] if there are no validation errors.
      - *outputs*: an {{MLNamedArrayBufferViews}}. The pre-allocated resources of required outputs. Will be [=MLNamedArrayBufferViews/transfer|transferred=] if there are no validation errors.

    **Returns:** Promise<{{MLComputeResult}}>.

    1. Let |promise| be [=a new promise=].
    1. If any of the following requirements are unmet, then [=reject=] |promise| with a "{{DataError}}" {{DOMException}} and stop.
        <div class=validusage>
            1. For each |key| -> |value| of |inputs|:
                1. |graph|.{{MLGraph/[[inputDescriptors]]}}[|key|] must [=map/exist=].
                1. Let |inputDesc| be |graph|.{{MLGraph/[[inputDescriptors]]}}[|key|].
                1. The type of {{ArrayBufferView}} |value| must match |inputDesc|.{{MLOperandDescriptor/type}} according to [this table](#appendices-mloperandtype-arraybufferview-compatibility).
                1. |value|.\[[ByteLength]] must equal to [=byte length=] of |inputDesc|.
            1. For each |key| -> |value| of |outputs|:
                1. |graph|.{{MLGraph/[[outputDescriptors]]}}[|key|] must [=map/exist=].
                1. Let |outputDesc| be |graph|.{{MLGraph/[[outputDescriptors]]}}[|key|].
                1. The type of {{ArrayBufferView}} |value| must match |outputDesc|.{{MLOperandDescriptor/type}} according to [this table](#appendices-mloperandtype-arraybufferview-compatibility).
                1. |value|.\[[ByteLength]] must equal to [=byte length=] of |outputDesc|.
        </div>
    1. Let |transferredInputs| be the result of [=MLNamedArrayBufferViews/transfer|transferring=] {{MLNamedArrayBufferViews}} |inputs|.
    1. Let |transferredOutputs| be the result of [=MLNamedArrayBufferViews/transfer|transferring=] {{MLNamedArrayBufferViews}} |outputs|.
    1. For each |key| -> |value| of |transferredInputs|:
        1. Let |inputDesc| be |graph|.{{MLGraph/[[inputDescriptors]]}}[|key|].
        1. Let |inputTensor| be a new tensor for |graph|.{{MLGraph/[[implementation]]}}.
        1. Set the data type of |inputTensor| to the one that matches the [=element type=] of {{ArrayBufferView}} |value|.
        1. Set the dimensions of |inputTensor| to |inputDesc|.{{MLOperandDescriptor/dimensions}}.
        1. Set the values of |inputTensor| to the values of |value|.
        1. Set the input of |graph|.{{MLGraph/[[implementation]]}} that is associated with |key| to |inputTensor|.
    1. For each |key| -> |value| of |transferredOutputs|:
        1. Issue a compute request for output of |graph|.{{MLGraph/[[implementation]]}} that is associated with |key|.
        1. Wait for the compute request to be completed.
        1. If there is an error returned by |graph|.{{MLGraph/[[implementation]]}}, then:
            1. [=reject=] |promise| with an "{{OperationError}}" {{DOMException}} and stop.
        1. Else:
            1. Let |outputTensor| be the output tensor returned by |graph|.{{MLGraph/[[implementation]]}}.
            1. Let |outputDesc| be |graph|.{{MLGraph/[[outputDescriptors]]}}[|key|].
            1. If the data type of |outputTensor| doesn't match the [=element type=] of {{ArrayBufferView}} |value|, then:
                1. [=reject=] |promise| with a "{{DataError}}" {{DOMException}} and stop.
            1. If the byte length of |outputTensor| is not equal to [=byte length=] of |outputDesc|, then:
                1. [=reject=] |promise| with an "{{OperationError}}" {{DOMException}} and stop.
            1. Else:
                1. Set the values of |value| to the values of |outputTensor|.
            1. If all compute requests are completed, then:
                1. Let |result| be a new {{MLComputeResult}}.
                1. Set |result|.{{MLComputeResult/inputs}} to |transferredInputs|.
                1. Set |result|.{{MLComputeResult/outputs}} to |transferredOutputs|.
                1. [=Resolve=] |promise| with |result| and stop.
    1. Return |promise|.
</div>

#### Examples #### {#api-mlcontext-async-execution-examples}

<div class="example">
<details open>
  <summary>
    The following code showcases the asynchronous computation.
  </summary>
  <pre highlight="js">
    const operandType = {type: 'float32', dimensions: [2, 2]};
    const context = await navigator.ml.createContext();
    const builder = new MLGraphBuilder(context);
    // 1. Create a computational graph 'C = 0.2 * A + B'.
    const constant = builder.constant(0.2);
    const A = builder.input('A', operandType);
    const B = builder.input('B', operandType);
    const C = builder.add(builder.mul(A, constant), B);
    // 2. Compile it into an executable.
    const graph = await builder.build({'C': C});
    // 3. Bind inputs to the graph and execute for the result.
    const bufferA = new Float32Array(4).fill(1.0);
    const bufferB = new Float32Array(4).fill(0.8);
    const bufferC = new Float32Array(4);
    const inputs = {'A': bufferA, 'B': bufferB};
    const outputs = {'C': bufferC};
    const result = await context.compute(graph, inputs, outputs);
    // The computed result of [[1, 1], [1, 1]] is in the buffer associated with
    // the output operand.
    console.log('Output value: ' + result.outputs.C);
    // Note: the result.outputs.C buffer is different from the bufferC, but it
    // shares the same backing memory allocation.
  </pre>
</details>
</div>

### WebGPU Interoperability ### {#api-mlcontext-webgpu-interop}
Create {{MLCommandEncoder}} interface used to record the ML workload onto a WebGPU-compatible {{GPUCommandBuffer}} to allow mixing of ML workload with other GPU workload in an application that leverages WebGPU. This method only succeeds on an {{MLContext}} created with {{GPUDevice}}. Otherwise, it throws an "{{OperationError}}" {{DOMException}}.

<script type=idl>
partial interface MLContext {
  MLCommandEncoder createCommandEncoder();
};
</script>

<div algorithm=mlcontext.createcommandencoder>
    **Returns:** {{MLCommandEncoder}}. The command encoder used to record ML workload on the GPU.
</div>

## The MLCommandEncoder interface ## {#api-mlcommandencoder}
The {{MLCommandEncoder}} interface represents a method of execution that synchronously records the computational workload of a compiled {{MLGraph}} to a {{GPUCommandBuffer}} on the calling thread. Since the workload is not immediately executed, just recorded, this method allows more flexibility for the caller to determine how and when the recorded commands will be submitted for execution on the GPU relative to other GPU workload on the same or different queue.

<script type=idl>
typedef (GPUBuffer or GPUTexture) MLGPUResource;

typedef record<DOMString, MLGPUResource> MLNamedGPUResources;

[SecureContext, Exposed=(Window, DedicatedWorker)]
interface MLCommandEncoder {};
</script>

<div class=internal-slots>
{{MLCommandEncoder}} has the following internal slots:
  <dl dfn-type=attribute dfn-for="MLCommandEncoder">
    : <dfn>\[[context]]</dfn> of type {{MLContext}}
    ::
        The context of type {{MLContext}} associated with this {{MLCommandEncoder}}.

    : <dfn>\[[implementation]]</dfn>
    ::
        The underlying implementation provided by the User Agent.
  </dl>
</div>

### Graph Initialization ### {#api-mlcommandencoder-graph-initialization}
Record the initialization of the {{MLGraph}}. This is a necessary step for optimal performance during graph execution as it gives the platform an opportunity to prepare and optimize constant input data for the subsequent execution of the graph. This method should only be called once per graph.

<script type=idl>
partial interface MLCommandEncoder {
  undefined initializeGraph(MLGraph graph);
};
</script>

<div>
    **Arguments:**
        - *graph*: an {{MLGraph}}. The compiled graph to be initialized with graph constant inputs.

    **Returns:** {{undefined}}.
</div>

<details open>
  <summary>
    The {{MLCommandEncoder/initializeGraph(graph)}} steps are:
  </summary>
  <div algorithm=mlcommandencoder.initializegraph>
    <div class="note">
        Graph initialization stage typically involves a process known as "weight preprocessing" where all the constant inputs to the graph are preprocessed and cached at the operating system level for subsequent graph execution calls. The initializing inputs are typically the constant weight data specified through the {{MLGraphBuilder/constant(descriptor, bufferView)|MLGraphBuilder/constant()}} method as constant operands during graph construction time.
    </div>
  </div>
</details>

### Dispatch Execution Commands ### {#api-mlcommandencoder-dispatch-commands}
Record the {{MLGraph}} execution with the inputs {{MLNamedGPUResources}} and outputs {{MLNamedGPUResources}}.

<script type=idl>
partial interface MLCommandEncoder {
  undefined dispatch(MLGraph graph, MLNamedGPUResources inputs, MLNamedGPUResources outputs);
};
</script>

<div>
    **Arguments:**
        - *graph*: an {{MLGraph}}. The compiled graph to be executed.
        - *inputs*: an {{MLNamedGPUResources}}. The resources of inputs.
        - *outputs*: an {{MLNamedGPUResources}}. The pre-allocated resources of required outputs.

    **Returns:** {{undefined}}.
</div>

<details open>
  <summary>
    The {{MLCommandEncoder/dispatch(graph, inputs, outputs)}} steps are:
  </summary>
  <div algorithm=mlcommandencoder.dispatch class=algorithm-steps>
    1. If any of the following requirements are unmet, then throw a "{{DataError}}" {{DOMException}} and stop.
        <div class=validusage>
            1. For each |key| -> |value| of |inputs|:
                1. |graph|.{{MLGraph/[[inputDescriptors]]}}[|key|] must [=map/exist=].
                1. Let |inputDesc| be |graph|.{{MLGraph/[[inputDescriptors]]}}[|key|].
                1. If |value| is a {{GPUBuffer}}, then:
                    1. |value|.{{GPUBuffer/size}} must equal to [=byte length=] of |inputDesc|.
            1. For each |key| -> |value| of |outputs|:
                1. |graph|.{{MLGraph/[[outputDescriptors]]}}[|key|] must [=map/exist=].
                1. Let |outputDesc| be |graph|.{{MLGraph/[[outputDescriptors]]}}[|key|].
                1. If |value| is a {{GPUBuffer}}, then:
                    1. |value|.{{GPUBuffer/size}} must equal to [=byte length=] of |outputDesc|.
        </div>
    1. For each |key| -> |value| of |inputs|:
        1. Set the input of |graph|.{{MLGraph/[[implementation]]}} that is associated with |key| to |value|.
    1. For each |key| -> |value| of |outputs|:
        1. Set the output of |graph|.{{MLGraph/[[implementation]]}} that is associated with |key| to |value|.
    1. Issue a compute request of |graph|.{{MLGraph/[[implementation]]}}.
    1. If there is an error returned by |graph|.{{MLGraph/[[implementation]]}}, then:
        1. Throw an "{{OperationError}}" {{DOMException}} and stop.
    1. Return {{undefined}}.
  </div>
</details>

### Generate GPU Command Buffer ### {#api-mlcommandencoder-generate-gpu-command-buffer}
Complete the recording of ML workload and return a WebGPU-compatible {{GPUCommandBuffer}} containing the recorded workload.

<script type=idl>
partial interface MLCommandEncoder {
  GPUCommandBuffer finish(optional GPUCommandBufferDescriptor descriptor = {});
};
</script>

<div algorithm=mlcommandencoder.finish>
    **Arguments:**
        - *descriptor*: an optional {{GPUCommandBufferDescriptor}}. Descriptor of the command buffer.

    **Returns:** {{GPUCommandBuffer}}.
</div>

## The MLGraphBuilder interface ## {#api-mlgraphbuilder}

The {{MLGraphBuilder}} interface defines a set of operations as identified by the [[#usecases]] that can be composed into a computational graph. It also represents the intermediate state of a graph building session.

<script type=idl>
typedef record<DOMString, MLOperand> MLNamedOperands;

dictionary MLBufferResourceView {
  required GPUBuffer resource;
  unsigned long long offset = 0;
  unsigned long long size;
};

typedef (ArrayBufferView or MLBufferResourceView) MLBufferView;

[SecureContext, Exposed=(Window, DedicatedWorker)]
interface MLGraphBuilder {
  // Construct the graph builder from the context.
  constructor(MLContext context);

  // Create an operand for a graph input.
  MLOperand input(DOMString name, MLOperandDescriptor descriptor);

  // Create an operand for a graph constant.
  MLOperand constant(MLOperandDescriptor descriptor, MLBufferView bufferView);

  // Create a single-value operand from the specified number of the specified type.
  MLOperand constant(double value, optional MLOperandType type = "float32");

  // Compile the graph up to the specified output operands asynchronously.
  Promise<MLGraph> build(MLNamedOperands outputs);

  // Compile the graph up to the specified output operands synchronously.
  [Exposed=(DedicatedWorker)]
  MLGraph buildSync(MLNamedOperands outputs);
};
</script>

<div class="note">
Both {{MLGraphBuilder}}.{{MLGraphBuilder/build()}} and {{MLGraphBuilder}}.{{MLGraphBuilder/buildSync()}} methods compile the graph builder state up to the specified output operands into a compiled graph according to the type of {{MLContext}} that creates it. Since this operation can be costly in some machine configurations, the calling thread of the {{MLGraphBuilder}}.{{MLGraphBuilder/buildSync()}} method must only be a worker thread to avoid potential disruption of the user experience. When the {{[[contextType]]}} of the {{MLContext}} is set to [=default-context|default=], the compiled graph is initialized right before the {{MLGraph}} is returned. This graph initialization stage is important for optimal performance of the subsequent graph executions. See [[#api-mlcommandencoder-graph-initialization]] for more detail.
</div>

{{MLBufferResourceView}} has the following members:
<dl dfn-type=dict-member dfn-for=MLBufferResourceView>
    : <dfn>resource</dfn>
    ::
        A {{GPUBuffer}} object. Specifies the GPU buffer source.

    : <dfn>offset</dfn>
    ::
        Specifies an {{unsigned long long}} offset in the buffer source.

    : <dfn>size</dfn>
    ::
        Specifies the {{unsigned long long}} size of the buffer view.
</dl>

<div class=internal-slots>
{{MLGraphBuilder}} has the following internal slots:
  <dl dfn-type=attribute dfn-for="MLGraphBuilder">
    : <dfn>\[[context]]</dfn> of type {{MLContext}}
    ::
        The context of type {{MLContext}} associated with this {{MLGraphBuilder}}.
  </dl>
</div>

### The {{MLGraphBuilder}} constructor ### {#api-mlgraphbuilder-constructor}
<details open>
  <summary>
    The [=new=] {{MLGraphBuilder}} constructor steps are:
  </summary>
  <div class=algorithm-steps>
    1. If [=this=]'s [=relevant global object=]'s [=associated Document=] is not [=allowed to use=] the [=webnn-feature|webnn=] feature, throw a "{{SecurityError}}" {{DOMException}} and abort these steps.
    1. Let |context| be the first argument.
    1. If the <a>validate MLContext</a> steps given |context| return `false`, throw a "{{TypeError}}" and abort these steps.
    1. Set {{MLGraphBuilder/[[context]]}} to |context|.
  </div>
</details>

### The {{MLGraphBuilder/input()}} method  ### {#api-mlgraphbuilder-input}
Create a named {{MLOperand}} based on a descriptor, that can be used as an input.

<div>
    **Arguments:**
        - *name*: a [=string=] name of the input.
        - *descriptor*: an {{MLOperandDescriptor}} object.
    **Returns:**: an {{MLOperand}} object.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/input(name, descriptor)}} steps are:
  </summary>
  <div algorithm=input class=algorithm-steps>
    <div class="note">
        The permissions and context validity have been checked by [[#api-mlgraphbuilder-constructor]] steps.
    </div>
    1. Let |name| be the first argument.
        1. If |name| is `undefined` or an empty [=string=], then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |descriptor| be the second argument.
        1. If |descriptor| is not an an object that [=implements=] {{MLOperandDescriptor}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. [=Assert=]: If |descriptor|.{{MLOperandDescriptor/dimensions}} does not [=map/exist=], then |descriptor| defines a scalar input.
        1. If |descriptor|.{{MLOperandDescriptor/dimensions}} [=map/exists=]:
            1. If the [=check dimensions=] steps given |descriptor|.{{MLOperandDescriptor/type}} and |descriptor|.{{MLOperandDescriptor/dimensions}} return `false`, throw a "{{DataError}}" {{DOMException}} and stop.
            1. If the [=byte length=] of |descriptor| is not supported by the underlying platform, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |operand| be the result of invoking the <a>create MLOperand</a> steps with [=this=] and |descriptor|.
        1. Set |operand|.{{MLOperand/[[name]]}} to |name|.
        1. Make a request to the underlying platform to:
            1. Create an [=implementation-defined=] platform input operand |operandImpl| given |descriptor|.
            1. Store a reference of |operandImpl| in |operand|.{{MLOperand/[[operand]]}}.
            1. Register |operand| as an input.
    1. Return |operand|.
  </div>
</details>

### The build() method ### {#api-mlgraphbuilder-build}
Build a composed graph up to a given output operand into a computational graph, asynchronously or synchronously.

#### The {{MLGraphBuilder/build(outputs)}} method #### {#api-mlgraphbuilder-build-outputs}
<details open>
  <summary>
    The {{MLGraphBuilder/build(outputs)}} steps are:
  </summary>
  <div algorithm=build-outputs class=algorithm-steps>
    <div class="note">
        The permissions and context validity have been checked by [[#api-mlgraphbuilder-constructor]] steps.
    </div>
    1. Let |promise| be [=a new promise=].
    1. Return |promise| and run the following steps [=in parallel=].
    1. Return the result of invoking {{MLGraphBuilder/buildSync(outputs)}} given |outputs|.
        1. If that throws, re-throw the error and stop.
  </div>
</details>

#### The {{MLGraphBuilder/buildSync(outputs)}} method #### {#api-mlgraphbuilder-buildsync-outputs}
<details open>
  <summary>
    The {{MLGraphBuilder/buildSync(outputs)}} steps are:
  </summary>
  <div algorithm=buildsync-outputs class=algorithm-steps>
    <div class="note">
        The permissions and context validity have been checked by [[#api-mlgraphbuilder-constructor]] steps.
    </div>
    1. If |outputs| is not an instance of {{MLNamedOperands}}, then throw an "{{TypeError}}" {{DOMException}} and stop.
    1. For each |element| in |outputs|:
        1. If |element|.key is not a [=string=], then throw an "{{TypeError}}" {{DOMException}} and stop.
        1. If |element|.value is not an instance of {{MLOperand}}, then throw an "{{TypeError}}" {{DOMException}} and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |graph| be a new {{MLGraph}}:
            1. Set |graph|.{{MLGraph/[[context]]}} to [=this=].{{MLGraphBuilder/[[context]]}}.
            1. Set |graph|.{{MLGraph/[[outputDescriptors]]}} to |outputs|.
        1. Make a request to the underlying platform to:
            1. Connect |graph| to a new [=implementation-defined=] graph implementation |graphImpl| given |graph|.
            1. Store a reference to |graphImpl| in |graph|.{{MLGraph/[[implementation]]}}.
        1. Make a request to the underlying platform to initialize the graph:
            1. For each |operand| in |outputs|:
                1. If |operand| was created as an input by the underlying platform:
                    1. Add |operand| to |graph|.{{MLGraph/[[inputDescriptors]]}}.
                    1. Initialize the weights of |operand|.
                1. If |operand| was created as a constant by the underlying platform:
                    1. Preprocess and optimize the tensor data of |operand|.
                1. Update |graphImpl| with |operand|.{{MLOperand/[[operand]]}}.
                1. Update |graphImpl| with |operand|.{{MLOperand/[[operator]]}}.
    1. Return |graph|.
  </div>
</details>

### The constant() method  ### {#api-mlgraphbuilder-constant-method}
Create a constant {{MLOperand}} that can be used in {{MLGraphBuilder}} methods.

#### The {{MLGraphBuilder/constant(descriptor, bufferView)}} method  #### {#api-mlgraphbuilder-constant}
<div>
    **Arguments:**
        - *descriptor*: an {{MLOperandDescriptor}} object
        - *bufferView*: an {{MLBufferView}}
    **Returns:**: an {{MLOperand}} object.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/constant(descriptor, bufferView)}} steps are:
  </summary>
  <div algorithm=constant class=algorithm-steps>
    <div class="note">
        The permissions and context validity have been checked by [[#api-mlgraphbuilder-constructor]] steps.
    </div>
    1. Let |descriptor| be the first argument.
    1. If |descriptor| is not an an object that [=implements=] {{MLOperandDescriptor}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If the [=byte length=] of |descriptor| is not supported by the underlying platform, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If the [=check dimensions=] steps given |descriptor|.{{MLOperandDescriptor/type}} and |descriptor|.{{MLOperandDescriptor/dimensions}} return `false`, throw a "{{DataError}}" {{DOMException}} and stop.
    1. Let |bufferView| be the second argument.
        1. If invoking <a>validate buffer with descriptor</a> given |bufferView| and |descriptor| return `false`, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |operand| be the result of invoking the <a>create MLOperand</a> steps with [=this=] and |descriptor|.
        1. Let |bytes| be the result of invoking [[=get a copy of the bytes held by the buffer source=]] given |bufferView|.
        1. Make a request to the underlying platform to:
            1. Create an [=implementation-defined=] platform operand |constantImpl| to represent a constant, given |descriptor|.
            1. Store a reference of |constantImpl| in |operand|.{{MLOperand/[[operand]]}}.
            1. Register |operand| as a tensor constant with |bytes| as value.
    1. Return |operand|.
  </div>
</details>

#### The {{MLGraphBuilder/constant(value, type)}} method  #### {#api-mlgraphbuilder-constant-value-type}

<div>
    **Arguments:**
        - *value*: a number
        - *type*: an optional {{MLOperandType}}, by default *"float32"*.
    **Returns:**: an {{MLOperand}} object.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/constant(value, type)}} steps are:
  </summary>
  <div algorithm=constant-value-type class=algorithm-steps>
    <div class="note">
        The permissions and context validity have been checked by [[#api-mlgraphbuilder-constructor]] steps.
    </div>
    1. If |value| is not a [=number=], then then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |type| is `undefined`, let |type| be `"float32"`.
    1. Otherwise, if |type| is not one of {{MLOperandType}}, then  throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |descriptor| be a new {{MLOperandDescriptor}}.
        1. Set |descriptor|.{{MLOperandDescriptor/type}} to |type|.
        1. Set |descriptor|.{{MLOperandDescriptor/dimensions}} to `undefined`.
            <div class="note">
                In the case of a scalar constant, |descriptor|.{{MLOperandDescriptor/dimensions}} is ignored.
            </div>
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |operand| be the result of invoking the <a>create MLOperand</a> steps with [=this=] and |descriptor|.
        1. Make a request to the underlying platform to:
            1. Create an [=implementation-defined=] platform operand |constantImpl| to represent a constant, given |descriptor|.
            1. Store a reference of |constantImpl| in |operand|.{{MLOperand/[[operand]]}}.
            1. Register |operand| as a scalar constant with |value| as value.
    1. Return |operand|.
  </div>
</details>

### The batchNormalization() method ### {#api-mlgraphbuilder-batchnorm}
Normalize the tensor values of input features across the batch dimension using [[Batch-Normalization]]. For each input feature, the mean and variance values of that feature supplied in this calculation as parameters are previously computed across the batch dimension of the input during the model training phase of this operation.

<script type=idl>
dictionary MLBatchNormalizationOptions {
  MLOperand scale;
  MLOperand bias;
  unsigned long axis = 1;
  float epsilon = 1e-5;
  MLActivation activation;
};

partial interface MLGraphBuilder {
  MLOperand batchNormalization(MLOperand input, MLOperand mean, MLOperand variance,
                             optional MLBatchNormalizationOptions options = {});
};
</script>

{{MLBatchNormalizationOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLBatchNormalizationOptions>
    : <dfn>scale</dfn>
    ::
        An {{MLOperand}}. Specifies the 1-D tensor of the scaling values whose length is equal to the size of the input dimension denoted by {{MLBatchNormalizationOptions/axis}}.

    : <dfn>bias</dfn>
    ::
        An {{MLOperand}}. Specifies the 1-D tensor of the bias values whose length is equal to the size of the input dimension denoted by {{MLBatchNormalizationOptions/axis}}.

    : <dfn>axis</dfn>
    ::
        A {{long}} scalar. Specifies the index to the feature count dimension of the input shape for which the mean and variance values are. Its value must be in the range [0, N-1] where N is the rank of input tensor. The default value is 1, corresponding to the channel (*"c"*) dimension in the *"nchw"* data layout.

    : <dfn>epsilon</dfn>
    ::
        A {{float}} scalar. Specifies A small value to prevent computational error due to divide-by-zero.

    : <dfn>activation</dfn>
    ::
        An {{MLActivation}} object. Specifies the optional activation function that immediately follows the normalization operation.
</dl>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input N-D tensor.
        - *mean*: an {{MLOperand}}. Specifies the 1-D tensor of the mean values of the input features across the batch whose length is equal to the size of the input dimension denoted by  {{MLBatchNormalizationOptions/axis}}.
        - *variance*: an {{MLOperand}}. The 1-D tensor of the variance values of the input features across the batch whose length is equal to the size of the input dimension denoted by {{MLBatchNormalizationOptions/axis}}.
        - *options*: an optional {{MLBatchNormalizationOptions}}. Specifies the optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The batch-normalized N-D tensor of the same shape as the input tensor.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/batchNormalization()}} method steps are:
  </summary>
  <div algorithm=batchnorm class=algorithm-steps>
    1. Let |input| be the first argument. To validate |input|, run these substeps:
        1. If |input| is not an [=object=] that [=implements=] {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
    1. Let |mean| be the second argument, representing a vector with the moving mean values for |input|. To validate |mean|, run the following substeps:
        1. If |mean| is not an [=object=] that [=implements=] {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
        1. If |mean|.{{MLOperand/[[descriptor]]}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}} is not equal with |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}} from which the dimension represented by |options|.axis is removed, then  throw a "{{TypeError}}" {{DOMException}} and abort these steps.
    1. Let |variance| be the third argument, representing the moving variance values of |input|.
    1. Let |options| be the fourth argument. To validate |options|, run these substeps:
        1. If |options|.axis does not [=map/exist=], let |options|."axis" be 1.
        1. If |options|.axis is not a number between 0 and the rank of |input|, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
        1. If |input| is a 4-D tensor of the *"nchw"* layout, set |options|.axis to 1.
        1. If |input| is a 4-D tensor of the *"nhwc"* layout, set |options|.axis to 3.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>create MLOperand</a> steps with [=this=] and |descriptor|, that may use the same underlying data as |input|.
        1. Make a request to the underlying platform to initialize the batch normalization:
            1. Create an [=implementation-defined=] platform operator |batchNormImpl| for this method, given |input|, |mean|, |variance| and |options|.
            1. If |options|.activation [=map/exists=],register it as activation to |batchNormImpl|.
            1. Connect |output| as output to |batchNormImpl|.
    1. Return |output|.
  </div>
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation when the input tensor is 4-D of the *"nchw"* layout and the activation is of operator type *relu* can be generically emulated from the usage of other operations as follow. However, user agents typically have a more efficient implementation for it, therefore its usage is encouraged from the performance standpoint.
    </summary>
    <pre highlight="js">
    const shape = [1,null,1,1];
    return builder.relu(
      builder.add(
        builder.mul(
          builder.reshape(options.scale, shape),
          builder.div(
            builder.sub(input, builder.reshape(mean, shape)),
            builder.pow(
              builder.add(builder.reshape(variance, shape), builder.constant(options.epsilon)),
              builder.constant(0.5))
            )),
        builder.reshape(options.bias, shape)));
    </pre>
  </details>
</div>

### The clamp() method ### {#api-mlgraphbuilder-clamp}
Clamp the input tensor element-wise within a range specified by the minimum and maximum values.
<script type=idl>
dictionary MLClampOptions {
  float minValue;
  float maxValue;
};

partial interface MLGraphBuilder {
  MLOperand clamp(MLOperand operand, optional MLClampOptions options = {});
  MLActivation clamp(optional MLClampOptions options = {});
};
</script>

<div class="note">
<details open>
  <summary>
    The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint.
  </summary>
  <pre highlight="js">
    if (options.minValue === undefined) {
      if (options.maxValue === undefined) {
        return x;
      } else {
        return builder.min(x, builder.constant(options.maxValue));
      }
    } else {
      if (options.maxValue === undefined) {
        return builder.max(x, builder.constant(options.minValue));
      } else {
        return builder.min(
            builder.max(x, builder.constant(options.minValue)),
            builder.constant(options.maxValue));
      }
    }
  </pre>
</div>

<details open>
  <summary>
    To <dfn>check clamp options</dfn> given |options|, run the following steps:
  </summary>
  <div class=algorithm-steps>
    1. If |options| is not an [=object=] that [=implements=] {{MLClampOptions}}, then return `false`.
    1. If |options|.{{MLClampOptions/minValue}} and |options|.{{MLClampOptions/maxValue}} are not a [=numeric type=], then then return `false`.
    1. If |options|.{{MLClampOptions/minValue}} is greater than |options|.{{MLClampOptions/maxValue}}, then return `false`.
    1. Return `true`.
  </div>
</details>

#### The {{MLGraphBuilder/clamp(operand, options)}} method #### {#api-mlgraphbuilder-clamp-operand-options}
<div>
    **Arguments:**
        - *operand*: an {{MLOperand}}. The input tensor.
        - *options*: an optional {{MLClampOptions}}. The optional parameters of the operation.
            - *minValue*: a {{float}} scalar. Specifies the minimum value of the range. When it is not specified, the clamping is not performed on the lower limit of the range.
            - *maxValue*: a {{float}} scalar. Specifies the maximum value of the range. When it is not specified, the clamping is not performed on the upper limit of the range.
    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as *operand*.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/clamp(operand, options)}} method steps are:
  </summary>
  <div algorithm=clamp class=algorithm-steps>
    1. Let |operand| be the first argument.
    1. Let |options| be the second argument.
        1. If running the <a>check clamp options</a> steps with |options| returns `false`, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |operand|.
        1. Make a request to the underlying platform to:
            1. Create an [=implementation-defined=] platform operator |clampImpl| for this method, given |options|.{{MLClampOptions/minValue}} and |options|.{{MLClampOptions/minValue}}.
            1. Store a reference of |clampImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent clamp output, given |output| and |clampImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |operand|.{{MLOperand/[[operand]]}} as input to |clampImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |clampImpl|.
    1. Return |output|.
  </div>
</details>

#### The {{MLGraphBuilder/clamp(options)}} method #### {#api-mlgraphbuilder-clamp-options}
<div>
    **Arguments:**
        - *options*: an optional {{MLClampOptions}}. The optional parameters of the operation.
            - *minValue*: a {{float}} scalar. Specifies the minimum value of the range. When it is not specified, the clamping is not performed on the lower limit of the range.
            - *maxValue*: a {{float}} scalar. Specifies the maximum value of the range. When it is not specified, the clamping is not performed on the upper limit of the range.
    **Returns:**
        - an {{MLActivation}}. The operator representing the clamp operation.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/clamp(options)}} method steps are:
  </summary>
  <div algorithm=clamp-options class=algorithm-steps>
    1. Let |options| be the first argument.
        1. If running the <a>check clamp options</a> steps with |options| returns `false`, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
    1. Let |op| be the result of invoking the <a>create MLActivation</a> steps with `"clamp"` and |options|.
        1. If that throws an error, re-throw the error and abort these steps.
    1. Return |op|.
  </div>
</details>

### The concat() method ### {#api-mlgraphbuilder-concat}
Concatenates the input tensors along a given axis.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand concat(sequence<MLOperand> inputs, unsigned long axis);
};
</script>
<div>
    **Arguments:**
        - *inputs*: a sequence of {{MLOperand}}. All input tensors must have the
            same shape, except for the size of the dimension to concatenate on.
        - *axis*: an {{unsigned long}} scalar. The axis that the inputs concatenate along. Its value must be in the range [0, N-1] where N is the rank of input tensors.

    **Returns:** an {{MLOperand}}. The concatenated tensor of all the inputs along
    the *axis*. The output tensor has the same shape except on the dimension
    that all the inputs concatenated along. The size of that dimension is
    computed as the sum of all the input sizes of the same dimension.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/concat(inputs, axis)}} steps are:
  </summary>
  <div algorithm=concat class=algorithm-steps>
    <div class="note">
        The permissions and context validity have been checked by [[#api-mlgraphbuilder-constructor]] steps.
    </div>
    1. Let |inputs| be the first argument.
        1. [=Assert=]: the type of |inputs| is sequence of {{MLOperand}} objects.
        1. [=Assert=]: the type of |axis| is `unsigned long`.
        1. [=Assert=]: the shape, i.e. {{MLOperandDescriptor/dimensions}}) of each operand in |inputs| is the same, except on the dimension given by |axis| on which they are concatenated.
        1. [=Assert=]: the {{MLOperandDescriptor/type}} of each operand in |inputs| is the same.
        1. If any of the following steps fail, then throw a "{{DataError}}" {{DOMException}} and stop.
            1. If |inputs| is not an array of [=objects=], fail.
            1. If |axis| is not a positive integer [=number=], fail.
            1. If |axis| is greater than or equal to the <a>rank</a> of |inputs|, fail.
            1. Let |desc| be |inputs|[0].{{MLOperand/[[descriptor]]}}.
            1. Let |desc|.{{MLOperandDescriptor/dimensions}}[|axis|] be `0`.
            1. For each |index| between 0 and the <a>rank</a> of |inputs|:
                1. If running <a>validate MLOperand</a> given |inputs|[|index|] and [=this=]  returns `false`, then fail.
                1. For each |dim| between 0 and the <a>rank</a> of |inputs|[|index|]:
                    <div class="note">
                        If the shape of each corresponding dimension and type of the operands, except for those of the dimension given by |axis|, is not the same, fail.
                    </div>
                    1. If |dim| is not equal to |axis| and if |inputs|[|index|].{{MLOperandDescriptor/dimensions}}[|dim|] is not equal to |inputs|[0].{{MLOperandDescriptor/dimensions}}[|dim|], fail.
                    1. If |inputs|[|dim|].{{MLOperandDescriptor/type}} is not equal to |inputs|[0].{{MLOperandDescriptor/type}}.
                    1. If |dim| is equal to |axis|, add to |desc|.{{MLOperandDescriptor/dimensions}}[|axis|] the value of |inputs|[|index|].{{MLOperandDescriptor/dimensions}}[|dim|].
        1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
            1. Let |output| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
            1. Make a request to the underlying platform to:
                1. Create an [=implementation-defined=] platform operator |concatImpl| for this method, given |inputs| and |axis|.
                1. Store a reference of |concatImpl| in |output|.{{MLOperand/[[operator]]}}.
                1. Create an [=implementation-defined=] platform operand |outputImpl| to represent output,given |output| and |concatImpl|.
                1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
            1. Connect |inputs| as input to |concatImpl|.
            1. Connect |output|.{{MLOperand/[[operand]]}} as output to |concatImpl|.
        1. Return |output|.
  </div>
</details>

### The conv2d() method ### {#api-mlgraphbuilder-conv2d}
Compute a 2-D convolution given 4-D input and filter tensors
<script type=idl>
enum MLConv2dFilterOperandLayout {
  "oihw",
  "hwio",
  "ohwi",
  "ihwo"
};

enum MLAutoPad {
  "explicit",
  "same-upper",
  "same-lower"
};

dictionary MLConv2dOptions {
  sequence<unsigned long> padding;
  sequence<unsigned long> strides;
  sequence<unsigned long> dilations;
  MLAutoPad autoPad = "explicit";
  unsigned long groups = 1;
  MLInputOperandLayout inputLayout = "nchw";
  MLConv2dFilterOperandLayout filterLayout = "oihw";
  MLOperand bias;
  MLActivation activation;
};

partial interface MLGraphBuilder {
  MLOperand conv2d(MLOperand input, MLOperand filter, optional MLConv2dOptions options = {});
};
</script>

{{MLConv2dOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLConv2dOptions>
    : <dfn>padding</dfn>
    ::
        A sequence of {{unsigned long}} of length 4: [beginning_height, ending_height, beginning_width, ending_width].
        Specifies the additional rows and columns added to the beginning and ending of each spatial dimension of the convolution input.
        The default value is [0, 0, 0, 0].

    : <dfn>strides</dfn>
    ::
        A sequence of {{unsigned long}} of length 2: [stride_height, stride_width].
        Specifies the stride of the sliding window for each spatial dimension of the convolution input.
        The default value is [1, 1].

    : <dfn>dilations</dfn>
    ::
        A sequence of {{unsigned long}} of length 2: [dilation_height, dilation_width]. Specifies the dilation factor for each spatial dimension applied on the convolution filter (kernel).
        The default value is [1, 1].

    : <dfn>autoPad</dfn>
    ::
        An {{MLAutoPad}} [=string=].
        Specifies the automatic input padding options.
        The default value is *"explicit"*, which means that the values in the {{MLConv2dOptions/padding}} array should be used for input padding.
        When the option is set other than *"explicit"*, the values in the {{MLConv2dOptions/padding}} array are ignored.

        With the *"same-upper"* option, the padding values are automatically computed such that the additional ending padding of the spatial input dimensions would allow all of the input values in the corresponding dimension to be filtered.

        The *"same-lower"* option is similar but padding is applied to the beginning padding of the spatial input dimensions instead of the ending one.

    : <dfn>groups</dfn>
    ::
        An {{unsigned long}} scalar.
        Specifies the number of groups that input channels and output channels are divided into.
        The default value is 1.

    : <dfn>inputLayout</dfn>
    ::
        An {{MLInputOperandLayout}} [=string=].
        Specifies the layout format of the input and output tensor as follows:
            - **"nchw"**
                - input tensor: *[batches, input_channels, height, width]*
                - output tensor: *[batches, output_channels, height, width]*
            - **"nhwc"**:
                - input tensor: *[batches, height, width, input_channels]*
                - output tensor: *[batches, height, width, output_channels]*
        The default value is *"nchw"*.

    : <dfn>filterLayout</dfn>
    ::
          An {{MLConv2dFilterOperandLayout}} [=string=].
          Specifies the layout format of the filter tensor as follow:
              - **"oihw"**: *[output_channels, input_channels/groups, height, width]*
              - **"hwio"**: *[height, width, input_channels/groups, output_channels]*
              - **"ohwi"**: *[output_channels, height, width, input_channels/groups]*
              - **"ihwo"**: *[input_channels/groups, height, width, output_channels]*
          The default value is *"oihw"*.

    : <dfn>bias</dfn>
    ::
          An {{MLOperand}} object.
          Specifies the additional 1-D tensor with the shape of *[output_channels]* whose values are to be added to the convolution result.

    : <dfn>activation</dfn>
    ::
            An {{MLActivation}} object.
            Specifies the optional activation function that immediately follows the convolution operation.
</dl>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input 4-D tensor. The logical shape
            is interpreted according to the value of *options*.{{MLConv2dOptions/inputLayout}}.
        - *filter*: an {{MLOperand}}. The filter 4-D tensor. The logical shape is
            interpreted according to the value of *options*.{{MLConv2dOptions/filterLayout}} and *options*.{{MLConv2dOptions/groups}}.
        - *options*: an {{MLConv2dOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output 4-D tensor that contains the convolution result. The output shape is interpreted according to the *options*.{{MLConv2dOptions/inputLayout}} value. More specifically, the spatial dimensions or the sizes of the last two dimensions of the output tensor for the *nchw* input layout can be calculated as follow:

    *output_size = 1 + (input_size - (filter_size - 1) ** *dilation - 1 + beginning_padding + ending_padding) / stride*
</div>

<div class="note">
    A *depthwise* conv2d operation is a variant of grouped convolution, used in models like the MobileNet, where the *options.groups* = input_channels = output_channels and the shape of filter tensor is [options.groups, 1, height, width]
    for *"oihw"* layout, [height, width, 1, options.groups] for *"hwio"* layout, [options.groups, height, width, 1] for *"ohwi"* layout and [1, height, width, options.groups] for *"ihwo"* layout.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/conv2d(input, filter, options)}} steps are:
  </summary>
  <div algorithm=conv2d class=algorithm-steps>
    1. If |input| or |filter| is not an instance of {{MLOperand}}, then then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |input_size| be the size of |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}.
    1. Let |filter_size| be the size of |filter|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}.
    1. If |input_size| is not `4`, then then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |filter_size| is not `4`, then then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options| is `undefined`, let |options| be an empty [=object=].
    1. If |options|.{{MLConv2dOptions/padding}} is `undefined`, set it to `[0, 0, 0, 0]`.
    1. If |options|.{{MLConv2dOptions/strides}} is `undefined`, set it to `[1, 1]`.
    1. If |options|.{{MLConv2dOptions/dilations}} is `undefined`, set it to `[1, 1]`.
    1. If |options|.{{MLConv2dOptions/autoPad}} is `undefined`, set it to `"explicit"`.
    1. If |options|.{{MLConv2dOptions/groups}} is `undefined`, set it to `1`.
    1. If |options|.{{MLConv2dOptions/inputLayout}} is `undefined`, set it to `"nchw"`.
    1. If |options|.{{MLConv2dOptions/filterLayout}} is `undefined`, set it to `"oihw"`.
    1. If |options|.{{MLConv2dOptions/bias}} [=map/exists=] and it is not an instance of {{MLOperand}}, then then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options|.{{MLConv2dOptions/activation}} [=map/exists=] and it is not an instance of {{MLActivation}}, then then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |output_shape| be the result of calculating output dimensions based on input, filter, dilation, padding and stride, taking into account |options|.{{MLConv2dOptions/inputLayout}}.
    1. Let |desc| a new {{MLOperandDescriptor}}.
    1. Set |desc|.{{MLOperandDescriptor/type}} to |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/type}}.
    1. Set |desc|.{{MLOperandDescriptor/dimensions}} to |output_shape|.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
        1. Make a request to the underlying platform to:
            1. Create an [=implementation-defined=] platform operator |conv2dImpl| for this method, given |options| and |filter|.
                1. If |options|.{{MLConv2dOptions/activation}} [=map/exists=],register it as activation to |conv2dImpl|.
            1. Store a reference of |conv2dImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |conv2dImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |conv2dImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |conv2dImpl|.
    1. Return |output|.
  </div>
</details>

### The convTranspose2d() method ### {#api-mlgraphbuilder-convtranspose2d}
Compute a 2-D transposed convolution given 4-D input and filter tensors
<script type=idl>

enum MLConvTranspose2dFilterOperandLayout {
  "iohw",
  "hwoi",
  "ohwi"
};

dictionary MLConvTranspose2dOptions {
  sequence<unsigned long> padding;
  sequence<unsigned long> strides;
  sequence<unsigned long> dilations;
  sequence<unsigned long> outputPadding;
  sequence<unsigned long> outputSizes;
  MLAutoPad autoPad = "explicit";
  unsigned long groups = 1;
  MLInputOperandLayout inputLayout = "nchw";
  MLConvTranspose2dFilterOperandLayout filterLayout = "iohw";
  MLOperand bias;
  MLActivation activation;
};

partial interface MLGraphBuilder {
  MLOperand convTranspose2d(MLOperand input, MLOperand filter,
                            optional MLConvTranspose2dOptions options = {});
};
</script>

{{MLConvTranspose2dOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLConvTranspose2dOptions>
    : <dfn>padding</dfn>
    ::
        A sequence of {{unsigned long}} of length 4: [beginning_height, ending_height, beginning_width, ending_width].
        Specifies the additional rows and columns added to the beginning and ending of each spatial dimension of the convolution input.
        The default value is [0, 0, 0, 0].

    : <dfn>strides</dfn>
    ::
        A sequence of {{unsigned long}} of length 2: [stride_height, stride_width].
        Specifies the stride of the sliding window for each spatial dimension of the convolution input.
        The default value is [1, 1].

    : <dfn>dilations</dfn>
    ::
        A sequence of {{unsigned long}} of length 2: [dilation_height, dilation_width]. Specifies the dilation factor for each spatial dimension applied on the convolution filter (kernel).
        The default value is [1, 1].

    : <dfn>outputPadding</dfn>
    ::
        A sequence of {{unsigned long}} of length 2.
        Specifies the padding values applied to each spatial dimension of the output tensor. The explicit padding values are needed to disambiguate the output tensor shape for transposed convolution when the value of the *options*.{{MLConvTranspose2dOptions/strides}} is greater than 1.

        Note that these values are only used to disambiguate output shape when needed; it does not necessarily cause any padding value to be written to the output tensor.

        The default values is [0, 0].

    : <dfn>outputSizes</dfn>
    ::
        A sequence of {{unsigned long}} of length 2.
        Specifies the sizes of the last two dimensions of the output tensor. When the output sizes are explicitly specified, the output padding values in {{MLConvTranspose2dOptions/outputPadding}} are ignored.

        If not specified, the output sizes are automatically computed.

    : <dfn>autoPad</dfn>
    ::
        An {{MLAutoPad}} [=string=].
        Specifies the automatic input padding options.
        The default value is *"explicit"*, which means that the values in the {{MLConvTranspose2dOptions/padding}} array should be used for input padding.

        When the option is set other than *"explicit"*, the values in the {{MLConvTranspose2dOptions/padding}} array are ignored.

        With the *"same-upper"* option, the padding values are automatically computed such that the additional ending padding of the spatial input dimensions would allow all of the input values in the corresponding dimension to be filtered.

        The *"same-lower"* option is similar but padding is applied to the beginning padding of the spatial input dimensions instead of the ending one.

    : <dfn>groups</dfn>
    ::
        An {{unsigned long}} scalar.
        Specifies the number of groups that input channels and output channels are divided into.
        The default value is 1.

    : <dfn>inputLayout</dfn>
    ::
        An {{MLInputOperandLayout}} [=string=].
        Specifies the layout format of the input and output tensor as follows:
            - **"nchw"**
                - input tensor: *[batches, input_channels, height, width]*
                - output tensor: *[batches, output_channels, height, width]*
            - **"nhwc"**:
                - input tensor: *[batches, height, width, input_channels]*
                - output tensor: *[batches, height, width, output_channels]*
        The default value is *"nchw"*.

    : <dfn>filterLayout</dfn>
    ::
        An {{MLConvTranspose2dFilterOperandLayout}} [=string=].
        Specifies the layout format of the filter tensor as follow:
            - **"iohw"**: [input_channels, output_channels/groups, height, width]
            - **"hwoi"**: [height, width, output_channels/groups, input_channels]
            - **"ohwi"**: [output_channels/groups, height, width, input_channels]
        The default value is *"iohw"*.

    : <dfn>bias</dfn>
    ::
        An {{MLOperand}} object.
        Specifies the additional 1-D tensor with the shape of *[output_channels]* whose values are to be added to the convolution result.

    : <dfn>activation</dfn>
    ::
        An {{MLActivation}} object.
        Specifies the optional activation function that immediately follows the convolution operation.
</dl>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input 4-D tensor. The logical shape
            is interpreted according to the value of *options*.{{MLConvTranspose2dOptions/inputLayout}}.
        - *filter*: an {{MLOperand}}. The filter 4-D tensor. The logical shape is
            interpreted according to the value of *options*.{{MLConvTranspose2dOptions/filterLayout}} and {{MLConvTranspose2dOptions/groups}}.
        - *options*: an optional {{MLConvTranspose2dOptions}}.

    **Returns:** an {{MLOperand}}. The output 4-D tensor that contains the transposed convolution result. The output shape is interpreted according to the *options*.{{MLConvTranspose2dOptions/inputLayout}} value. More specifically, unless the *options*.{{MLConvTranspose2dOptions/outputSizes}} values are explicitly specified, the *options*.{{MLConvTranspose2dOptions/outputPadding}} may be needed to compute the spatial dimension values of the output tensor as follow:

    *output_size = (input_size - 1) ** *stride + (filter_size - 1) ** *dilation + 1 - beginning_padding - ending_padding + output_padding*
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/convTranspose2d(input, filter, options)}} steps are:
  </summary>
  <div algorithm=convtranspose2d class=algorithm-steps>
    1. If |input| or |filter| is not an instance of {{MLOperand}}, then then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |input_size| be the size of |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}.
    1. Let |filter_size| be the size of |filter|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}.
    1. If |input_size| is not `4`, then then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |filter_size| is not `4`, then then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options| is `undefined`, let |options| be an empty [=object=].
    1. If |options|.{{MLConvTranspose2dOptions/padding}} is `undefined`, set it to `[0, 0, 0, 0]`.
    1. If |options|.{{MLConvTranspose2dOptions/strides}} is `undefined`, set it to `[1, 1]`.
    1. If |options|.{{MLConvTranspose2dOptions/dilations}} is `undefined`, set it to `[1, 1]`.
    1. If |options|.{{MLConvTranspose2dOptions/outputPadding}} is `undefined`, set it to `[0, 0]`.
    1. If |options|.{{MLConvTranspose2dOptions/autoPad}} is `undefined`, set it to `"explicit"`.
    1. If |options|.{{MLConvTranspose2dOptions/groups}} is `undefined`, set it to `1`.
    1. If |options|.{{MLConvTranspose2dOptions/inputLayout}} is `undefined`, set it to `"nchw"`.
    1. If |options|.{{MLConvTranspose2dOptions/filterLayout}} is `undefined`, set it to `"iohw"`.
    1. If |options|.{{MLConvTranspose2dOptions/bias}} [=map/exists=] and it is not an instance of {{MLOperand}}, then then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options|.{{MLConvTranspose2dOptions/activation}} [=map/exists=] and it is not an instance of {{MLActivation}}, then then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |output_shape| be the result of calculating output dimensions based on |input|, |filter|, |options|.{{MLConvTranspose2dOptions/dilations}}, |options|.{{MLConvTranspose2dOptions/padding}} and |options|.{{MLConvTranspose2dOptions/strides}}, taking into account |options|.{{MLConvTranspose2dOptions/inputLayout}}.
    1. Let |desc| a new {{MLOperandDescriptor}}.
    1. Set |desc|.{{MLOperandDescriptor/type}} to |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/type}}.
    1. Set |desc|.{{MLOperandDescriptor/dimensions}} to |output_shape|.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
        1. Make a request to the underlying platform to:
            1. Create an [=implementation-defined=] platform operator |convTranspose2dImpl| for this method, given |options| and |filter|.
                1. If |options|.{{MLConvTranspose2dOptions/activation}} [=map/exists=],register it as activation to |convTranspose2dImpl|.
            1. Store a reference of |convTranspose2dImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |convTranspose2dImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |convTranspose2dImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |convTranspose2dImpl|.
    1. Return |output|.
  </div>
</details>

### Element-wise binary operations ### {#api-mlgraphbuilder-binary}
Compute the element-wise binary addition, subtraction, multiplication, division,
maximum and minimum of the two input tensors.

The element-wise binary operations will be broadcasted according to
[[!numpy-broadcasting-rule]]. The rank of the output tensor is the maximum
rank of the input tensors. For each dimension of the output tensor, its size
is the maximum size along that dimension of the input tensors.

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand add(MLOperand a, MLOperand b);
  MLOperand sub(MLOperand a, MLOperand b);
  MLOperand mul(MLOperand a, MLOperand b);
  MLOperand div(MLOperand a, MLOperand b);
  MLOperand max(MLOperand a, MLOperand b);
  MLOperand min(MLOperand a, MLOperand b);
  MLOperand pow(MLOperand a, MLOperand b);
};
</script>

<div>
    **Arguments:**
        - *a*: an {{MLOperand}}. The first input tensor.
        - *b*: an {{MLOperand}}. The second input tensor.

    **Returns:** an {{MLOperand}}. The output tensor that contains the result of
    element-wise binary operation of the two input tensors.
</div>
<div>
    **Operation types:**
        - *add*: Add the values of the two input tensors, element-wise.
        - *sub*: Subtract the values of the second input tensor from the values of the first input tensor, element-wise.
        - *mul*: Multiply the values of the two input tensors, element-wise.
        - *div*: Divide the values of the first input tensor with the values of the second tensor, element-wise.
        - *max*: Select the greater values of the two input tensors, element-wise.
        - *min*: Select the lesser values of the two input tensors, element-wise.
        - *pow*: Compute the values of the values of the first input tensor to the power of the values of the second input tensor, element-wise.
</div>

<details open>
  <summary>
    To <dfn for="MLGraphBuilder" data-lt="element-wise-binary-op">create element-wise binary operation</dfn> given |op|, |a| and |b|, run the following steps:
  </summary>
  <div algorithm=binary class=algorithm-steps>
    1. [=Assert=]: |op| is one of "add", "sub", "mul", "div", "max", "min", "pow".
    1. If |a| or |b| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |a|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/type}} is not equal to |b|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/type}}, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. Let |descriptor| be a new {{MLOperandDescriptor}}.
    1. Set |descriptor|.{{MLOperandDescriptor/dimensions}}.{{MLOperandDescriptor/type}} to |a|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/type}}.
    1. Let |descriptor|.{{MLOperandDescriptor/dimensions}} be the result of running the [=MLGraphBuilder/broadcast-shapes=] steps given |a|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}} and |b|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}.
        1. If that throws an error, re-throw the error and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |descriptor|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the binary operation |op|, given |a| and |b|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |a|.{{MLOperand/[[operand]]}} and |b|.{{MLOperand/[[operand]]}} as inputs to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

<details open>
  <summary>
    To <dfn for="MLGraphBuilder" lt="broadcast-shapes">broadcast shapes</dfn> given |shape1| and |shape2|, run the following steps:
  </summary>
  <div algorithm=broadcast-shape class=algorithm-steps>
    1. [=Assert=]: The type of |shape1| and |shape2| is `sequence of unsigned long`.
    1. Let |output| be the result of invoking the [=implementation-defined=] shape broadcast on |shape1| and |shape2|.
            1. If that fails, throw a "{{DataError}}" {{DOMException}} and stop.
    1. Return |output|.
        <div class = "note">
        The most common implementation is that two shapes are compatible, when each of their corresponding dimensions are equal, or one of them is 1. The output shape consists of the maximum of the corresponding dimensions.
        </div>
  </div>
</details>

<details open>
  <summary>
    The element-wise binary operation algorithms invoke the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation =] steps as follows.
  </summary>
  <div class=algorithm-steps>
    The {{MLGraphBuilder/add(a, b)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation =] given "add", |a| and |b|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/sub(a, b)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation =] given "sub", |a| and |b|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/mul(a, b)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation =] given "mul", |a| and |b|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/div(a, b)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation =] given "div", |a| and |b|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/max(a, b)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation =] given "max", |a| and |b|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/min(a, b)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation =] given "min", |a| and |b|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/pow(a, b)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation =] given "pow", |a| and |b|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.
</div>
</details>

### Element-wise unary operations ### {#api-mlgraphbuilder-unary}
Compute the element-wise unary operation for input tensor.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand abs(MLOperand input);
  MLOperand ceil(MLOperand input);
  MLOperand cos(MLOperand input);
  MLOperand exp(MLOperand input);
  MLOperand floor(MLOperand input);
  MLOperand log(MLOperand input);
  MLOperand neg(MLOperand input);
  MLOperand sin(MLOperand input);
  MLOperand tan(MLOperand input);
};
</script>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.

    **Returns:** an {{MLOperand}}. The output tensor that contains the result of
    element-wise unary operation of the input tensor. The shape of the output
    tensor is the same as the shape of input tensor.
</div>
<div>
    **Operation types:**
        - *abs*: Compute the absolute value of the input tensor, element-wise.
        - *ceil*: Compute the ceiling of the input tensor, element-wise.
        - *cos*: Compute the cosine of the input tensor, element-wise.
        - *exp*: Compute the exponential of the input tensor, element-wise.
        - *floor*: Compute the floor of the input tensor, element-wise.
        - *log*: Compute the natural logarithm of the input tensor, element-wise.
        - *neg*: Compute the numerical negative value of the input tensor, element-wise.
        - *sin*: Compute the sine of the input tensor, element-wise.
        - *tan*: Compute the tangent of the input tensor, element-wise.
</div>

<details open>
  <summary>
    To <dfn for="MLGraphBuilder" data-lt="element-wise-unary-op">create element-wise unary operation</dfn> given |op| and |input|, run the following steps:
  </summary>
  <div algorithm=unary class=algorithm-steps>
    1. [=Assert=]: |op| is one of "abs", "ceil", "cos", "exp", "floor", "log", "neg", "sin", "tan".
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |kind| be `"output"`.
    1. Let |descriptor| be a new {{MLOperandDescriptor}}.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the unary operation |op|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

<details open>
  <summary>
    The element-wise unary operation algorithms invoke the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation =] steps as follows.
  </summary>
  <div class=algorithm-steps>
    The {{MLGraphBuilder/abs(input)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation =] given "abs" and |input|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/ceil(input)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation =] given "ceil" and |input|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/cos(input)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation =] given "cos" and |input|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/exp(input)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation =] given "exp" and |input|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/floor(input)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation =] given "floor" and |input|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/log(input)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation =] given "log" and |input|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/neg(input)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation =] given "neg" and |input|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/sin(input)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation =] given "sin" and |input|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/tan(input)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation =] given "tan" and |input|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.
  </div>
</details>

### The elu() method ### {#api-mlgraphbuilder-elu}
Calculate the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#ELU"> exponential linear unit function</a> (ELU) on the input tensor element-wise. The calculation follows the expression `max(0, x) + alpha * (exp(min(0, x)) - 1)`.

<script type=idl>
dictionary MLEluOptions {
  float alpha = 1;
};

partial interface MLGraphBuilder {
  MLOperand elu(MLOperand input, optional MLEluOptions options = {});
  MLActivation elu(optional MLEluOptions options = {});
};
</script>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint.
    </summary>
    <pre highlight="js">
    return builder.add(
              builder.max(builder.constant(0), x),
              builder.mul(
                builder.constant(options.alpha),
                builder.sub(
                  builder.exp(builder.min(builder.constant(0), x)),
                  builder.constant(1))));
    </pre>
  </details>
</div>

<details open>
  <summary>
    To <dfn>check ELU options</dfn> given |options|, run the following steps:
  </summary>
  <div algorithm=check-elu-options class=algorithm-steps>
    1. If |options| is not an [=object=] that [=implements=] {{MLEluOptions}}, then return `false`.
    1. If |options|.{{MLEluOptions/alpha}} is `undefined`, set |options|.{{MLEluOptions/alpha}} to `1`.
    1. Else if |options|.{{MLEluOptions/alpha}} is not a [=numeric type=], then then return `false`.
    1. Return `true`.
  </div>
</details>

#### The {{MLGraphBuilder/elu(input, options)}} method #### {#api-mlgraphbuilder-elu-input-options}
<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.
        - *options*: an optional {{MLEluOptions}}. The optional parameters of the operation.
            - *alpha*: a {{float}} scalar multiplier, default to 1.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as *x*.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/elu(input, options)}} method steps are:
  </summary>
  <div algorithm=elu-input-options class=algorithm-steps>
    1. Let |input| be the first argument.
    1. Let |options| be the second argument.
        1. If running the <a>check ELU options</a> steps with |options| returns `false`, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the ELU operation, given |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

#### The {{MLGraphBuilder/elu(options)}} method #### {#api-mlgraphbuilder-elu-options}
<div>
    **Arguments:**
        - *options*: an optional {{MLEluOptions}}. The optional parameters of the operation.
            - *alpha*: a {{float}} scalar multiplier, default to 1.

    **Returns:**
        - an {{MLActivation}}. The activation function representing the elu operation.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/elu(options)}} method steps are:
  </summary>
  <div algorithm=elu-options class=algorithm-steps>
    1. Let |options| be the first argument.
        1. If |options| is `undefined`, let |options| be a new {{MLEluOptions}} object.
        1. If running the <a>check ELU options</a> steps with |options| returns `false`, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
    1. Let |op| be the result of invoking the <a>create MLActivation</a> steps with `"elu"` and |options|.
    1. Return |op|.
  </div>
</details>

### The gemm() method ### {#api-mlgraphbuilder-gemm}
Calculate the [general matrix multiplication of the Basic Linear Algebra Subprograms](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3). The calculation follows the expression `alpha * A * B + beta * C`, where `A` is a 2-D tensor with shape [M, K] or [K, M], `B` is a 2-D tensor with shape [K, N] or [N, K], and `C` is broadcastable to the shape [M, N]. `A` and `B` may optionally be transposed prior to the calculation.

<script type=idl>
dictionary MLGemmOptions {
  MLOperand c;
  float alpha = 1.0;
  float beta = 1.0;
  boolean aTranspose = false;
  boolean bTranspose = false;
};

partial interface MLGraphBuilder {
  MLOperand gemm(MLOperand a, MLOperand b, optional MLGemmOptions options = {});
};
</script>

{{MLGemmOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLGemmOptions>
    : <dfn>c</dfn>
    ::
        An {{MLOperand}}. Specifies the third input tensor. It is either a scalar, or of the shape that is unidirectionally broadcastable to the shape [M, N] according to [[!numpy-broadcasting-rule]]. When it is not specified, the computation is done as if *c* is a scalar `0.0`.

    : <dfn>alpha</dfn>
    ::
        A {{float}} scalar multiplier for the first input.

    : <dfn>beta</dfn>
    ::
        A {{float}} scalar multiplier for the third input {{MLGemmOptions/c}}.

    : <dfn>aTranspose</dfn>
    ::
        A {{boolean}} indicating if the first input should be transposed prior to calculating the output.

    : <dfn>bTranspose</dfn>
    ::
        A {{boolean}} indicating if the second input should be transposed prior to calculating the output.
</dl>

<div>
    **Arguments:**
        - *a*: an {{MLOperand}}. The first input 2-D tensor with shape [M, K] if *aTranspose* is false, or [K, M] if *aTranspose* is true.
        - *b*: an {{MLOperand}}. The second input 2-D tensor with shape [K, N] if *bTranspose* is false, or [N, K] if *bTranspose* is true.
        - *options*: an optional {{MLGemmOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output 2-D tensor of shape [M, N] that contains the calculated product of all the inputs.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/gemm(a, b, options)}} steps are:
  </summary>
  <div algorithm=gemm class=algorithm-steps>
    1. If |a| or |b| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options| is `undefined`, let |options| be an empty [=object=].
    1. If |options|.{{MLGemmOptions/alpha}} is `undefined`, set it to `1.0`.
    1. If |options|.{{MLGemmOptions/beta}} is `undefined`, set it to `1.0`.
    1. If |options|.{{MLGemmOptions/aTranspose}} is `undefined`, set it to `false`.
    1. If |options|.{{MLGemmOptions/aTranspose}} is not `false`, set it to `true`.
    1. If |options|.{{MLGemmOptions/bTranspose}} is `undefined`, set it to `false`.
    1. If |options|.{{MLGemmOptions/bTranspose}} is not `false`, set it to `true`.
    1. Let |shapeA| be |a|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}} and |sizeA| the size of |shapeA|.
    1. Let |shapeB| be |a|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}} and |sizeB| the size of |shapeB|.
    1. If |sizeA| is not `2` or |sizeB| is not `2`, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLGemmOptions/aTranspose}} is `true`, then let |shapeA| be the reverse array of |shapeA|.
    1. If |options|.{{MLGemmOptions/bTranspose}} is `true`, then let |shapeB| be the reverse array of |shapeB|.
    1. If |shapeA|[1] is not equal to |shapeB|[0], then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLGemmOptions/c}} [=map/exists=] and is not unidirectionally broadcastable to the shape [|shapeA|[0], |shapeB|[1]] according to the [[!numpy-broadcasting-rule]], then throw a "{{DataError}}" {{DOMException}} and stop.
        <div class="note">
            Type compatibility between |a|, |b| and |options|.{{MLGemmOptions/c}} can be also checked.
        </div>
    1. Let |desc| a new {{MLOperandDescriptor}}.
    1. Set |desc|.{{MLOperandDescriptor/dimensions}} to [|shapeA|[0], |shapeB|[1]].
    1. Set |desc|.{{MLOperandDescriptor/type}} to |a|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/type}}.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the GEMM operation, given |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |a|.{{MLOperand/[[operand]]}} and |b|.{{MLOperand/[[operand]]}} as inputs to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation can be generically emulated from the usage of other operations as follow. However, user agents typically have a more efficient implementation for it, therefore its usage is encouraged from the performance standpoint.
  </summary>
  <pre highlight="js">
    if (options.aTranspose)
      a = builder.transpose(a);

    if (options.bTranspose)
      b = builder.transpose(b);

    let ab = builder.matmul(builder.mul(builder.constant(options.alpha), a), b);
    return (c ? builder.add(ab, builder.mul(builder.constant(options.beta), c)) : ab);
  </pre>
</details>
</div>

### The gru() method ### {#api-mlgraphbuilder-gru}
Gated Recurrent Unit [[GRU]] recurrent network uses an update, reset, and new gate to compute the output state that rolls into the output across the temporal sequence of the network.
<script type=idl>
enum MLGruWeightLayout {
  "zrn",  // update-reset-new gate ordering
  "rzn"   // reset-update-new gate ordering
};

enum MLRecurrentNetworkDirection {
  "forward",
  "backward",
  "both"
};

dictionary MLGruOptions {
  MLOperand bias;
  MLOperand recurrentBias;
  MLOperand initialHiddenState;
  boolean resetAfter = true;
  boolean returnSequence = false;
  MLRecurrentNetworkDirection direction = "forward";
  MLGruWeightLayout layout = "zrn";
  sequence<MLActivation> activations;
};

partial interface MLGraphBuilder {
  sequence<MLOperand> gru(MLOperand input, MLOperand weight, MLOperand recurrentWeight,
                          unsigned long steps, unsigned long hiddenSize,
                          optional MLGruOptions options = {});
};
</script>

{{MLGruOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLGruOptions>
    : <dfn>bias</dfn>
    ::
        An {{MLOperand}}. Specifies the 2-D input bias tensor of shape [num_directions, 3 * hidden_size]. The ordering of the bias vectors in the second dimension of the tensor shape is specified according to the {{MLGruOptions/layout}} argument.

    : <dfn>recurrentBias</dfn>
    ::
        An {{MLOperand}}. Specifies the 2-D recurrent bias tensor of shape [num_directions, 3 * hidden_size]. The ordering of the bias vectors in the second dimension of the tensor shape is specified according to the {{MLGruOptions/layout}} argument.

    : <dfn>initialHiddenState</dfn>
    ::
        An {{MLOperand}}. The 3-D initial hidden state tensor of shape [num_directions, batch_size, hidden_size].
        When not specified, implementations SHOULD use a tensor filled with zero.

    : <dfn>resetAfter</dfn>
    ::
        A {{boolean}} indicating whether to apply the reset gate after or before matrix multiplication. The default value is `true`.

    : <dfn>returnSequence</dfn>
    ::
        A {{boolean}} indicating whether to also return the entire sequence with every output from each time step in it in addition to the output of the last time step.
        The default value is `false`.

    : <dfn>direction</dfn>
    ::
        An {{MLRecurrentNetworkDirection}}. Specifies the processing direction of the input sequence. When set to `"both"`, the size of the first dimension of the weight and the bias tensor shapes must be `2`, and the input is processed in both directions.

    : <dfn>layout</dfn>
    ::
        An {{MLGruWeightLayout}}. The ordering of the weight and bias vectors for the internal gates of GRU, specifically the `update (z)`, `reset (r)`, and `new (n)` gate, as indicated in the second dimension of the weight and bias tensor shape. When not specified, the default layout is `"zrn"`.

    : <dfn>activations</dfn>
    ::
        A sequence of {{MLActivation}}. Specifies a pair of activation functions with the first function used for the update and reset gate, and the second used for the new gate. When not specified, implementations SHOULD use the the pair of sigmoid (`"sigmoid"`) and the hyperbolic tangent (`"tanh"`) functions, respectively.
</dl>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input 3-D tensor of shape [steps, batch_size, input_size].
        - *weight*: an {{MLOperand}}. The 3-D input weight tensor of shape [num_directions, 3 * hidden_size, input_size]. The ordering of the weight vectors in the second dimension of the tensor shape is specified according to the |options|.{{MLGruOptions/layout}} argument.
        - *recurrentWeight*: an {{MLOperand}}. The 3-D recurrent weight tensor of shape [num_directions, 3 * hidden_size, hidden_size]. The ordering of the weight vectors in the second dimension of the tensor shape is specified according to the |options|.{{MLGruOptions/layout}} argument.
        - *steps*: an {{unsigned long}} scalar. The number of time steps in the recurrent network. The value must be greater than 0.
        - *hiddenSize*: an {{unsigned long}} scalar. The value of the third dimension of the cell output tensor shape. It indicates the number of features in the hidden state.
        - *options*: an optional {{MLGruOptions}}. The optional parameters of the operation.

    **Returns:** a sequence of {{MLOperand}}. The first element of the sequence is a 3-D tensor of shape [num_directions, batch_size, hidden_size], the cell output from the last time step of the network. Additionally, if |options|.{{MLGruOptions/returnSequence}} is set to `true`, the second element is the 4-D output tensor of shape [steps, num_directions, batch_size, hidden_size] containing every cell outputs from each time step in the temporal sequence.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/gru(input, weight, recurrentWeight, steps, hiddenSize, options)}} steps are:
  </summary>
  <div algorithm=gru class=algorithm-steps>
    1. If |input|, |weight| or |recurrentWeight| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If the rank of |input| or |weight| is not `3`, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If the rank of |weight| or |recurrentWeight| is not `2`, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options| is `undefined`, let |options| be an empty [=object=].
    1. If |options|.{{MLGruOptions/bias}} [=map/exists=].
        1. If it is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If its rank is not `2`, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLGruOptions/recurrentBias}} [=map/exists=].
        1. If it is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If its rank is not `2`, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLGruOptions/initialHiddenState}} [=map/exists=].
        1. If it is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If its rank is not `3`, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLGruOptions/resetAfter}} is `undefined`, set it to `true`.
    1. If |options|.{{MLGruOptions/returnSequence}} is `undefined`, set it to `false`.
    1. If |options|.{{MLGruOptions/direction}} is `undefined`, set it to `"forward"`.
    1. If |options|.{{MLGruOptions/direction}} is not one of {{MLRecurrentNetworkDirection}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options|.{{MLGruOptions/layout}} is `undefined`, set it to `"zrn"`.
    1. If |options|.{{MLGruOptions/layout}} is not one of {{MLGruWeightLayout}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options|.{{MLGruOptions/activations}} [=map/exists=] and is not an array of size `2`, or if any of its elements is not an instance of {{MLActivation}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |steps| is not a [=number=] or it is `0`, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |output| be an empty sequence of {{MLOperand}} objects.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for `"gru"`, given |weight|, |recurrentWeight|, |steps|, |hiddenSize| and |options| as parameters.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output| as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation can be generically emulated from the usage of other operations as follows. However, user agents typically have a more efficient implementation for it, therefore its usage is encouraged from the performance standpoint.
  </summary>
  <pre highlight="js">
    const numDirections = (options.direction == "both" ? 2 : 1);
    let hiddenState = options.initialHiddenState;

    if (!hiddenState) {
      const desc = { type: 'float32', dimensions: [numDirections, 1, hiddenSize] };
      const totalSize = numDirections * hiddenSize;
      hiddenState = builder.constant(desc, new Float32Array(totalSize).fill(0));
    }

    let sequence = null;
    let currentWeight = [];
    let currentRecurrentWeight = [];
    let currentBias = [];
    let currentRecurrentBias = [];

    for (let dir = 0; dir < numDirections; ++dir) {
      currentWeight.push(builder.squeeze(builder.slice(weight, [dir, 0, 0], [1, 3 * hidden_size, input_size]), { axes: [0] }));
      currentRecurrentWeight.push(builder.squeeze(builder.slice(recurrentWeight, [dir, 0, 0], [1, 3 * hidden_size, hidden_size]), { axes: [0] }));
      currentBias.push(options.bias ? (builder.squeeze(builder.slice(options.bias, [dir, 0], [1, 3 * hidden_size]), { axes: [0] })) : null);
      currentRecurrentBias.push(options.recurrentBias ?
        (builder.squeeze(builder.slice(options.recurrentBias, [dir, 0], [1, 3 * hidden_size]), { axes: [0] })) : null);
    }

    for (let step = 0; step < steps; ++step) {
      let currentHidden = [];
      let currentOutput = null;

      for (let dir = 0; dir < numDirections; ++dir) {
        currentHidden.push(builder.squeeze(builder.slice(hiddenState, [dir, 0, 0], [1, batch_size, hidden_size]), { axes: [0] }));
      }

      for (let dir = 0; dir < numDirections; ++dir) {
        let slice = (dir == 1 || options.direction == "backward" ? steps - step - 1 : step);
        let currentInput = builder.squeeze(builder.slice(input, [slice, 0, 0], [1, batch_size, input_size]), { axes: [0] });

        let result = builder.reshape(
          builder.gruCell(
            currentInput, currentWeight[dir], currentRecurrentWeight[dir],
            currentHidden[dir], hiddenSize, { bias: currentBias[dir],
            recurrentBias: currentRecurrentBias[dir], resetAfter: options.resetAfter,
            layout: options.layout, activations: options.activations }),
          [1, null, hiddenSize]);

        currentOutput = (currentOutput ? builder.concat([currentOutput, result], 0) : result);
      }

      hiddenState = currentOutput;

      if (options.returnSequence) {
        currentOutput = builder.reshape(currentOutput, [1, numDirections, null, hiddenSize]);
        sequence = (sequence ? builder.concat([sequence, currentOutput], 0) : currentOutput);
      }
    }

    return (sequence ? [hiddenState, sequence] : [hiddenState]);
  </pre>
</details>
</div>

### The gruCell() method ### {#api-mlgraphbuilder-grucell}
A single time step of the Gated Recurrent Unit [[GRU]] recurrent network using an update gate and a reset gate to compute the hidden state that rolls into the output across the temporal sequence of a recurrent network.

<script type=idl>
dictionary MLGruCellOptions {
  MLOperand bias;
  MLOperand recurrentBias;
  boolean resetAfter = true;
  MLGruWeightLayout layout = "zrn";
  sequence<MLActivation> activations;
};

partial interface MLGraphBuilder {
  MLOperand gruCell(MLOperand input, MLOperand weight, MLOperand recurrentWeight,
                    MLOperand hiddenState, unsigned long hiddenSize,
                    optional MLGruCellOptions options = {});
};
</script>

{{MLGruCellOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLGruCellOptions>
    : <dfn>bias</dfn>
    ::
        An {{MLOperand}}. Specifies the 1-D input bias tensor of shape [3 * hidden_size]. The ordering of the bias vectors in the second dimension of the tensor shape is specified according to the {{MLGruOptions/layout}} argument.

    : <dfn>recurrentBias</dfn>
    ::
        An {{MLOperand}}. Specifies the 1-D recurrent bias tensor of shape [3 * hidden_size]. The ordering of the bias vectors in the second dimension of the tensor shape is specified according to the {{MLGruOptions/layout}} argument.

    : <dfn>resetAfter</dfn>
    ::
        A {{boolean}} indicating whether to apply the reset gate after or before matrix multiplication. The default value is `true`.

    : <dfn>layout</dfn>
    ::
        An {{MLGruWeightLayout}}. The ordering of the weight and bias vectors for the internal gates of GRU, specifically the `update (z)`, `reset (r)`, and `new (n)` gate, as indicated in the second dimension of the weight and bias tensor shape. When not specified, the default layout is `"zrn"`.

    : <dfn>activations</dfn>
    ::
        A sequence of {{MLActivation}}. Specifies a pair of activation functions with the first function used for the update and reset gate, and the second used for the new gate. When not specified, implementations SHOULD use the the pair of sigmoid (`"sigmoid"`) and the hyperbolic tangent (`"tanh"`) functions, respectively.
</dl>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input 2-D tensor of shape [batch_size, input_size].
        - *weight*: an {{MLOperand}}. The 2-D input weight tensor of shape [3 * hidden_size, input_size]. The ordering of the weight vectors in the first dimension of the tensor shape is specified according to the *options.layout* argument.
        - *recurrentWeight*: an {{MLOperand}}. The 2-D recurrent weight tensor of shape [3 * hidden_size, hidden_size]. The ordering of the weight vectors in the first dimension of the tensor shape is specified according to the *options.layout* argument.
        - *hiddenState*: an {{MLOperand}}. The 2-D input hidden state tensor of shape [batch_size, hidden_size].
        - *hiddenSize*: an {{unsigned long}} scalar. The value of the second dimension of the output tensor shape. It indicates the number of features in the hidden state.
        - *options*: an optional {{MLGruCellOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The 2-D tensor of shape [batch_size, hidden_size], the cell output hidden state of a single time step of the recurrent network.
</div>

<details open>
  <summary>
     The {{MLGraphBuilder/gruCell(input, weight, recurrentWeight, hiddenState, hiddenSize, options)}} steps are:
  </summary>
  <div algorithm=grucell class=algorithm-steps>
    1. If |input|, |weight| or |recurrentWeight| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If the rank of |input| or |weight| is not `3`, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If the rank of |weight| or |recurrentWeight| is not `2`, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options| is `undefined`, let |options| be an empty [=object=].
    1. If |options|.{{MLGruOptions/bias}} [=map/exists=].
        1. If it is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If its rank is not `1`, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLGruOptions/recurrentBias}} [=map/exists=].
        1. If it is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If its rank is not `1`, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLGruOptions/resetAfter}} is `undefined`, set it to `true`.
    1. If |options|.{{MLGruOptions/layout}} is `undefined`, set it to `"zrn"`.
    1. If |options|.{{MLGruOptions/layout}} is not one of {{MLGruWeightLayout}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options|.{{MLGruOptions/activations}} [=map/exists=] and is not an array of size `2`, or if any of its elements is not an instance of {{MLActivation}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |desc| a new {{MLOperandDescriptor}}.
    1. Set |desc|.{{MLOperandDescriptor/dimensions}} to [ |input|.{{MLOperandDescriptor/dimensions}}[0], |hiddenSize| ].
    1. Set |desc|.{{MLOperandDescriptor/type}} to |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/type}}.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for `"gruCell"`, given |weight|, |recurrentWeight|, |hiddenState|, |hiddenSize| and |options| as parameters.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation can be generically emulated via other operations as shown below, when the weight layout is the default *"zrn"* layout, and the activation functions of the update/reset gate and new gate are of the operator types *sigmoid* and *tanh* respectively.
  </summary>
  <pre highlight="js">
    const one = builder.constant(1);
    const zero = builder.constant(0);

    // update gate (z)
    let z = builder.sigmoid(
      builder.add(
        builder.add(
          (options.bias ? builder.slice(options.bias, [0], [hiddenSize]) : zero),
          (options.recurrentBias ? builder.slice(options.recurrentBias, [0], [hiddenSize]) : zero)
          ),
        builder.add(
          builder.matmul(
            input,
            builder.transpose(builder.slice(weight, [0, 0], [hiddenSize, input_size]))
            ),
          builder.matmul(
            hiddenState,
            builder.transpose(builder.slice(recurrentWeight, [0, 0], [hiddenSize, hidden_size]))
            )
          )
        )
      );

    // reset gate (r)
    let r = builder.sigmoid(
      builder.add(
        builder.add(
          (options.bias ? builder.slice(options.bias, [hiddenSize], [hiddenSize]) : zero),
          (options.recurrentBias ? builder.slice(options.recurrentBias, [hiddenSize], [hiddenSize]) : zero)
          ),
        builder.add(
          builder.matmul(
            input,
            builder.transpose(builder.slice(weight, [hiddenSize, 0], [hiddenSize, input_size]))
            ),
          builder.matmul(
            hiddenState,
            builder.transpose(builder.slice(recurrentWeight, [hiddenSize, 0], [hiddenSize, hidden_size]))
            )
          )
        )
      );

    // new gate (n)
    let n;
    if (resetAfter) {
      n = builder.tanh(
        builder.add(
          (options.bias ? builder.slice(options.bias, [2 * hiddenSize], [hiddenSize]) : zero),
          builder.add(
            builder.matmul(
              input,
              builder.transpose(builder.slice(weight, [2 * hiddenSize, 0], [hiddenSize, input_size]))
              ),
            builder.mul(
              r,
              builder.add(
                (options.recurrentBias ? builder.slice(options.recurrentBias, [2 * hiddenSize], [hiddenSize]) : zero),
                builder.matmul(
                  hiddenState,
                  builder.transpose(builder.slice(recurrentWeight, [2 * hiddenSize, 0], [hiddenSize, hidden_size]))
                  )
                )
              )
            )
          )
        );
    }
    else {
      n = builder.tanh(
        builder.add(
          builder.add(
            (options.bias ? builder.slice(options.bias, [2 * hiddenSize], [hiddenSize]) : zero),
            (options.recurrentBias ? builder.slice(options.recurrentBias, [2 * hiddenSize], [hiddenSize]) : zero)
            ),
          builder.add(
            builder.matmul(
              input,
              builder.transpose(builder.slice(weight, [2 * hiddenSize, 0], [hiddenSize, input_size]))
              ),
            builder.matmul(
              builder.mul(r, hiddenState),
              builder.transpose(builder.slice(recurrentWeight, [2 * hiddenSize, 0], [hiddenSize, hidden_size]))
              )
            )
          )
        );
    }

    // compute the new hidden state
    return builder.add(builder.mul(z, hiddenState), builder.mul(n, builder.sub(one, z)));
  </pre>
</details>
</div>

### The hardSigmoid() method ### {#api-mlgraphbuilder-hard-sigmoid}
Calculate the non-smooth <a href="https://en.wikipedia.org/wiki/Hard_sigmoid">hard sigmoid function</a> on the input tensor, used instead of the sigmoid function for faster computation.
<script type=idl>
dictionary MLHardSigmoidOptions {
  float alpha = 0.2;
  float beta = 0.5;
};

partial interface MLGraphBuilder {
  MLOperand hardSigmoid(MLOperand input, optional MLHardSigmoidOptions options = {});
  MLActivation hardSigmoid(optional MLHardSigmoidOptions options = {});
};
</script>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint.
    </summary>
    <pre highlight="js">
    return builder.max(
               builder.min(
                   builder.add(
                       builder.mul(builder.constant(options.alpha), x),
                       builder.constant(options.beta)),
                   builder.constant(1)),
               builder.constant(0));
    </pre>
  </details>
</div>

{{MLHardSigmoidOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLHardSigmoidOptions>
    : <dfn>alpha</dfn>
    ::
         A {{float}} scalar multiplier.
         The default value is `0.2`.
    : <dfn>beta</dfn>
    ::
         A {{float}} point scalar addition.
         The default value is `0.5`.
</dl>

<details open>
  <summary>
    To <dfn>check hard-sigmoid options</dfn> given |options|, run the following steps:
  </summary>
  <div algorithm=check-hard-sigmoid-options class=algorithm-steps>
    1. If |options| is not an [=object=] that [=implements=] {{MLHardSigmoidOptions}}, then return `false`.
    1. If |options|.{{MLEluOptions/alpha}} is `undefined`, set |options|.{{MLHardSigmoidOptions/alpha}} to `0.2`.
    1. Else if |options|.{{MLHardSigmoidOptions/alpha}} is not a [=numeric type=], then then return `false`.
    1. If |options|.{{MLHardSigmoidOptions/beta}} is `undefined`, set |options|.{{MLHardSigmoidOptions/beta}} to `0.5`.
    1. Else if |options|.{{MLHardSigmoidOptions/beta}} is not a [=numeric type=], then then return `false`.
    1. Return `true`.
  </div>
</details>

#### The {{MLGraphBuilder/hardSigmoid(input, options)}} method #### {#api-mlgraphbuilder-hardsigmoid-input-options}
<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.
        - *options*: an optional {{MLHardSigmoidOptions}}. The optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as *input*.
</div>
<div algorithm=hardsigmoid-input-options class=algorithm-steps>
    The {{MLGraphBuilder/hardSigmoid(input, options)}} method steps are:
    1. Let |input| be the first argument.
    1. Let |options| be the second argument.
        1. If running the <a>check hard-sigmoid options</a> steps with |options| returns `false`, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the hard sigmoid operation, given |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
</div>

#### The {{MLGraphBuilder/hardSigmoid(options)}} method #### {#api-mlgraphbuilder-hardsigmoid-options}
<div>
    **Arguments:**
        - *options*: an optional {{MLHardSigmoidOptions}}. The optional parameters of the operation.

    **Returns:**
        - an {{MLActivation}}. The activation function representing the hard sigmoid operation.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/hardSigmoid(options)}} method steps are:
  </summary>
  <div algorithm=hard-sigmoid-options class=algorithm-steps>
    1. Let |options| be the first argument.
        1. If running the <a>check hard-sigmoid options</a> steps with |options| returns `false`, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
    1. Let |op| be the result of invoking the <a>create MLActivation</a> steps with `"hardSigmoid"` and |options|.
        1. If that throws an error, re-throw the error and abort these steps.
    1. Return |op|.
  </div>
</details>

### The hardSwish() method ### {#api-mlgraphbuilder-hard-swish}
Computes the nonlinear function `y = x * max(0, min(6, (x + 3))) / 6` that is introduced by [[MobileNetV3]] on the input tensor element-wise.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand hardSwish(MLOperand input);
  MLActivation hardSwish();
};
</script>

<div class="note">
<details open>
  <summary>
    The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint.
  </summary>
  <pre highlight="js">
    return builder.div(
               builder.mul(
                   x,
                   builder.max(
                       builder.constant(0),
                       builder.min(
                           builder.constant(6),
                           builder.add(x, builder.constant(3))))),
               builder.constant(6));
  </pre>
</details>
</div>

#### The {{MLGraphBuilder/hardSwish(input)}} method #### {#api-mlgraphbuilder-hardswish-input}
<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as *input*.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/hardSwish(input)}} method steps are:
  </summary>
  <div algorithm=hardswish-input class=algorithm-steps>
    1. Let |input| be the first argument.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the hard-swish operation.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

#### The {{MLGraphBuilder/hardSwish()}} method #### {#api-mlgraphbuilder-hardswish}
<div>
    **Arguments:**
        - None.

    **Returns:**
        - an {{MLActivation}}. The activation function representing the hard-swish operation.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/hardSwish()}} method steps are:
  </summary>
  <div algorithm=hard-swish class=algorithm-steps>
    1. Let |op| be the result of invoking the <a>create MLActivation</a> steps with `"hardSwish"`.
        1. If that throws an error, re-throw the error and abort these steps.
    1. Return |op|.
 </div>
</details>

### The instanceNormalization() method ### {#api-mlgraphbuilder-instancenorm}
Normalize the input features using [[Instance-Normalization]]. Unlike [[#api-mlgraphbuilder-batchnorm]] where the mean and variance values used in the calculation are previously computed across the batch dimension during the model training phase, the mean and variance values used in the calculation of an instance normalization are computed internally on the fly per input feature.

<script type=idl>
dictionary MLInstanceNormalizationOptions {
  MLOperand scale;
  MLOperand bias;
  float epsilon = 1e-5;
  MLInputOperandLayout layout = "nchw";
};

partial interface MLGraphBuilder {
  MLOperand instanceNormalization(MLOperand input,
                                optional MLInstanceNormalizationOptions options = {});
};
</script>

The {{MLInstanceNormalizationOptions}} members are:
<dl dfn-type=dict-member dfn-for=MLInstanceNormalizationOptions>
    : <dfn>scale</dfn>
    ::
        An {{MLOperand}}. Specifies he 1-D tensor of the scaling values whose length is equal to the number of channels, i.e. the size of the feature dimension of the input. For example, for an |input| tensor with `nchw` layout, the length is the value of |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[1].

    : <dfn>bias</dfn>
    ::
        An {{MLOperand}}. Specifies the 1-D tensor of the bias values whose length is equal to the size of the feature dimension of the input. For example, for an |input| tensor with `nchw` layout, the length is the value of |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[1].

    : <dfn>epsilon</dfn>
    ::
        A {{float}} scalar. Specifies a small value to prevent computational error due to divide-by-zero.

    : <dfn>layout</dfn>
    ::
        An {{MLInputOperandLayout}}. Specifies the layout format of the input.

</dl>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input 4-D tensor.
        - *options*: an optional {{MLInstanceNormalizationOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The instance-normalized 4-D tensor of the same shape as the input tensor.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/instanceNormalization(input, options)}} steps are:
  </summary>
  <div algorithm=instancenorm class=algorithm-steps>
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If the rank of |input| is not `4`, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options| is `undefined`, let |options| be an empty [=object=].
    1. If |options|.{{MLInstanceNormalizationOptions/scale}} is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If the rank of |options|.{{MLInstanceNormalizationOptions/scale}} is not equal to the size of the channel dimension of |input|, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLInstanceNormalizationOptions/bias}} is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If the rank of |options|.{{MLInstanceNormalizationOptions/bias}} is not equal to the size of the channel dimension of |input|, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLInstanceNormalizationOptions/epsilon}} is `undefined`, let it be `0.00001`.
    1. If |options|.{{MLInstanceNormalizationOptions/layout}} is `undefined`, let it be `"nchw"`.
    1. Otherwise if |options|.{{MLInstanceNormalizationOptions/layout}} is not one of {{MLInputOperandLayout}}, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the instance normalization operation, given |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation when the input tensor is 4-D of the *"nchw"* layout can be generically emulated from
    the usage of other operations as follow. However, user agents typically have a more efficient implementation for it,
    therefore its usage is encouraged from the performance standpoint.
  </summary>
  <pre highlight="js">
    // The mean reductions happen over the spatial dimensions of the input
    // e.g. axis 2 and 3 of the input tensor.
    const reduceOptions = { axes: [2,3], keepDimensions: true };
    const mean = builder.reduceMean(input, reduceOptions);
    const variance = builder.reduceMean(
      builder.pow(
        builder.sub(input, mean),
        buider.constant(2)),
      reduceOptions
      );

    // The scale and bias values are applied per input feature
    // e.g. axis 1 of the input tensor.
    const shape = [1,null,1,1];
    return builder.add(
      builder.mul(
        builder.reshape(options.scale, shape),
        builder.div(
          builder.sub(input, mean),
          buidler.pow(
            builder.add(variance, options.epsilon),
            builder.constant(0.5))
          )
        ),
      builder.reshape(options.bias, shape)
      );
  </pre>
</details>
</div>

### The leakyRelu() method ### {#api-mlgraphbuilder-leakyrelu}
Calculate the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Leaky_ReLU"> leaky version of rectified linear function</a> on the input tensor element-wise. The calculation follows the expression `max(0, x) + alpha ∗ min(0, x)`.

<script type=idl>
dictionary MLLeakyReluOptions {
  float alpha = 0.01;
};

partial interface MLGraphBuilder {
  MLOperand leakyRelu(MLOperand input, optional MLLeakyReluOptions options = {});
  MLActivation leakyRelu(optional MLLeakyReluOptions options = {});
};
</script>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint.
    </summary>
    <pre highlight="js">
    return builder.add(builder.max(builder.constant(0), x),
              builder.mul(builder.constant(options.alpha), builder.min(builder.constant(0), x)));
    </pre>
  </details>
</div>

{{MLLeakyReluOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLLeakyReluOptions>
    : <dfn>alpha</dfn>
    ::
         A {{float}} scalar multiplier.
         The default value is `0.01`.
</dl>

<details open>
  <summary>
    To <dfn>check leaky-relu options</dfn> given |options|, run the following steps:
  </summary>
  <div algorithm=check-leaky-relu-options class=algorithm-steps>
    1. If |options| is not an [=object=] that [=implements=] {{MLLeakyReluOptions}}, then return `false`.
    1. If |options|.{{MLLeakyReluOptions/alpha}} is `undefined`, set |options|.{{MLLeakyReluOptions/alpha}} to `1`.
    1. Else if |options|.{{MLLeakyReluOptions/alpha}} is not a [=numeric type=], then then return `false`.
    1. Return `true`.
  </div>
</details>

#### The {{MLGraphBuilder/leakyRelu(input, options)}} method #### {#api-mlgraphbuilder-leaky-relu-input-options}
<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.
        - *options*: an optional {{MLLeakyReluOptions}}. The optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as *input*.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/leakyRelu(input, options)}} method steps are:
  </summary>
  <div algorithm=leakyrelu-input-options class=algorithm-steps>
    1. Let |input| be the first argument.
    1. Let |options| be the second argument.
        1. If |options| is `undefined`, let |options| be a new {{MLLeakyReluOptions}} object.
        1. If running the <a>check leaky-relu options</a> steps with |options| returns `false`, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the Leaky RELU operation, given |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

#### The {{MLGraphBuilder/leakyRelu(options)}} method #### {#api-mlgraphbuilder-leaky-relu-options}
<div>
    **Arguments:**
        - *options*: an optional {{MLLeakyReluOptions}}. The optional parameters of the operation.

    **Returns:**
        - an {{MLActivation}}. The activation function representing the leaky relu operation.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/elu(options)}} method steps are:
  </summary>
  <div algorithm=leakyrelu-options class=algorithm-steps>
    1. Let |options| be the first argument.
        1. If |options| is `undefined`, let |options| be a new {{MLLeakyReluOptions}} object.
        1. If running the <a>check leaky-relu options</a> steps with |options| returns `false`, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
    1. Let |op| be the result of invoking the <a>create MLActivation</a> steps with `"leakyRelu"` and |options|.
        1. If that throws an error, re-throw the error and abort these steps.
    1. Return |op|.
  </div>
</details>

### The linear() method ### {#api-mlgraphbuilder-linear}
Calculate a linear function `y = alpha * x + beta` on the input tensor.

<script type=idl>
dictionary MLLinearOptions {
  float alpha = 1;
  float beta = 0;
};

partial interface MLGraphBuilder {
  MLOperand linear(MLOperand input, optional MLLinearOptions options = {});
  MLActivation linear(optional MLLinearOptions options = {});
};
</script>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint.
    </summary>
    <pre highlight="js">
    return builder.add(
              builder.mul(x, builder.constant(options.alpha)),
              builder.constant(options.beta));
    </pre>
  </details>
</div>

{{MLLinearOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLLinearOptions>
    : <dfn>alpha</dfn>
    ::
         A {{float}} scalar multiplier.
         The default value is `1`.
    : <dfn>beta</dfn>
    ::
         A {{float}} scalar addition.
         The default value is `0`.
</dl>

<details open>
  <summary>
    To <dfn>check linear options</dfn> given |options|, run the following steps:
  </summary>
  <div algorithm=check-linear-options class=algorithm-steps>
    1. If |options| is not an [=object=] that [=implements=] {{MLLinearOptions}}, then return `false`.
    1. If |options|.{{MLEluOptions/alpha}} is `undefined`, set |options|.{{MLLinearOptions/alpha}} to `1`.
    1. Else if |options|.{{MLLinearOptions/alpha}} is not a [=numeric type=], then then return `false`.
    1. If |options|.{{MLLinearOptions/beta}} is `undefined`, set |options|.{{MLLinearOptions/beta}} to `0`.
    1. Else if |options|.{{MLLinearOptions/beta}} is not a [=numeric type=], then then return `false`.
    1. Return `true`.
  </div>
</details>

#### The {{MLGraphBuilder/linear(input, options)}} method #### {#api-mlgraphbuilder-linear-input-options}
<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.
        - *options*: an optional {{MLLinearOptions}}. The optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as *x*.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/linear(input, options)}} method steps are:
  </summary>
  <div algorithm=linear-input-options class=algorithm-steps>
    1. Let |input| be the first argument.
    1. Let |options| be the second argument.
        1. If running the <a>check linear options</a> steps with |options| returns `false`, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the linear operation, given |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

#### The {{MLGraphBuilder/linear(options)}} method #### {#api-mlgraphbuilder-linear-options}
<div>
    **Arguments:**
        - *options*: an optional {{MLLinearOptions}}. The optional parameters of the operation.

    **Returns:**
        - an {{MLActivation}}. The activation function representing the linear operation.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/linear(options)}} method steps are:
  </summary>
  <div algorithm=linear-options class=algorithm-steps>
    1. Let |options| be the first argument.
        1. If running the <a>check linear options</a> steps with |options| returns `false`, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
    1. Let |op| be the result of invoking the <a>create MLActivation</a> steps with `"linear"` and |options|.
        1. If that throws an error, re-throw the error and abort these steps.
    1. Return |op|.
  </div>
</details>

### The lstm() method ### {#api-mlgraphbuilder-lstm}
Long Short-Term Memory [[LSTM]] recurrent network uses an input, output, forget, and cell gate to compute the output state that rolls into the output across the temporal sequence of the network.

<script type=idl>
enum MLLstmWeightLayout {
  "iofg", // input-output-forget-cell gate ordering
  "ifgo"  // input-forget-cell-output gate ordering
};

dictionary MLLstmOptions {
  MLOperand bias;
  MLOperand recurrentBias;
  MLOperand peepholeWeight;
  MLOperand initialHiddenState;
  MLOperand initialCellState;
  boolean returnSequence = false;
  MLRecurrentNetworkDirection direction = "forward";
  MLLstmWeightLayout layout = "iofg";
  sequence<MLActivation> activations;
};

partial interface MLGraphBuilder {
  sequence<MLOperand> lstm(MLOperand input, MLOperand weight, MLOperand recurrentWeight,
                           unsigned long steps, unsigned long hiddenSize,
                           optional MLLstmOptions options = {});
};
</script>

{{MLLstmOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLLstmOptions>
    : <dfn>bias</dfn>
    ::
        An {{MLOperand}}. Specifies the 2-D input bias tensor of shape [num_directions, 4 * hidden_size]. The ordering of the bias vectors in the second dimension of the tensor shape is specified according to {{MLLstmOptions/layout}}.

    : <dfn>recurrentBias</dfn>
    ::
        An {{MLOperand}}. Specifies the 2-D recurrent bias tensor of shape [num_directions, 4 * hidden_size]. The ordering of the bias vectors in the first dimension of the tensor shape is specified according to {{MLLstmOptions/layout}}.

    : <dfn>peepholeWeight</dfn>
    ::
        An {{MLOperand}}. Specifies the 2-D weight tensor for peepholes of shape [num_directions, 4 * hidden_size]. The pack ordering of the weight vectors is for the `input (i)`, `output (o)`, and `forget (f)` gate, respectively.

    : <dfn>initialHiddenState</dfn>
    ::
        An {{MLOperand}}. Specifies the 3-D initial hidden state tensor of shape [num_directions, batch_size, hidden_size]. When not specified, implementations SHOULD use a tensor filled with zero.

    : <dfn>initialCellState</dfn>
    ::
        An {{MLOperand}}. Specifies the 3-D initial hidden state tensor of shape [num_directions, batch_size, hidden_size]. When not specified, implementations SHOULD use a tensor filled with zero.

    : <dfn>returnSequence</dfn>
    ::
         A {{boolean}} indicating whether to also return the entire sequence with every output from each time step in it in addition to the output of the last time step.

    : <dfn>direction</dfn>
    ::
        An {{MLRecurrentNetworkDirection}}. Specifies the processing direction of the input sequence. When set to `"both"`, the size of the first dimension of the weight and the bias tensor shapes must be `2`, and the input is processed in both directions.

    : <dfn>layout</dfn>
    ::
        An {{MLLstmWeightLayout}}. The ordering of the weight and bias vectors for the internal gates of LSTM, specifically the `input (i)`, `output (o)`, `forget (f)`, and `cell (g)` gate, as indicated in the first dimension of the weight and bias tensor shapes. When not specified, the default layout is `"iofg"`.

    : <dfn>activations</dfn>
    ::
        A sequence of {{MLActivation}}. A sequence of three activation functions, the first one is used for the `input (i)`, `forget (f)`, and `output (o)` gate, the second one is used for the `cell (g)` gate, and the last used for filtering the output cell state before combining it with the result of the output gate to form the output hidden state. When not specified, implementations SHOULD use the sequence of the sigmoid function (`"sigmoid"`) followed by two hyperbolic tangent functions (`"tanh"`) respectively.
</dl>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input 3-D tensor of shape [steps, batch_size, input_size].
        - *weight*: an {{MLOperand}}. The 3-D input weight tensor of shape [num_directions, 4 * hidden_size, input_size]. The ordering of the weight vectors in the second dimension of the tensor shape is specified according to the |options|.{{MLLstmOptions/layout}}.
        - *recurrentWeight*: an {{MLOperand}}. The 3-D recurrent weight tensor of shape [num_directions, 4 * hidden_size, hidden_size]. The ordering of the weight vectors in the second dimension of the tensor shape is specified according to the |options|.{{MLLstmOptions/layout}} argument.
        - *steps*: an {{unsigned long}} scalar. The number of time steps in the recurrent network. The value must be greater than 0.
        - *hiddenSize*: an {{unsigned long}} scalar. The value of the third dimension of the cell output tensor shape. It indicates the number of features in the hidden state.
        - *options*: an optional {{MLLstmOptions}}. The optional parameters of the operation.

    **Returns:** a sequence of {{MLOperand}}. The first element of the sequence is a 3-D tensor of shape [num_directions, batch_size, hidden_size], the output hidden state from the last time step of the network. The second element is a 3-D tensor of shape [num_directions, batch_size, hidden_size], the output cell state from the last time step of the network. Additionally, if |options|.{{MLLstmOptions/returnSequence}} is set to true, the third element is the 4-D output tensor of shape [steps, num_directions, batch_size, hidden_size] containing every output from each time step in the temporal sequence.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/lstm(input, weight, recurrentWeight, steps, hiddenSize, options)}} steps are:
  </summary>
  <div algorithm=lstm class=algorithm-steps>
    1. If |options| is `undefined`, let |options| be an empty [=object=].
    1. If |options|.{{MLLstmOptions/direction}} is `undefined`, set it to `"forward"`.
    1. If |options|.{{MLLstmOptions/direction}} is not one of {{MLRecurrentNetworkDirection}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |num_directions| be `1` if |options|.{{MLLstmOptions/direction}} is `"forward"`, or otherwise let it be `2`.
    1. If |input|, |weight| or |recurrentWeight| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        <div class="note">
            The shape of |input|, |weight| or |recurrentWeight| could be also checked here.
        </div>
    1. If |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[0] is not equal to |steps|, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. Let |batch_size| be |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[1].
    1. If |options|.{{MLLstmOptions/bias}} [=map/exists=].
        1. If it is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If its rank is not `2`, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmOptions/bias}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[0] is not |num_directions|, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmOptions/bias}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[1] is not 4 * |hiddenSize|, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLLstmOptions/recurrentBias}} [=map/exists=].
        1. If it is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If its rank is not `2`, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmOptions/recurrentBias}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[0] is not |num_directions|, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmOptions/recurrentBias}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[1] is not 4 * |hiddenSize|, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLLstmOptions/peepholeWeight}} [=map/exists=].
        1. If it is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If its rank is not `2`, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmOptions/peepholeWeight}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[0] is not |num_directions|, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmOptions/peepholeWeight}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[1] is not 4 * |hiddenSize|, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLLstmOptions/initialHiddenState}} [=map/exists=].
        1. If it is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If its rank is not `3`, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmOptions/initialHiddenState}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[0] is not |num_directions|, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmOptions/initialHiddenState}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[1] is not equal to |batch_size|, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmOptions/initialHiddenState}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[2] is not |hiddenSize|, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLLstmOptions/initialCellState}} [=map/exists=].
        1. If it is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If its rank is not `3`, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmOptions/initialCellState}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[0] is not |num_directions|, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmOptions/initialCellState}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[1] is not equal to |batch_size|, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmOptions/initialCellState}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[2] is not |hiddenSize|, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLLstmOptions/returnSequence}} is `undefined`, set it to `false`.
    1. If |options|.{{MLLstmOptions/layout}} is `undefined`, set it to `"iofg"`.
    1. If |options|.{{MLLstmOptions/layout}} is not one of {{MLLstmWeightLayout}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options|.{{MLLstmOptions/activations}} [=map/exists=]:
        1. If it is not an array of size `3`, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If any of its elements is not an instance of {{MLActivation}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |desc| a new {{MLOperandDescriptor}}.
        1. Set |desc|.{{MLOperandDescriptor/dimensions}} to [ |nume_directions|, |batch_size|, |hiddenSize| ].
        1. Set |desc|.{{MLOperandDescriptor/type}} to |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/type}}.
        1. Let |output0| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
        1. Let |output1| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
        1. Set |desc|.{{MLOperandDescriptor/dimensions}} to [ |steps|, |nume_directions|, |batch_size|, |hiddenSize| ].
        1. Let |output2| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
        1. Let |output| be the array [ |output0|, |output1|, |output2 ].
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the LSTM operation, given |weight|, |recurrentWeight|, |steps|, |hiddenSize| and |options|.
            1. Store a reference of |opImpl| in |output0|.{{MLOperand/[[operator]]}}, |output1|.{{MLOperand/[[operator]]}} and |output2|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output0|.{{MLOperand/[[operand]]}}, |output1|.{{MLOperand/[[operand]]}} and |output2|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output| as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation can be generically emulated from the usage of other operations as follow. However, user agents typically have a more efficient implementation for it, therefore its usage is encouraged from the performance standpoint.
  </summary>
  <pre highlight="js">
    const numDirections = (options.direction == "both" ? 2 : 1);
    let hiddenState = options.initialHiddenState;
    let cellState = options.initialCellState;

    if (!hiddenState) {
      const desc = { type: 'float32', dimensions: [numDirections, 1, hiddenSize] };
      const totalSize = numDirections * hiddenSize;
      hiddenState = builder.constant(desc, new Float32Array(totalSize).fill(0));
    }

    if (!cellState) {
      const desc = { type: 'float32', dimensions: [numDirections, 1, hiddenSize] };
      const totalSize = numDirections * hiddenSize;
      cellState = builder.constant(desc, new Float32Array(totalSize).fill(0));
    }

    let sequence = null;
    let currentWeight = [];
    let currentRecurrentWeight = [];
    let currentBias = [];
    let currentRecurrentBias = [];
    let currentPeepholeWeight = [];

    for (let dir = 0; dir < numDirections; ++dir) {
      currentWeight.push(builder.squeeze(builder.slice(weight, [dir, 0, 0], [1, 4 * hidden_size, input_size]), { axes: [0] }));
      currentRecurrentWeight.push(builder.squeeze(builder.slice(recurrentWeight, [dir, 0, 0], [1, 4 * hidden_size, hidden_size]), { axes: [0] }));
      currentBias.push(options.bias ? (builder.squeeze(builder.slice(options.bias, [dir, 0], [1, 4 * hidden_size]), { axes: [0] })) : null);
      currentRecurrentBias.push(options.recurrentBias ?
        (builder.squeeze(builder.slice(options.recurrentBias, [dir, 0], [1, 4 * hidden_size]), { axes: [0] })) : null);
      currentPeepholeWeight.push(options.peepholeWeight ?
        (builder.squeeze(builder.slice(options.peepholeWeight, [dir, 0], [1, 3 * hidden_size]), { axes: [0] })) : null);
    }

    for (let step = 0; step < steps; ++step) {
      let currentHidden = [];
      let currentCell = [];
      let nextHidden = null;
      let nextCell = null;

      for (let dir = 0; dir < numDirections; ++dir) {
        currentHidden.push(builder.squeeze(builder.slice(hiddenState, [dir, 0, 0], [1, batch_size, hidden_size]), { axes: [0] }));
        currentCell.push(builder.squeeze(builder.slice(cellState, [dir, 0, 0], [1, batch_size, hidden_size]), { axes: [0] }));
      }

      for (let dir = 0; dir < numDirections; ++dir) {
        let slice = (dir == 1 || options.direction == "backward" ? steps - step - 1 : step);
        let currentInput = builder.squeeze(builder.slice(input, [slice, 0, 0], [1, batch_size, input_size]), { axes: [0] });

        let results = builder.lstmCell(
          currentInput, currentWeight[dir], currentRecurrentWeight[dir],
          currentHidden[dir], currentCell[dir], hiddenSize, { bias: currentBias[dir],
          recurrentBias: currentRecurrentBias[dir], peepholeWeight: currentPeepholeWeight[dir],
          layout: options.layout, activations: options.activations });

        let output = builder.reshape(results[0], [1, null, hiddenSize]);
        let cell = builder.reshape(results[1], [1, null, hiddenSize]);

        nextHidden = (nextHidden ? builder.concat([nextHidden, output], 0) : output);
        nextCell = (nextCell ? builder.concat([nextCell, cell], 0) : cell);
      }

      hiddenState = nextHidden;
      cellState = nextCell;

      if (options.returnSequence) {
        nextHidden = builder.reshape(nextHidden, [1, numDirections, null, hiddenSize]);
        sequence = (sequence ? builder.concat([sequence, nextHidden], 0) : nextHidden);
      }
    }

    return (sequence ? [hiddenState, cellState, sequence] : [hiddenState, cellState]);
  </pre>
</details>
</div>

### The lstmCell() method ### {#api-mlgraphbuilder-lstmcell}
A single time step of the Long Short-Term Memory [[LSTM]] recurrent network using a cell state, an input, output, and forget gate to compute the cell state and the hidden state of the next time step that rolls into the output across the temporal sequence of the network.

<script type=idl>
dictionary MLLstmCellOptions {
  MLOperand bias;
  MLOperand recurrentBias;
  MLOperand peepholeWeight;
  MLLstmWeightLayout layout = "iofg";
  sequence<MLActivation> activations;
};

partial interface MLGraphBuilder {
  sequence<MLOperand> lstmCell(MLOperand input, MLOperand weight, MLOperand recurrentWeight,
                               MLOperand hiddenState, MLOperand cellState, unsigned long hiddenSize,
                               optional MLLstmCellOptions options = {});
};
</script>

{{MLLstmCellOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLLstmCellOptions>
    : <dfn>bias</dfn>
    ::
        An {{MLOperand}}. The 1-D input bias tensor of shape [4 * hidden_size]. The ordering of the bias vectors in the first dimension of the tensor shape is specified according to the {{MLLstmCellOptions/layout}} argument.

    : <dfn>recurrentBias</dfn>
    ::
        An {{MLOperand}}. The 1-D recurrent bias tensor of shape [4 * hidden_size]. The ordering of the bias vectors in the first dimension of the tensor shape is specified according to the {{MLLstmCellOptions/layout}} argument.

    : <dfn>peepholeWeight</dfn>
    ::
        An {{MLOperand}}. The 1-D weight tensor for peepholes of shape [3 * hidden_size]. The pack ordering of the weight vectors is for the `input (i)`, `output (o)`, and `forget (f)` gate, respectively.

    : <dfn>layout</dfn>
    ::
        An {{MLLstmWeightLayout}}. The ordering of the weight and bias vectors for the internal gates of LSTM, specifically the `input (i)`, `output (o)`, `forget (f)`, and `cell (g)` gate, as indicated in the first dimension of the weight and bias tensor shapes. When not specified, the default layout is `"iofg"`.

    : <dfn>activations</dfn>
    ::
        A sequence of {{MLActivation}}. A sequence of three activation functions, the first one is used for the `input (i)`, `forget (f)`, and `output (o)` gate, the second one is used for the `cell (g)` gate, and the last used for filtering the output cell state before combining it with the result of the output gate to form the output hidden state. When not specified, they are assumed to be of the sigmoid function (`"sigmoid"`) followed by two hyperbolic tangent functions (`"tanh"`) respectively.
</dl>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input 2-D tensor of shape [batch_size, input_size].
        - *weight*: an {{MLOperand}}. The 2-D input weight tensor of shape [4 * hidden_size, input_size]. The ordering of the weight vectors in the first dimension of the tensor shape is specified according to the *options.layout* argument.
        - *recurrentWeight*: an {{MLOperand}}. The 2-D recurrent weight tensor of shape [4 * hidden_size, hidden_size]. The ordering of the weight vectors in the first dimension of the tensor shape is specified according to the *options.layout* argument.
        - *hiddenState*: an {{MLOperand}}. The 2-D input hidden state tensor of shape [batch_size, hidden_size].
        - *cellState*: an {{MLOperand}}. The 2-D input cell state tensor of shape [batch_size, hidden_size].
        - *hiddenSize*: an {{unsigned long}} scalar. The value of the second dimension of the output tensor shape. It indicates the number of features in the hidden state.
        - *options*: an optional {{MLLstmCellOptions}}. The optional parameters of the operation.

    **Returns:** a sequence of {{MLOperand}}. The first element of the sequence is the output hidden state of the current time step of the recurrent network. The following element is the output cell state. Both elements are 2-D tensors of shape [batch_size, hidden_size].
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/lstmCell(input, weight, recurrentWeight, hiddenState, cellState, hiddenSize, options)}} steps are:
  </summary>
  <div algorithm=lstmcell class=algorithm-steps>
    1. If |input|, |weight|, |recurrentWeight|, |hiddenState| or |cellState| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If the rank of |input|, |weight|, |recurrentWeight|, |hiddenState| or |cellState| is not `2`, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. Let |batch_size| be |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[0].
    1. If |options| is `undefined`, let |options| be an empty [=object=].
    1. If |options|.{{MLLstmCellOptions/bias}} [=map/exists=].
        1. If it is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If its rank is not `1`, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmCellOptions/bias}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[0] is not 4 * |hiddenSize|, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLLstmCellOptions/recurrentBias}} [=map/exists=].
        1. If it is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If its rank is not `1`, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmCellOptions/recurrentBias}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[0] is not 4 * |hiddenSize|, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLLstmCellOptions/peepholeWeight}} [=map/exists=].
        1. If it is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If its rank is not `1`, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If |options|.{{MLLstmCellOptions/peepholeWeight}}.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[0] is not 3 * |hiddenSize|, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. If |options|.{{MLLstmCellOptions/layout}} is `undefined`, set it to `"iofg"`.
    1. If |options|.{{MLLstmCellOptions/layout}} is not one of {{MLLstmWeightLayout}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options|.{{MLLstmCellOptions/activations}} [=map/exists=]:
        1. If it is not an array of size `3`, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If any of its elements is not an instance of {{MLActivation}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |desc| a new {{MLOperandDescriptor}}.
    1. Set |desc|.{{MLOperandDescriptor/dimensions}} to [ |batch_size|, |hiddenSize| ].
    1. Set |desc|.{{MLOperandDescriptor/type}} to |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/type}}.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output0| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
        1. Let |output1| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
        1. Let |output| be the array [ |output0|, |output1| ].
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the LSTM cell operation, given |weight|, |recurrentWeight|, |hiddenState|, |cellState|, |hiddenSize| and |options|.
            1. Store a reference of |opImpl| in |output0|.{{MLOperand/[[operator]]}} and |output1|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output0|.{{MLOperand/[[operand]]}} and |output1|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output| as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation can be generically emulated via other operations as shown below, when the weight layout is the default *"iofg"* layout, and the activation functions of the input/forget/output gate and the cell gate/the cell state's filter for the output hidden state are of the operator types *sigmoid* and *tanh* respectively.
  </summary>
  <pre highlight="js">
    const zero = builder.constant(0);

    // input gate (i)
    let i = builder.sigmoid(
      builder.add(
        builder.mul(
          cellState,
          (options.peepholeWeight ? builder.slice(options.peepholeWeight, [0], [hiddenSize]) : zero)
        ),
        builder.add(
          builder.add(
            (options.bias ? builder.slice(options.bias, [0], [hiddenSize]) : zero),
            (options.recurrentBias ? builder.slice(options.recurrentBias, [0], [hiddenSize]) : zero)
          ),
          builder.add(
            builder.matmul(
              input,
              builder.transpose(builder.slice(weight, [0, 0], [hiddenSize, input_size]))
            ),
            builder.matmul(
              hiddenState,
              builder.transpose(builder.slice(recurrentWeight, [0, 0], [hiddenSize, hidden_size]))
            )
          )
        )
      )
    );

    // forget gate (f)
    let f = builder.sigmoid(
      builder.add(
        builder.mul(
          cellState,
          (options.peepholeWeight ? builder.slice(options.peepholeWeight, [2 * hiddenSize], [hiddenSize]) : zero)
        ),
        builder.add(
          builder.add(
            (options.bias ? builder.slice(options.bias, [2 * hiddenSize], [hiddenSize]) : zero),
            (options.recurrentBias ? builder.slice(options.recurrentBias, [2 * hiddenSize], [hiddenSize]) : zero)
          ),
          builder.add(
            builder.matmul(
              input,
              builder.transpose(builder.slice(weight, [2 * hiddenSize, 0], [hiddenSize, input_size]))
            ),
            builder.matmul(
              hiddenState,
              builder.transpose(builder.slice(recurrentWeight, [2 * hiddenSize, 0], [hiddenSize, hidden_size]))
            )
          )
        )
      )
    );

    // cell gate (g)
    let g = builder.tanh(
      builder.add(
        builder.add(
          (options.bias ? builder.slice(options.bias, [3 * hiddenSize], [hiddenSize]) : zero),
          (options.recurrentBias ? builder.slice(options.recurrentBias, [3 * hiddenSize], [hiddenSize]) : zero)
        ),
        builder.add(
          builder.matmul(
            input,
            builder.transpose(builder.slice(weight, [3 * hiddenSize, 0], [hiddenSize, input_size]))
          ),
          builder.matmul(
            hiddenState,
            builder.transpose(builder.slice(recurrentWeight, [3 * hiddenSize, 0], [hiddenSize, hidden_size]))
          )
        )
      )
    );

    // output gate (o)
    let o = builder.sigmoid(
      builder.add(
        builder.mul(
          cellState,
          (options.peepholeWeight ? builder.slice(options.peepholeWeight, [hiddenSize], [hiddenSize]) : zero)
        ),
        builder.add(
          builder.add(
            (options.bias ? builder.slice(options.bias, [hiddenSize], [hiddenSize]) : zero),
            (options.recurrentBias ? builder.slice(options.recurrentBias, [hiddenSize], [hiddenSize]) : zero)
          ),
          builder.add(
            builder.matmul(
              input,
              builder.transpose(builder.slice(weight, [hiddenSize, 0], [hiddenSize, input_size]))
            ),
            builder.matmul(
              hiddenState,
              builder.transpose(builder.slice(recurrentWeight, [hiddenSize, 0], [hiddenSize, hidden_size]))
            )
          )
        )
      )
    );

    // output cell state (ct)
    let ct = builder.add(builder.mul(f, cellState), builder.mul(i, g));

    // output hidden state (ht)
    let ht = builder.mul(o, builder.tanh(ct));

    return [ht, ct];
  </pre>
</details>
</div>

### The matmul() method ### {#api-mlgraphbuilder-matmul}
Compute the matrix product of two input tensors.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand matmul(MLOperand a, MLOperand b);
};
</script>

<div>
    **Arguments:**
        - *a*: an {{MLOperand}}. The first N-dimensional input tensor.
        - *b*: an {{MLOperand}}. The second N-dimensional input tensor.

    **Returns:** an {{MLOperand}}. The output tensor that contains the matrix
    product of two input tensors.
</div>
<div>
    Computes the matrix product of two input tensors as follows:
        - If both *a* and *b* are 2-dimensional, they are multiplied like conventional
            matrices and produce a 2-dimensional tensor as the output.
        - If either *a* or *b* is `N`-dimensional where `N > 2`, it is treated as a stack of matrices with dimensions corresponding to the last two indices. The matrix multiplication will be broadcasted accordingly by following the [[!numpy-broadcasting-rule]]. The output is a `N`-dimensional tensor whose rank is the maximum rank of the input tensors. For each dimension, except the last two, of the output tensor, its size is the maximum size along that dimension of the input tensors.
        - If *a* is 1-dimensional, it is converted to a 2-dimensional tensor by prepending a 1 to its dimensions.
        - If *b* is 1-dimensional, it is converted to a 2-dimensional tensor by by appending a 1 to its dimensions.
        - If both *a* and *b* are 1-dimensional, the operation is a vector dot-product, which produces a scalar output.
</div>

<details open>
  <summary>
    To <dfn dfn-for=MLGraphBuilder>calculate matmul output sizes</dfn>, given |a| and |b| run the following steps:
  </summary>
  <div class=algorithm-steps>
    1. Let |shapeA| be |a|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}} and |sizeA| the size of |shapeA|.
    1. Let |shapeB| be |a|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}} and |sizeB| the size of |shapeB|.
    1. If |sizeA| and |sizeB| is `1`, return `[ 1 ]`.
    1. If | sizeA| is `1` and |sizeB| is not, then insert `1` in the front of |shapeA| to become [ 1 | |shapeA| ] and let |sizeA| be `2`.
    1. If | sizeB| is `1` and |sizeA| is not, then insert `1` in the front of |shapeB| to become [ 1 | |shapeB| ] and let |sizeB| be `2`.
    1. Let |shape| be an array whose size |size| is the maximum of |sizeA| and |sizeB|.
    1. For each |index| between 0 and |size|:
       1. Set |shape|[|index|] to the maximum of |shapeA|[|index|] and |shapeB|[|index|].
    1. Return |shape|.
  </div>
</details>

<details open>
  <summary>
    The {{MLGraphBuilder/matmul(a, b)}} steps are:
  </summary>
  <div algorithm=matmul class=algorithm-steps>
    1. If |a| or |b| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |desc| a new {{MLOperandDescriptor}}.
    1. Set |desc|.{{MLOperandDescriptor/dimensions}} to the result of invoking the <a>calculate matmul output sizes</a> given |a| and |b|.
    1. Set |desc|.{{MLOperandDescriptor/type}} to |a|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/type}}.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the matrix multiplication operation.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |a|.{{MLOperand/[[operand]]}} and |b|.{{MLOperand/[[operand]]}} as inputs to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

### The pad() method ### {#api-mlgraphbuilder-pad}
Inflate the tensor with constant or mirrored values on the edges.
<script type=idl>
enum MLPaddingMode {
  "constant",
  "edge",
  "reflection",
  "symmetric"
};

dictionary MLPadOptions {
  MLPaddingMode mode = "constant";
  float value = 0;
};

partial interface MLGraphBuilder {
  MLOperand pad(MLOperand input,
                sequence<unsigned long> beginningPadding,
                sequence<unsigned long> endingPadding,
                optional MLPadOptions options = {});
};
</script>

{{MLPadOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLPadOptions>
    : <dfn>mode</dfn>
    ::
        An {{MLPaddingMode}} [=string=].
        Specifies the different ways to pad the tensor.
        The default value is `"constant"`.

    : <dfn>value</dfn>
    ::
        A {{float}}.
        Specifies the padding value when {{MLPadOptions/mode}} is set to `"constant"`.
        The default value is `0`.
</dl>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.
        - *beginningPadding*: a sequence of {{unsigned long}}. The sequence of unsigned integer values indicating the number of padding values to add at the beginning of each input dimension, of length *N* where *N* is the rank of the input tensor. For each dimension *d* of *input*, *beginningPadding[d]* indicates how many values to add before the content in that dimension.
        - *endingPadding*: a sequence of {{unsigned long}}. The sequence of unsigned integer values indicating the number of padding values to add at the ending of each input dimension, of length *N* where *N* is the rank of the input tensor. For each dimension *d* of *input*, *endingPadding[d]* indicates how many values to add after the content in that dimension.
        - *options*: an optional {{MLPadOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The padded output tensor. Each dimension of the output tensor can be calculated as follow:

    *output size = beginning padding + input size + ending padding*
</div>

<details open>
  <summary>
    To <dfn dfn-for=MLGraphBuilder>calculate padding output sizes</dfn>, given |input|, |beginningPadding| and |endingPadding|, run the following steps:
  </summary>
  <div class=algorithm-steps>
    1. Let |shape| be a copy of |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}.
    1. For |index| between `0` and the rank of |shape|:
        1. Add to |shape|[|index|] the value of |beginningPadding|[|index|].
        1. Add to |shape|[|index|] the value of |endingPadding|[|index|].
    1. Return |shape|.
  </div>
</details>

<details open>
  <summary>
    The {{MLGraphBuilder/pad(input, beginningPadding, endingPadding, options)}} steps are:
  </summary>
  <div algorithm=pad class=algorithm-steps>
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |beginningPadding| or |endingPadding| is not a sequence of {{unsigned long}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options| is `undefined`, let |options| be an empty [=object=].
    1. If |options|.{{MLPadOptions/mode}} is `undefined`, set it to `"constant"`.
        1. Otherwise, if |options|.{{MLPadOptions/mode}} is not one of {{MLPaddingMode}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options|.{{MLPadOptions/value}} is `undefined`, set it to `0`.
    1. Let |desc| be a copy of |input|.{{MLOperand/[[descriptor]]}}.
    1. Set |desc|.{{MLOperandDescriptor/dimensions}} to the result of invoking the <a>calculate padding output sizes</a> given |input|, |beginningPadding| and |endingPadding|.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the padding operation, given |beginningPadding|, |endingPadding| and |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

<div class="example">
<details open>
  <summary>
    Examples for constant, edge, reflection and symmetric padding:
  </summary>
  <pre highlight="js">
    // input: [[1,2,3], [4,5,6]]
    const input = builder.constant(
      { type: 'float32', dimensions: [2,3] }, new Float32Array([1,2,3,4,5,6]));

    const beginningPadding = [1,2];
    const endingPadding = [1,2];

    // "constant" padded:
    //    [[0,0,0,0,0,0,0],
    //     [0,0,1,2,3,0,0],
    //     [0,0,4,5,6,0,0],
    //     [0,0,0,0,0,0,0]]
    builder.pad(input, beginningPadding, endingPadding);

    // "edge" padded:
    //    [[1,1,1,2,3,3,3],
    //     [1,1,1,2,3,3,3],
    //     [4,4,4,5,6,6,6],
    //     [4,4,4,5,6,6,6]]
    builder.pad(input, beginningPadding, endingPadding, { mode: "edge" });

    // "reflection" padded:
    //    [[6,5,4,5,6,5,4],
    //     [3,2,1,2,3,2,1],
    //     [6,5,4,5,6,5,4],
    //     [3,2,1,2,3,2,1]]
    builder.pad(input, beginningPadding, endingPadding, { mode: "reflection" });

    // "symmetric" padded:
    //    [[2,1,1,2,3,3,2],
    //     [2,1,1,2,3,3,2],
    //     [5,4,4,5,6,6,5],
    //     [5,4,4,5,6,6,5]]
    builder.pad(input, beginningPadding, endingPadding, { mode: "symmetric" });
  </pre>
</details>
</div>

### Pooling operations ### {#api-mlgraphbuilder-pool2d}
Compute a *mean*, *L2 norm*, or *max* reduction operation across all the elements within the moving window over the input tensor. See the description of each type of reduction in [[#api-mlgraphbuilder-reduce]].
<script type=idl>
enum MLRoundingType {
  "floor",
  "ceil"
};

dictionary MLPool2dOptions {
  sequence<unsigned long> windowDimensions;
  sequence<unsigned long> padding;
  sequence<unsigned long> strides;
  sequence<unsigned long> dilations;
  MLAutoPad autoPad = "explicit";
  MLInputOperandLayout layout = "nchw";
  MLRoundingType roundingType = "floor";
  sequence<unsigned long> outputSizes;
};

partial interface MLGraphBuilder {
  MLOperand averagePool2d(MLOperand input, optional MLPool2dOptions options = {});
  MLOperand l2Pool2d(MLOperand input, optional MLPool2dOptions options = {});
  MLOperand maxPool2d(MLOperand input, optional MLPool2dOptions options = {});
};
</script>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input 4-D tensor. The logical shape
            is interpreted according to the value of *options.layout*.
        - *options*: an optional {{MLPool2dOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output 4-D tensor that contains the
    result of the reduction. The logical shape is interpreted according to the
    value of *layout*. More specifically, if the *options.roundingType* is *"floor"*, the spatial dimensions of the output tensor can be calculated as follow:

    *output size = floor(1 + (input size - filter size + beginning padding + ending padding) / stride)*

    or if *options.roundingType* is *"ceil"*:

    *output size = ceil(1 + (input size - filter size + beginning padding + ending padding) / stride)*
</div>

<div class="note">
    A *global* pooling operation such as one for the max pooling operation is a variant of pooling where the window dimensions is the spatial dimensions (last two dimensions) of the input shape, as follow.
    <pre highlight="js">
    // 'global' max pooling
    builder.maxPool2d(input);
    </pre>
</div>

{{MLPool2dOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLPool2dOptions>
    : <dfn>windowDimensions</dfn>
    ::
         A sequence of {{unsigned long}} of length 2: [window_height, window_width].
         Specifies the dimensions of the sliding window.
         The default value for the window dimensions are the height and width dimensions of the input shape.

    : <dfn>padding</dfn>
    ::
        A sequence of {{unsigned long}} of length 4: [beginning_height, ending_height, beginning_width, ending_width].
        Specifies the additional rows and columns added to the beginning and ending of each spatial dimension of the convolution input.
        The default value is [0,0,0,0].

    : <dfn>strides</dfn>
    ::
        A sequence of {{unsigned long}} of length 2: [stride_height, stride_width].
        Specifies the stride of the sliding window for each spatial dimension of the convolution input.
        The default value is [1,1].

    : <dfn>dilations</dfn>
    ::
        A sequence of {{unsigned long}} of length 2: [dilation_height, dilation_width]. Specifies the dilation factor for each spatial dimension applied on the convolution filter (kernel).
        The default value is [1,1].

    : <dfn>autoPad</dfn>
    ::
        An {{MLAutoPad}} [=string=]].
        Specifies the automatic input padding options.
        The default value is *"explicit"*, which means that the values in the {{MLPool2dOptions/padding}} array should be used for input padding.
        When the option is set other than *"explicit"*, the values in the {{MLPool2dOptions/padding}} array are ignored.

        With the *"same-upper"* option, the padding values are automatically computed such that the additional ending padding of the spatial input dimensions would allow all of the input values in the corresponding dimension to be filtered.

        The *"same-lower"* option is similar but padding is applied to the beginning padding of the spatial input dimensions instead of the ending one.

    : <dfn>layout</dfn>
    ::
        An {{MLInputOperandLayout}} [=string=].
        Specifies the layout format of the input and output tensor as follows:
            - **"nchw"**
                - input tensor: *[batches, input_channels, height, width]*
                - output tensor: *[batches, output_channels, height, width]*
            - **"nhwc"**:
                - input tensor: *[batches, height, width, input_channels]*
                - output tensor: *[batches, height, width, output_channels]*
        The default value is *"nchw"*.

    : <dfn>roundingType</dfn>
    ::
        An {{MLRoundingType}} [=string=].
        Specifies the rounding function used to compute the output shape.

    : <dfn>outputSizes</dfn>
    ::
        A sequence of {{unsigned long}} of length 2.
        Specifies the sizes of the two spacial dimensions of the output tensor. When the output sizes are explicitly specified, the {{MLPool2dOptions/roundingType}} is ignored.

        If not specified, the output sizes are automatically computed.

</dl>

<details open>
  <summary>
    To <dfn for="MLGraphBuilder" data-lt="pooling-op">create pooling operation</dfn> given |op|, |input| and |options|, run the following steps:
  </summary>
  <div algorithm=create-pooling-operation class=algorithm-steps>
    1. [=Assert=]: |op| is one of "averagePool2d", "l2Pool2d", "maxPool2d".
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options| is `undefined`, let |options| be a new {{MLPool2dOptions}} object.
    1. If |options|.{{MLPool2dOptions/outputSizes}} [=map/exists=], or if |options|.{{MLPool2dOptions/padding}} is `undefined`, set |options|.{{MLPool2dOptions/padding}} to `[0, 0, 0, 0]`.
    1. If |options|.{{MLPool2dOptions/strides}} is `undefined`, set |options|.{{MLPool2dOptions/strides}} to `[1, 1]`.
    1. If |options|.{{MLPool2dOptions/dilations}} is `undefined`, set |options|.{{MLPool2dOptions/dilations}} to `[1, 1]`.
    1. If |options|.{{MLPool2dOptions/autoPad}} is `undefined`, set |options|.{{MLPool2dOptions/autoPad}} to `"explicit`.
    1. If |options|.{{MLPool2dOptions/autoPad}} is not `"explicit"`, set |options|.{{MLPool2dOptions/padding}} to `[0, 0, 0, 0]`.
    1. If |options|.{{MLPool2dOptions/layout}} is `undefined`, set |options|.{{MLPool2dOptions/layout}} to `"nchw"`.
    1. If |options|.{{MLPool2dOptions/roundingType}} is `undefined`, set |options|.{{MLPool2dOptions/roundingType}} to `"floor"`.
    1. Let |desc| be a copy of |input|.{{MLOperand/[[descriptor]]}}.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Make a request to the underlying platform to:
            1. Calculate the output dimensions given |input| and |options|. Let |desc|.{{MLOperandDescriptor/dimensions}} be the result of that.
            1. Let |output| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the |op| pooling operation, given |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

<details open>
  <summary>
    The following pooling algorithms are supported.
  </summary>
  <div algorithm=averagePool2d class=algorithm-steps>
    The {{MLGraphBuilder/averagePool2d(input, options)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/pooling-op | create pooling operation =] given `"averagePool2d"`, |input| and |options|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.
  </div>

  <div algorithm=l2Pool2d class=algorithm-steps>
    The {{MLGraphBuilder/l2Pool2d(input, options)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/pooling-op | create pooling operation =] given `"l2Pool2d"`, |input| and |options|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.
  </div>

  <div algorithm=maxPool2d class=algorithm-steps>
    The {{MLGraphBuilder/maxPool2d(input, options)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/pooling-op | create pooling operation =] given `"maxPool2d"`, |input| and |options|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.
  </div>
</details>

### The prelu() method ### {#api-mlgraphbuilder-prelu}
Calculate the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Parametric_ReLU">parametric version of rectified linear function (Parametric ReLU)</a> on the input tensor element-wise. Parametric ReLU is a type of leaky ReLU that, instead of having a scalar slope like 0.01, making the slope (coefficient of leakage) into a parameter that is learned during the model training phase of this operation. The calculation follows the expression `max(0, x) + slope ∗ min(0, x)`.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand prelu(MLOperand input, MLOperand slope);
};
</script>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.
        - *slope*: an {{MLOperand}}. The slope tensor. Its shape is either the same as, or unidirectionally broadcastable to the shape of input tensor *input* according to [[!numpy-broadcasting-rule]].

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as *x*.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/prelu(input, slope)}} steps are:
  </summary>
  <div algorithm=prelu-input-slope class=algorithm-steps>
    1. If |input| or |slope| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |descriptor| be a new {{MLOperandDescriptor}}.
    1. Set |descriptor|.{{MLOperandDescriptor/dimensions}}.{{MLOperandDescriptor/type}} to |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/type}}.
    1. Let |descriptor|.{{MLOperandDescriptor/dimensions}} be the result of running the [=MLGraphBuilder/broadcast-shapes=] steps given |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}} and |slope|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}.
        1. If that throws an error, re-throw the error and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |descriptor|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the PreLU operation, given |slope|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint.
    </summary>
    <pre highlight="js">
    return builder.add(builder.max(builder.constant(0), x),
                       builder.mul(slope, builder.min(builder.constant(0), x)));
    </pre>
  </details>
</div>

### Reduction operations ### {#api-mlgraphbuilder-reduce}
Reduce the input tensor along all dimensions, or along the axes specified in the {{MLReduceOptions/axes}}  array parameter. For each specified axis, the dimension with that index is reduced, i.e. the resulting tensor will not contain it, unless the {{MLReduceOptions/keepDimensions}} option is specified. The values of the resulting tensor are calculated using the specified reduction function that takes as parameters all the values across the reduced dimension.
<script type=idl>
dictionary MLReduceOptions {
  sequence<unsigned long> axes = null;
  boolean keepDimensions = false;
};

partial interface MLGraphBuilder {
  MLOperand reduceL1(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceL2(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceLogSum(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceLogSumExp(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceMax(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceMean(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceMin(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceProduct(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceSum(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceSumSquare(MLOperand input, optional MLReduceOptions options = {});
};
</script>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.
        - *options*: an optional {{MLReduceOptions}}. The optional parameters of the operation.
            - *axes*: a sequence of {{unsigned long}}. The dimensions to reduce. The values in the sequence must be in the range [0, N-1] where N is the rank of input tensor.
                If not present, all dimensions are reduced.
            - *keepDimensions*: a {{boolean}}. If true, retains reduced dimensions with size of 1.
                The default value is false.

    **Returns:** an {{MLOperand}}. The reduced output tensor.
</div>

<div class="note">
    **Reduction types:**
        - *L1*: Compute the <a href="https://mathworld.wolfram.com/L1-Norm.html">L1 norm</a> of all the input values along the axes.
        - *L2*: Compute the <a href="https://mathworld.wolfram.com/L2-Norm.html">L2 norm</a> of all the input values along the axes.
        - *LogSum*: Compute the log value of the sum of all the input values along the axes.
        - *LogSumExp*: Compute the log value of the sum of the exponent of all the input values along the axes.
        - *Max*: Compute the maximum value of all the input values along the axes.
        - *Mean*: Compute the average value of all the input values along the axes.
        - *Min*: Compute the minimum value of all the input values along the axes.
        - *Product*: Compute the product of all the input values along the axes.
        - *Sum*: Compute the sum of all the input values along the axes.
        - *SumSquare*: Compute the sum of the square of all the input values along the axes.
</div>

<details open>
  <summary>
    To <dfn for="MLGraphBuilder" data-lt="reduce-op">create reduce operation</dfn> given |op|, |input| and |options|, run the following steps:
  </summary>
  <div algorithm=reduce class=algorithm-steps>
    1. [=Assert=]: |op| is one of "reduceL1", "reduceL2", "reduceLogSum", "reduceLogSumExp", "reduceMax", "reduceMean", "reduceMin", "reduceProduct", "reduceSum", "reduceSumSquare".
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options| is `undefined`, let |options| be a new {{MLReduceOptions}} object with |options|.{{MLReduceOptions/keepDimensions}} set to `false` and |options|.{{MLReduceOptions/axes}} set to `null`.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the |op| reduce operation, given |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

<details open>
  <summary>
    The following reduce algorithms are supported.
  </summary>
    The {{MLGraphBuilder/reduceL1(input, options)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/reduce-op | create reduce operation =] given "reduceL1", |input| and |options|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/reduceL2(input, options)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/reduce-op | create reduce operation =] given "reduceL2", |input| and |options|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/reduceLogSum(input, options)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/reduce-op | create reduce operation =] given "reduceLogSum", |input| and |options|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/reduceLogSumExp(input, options)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/reduce-op | create reduce operation =] given "reduceLogSumExp", |input| and |options|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/reduceMax(input, options)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/reduce-op | create reduce operation =] given "reduceMax", |input| and |options|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/reduceMean(input, options)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/reduce-op | create reduce operation =] given "reduceMean", |input| and |options|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/reduceMin(input, options)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/reduce-op | create reduce operation =] given "reduceMin", |input| and |options|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/reduceProduct(input, options)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/reduce-op | create reduce operation =] given "reduceProduct", |input| and |options|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/reduceSum(input, options)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/reduce-op | create reduce operation =] given "reduceSum", |input| and |options|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.

    The {{MLGraphBuilder/reduceSumSquare(input, options)}} steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/reduce-op | create reduce operation =] given "reduceSumSquare", |input| and |options|.
            1. If that throws an error, then re-throw the error and stop.
        1. Return |output|.
</details>

### The relu() method ### {#api-mlgraphbuilder-relu-method}
Compute the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">rectified linear function</a> of the input tensor.

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand relu(MLOperand input);
  MLActivation relu();
};
</script>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint.
    </summary>
    <pre highlight="js">
    return builder.max(builder.constant(0), x);
    </pre>
  </details>
</div>

#### The {{MLGraphBuilder/relu(input)}} method #### {#api-mlgraphbuilder-relu-input}
<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as *x*.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/relu(input)}} steps are:
  </summary>
  <div algorithm=relu-input class=algorithm-steps>
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the ReLU operation.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

#### The {{MLGraphBuilder/relu()}} method #### {#api-mlgraphbuilder-relu}
<div>
    **Arguments:**
        - None.

    **Returns:**
        - an {{MLActivation}}. The activation function representing the relu operation.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/relu()}} method steps are:
  </summary>
  <div algorithm=relu class=algorithm-steps>
    1. Let |op| be the result of invoking the <a>create MLActivation</a> steps with `"relu"`.
        1. If that throws an error, re-throw the error and abort these steps.
    1. Return |op|.
  </div>
</details>

### The resample2d() method ### {#api-mlgraphbuilder-resample2d-method}
Resample the tensor values from the source to the destination spatial dimensions according to the scaling factors.
<script type=idl>
enum MLInterpolationMode {
  "nearest-neighbor",
  "linear"
};

dictionary MLResample2dOptions {
  MLInterpolationMode mode = "nearest-neighbor";
  sequence<float> scales;
  sequence<unsigned long> sizes;
  sequence<unsigned long> axes;
};

partial interface MLGraphBuilder {
  MLOperand resample2d(MLOperand input, optional MLResample2dOptions options = {});
};
</script>
<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input 4-D tensor.
        - *options*: an optional {{MLResample2dOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output 4-D tensor.
</div>

{{MLResample2dOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLResample2dOptions>
    : <dfn>mode</dfn>
    ::
        An {{MLInterpolationMode}} [=string=].
        Specifies the interpolation algorithm used to fill the output tensor values.
        The default value is `"nearest-neighbor"`, standing for *Nearest Neighbor* interpolation.

    : <dfn>scales</dfn>
    ::
        A sequence of {{float}} of length 2.
        Specifies the scaling factor in each spatial dimensions of the input: [scale_height, scale_width].
        The default value is [1.0, 1.0].

    : <dfn>sizes</dfn>
    ::
        A sequence of {{unsigned long}} of length 2.
        Specifies the target sizes for each spatial dimensions of the input: [size_height, size_width]. When the target sizes are specified, the {{MLResample2dOptions/scales}} argument is ignored, since the scaling factor values are derived from the target sizes of each spatial dimension of the input.

    : <dfn>axes</dfn>
    ::
        A sequence of {{unsigned long}} of length 2.
        Specifies the two consecutive dimensions of the input tensor to which the interpolation algorithm applies. The valid values in the sequence are [0, 1], [1, 2] or [2, 3].
        The default value is [2, 3].
</dl>

<details open>
  <summary>
    To <dfn for="MLGraphBuilder">check resample options</dfn> given |options|, run the following steps:
  </summary>
  <div algorithm=check-resample-options class=algorithm-steps>
    1. If |options| is `undefined`, let |options| be a new {{MLResample2dOptions}} object.
    1. If |options|.{{MLResample2dOptions/mode}} [=map/exists=]:
        1. If its value is not one of `"nearest-neighbor"` or `"linear"`, return `null`.
    1. Otherwise, set |options|.{{MLResample2dOptions/mode}} to `"nearest-neighbor"`.
    1. If |options|.{{MLResample2dOptions/scales}} [=map/exists=]:
        1. If its size is not `2`, or if any of its values is not greater than `0`, return `null`.
    1. Otherwise, set |options|.{{MLResample2dOptions/scales}} to `[1.0, 1.0]`.
    1. If |options|.{{MLResample2dOptions/sizes}} [=map/exists=]: if its size is not `2`, or if any of its values is not greater than `0`, return `null`.
    1. If |options|.{{MLResample2dOptions/axes}} [=map/exists=]:
        1. If its value is not one of `[0, 1], [1, 2], [2, 3]`, return `null`.
    1. Otherwise, set |options|.{{MLResample2dOptions/axes}} to `[2, 3]`.
    1. Return |options|.
  </div>
</details>

<details open>
  <summary>
    To <dfn for="MLGraphBuilder">resample output sizes</dfn> given |input| and |options|, run the following steps:
  </summary>
  <div algorithm=resample-output-sizes class=algorithm-steps>
    1. Let |desc| be an {{MLOperandDescriptor}} initialized to |input|.{{MLOperand/[[descriptor]]}}.
    1. If |options|.{{MLResample2dOptions/sizes}} [=map/exists=], then set |desc|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}} to |options|.{{MLResample2dOptions/sizes}} and return |desc|.
    1. For |index| between `0` and the rank of |desc|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}:
        1. Let |inputSize| be the size of |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}[|index|].
        1. Let |outputSize| be |inputSize| multiplied by |options|.{{MLResample2dOptions/scales}}.
            1. If that fails or |outputSize| is not a positive [=number=], then throw a "{{DataError}}" {{DOMException}} and stop.
        1. Set |desc|.{{MLOperandDescriptor/dimensions}}[|index|] to |outputSize|.
    1. Return |desc|.
  </div>
</details>

<details open>
  <summary>
    The {{MLGraphBuilder/resample2d(input, options)}} steps are:
  </summary>
  <div algorithm=resample2d class=algorithm-steps>
    1. Check if the input is a 4-dimensional tensor: if the size of |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}} is not `4`, throw a "{{DataError}}" {{DOMException}} and stop.
    1. Let |options| be the result of running the <a>check resample options</a> steps given |options|.
        1. If that returns `null`, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. Let |desc| be the result of running the <a>resample output sizes</a> steps given |options|.
        1. If that throws an error, re-throw the error and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the resample 2D operation, given |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

### The reshape() method ### {#api-mlgraphbuilder-reshape-method}
Alter the shape of a tensor to a new shape. Reshape does not copy or change the content of the tensor. It just changes the tensor's logical dimensions for the subsequent operations.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand reshape(MLOperand input, sequence<unsigned long?> newShape);
};
</script>
<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.
        - *newShape*: a sequence of {{nullable}} {{unsigned long}}. The shape of the output tensor.
            The number of elements implied by *newShape* must be the same as the
            number of elements in the input tensor. Only one component of
            *newShape* can be the special value of `null`. The size of the dimension
            with the value `null` is computed so that the total size remains
            constant.

    **Returns:** an {{MLOperand}}. The output tensor. The values of the output
    tensor are the same as values of the input tensor. The shape of the output
    tensor is specified by the *newShape* argument.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/reshape(input, newShape)}} steps are:
  </summary>
  <div algorithm=reshape class=algorithm-steps>
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. Let |outputShape| be an empty array of {{unsigned long}}.
    1. If |newShape| is a scalar [=number=], set |outputShape| to `[ 1 ]`.
    1. Otherwise, if |newShape| is an array of {{unsigned long}}:
        1. If the size of |newShape| is `0`, set |outputShape| to `[ 1 ]` (reshaping to scalar).
        1. If |newShape| contains more than one `null` value, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If any value in |newShape| is `0`, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. Let |inputElementCount| be  the product of all elements in |inputs|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}.
        1. If |newShape| contains a `null` value, set that value to |inputElementCount| divided by the product of all other values in |newShape|.
            1. If that value is too large for {{unsigned long}}, then throw a "{{DataError}}" {{DOMException}} and stop.
        1. If product of all values in |newShape| is not equal to |inputElementCount|, then throw a "{{DataError}}" {{DOMException}} and stop.
    1. Let |desc| be a copy of |input|.{{MLOperand/[[descriptor]]}}.
    1. Set |desc|.{{MLOperandDescriptor/dimensions}} to |newShape|.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>create MLOperand</a> steps given [=this=] and |desc|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the reshape operation.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

### The sigmoid() method ### {#api-mlgraphbuilder-sigmoid-method}
Compute the <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid function</a> of the input tensor. The calculation follows the expression `1 / (exp(-x) + 1)`.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand sigmoid(MLOperand input);
  MLActivation sigmoid();
};
</script>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint.
    </summary>
    <pre highlight="js">
    return builder.div(
              builder.constant(1),
              builder.add(
                builder.exp(builder.neg(x)),
                builder.constant(1)));
    </pre>
  </details>
</div>

#### The {{MLGraphBuilder/sigmoid(input)}} method #### {#api-mlgraphbuilder-sigmoid-input}
<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as *input*.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/sigmoid(input)}} steps are:
  </summary>
  <div algorithm=sigmoid-input class=algorithm-steps>
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the sigmoid operation.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

#### The {{MLGraphBuilder/sigmoid()}} method #### {#api-mlgraphbuilder-sigmoid}
<div>
    **Arguments:**
        - None.

    **Returns:**
        - an {{MLActivation}}. The activation function representing the sigmoid operation.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/sigmoid()}} method steps are:
  </summary>
  <div algorithm=sigmoid class=algorithm-steps>
    1. Let |op| be the result of invoking the <a>create MLActivation</a> steps with `"sigmoid"`.
        1. If that throws an error, re-throw the error and abort these steps.
    1. Return |op|.
  </div>
</details>

### The slice() method ### {#api-mlgraphbuilder-slice}
Produce a slice of the input tensor.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand slice(MLOperand input, sequence<unsigned long> starts, sequence<unsigned long> sizes);
};
</script>
<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.
        - *starts*: a sequence of {{unsigned long}}. The sequence of unsigned integer values indicating the starting index to slice of each input dimension, of length N where N is the rank of the input tensor. For each dimension *d* of *input*, *starts[d]* indicates the starting index to slice in that dimension. The starting index must be in the range [0, input size - 1] in that dimension.
        - *sizes*: a sequence of {{unsigned long}}. The sequence of unsigned integer values indicating the number of elements to slice of each input dimension, of length N where N is the rank of the input tensor. For each dimension *d* of *input*, *sizes[d]* indicates the number of elements to slice in that dimension. The size must not be 0 and must satisfy the constraint *starting index + size <= input size* in that dimension.

    **Returns:** an {{MLOperand}}. The output tensor of the same rank as the input tensor with tensor values stripped to the specified starting and ending indices in each dimension.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/slice(input, starts, sizes)}} steps are:
  </summary>
  <div algorithm=slice class=algorithm-steps>
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |starts| or |sizes| is not a sequence of {{long}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |sizes|.size is 0, then throw a "{{TypeError}}" {{DOMException}} and stop.
        <div class="note">
            Further validation of |starts| and |sizes| given |input| is left [=implementation-defined=].
        </div>
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the slice operation, given |starts| and |sizes|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

### The softmax() method ### {#api-mlgraphbuilder-softmax-method}
Compute the [softmax](https://en.wikipedia.org/wiki/Softmax_function) values of
the 2-D input tensor along axis 1.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand softmax(MLOperand input);
  MLActivation softmax();
};
</script>

<div class="note">
<details open>
  <summary>
    The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint.
  </summary>
  <pre highlight="js">
    // This sample deploys a well-known implementation trick [1] to compute the
    // exponentials of the distances to the max value, instead of the exponentials
    // of the input values itself, in order to increase the numerical stability of
    // the result.
    // [1]: https://cs231n.github.io/linear-classify/#softmax
    const max_x = builder.reduceMax(x, { axes: [1], keepDimensions: true });
    const exp_x = builder.exp(builder.sub(x, max_x));
    return builder.div(exp_x, builder.reduceSum(exp_x, { axes: [1], keepDimensions: true }));
  </pre>
</details>
</div>

#### The {{MLGraphBuilder/softmax(input)}} method #### {#api-mlgraphbuilder-softmax-input}
<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input 2-D tensor.

    **Returns:**
        - an {{MLOperand}}. The output 2-D tensor that contains the softmax results, of the same shape as the input tensor.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/softmax(input)}} steps are:
  </summary>
  <div algorithm=softmax-input class=algorithm-steps>
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the softmax operation.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

#### The {{MLGraphBuilder/softmax()}} method #### {#api-mlgraphbuilder-softmax}
<div>
    **Arguments:**
        - None.

    **Returns:**
        - an {{MLActivation}}. The activation function representing the softmax operation.
</div>
<details open>
  <summary>
    The {{MLGraphBuilder/softmax()}} method steps are:
  </summary>
  <div algorithm=softmax class=algorithm-steps>
    1. Let |op| be the result of invoking the <a>create MLActivation</a> steps with `"softmax"`.
        1. If that throws an error, re-throw the error and abort these steps.
    1. Return |op|.
  </div>
</details>

### The softplus() method ### {#api-mlgraphbuilder-softplus-method}
Compute the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Softplus">softplus function</a> of the input tensor. The calculation follows the expression `ln(1 + exp(steepness * x)) / steepness`.
<script type=idl>
dictionary MLSoftplusOptions {
  float steepness = 1;
};

partial interface MLGraphBuilder {
  MLOperand softplus(MLOperand input, optional MLSoftplusOptions options = {});
  MLActivation softplus(optional MLSoftplusOptions options = {});
};
</script>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint.
    </summary>
    <pre highlight="js">
    return builder.div(
              builder.log(
                builder.add(
                  builder.exp(builder.mul(x, builder.constant(options.steepness))),
                  builder.constant(1))),
              builder.constant(options.steepness));
    </pre>
  </details>
</div>

{{MLSoftplusOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLSoftplusOptions>
    : <dfn>steepness</dfn>
    ::
         A {{float}} scalar parameter.
         The default value is `1`.
</dl>

<details open>
  <summary>
    To <dfn>check softplus options</dfn> given |options|, run the following steps:
  </summary>
  <div algorithm=check-softplus-options class=algorithm-steps>
    1. If |options| is not an [=object=], then return `false`.
    1. If |options|.{{MLSoftplusOptions/steepness}} is `undefined`, set |options|.{{MLSoftplusOptions/steepness}} to `1`.
    1. Else if |options|.{{MLSoftplusOptions/steepness}} is not a [=numeric type=], then then return `false`.
    1. Return `true`.
  </div>
</details>

#### The {{MLGraphBuilder/softplus(input, options)}} method #### {#api-mlgraphbuilder-softplus-input-options}
<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.
        - *options*: an optional {{MLSoftplusOptions}}. The optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as *x*.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/softplus(input, options)}} method steps are:
  </summary>
  <div algorithm=softplus-input-options class=algorithm-steps>
    1. Let |input| be the first argument.
    1. Let |options| be the second argument.
        1. If running the <a>check softplus options</a> steps with |options| returns `false`, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the softplus operation, given |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

#### The {{MLGraphBuilder/softplus(options)}} method #### {#api-mlgraphbuilder-softplus-options}
<div>
    **Arguments:**
        - *options*: an optional {{MLSoftplusOptions}}. The optional parameters of the operation.

    **Returns:**
        - an {{MLActivation}}. The activation function representing the softplus operation.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/softplus(options)}} method steps are:
  </summary>
  <div algorithm=softplus-options class=algorithm-steps>
    1. Let |options| be the first argument.
        1. If running the <a>check softplus options</a> steps with |options| returns `false`, then throw a "{{TypeError}}" {{DOMException}} and abort these steps.
    1. Let |op| be the result of invoking the <a>create MLActivation</a> steps with `"softplus"` and |options|.
        1. If that throws an error, re-throw the error and abort these steps.
    1. Return |op|.
  </div>
</details>

### The softsign() method ### {#api-mlgraphbuilder-softsign-method}
Compute the <a href="https://pytorch.org/docs/stable/generated/torch.nn.Softsign.html">softsign function</a> of the input tensor. The calculation follows the expression `x / (1 + |x|)`.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand softsign(MLOperand input);
  MLActivation softsign();
};
</script>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint.
    </summary>
    <pre highlight="js">
    return builder.div(x, builder.add(builder.constant(1), builder.abs(x)));
    </pre>
  </details>
</div>

#### The {{MLGraphBuilder/softsign(input)}} method #### {#api-mlgraphbuilder-softsign-input}
<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as *x*.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/softsign(input)}} steps are:
  </summary>
  <div algorithm=softsign-input class=algorithm-steps>
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the softsign operation, given |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

#### The {{MLGraphBuilder/softsign()}} method #### {#api-mlgraphbuilder-softsign}
<div>
    **Arguments:**
        - None.

    **Returns:**
        - an {{MLActivation}}. The activation function representing the softsign operation.
</div>
<details open>
  <summary>
    The {{MLGraphBuilder/softsign()}} method steps are:
  </summary>
  <div algorithm=softsign class=algorithm-steps>
    1. Let |op| be the result of invoking the <a>create MLActivation</a> steps with `"softsign"`.
        1. If that throws an error, re-throw the error and abort these steps.
    1. Return |op|.
  </div>
</details>

### The split() method ### {#api-mlgraphbuilder-split}
Split the input tensor into a number of sub tensors along the given axis.
<script type=idl>
dictionary MLSplitOptions {
  unsigned long axis = 0;
};

partial interface MLGraphBuilder {
  sequence<MLOperand> split(MLOperand input,
                          (unsigned long or sequence<unsigned long>) splits,
                          optional MLSplitOptions options = {});
};
</script>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.
        - *splits*: an {{unsigned long}} or a sequence of {{unsigned long}}. If an {{unsigned long}}, it specifies the number of output tensors along the axis. The number must evenly divide the dimension size of *input* along *options.axis*. If a sequence of {{unsigned long}}, it specifies the sizes of each output tensor along the *options.axis*. The sum of sizes must equal to the dimension size of *input* along *options.axis*.
        - *options*: an optional {{MLSplitOptions}}. The optional parameters of the operation.

    **Returns:** a sequence of {{MLOperand}}. The splitted output tensors. If *splits* is an {{unsigned long}}, the length of the output sequence equals to *splits*. The shape of each output tensor is the same as *input* except the dimension size of *axis* equals to the quotient of dividing the dimension size of *input* along *axis* by *splits*. If *splits* is a sequence of {{unsigned long}}, the length of the output sequence equals to the length of *splits*. The shape of the i-th output tensor is the same as as *input* except along *axis* where the dimension size is *splits[i]*.
</div>

{{MLSplitOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLSplitOptions>
    : <dfn>axis</dfn>
    ::
        An {{unsigned long}} scalar. The dimension along which to split. Its value must be in the range [0, N-1] where N is the rank of input tensor.
        The default value is `0`.
</dl>

<details open>
  <summary>
    The {{MLGraphBuilder/split(input, splits, options)}} steps are:
  </summary>
  <div algorithm=split class=algorithm-steps>
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options| is `undefined`, let |options| be an empty [=object=].
    1. If |options|.{{MLSplitOptions/axis}} is `undefined`, let |options|.{{MLSplitOptions/axis}} be `0`.
    1. If |splits| is not {{unsigned long}} or a sequence of {{unsigned long}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the split operation, given |splits| and |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint.
  </summary>
  <pre highlight="js">
    // This sample shows the case that the splits parameter is an array.
    const outputs = [];
    let starts = Array(input_rank).fill(0);
    let sizes = input_shape;
    let start = 0;
    for (const size of splits) {
      starts[options.axis] = start;
      sizes[options.axis] = size;
      outputs.push(builder.slice(input, starts, sizes));
      start += size;
    }
    return outputs;
  </pre>
</details>
</div>

### The squeeze() method ### {#api-mlgraphbuilder-squeeze}
Reduce the rank of a tensor by eliminating dimensions with size 1 of the tensor shape. Squeeze only affects the tensor's logical dimensions. It does not copy or change the content in the tensor.
<script type=idl>
dictionary MLSqueezeOptions {
  sequence<unsigned long> axes;
};

partial interface MLGraphBuilder {
  MLOperand squeeze(MLOperand input, optional MLSqueezeOptions options = {});
};
</script>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.
        - *options*: an optional {{MLSqueezeOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output tensor of the same or reduced rank with the shape dimensions of size 1 eliminated.
</div>

{{MLSqueezeOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLSqueezeOptions>
    : <dfn>axes</dfn>
    ::
        A sequence of {{unsigned long}}.
        Specifies the indices to the shape dimensions of size 1 to eliminate. The values in the sequence must be in the range [0, N-1] where N is the rank of input tensor.
        When not specified, every shape dimensions of size 1 in the tensor are eliminated.
</dl>

<details open>
  <summary>
    The {{MLGraphBuilder/squeeze(input, options)}} steps are:
  </summary>
  <div algorithm=squeeze class=algorithm-steps>
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options| is `undefined`, let |options| be an empty [=object=].
    1. If |options|.{{MLSqueezeOptions/axes}} [=map/exists=], then:
        1. Let |dimensions| be |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}.
        1. For |index| between 0 and the size of |options|.{{MLSqueezeOptions/axes}}:
            1. Let |oneDimIndex| be |options|.{{MLSqueezeOptions/axes}}[|index|].
            1. If |dimensions|[|oneDimIndex|] is not `1`, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the squeeze operation, given |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

### The tanh() method ### {#api-mlgraphbuilder-tanh-method}
Compute the <a href="https://en.wikipedia.org/wiki/Hyperbolic_functions">hyperbolic tangent function</a> of the input tensor. The calculation follows the expression `(exp(2 * x) - 1) / (exp(2 * x) + 1)`.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand tanh(MLOperand input);
  MLActivation tanh();
};
</script>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be generically emulated from the usage of
    other operations as follow. However, user agents typically have a more
    efficient implementation for it, therefore its usage is encouraged from the
    performance standpoint.
    </summary>
    <pre highlight="js">
    return builder.div(
              builder.sub(builder.exp(builder.mul(builder.constant(2), x)), builder.constant(1)),
              builder.add(builder.exp(builder.mul(builder.constant(2), x)), builder.constant(1)));
    </pre>
  </details>
</div>

#### The {{MLGraphBuilder/tanh(input)}} method #### {#api-mlgraphbuilder-tanh-input}
<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input tensor.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as *x*.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/tanh(input)}} steps are:
  </summary>
  <div algorithm=tanh-input class=algorithm-steps>
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the hyperbolic tangent operation.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

#### The {{MLGraphBuilder/tanh()}} method #### {#api-mlgraphbuilder-tanh}
<div>
    **Arguments:**
        - None.

    **Returns:**
        - an {{MLActivation}}. The activation function representing the tanh operation.
</div>

<details open>
  <summary>
    The {{MLGraphBuilder/tanh()}} method steps are:
  </summary>
  <div algorithm=tanh class=algorithm-steps>
    1. Let |op| be the result of invoking the <a>create MLActivation</a> steps with `"tanh"`.
        1. If that throws an error, re-throw the error and abort these steps.
    1. Return |op|.
  </div>
</details>

### The transpose() method ### {#api-mlgraphbuilder-transpose}
Permute the dimensions of the input tensor according to the *permutation* argument.
<script type=idl>
dictionary MLTransposeOptions {
  sequence<unsigned long> permutation;
};

partial interface MLGraphBuilder {
  MLOperand transpose(MLOperand input, optional MLTransposeOptions options = {});
};
</script>

<div>
    **Arguments:**
        - *input*: an {{MLOperand}}. The input N-D tensor.
        - *options*: an optional {{MLTransposeOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The permuted or transposed N-D tensor.
</div>

{{MLTransposeOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLTransposeOptions>
    : <dfn>permutation</dfn>
    ::
        A sequence of {{unsigned long}} values.
        Specifies the values used to permute the output shape.
        The default value is [N-1, ..., 0], where N is the rank of the input tensor, e.g. [2,1,0] for a 3-D tensor.
        These default values cause the output to become a transposed tensor of the input. When specified, the number of values in the sequence must be the same as the rank of the input tensor, and the values in the sequence must be within the range from 0 to N-1 with no two or more same values found in the sequence.
</dl>

<details open>
  <summary>
    The {{MLGraphBuilder/transpose(input, options)}} steps are:
  </summary>
  <div algorithm=transpose class=algorithm-steps>
    1. If |input| is not an instance of {{MLOperand}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If |options| is `undefined`, let |options| be an empty [=object=].
    1. If |options|.{{MLTransposeOptions/permutation}} is `undefined`, let |options|.{{MLTransposeOptions/permutation}} be the reversed sequence of all indices for |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}.
    1. Otherwise if |options|.{{MLTransposeOptions/permutation}} [=map/exists=]:
        1. If |options|.{{MLTransposeOptions/permutation}} is not a sequence of {{unsigned long}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If the rank of |options|.{{MLTransposeOptions/permutation}} is not the same as the rank of |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}}, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If the values in |options|.{{MLTransposeOptions/permutation}} are not between `0` and the rank of |input|.{{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dimensions}} minus `1`, then throw a "{{TypeError}}" {{DOMException}} and stop.
        1. If the values in |options|.{{MLTransposeOptions/permutation}} contain duplicate value, then throw a "{{TypeError}}" {{DOMException}} and stop.
    1. If any of the following sub-steps fail, throw an "{{OperationError}}" {{DOMException}} and stop.
        1. Let |output| be the result of invoking the <a>copy MLOperand</a> steps given |input|.
        1. Make a request to the underlying platform to:
            1. Let |opImpl| be an [=implementation-defined=] platform operator for the transpose operation, given |options|.
            1. Store a reference of |opImpl| in |output|.{{MLOperand/[[operator]]}}.
            1. Create an [=implementation-defined=] platform operand |outputImpl| to represent the output, given |output| and |opImpl|.
            1. Store a reference to |outputImpl| in |output|.{{MLOperand/[[operand]]}}.
        1. Connect |input|.{{MLOperand/[[operand]]}} as input to |opImpl|.
        1. Connect |output|.{{MLOperand/[[operand]]}} as output to |opImpl|.
    1. Return |output|.
  </div>
</details>

Examples {#examples}
=====================

<div class="example">
The following code gets the MLContext object.
<pre highlight="js">
const context = await navigator.ml.createContext({powerPreference: 'low-power'});
</pre>
</div>

<div class="example">
Given the following build graph:
<pre>
    constant1 ---+
                +--- Add ---> intermediateOutput1 ---+
    input1    ---+                                    |
                                                    +--- Mul---> output
    constant2 ---+                                    |
                +--- Add ---> intermediateOutput2 ---+
    input2    ---+
</pre>
<details open>
  <summary>
    The following code implements the graph:
  </summary>
  <pre highlight="js">
    // Use tensors in 4 dimensions.
    const TENSOR_DIMS = [1, 2, 2, 2];
    const TENSOR_SIZE = 8;

    const builder = new MLGraphBuilder(context);

    // Create MLOperandDescriptor object.
    const desc = {type: 'float32', dimensions: TENSOR_DIMS};

    // constant1 is a constant MLOperand with the value 0.5.
    const constantBuffer1 = new Float32Array(TENSOR_SIZE).fill(0.5);
    const constant1 = builder.constant(desc, constantBuffer1);

    // input1 is one of the input MLOperands. Its value will be set before execution.
    const input1 = builder.input('input1', desc);

    // constant2 is another constant MLOperand with the value 0.5.
    const constantBuffer2 = new Float32Array(TENSOR_SIZE).fill(0.5);
    const constant2 = builder.constant(desc, constantBuffer2);

    // input2 is another input MLOperand. Its value will be set before execution.
    const input2 = builder.input('input2', desc);

    // intermediateOutput1 is the output of the first Add operation.
    const intermediateOutput1 = builder.add(constant1, input1);

    // intermediateOutput2 is the output of the second Add operation.
    const intermediateOutput2 = builder.add(constant2, input2);

    // output is the output MLOperand of the Mul operation.
    const output = builder.mul(intermediateOutput1, intermediateOutput2);
  </pre>
</details>
</div>

<div class="example">
Compile the graph up to the output operand.
<pre highlight="js">
// Compile the constructed graph.
const graph = await builder.build({'output': output});
</pre>
</div>

<div class="example">
<details open>
  <summary>
    The following code executes the compiled graph.
  </summary>
  <pre highlight="js">
    // Setup the input buffers with value 1.
    const inputBuffer1 = new Float32Array(TENSOR_SIZE).fill(1);
    const inputBuffer2 = new Float32Array(TENSOR_SIZE).fill(1);
    const outputBuffer = new Float32Array(TENSOR_SIZE);

    // Execute the compiled graph with the specified inputs.
    const inputs = {
    'input1': inputBuffer1,
    'input2': inputBuffer2,
    };
    const outputs = {'output': outputBuffer};
    const result = await context.compute(graph, inputs, outputs);

    console.log('Output value: ' + result.outputs.output);
    // Output value: 2.25,2.25,2.25,2.25,2.25,2.25,2.25,2.25
  </pre>
</details>
</div>

# Appendices # {#appendices}

## {{MLOperandType}} and {{ArrayBufferView}} compatibility ## {#appendices-mloperandtype-arraybufferview-compatibility}

<table class='data'>
    <thead class=stickyheader>
        <tr>
            <th>{{MLOperandType}}
            <th>{{ArrayBufferView}}
    </thead>
    <tr>
        <td>{{MLOperandType/float32}}
        <td>{{Float32Array}}
    <tr>
        <td>{{MLOperandType/float16}}
        <td>{{Float16Array}}
    <tr>
        <td>{{MLOperandType/int32}}
        <td>{{Int32Array}}
    <tr>
        <td>{{MLOperandType/uint32}}
        <td>{{Uint32Array}}
    <tr>
        <td>{{MLOperandType/int8}}
        <td>{{Int8Array}}
    <tr>
        <td>{{MLOperandType/uint8}}
        <td>{{Uint8Array}}
</table>

<p class="note">{{Float16Array}} is at <a href="https://tc39.es/process-document/">ECMA Stage 3</a> signaling its design is finished. Implementers wanting to enable this type ahead native implementations can emulate the type by passing raw bits via {{Uint16Array}}. <a href="https://github.com/webmachinelearning/webnn/issues/373">[Issue webnn#373]</a></p>

<h2 id="acknowledgements">Acknowledgements</h2>

This specification follows the concepts of the Android Neural Networks API C
API.

Thanks to Tomoyuki Shimizu, Ningxin Hu, Zhiqiang Yu and Belem Zhang for the use
cases.

Thanks to Nikhil Thorat, Daniel Smilkov, Ganesan Ramalingam, Rafael Cintron and
Benjamin Poulain for their contributions to the API specification.

Thanks to Sangwhan Moon and the W3C Technical Architecture Group for review of this specification for web architecture fit, design consistency and developer ergonomics.

Thanks to W3C Privacy Interest Group for privacy and security review and feedback.

Thanks to Alex Gough and the Chrome Security team for security review and questions.

Thanks to Michal Karzynski for sharing practical guidelines and learnings from ONNX.

Thanks to Kaustubha Govind and Chrome privacy reviewers for feedback and privacy considerations.

Thanks to Jiewei Qian for Chromium implementation review and feedback.

<pre class="biblio">
{
  "Models": {
      "href": "https://github.com/webmachinelearning/webnn/blob/master/op_compatibility/first_wave_models.md",
      "title": "The first-wave models",
      "authors": ["Machine Learning for the Web Community Group"],
      "date": "2020"
  },
  "numpy-broadcasting-rule": {
    "href": "https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html#general-broadcasting-rules",
    "title": "General Broadcasting Rules of NumPy",
    "authors": ["The SciPy community"],
    "date": "July 2019"
  },
  "SSD": {
    "href": "https://arxiv.org/abs/1512.02325",
    "title": "SSD: Single Shot MultiBox Detector",
    "authors": [
      "Wei Liu",
      "Dragomir Anguelov",
      "Dumitru Erhan",
      "Christian Szegedy",
      "Scott Reed",
      "Cheng-Yang Fu",
      "Alexander C. Berg"
    ],
    "date": "December 2016"
  },
  "YOLO": {
    "href": "https://arxiv.org/abs/1506.02640",
    "title": "You Only Look Once: Unified, Real-Time Object Detection",
    "authors": [
      "Joseph Redmon",
      "Santosh Divvala,",
      "Ross Girshick",
      "Ali Farhadi"
    ],
    "date": "May 2016"
  },
  "DeepLabv3+": {
    "href": "https://arxiv.org/abs/1802.02611",
    "title": "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation",
    "authors": [
      "Liang-Chieh Chen",
      "Yukun Zhu",
      "George Papandreou",
      "Florian Schroff",
      "Hartwig Adam"
    ],
    "date": "August 2018"
  },
  "MaskR-CNN": {
    "href": "https://arxiv.org/abs/1703.06870",
    "title": "Mask R-CNN",
    "authors": [
      "Kaiming He",
      "Georgia Gkioxari",
      "Piotr Dollár",
      "Ross Girshick"
    ],
    "date": "January 2018"
  },
  "PoseNet": {
    "href": "https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5",
    "title": "Real-time Human Pose Estimation in the Browser with TensorFlow.js",
    "authors": [
      "Dan Oved"
    ],
    "date": "May 2018"
  },
  "FaceNet": {
    "href": "https://arxiv.org/abs/1503.03832",
    "title": "FaceNet: A Unified Embedding for Face Recognition and Clustering",
    "authors": [
      "Florian Schroff",
      "Dmitry Kalenichenko",
      "James Philbin"
    ],
    "date": "June 2015"
  },
  "FAN": {
    "href": "https://arxiv.org/abs/1703.07332",
    "title": "How far are we from solving the 2D & 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks)",
    "authors": [
      "Adrian Bulat",
      "Georgios Tzimiropoulos"
    ],
    "date": "September 2017"
  },
  "ContextualLoss": {
    "href": "https://arxiv.org/abs/1803.02077",
    "title": "The Contextual Loss for Image Transformation with Non-Aligned Data",
    "authors": [
      "Roey Mechrez",
      "Itamar Talmi",
      "Lihi Zelnik-Manor"
    ],
    "date": "July 2018"
  },
  "PairedCycleGAN": {
    "href": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chang_PairedCycleGAN_Asymmetric_Style_CVPR_2018_paper.html",
    "title": "PairedCycleGAN: Asymmetric Style Transfer for Applying and Removing Makeup",
    "authors": [
      "Huiwen Chang",
      "Jingwan Lu",
      "Fisher Yu",
      "Adam Finkelstein"
    ],
    "date": "June 2018"
  },
  "SRGAN": {
    "href": "https://arxiv.org/abs/1609.04802",
    "title": "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network",
    "authors": [
      "Christian Ledig",
      "Lucas Theis",
      "Ferenc Huszar",
      "Jose Caballero",
      "Andrew Cunningham",
      "Alejandro Acosta",
      "Andrew Aitken",
      "Alykhan Tejani",
      "Johannes Totz",
      "Zehan Wang",
      "Wenzhe Shi"
    ],
    "date": "May 2017"
  },
  "im2txt": {
    "href": "https://arxiv.org/abs/1609.06647",
    "title": "Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge",
    "authors": [
      "Oriol Vinyals",
      "Alexander Toshev",
      "Samy Bengio",
      "Dumitru Erhan"
    ],
    "date": "September 2016"
  },
  "GNMT": {
    "href": "https://github.com/tensorflow/nmt",
    "title": "Neural Machine Translation (seq2seq) Tutorial",
    "authors": [
      "Minh-Thang Luong",
      "Eugene Brevdo",
      "Rui Zhao"
    ],
    "date": "May 2017"
  },
  "OpenNMT": {
    "href": "https://arxiv.org/abs/1701.02810",
    "title": "OpenNMT: Open-Source Toolkit for Neural Machine Translation",
    "authors": [
      "Guillaume Klein",
      "Yoon Kim",
      "Yuntian Deng",
      "Jean Senellart",
      "Alexander M. Rush"
    ],
    "date": "March 2017"
  },
  "DeepMoji": {
    "href": "https://arxiv.org/abs/1708.00524",
    "title": "Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm",
    "authors": [
      "Bjarke Felbo",
      "Alan Mislove",
      "Anders Søgaard",
      "Iyad Rahwan",
      "Sune Lehmann"
    ],
    "date": "October 2017"
  },
  "Video-Summarization-with-LSTM": {
    "href": "http://www-scf.usc.edu/~zhan355/ke_eccv2016.pdf",
    "title": "Video summarization with long short-term memory",
    "authors": [
      "Ke Zhang",
      "Wei-Lun Chao",
      "Fei Sha",
      "Kristen Grauman"
    ],
    "date": "October 2016"
  },
  "LeakyReLU": {
    "href": "https://pdfs.semanticscholar.org/367f/2c63a6f6a10b3b64b8729d601e69337ee3cc.pdf",
    "title": "Rectifier Nonlinearities Improve Neural Network Acoustic Models",
    "authors": [
      "Andrew L. Maas",
      "Awni Y. Hannun",
      "Andrew Y. Ng"
    ],
    "date": "June 2013"
  },
  "ELU": {
    "href": "https://arxiv.org/abs/1511.07289",
    "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)",
    "authors": [
      "Djork-Arné Clevert",
      "Thomas Unterthiner",
      "Sepp Hochreiter"
    ],
    "date": "February 2016"
  },
  "RNNoise": {
    "href": "https://github.com/xiph/rnnoise",
    "title": "Recurrent neural network for audio noise reduction",
    "authors": [
      "Jean-Marc Valin"
    ],
    "date": "September 2017"
  },
  "GRU": {
    "href": "https://arxiv.org/pdf/1406.1078.pdf",
    "title": "Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation",
    "authors": [
      "Kyunghyun Cho",
      "Bart van Merrienboer",
      "Caglar Gulcehre",
      "Dzmitry Bahdanau",
      "Fethi Bougares",
      "Holger Schwenk",
      "Yoshua Bengio"
    ],
    "date": "September 2014"
  },
  "LSTM": {
    "href": "https://doi.org/10.1162/neco.1997.9.8.1735",
    "title": "Long Short-Term Memory",
    "authors": [
      "Sepp Hochreiter",
      "Jürgen Schmidhuber"
    ],
    "date": "November 1997"
  },
  "Batch-Normalization": {
    "href": "https://arxiv.org/abs/1502.03167",
    "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
    "authors": [
      "Sergey Ioffe",
      "Christian Szegedy"
    ],
    "date": "March 2015"
  },
  "Instance-Normalization": {
    "href": "https://arxiv.org/abs/1607.08022",
    "title": "Instance Normalization: The Missing Ingredient for Fast Stylization",
    "authors": [
      "Dmitry Ulyanov",
      "Andrea Vedaldi",
      "Victor Lempitsky"
    ],
    "date": "July 2016"
  },
  "FaceForensics++": {
    "href": "https://github.com/ondyari/FaceForensics",
    "title": "FaceForensics++",
    "authors": [
      "Andreas Rössler",
      "Davide Cozzolino",
      "Luisa Verdoliva",
      "Christian Riess",
      "Justus Thies",
      "Matthias Nießner"
    ],
    "date": "January 2019"
  },
  "MobileNetV3": {
    "href": "https://arxiv.org/pdf/1905.02244",
    "title": "Searching for MobileNetV3",
    "authors": [
      "Andrew Howard",
      "Mark Sandler",
      "Grace Chu",
      "Liang-Chieh Chen",
      "Bo Chen",
      "Mingxing Tan",
      "Weijun Wang",
      "Yukun Zhu",
      "Ruoming Pang",
      "Vijay Vasudevan",
      "Quoc V. Le",
      "Hartwig Adam"
    ],
    "date": "November 2019"
  },
  "POWERFUL-FEATURES": {
    "href": "https://w3c.github.io/webappsec-secure-contexts/",
    "title": "Secure Contexts",
    "authors": [
      "Mike West"
    ]
  }
}
</pre>
