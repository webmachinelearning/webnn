<pre class='metadata'>
Title: Web Neural Network API
Shortname: webnn
Level: None
Status: w3c/ED
Group: webmlwg
TR: https://www.w3.org/TR/webnn/
URL: https://webmachinelearning.github.io/webnn/
Editor: Ningxin Hu 68202, Intel Corporation https://intel.com
Editor: Dwayne Robinson 140212, Microsoft Corporation https://microsoft.com
Former Editor: Chai Chaoweeraprasit 120203, Microsoft Corporation https://microsoft.com
Abstract: This document describes a dedicated low-level API for neural network inference hardware acceleration.
Repository: https://github.com/webmachinelearning/webnn
Test Suite: https://github.com/web-platform-tests/wpt/tree/master/webnn
Implementation Report: https://wpt.fyi/results/webnn?label=master&label=experimental&aligned&q=webnn
!Other: <a href="https://webmachinelearning.github.io/webnn-status/">Implementation Status</a>, <a href="https://github.com/webmachinelearning/webnn/blob/master/explainer.md">Explainer</a>, <a href="https://github.com/webmachinelearning/webnn-samples">Samples</a>
Markup Shorthands: markdown yes
Markup Shorthands: dfn yes
Markup Shorthands: idl yes
Markup Shorthands: css no
Logo: https://webmachinelearning.github.io/webmachinelearning-logo.png
Deadline: 2023-10-01
Assume Explicit For: yes
Complain About: accidental-2119 yes
Status Text: <p>
  Since the <a href="https://www.w3.org/TR/2023/CR-webnn-20230330/">initial Candidate Recommendation Snapshot</a> the Working Group has gathered further <a href="https://webmachinelearning.github.io/webnn-status/">implementation experience</a> and added new operations and data types needed for well-known <a href="https://github.com/webmachinelearning/webnn/issues/375">transformers to support generative AI use cases</a>. In addition, informed by this implementation experience, the group removed <code>MLCommandEncoder</code>, support for synchronous execution, and higher-level operations that can be expressed in terms of lower-level primitives in a performant manner. The group has also updated the specification to use modern authoring conventions to improve interoperability and precision of normative definitions.
  The group is developing a new feature, a <a href="https://github.com/webmachinelearning/webnn/issues/482">backend-agnostic storage type</a>, to improve performance and interoperability between the WebNN, WebGPU APIs and purpose-built hardware for ML and expects to republish this document as a Candidate Recommendation Snapshot when ready for implementation.
  This document is maintained and
  updated at any time. Some parts of this document are work in progress and
  further improvements are expected to be reflected in revised Candidate
  Recommendation Drafts and Snapshots.
  </p>
  <p>Before requesting transition to <a href="https://www.w3.org/standards/types#PR">Proposed Recommendation</a>, the Working Group will seek to demonstrate that:</p>
  <ul>
  <li>the API is implementable on top of existing APIs of major platforms, such as Android, Windows and macOS/iOS;</li>
  <li>it has at least two independent, interoperable implementations of every feature defined in the specification, where interoperability can be verified by passing open test suites, and two or more implementations interoperating with each other;</li>
  <li>it has an open test suite of every feature defined in the specification.</li>
  </ul>
Text Macro: EMULATED generically emulated from the usage of other operations as follows, although user agents typically have a more efficient implementation. In cases where the underlying platform does not directly support an operation, this decomposition can be used as a template to guide the implementation.
</pre>
<pre class="anchors">
urlPrefix: https://tc39.es/ecma262/; spec: ECMA-262
    type: dfn
        text: element size; url: table-the-typedarray-constructors
        text: view constructor; url: table-the-typedarray-constructors
        text: equally close values; url: sec-ecmascript-language-types-number-type
        text: settled; for: Promise; url: sec-promise-objects
</pre>

<pre class="link-defaults">
spec:html;
    type:interface; text:Navigator
spec:webidl;
    type:dfn; text:record
    type:dfn; text:resolve
spec:ecmascript; for:ECMAScript;
    type:dfn; text:realm
</pre>

<style>
/* Make <dl> blocks more distinct from their surroundings. */
main dl:not(.switch) {
    border-left: thin solid #f3e48c;
    padding-left: .5em;
}

/* <p> by default has these margins. Update ul/ol/dl to match,
 * since they are also put in places where paragraphs go. */
p, ul, ol, dl {
    margin: 1em 0;
}

/* Override rule making <code> smaller than surrounding text. */
dfn code {
    font-size: 100%;
}

/* Style <details>, for clarity of presentation of these blocks. */
details {
    padding: .5em;
    border: thin solid #88e !important;
    border-radius: .5em;
}

summary {
    font-weight: bold;
    margin: -0.5em -0.5em 0;
    padding: 0.5em;
}

/* Algorithm declaration and steps. */
.algorithm > summary {
    font-weight: normal;
}

.algorithm > ol {
    position: relative;
}
.algorithm > ol::after {
    content: "Algorithm";
    font-weight: bold;
    font-style: italic;
    font-size: 130%;
    color: rgba(0, 0, 0, 0.15);
    color: var(--watermark-text);
    position: absolute;
    right: .3em;
    bottom: -1em;
}

/* Internal slots */
div.internal-slots {
    padding: .5em;
    border: thin solid #88e !important;
    border-radius: .5em;
}

.internal-slots {
    position: relative;
}
.internal-slots::after {
    font-weight: bold;
    font-style: italic;
    font-size: 130%;
    color: rgba(0, 0, 0, 0.15);
    color: var(--watermark-text);
    position: absolute;
    right: .3em;
    bottom: .1em;
}

/*
 * Ensure that argumentdef blocks don't overflow algorithm section borders. This is made far harder
 * than it needs to be because the top-level W3C stylesheet has several @media + min-width variants
 * that mark themselves as !important and then proceed to do the wrong thing.
 */
@media screen and (min-width: 78em) {
    body:not(.toc-inline) .algorithm .overlarge {
        margin-right: auto !important;
    }
}
@media screen and (min-width: 90em) {
    body:not(.toc-inline) .algorithm .overlarge {
        margin-right: auto !important;
    }
}
.algorithm .overlarge {
    margin-right: auto !important;
}

/*
 * The default algorithm style has a caption that doesn't suit this spec's
 * formatting particularly well. Hide it.
 */
.algorithm .argumentdef {
    margin-top: 0;
}
.algorithm .argumentdef>caption {
    display: none;
}

/*
 * Add vertical lines to demarcate multi-column cells.
 */
table.data td[colspan] {
    border-left-style: dotted;
    border-right-style: dotted;
}

table.data.no-colspan-center td[colspan],
table.data.no-colspan-center th[colspan] {
    text-align: unset;
}

table.data tr.row-continuation td,
table.data tr.row-continuation th {
    border-top: none;
}

/*
 * Sticky table headers.
 */
.overlarge {
    /* position: sticky doesn't work inside scrollable elements. */
    overflow-x: unset;
}
thead.stickyheader th, th.stickyheader {
    position: sticky;
    top: 0;
    background: #f8f8f8;
    background: var(--stickyheader-background);
}

/*
 * Generic table format.
 */
th {
  text-align: left;
}

th, td {
  border-bottom: 1px solid black;
  border-collapse: collapse; /* BUG: This property only applies to TABLE. */
  padding-left: 5px;
  padding-right: 5px;
}

/*
 * Grid table format.
 */
table.grid {
  border-collapse: collapse;
  table-layout: fixed;
  width: 100%;
}

table.grid td, table.grid th {
  border: 1px solid black;
}

table.grid th {
  text-align: center;
}

/* For a table header cell that is split diagonally */
th.split {
  background-image: url("data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' version='1.1' preserveAspectRatio='none' viewBox='0 0 1 1'><line x1='0' y1='0' x2='1' y2='1' stroke='black' vector-effect='non-scaling-stroke'/></svg>");
  background-repeat: no-repeat;
  background-size: 100% 100%;
  position: relative;
}

th.split .bottom-left {
    display: block;
    position: absolute;
    bottom: 1px;
    left: 5px;
}

th.split .top-right {
    display: block;
    position: absolute;
    top: 1px;
    right: 5px;
}

/*
 * Darkmode colors
 */
:root {
    --watermark-text: rgba(0, 0, 0, 15%);
    --stickyheader-background: #f8f8f8;
    --tint-red: rgba(255, 0, 0, 6%);
    --tint-green: rgba(0, 255, 0, 10%);
    --tint-blue: rgba(0, 0, 255, 5%);
    --tint-purple: rgba(255, 0, 255, 5%);
}
@media (prefers-color-scheme:dark) {
    :root {
        --watermark-text: rgba(255, 255, 255, 25%);
        --stickyheader-background: #181818;
        --tint-red: rgba(255, 0, 0, 20%);
        --tint-green: rgba(0, 255, 0, 18%);
        --tint-blue: rgba(0, 130, 255, 24%);
        --tint-purple: rgba(255, 0, 255, 22%);
    }
}


/* Floating button for collapse/expand all details elements */

.collapse-expand-button {
  position: fixed;
  bottom: 40px;
  right: 40px;
  width: 40px;
  height: 40px;
  border: none;
  border-radius: 50%;
  background-color: green;
  color: ghostwhite;
  font-size: 32px;
  text-align: center;
  align-items:center;
  justify-content:center;
  cursor: pointer;
}

.collapse-expand-button:hover {
  background-color: green;
}

.collapse-expand-button.expand {
  background-color: red;
}

.collapse-expand-button.expand::before {
  content: "+";
}

.collapse-expand-button.collapse {
  background-color: green;
}

.collapse-expand-button.collapse::before {
  content: "-";
}

.collapse-expand-button .tooltiptext {
  visibility: hidden;
  bottom: 20px;
  right: 20px;
  width: 120px;
  background-color: ghostwhite;
  color: black;
  font-size: 18px;
  text-align: center;
  align-items:center;
  justify-content:center;
  padding: 5px 0;
  border-radius: 5px;

  /* position */
  position: absolute;
  z-index: 1;
  bottom: 100%;
  left: 50%;
  margin-left: -60px;
      /* Use half of the width (120/2 = 60), to center the tooltip */
}

.collapse-expand-button:hover .tooltiptext {
  visibility: visible;
  opacity: 0.75;
}

/* end of floating collapse/expand button */

</style>

<button class="collapse-expand-button" onclick="toggleCE()">
    <span class="tooltiptext">Collapse all</span>
</button>

<script>
    var ceButton = document.querySelector(".collapse-expand-button");
    ceButton.classList.add("collapse");  // All details are expanded by default.
    var scrollY = window.scrollY;
    window.addEventListener('scroll', function() {
        scrollY = window.scrollY;
        ceButton.style.top = scrollY + window.innerHeight - 60 + 'px';
    });

    function toggleCE() {
        var button = document.querySelector(".collapse-expand-button");
        var tip = document.querySelector(".tooltiptext");
        var allDetails = document.querySelectorAll(':not(.head) > details');

        Array.from(allDetails).forEach(function(detail, index) {
            if (button.classList.contains("expand")) {
                detail.open = true;
            } else {
                detail.removeAttribute('open');
            }
        });

        if (button.classList.contains("expand")) {
            button.classList.remove("expand");
            button.classList.add("collapse");
            tip.innerHTML = "Collapse all";
        } else {
            button.classList.remove("collapse");
            button.classList.add("expand");
            tip.innerHTML = "Expand all";
        }
    }

    // Prevent clicks on active parts of definition don't toggle details.
    document.addEventListener('DOMContentLoaded', function() {
        var targets = document.querySelectorAll('summary dfn,summary var');
        Array.from(targets).forEach(function(target) {
            target.addEventListener('click', function(e) {
                e.preventDefault();
            });
        });
    });
</script>

Introduction {#intro}
=====================

The Web Neural Network API defines a web-friendly hardware-agnostic abstraction layer that makes use of Machine Learning capabilities of operating systems and underlying hardware platforms without being tied to platform-specific capabilities. The abstraction layer addresses the requirements of key Machine Learning JavaScript frameworks and also allows web developers familiar with the ML domain to write custom code without the help of libraries.

For an illustrated introduction, please see the <a href="https://github.com/webmachinelearning/webnn/blob/master/explainer.md">explainer</a>.

Use cases {#usecases}
=====================

## Application Use Cases ## {#usecases-application}

This section illustrates application-level use cases for neural network
inference hardware acceleration. All applications in those use cases can be
built on top of pre-trained deep neural network (DNN) [[models]].

Note: Please be aware that some of the use cases described here, are by their very nature, privacy-invasive. Developers who are planning to use the API for such use cases <span class=allow-2119>should</span> ensure that the API is being used to benefit users, for purposes that users understand, and approve. They <span class=allow-2119>should</span> apply the Ethical Principles for Web Machine Learning [[webmachinelearning-ethics]] and implement appropriate privacy risk mitigations such as transparency, data minimisation, and users controls.

### Person Detection ### {#usecase-person-detection}

A user opens a web-based video conferencing application, but she temporarily
leaves from her room. The application is watching whether she is in front of her
PC by using object detection (for example, using object detection approaches
such as [[SSD]] or [[YOLO]] that use a single DNN) to detect regions in a camera
input frame that include persons.

When she comes back, the application automatically detects her and notifies
other online users that she is active now.

### Semantic Segmentation ### {#usecase-segmentation}

A user joins a teleconference via a web-based video conferencing application at
her desk since no meeting room in her office is available. During the
teleconference, she does not wish that her room and people in the background are
visible. To protect the privacy of the other people and the surroundings, the
application runs a machine learning model such as [[DeepLabv3+]], [[MaskR-CNN]]
or [[SegAny]] to semantically split an image into segments and replaces
segments that represent other people and background with another picture.

### Skeleton Detection ### {#usecase-skeleton-detection}

A web-based video conferencing application tracks a pose of user's skeleton by
running a machine learning model, which allows for real-time human pose
estimation, such as [[PoseNet]] to recognize her gesture and body language. When
she raises her hand, her microphone is automatically unmuted and she can start
speaking on the teleconference.

### Face Recognition ### {#usecase-face-recognition}

There are multiple people in the conference room and they join an online meeting
using a web-based video conferencing application. The application detects faces
of participants by using object detection (for example, using object detection
approaches such as [[SSD]]) and checks whether each face was present at the
previous meeting or not by running a machine learning model such as [[FaceNet]],
which verifies whether two faces would be identical or not.

### Facial Landmark Detection ### {#usecase-facial-landmarks}

A user wants to find new glasses that beautifully fits her on an online glasses
store. The online store offers web-based try-on simulator that runs a machine
learning model such as Face Alignment Network [[FAN]] to detect facial landmarks
like eyes, nose, mouth, etc. When she chooses a pair of glasses, the simulator
properly renders the selected glasses on the detected position of eyes on her
facial image.

### Style Transfer ### {#usecase-style-transfer}

A user is looking for cosmetics on an online store and wondering which color may
fit her face. The online store shows sample facial makeup images of cosmetics,
and offers makeup simulator that runs a machine learning model like
[[ContextualLoss]] or [[PairedCycleGAN]] to transfer the makeup style of the
sample makeup image to her facial image. She can check how the selected makeup
looks like on her face by the simulator.

### Super Resolution ### {#usecase-super-resolution}

A web-based video conferencing is receiving a video stream from its peer, but
the resolution of the video becomes lower due to network congestion. To prevent
degradation of the perceived video quality, the application runs a machine
learning model for super-resolution such as [[SRGAN]] to generate
higher-resolution video frames.

### Image Captioning ### {#usecase-image-captioning}

For better accessibility, a web-based presentation application provides
automatic image captioning by running a machine learning model such as
[[im2txt]] which predicts explanatory words of the presentation slides.

### Text-to-image ### {#usecase-text-to-image}

Images are a core part of modern web experiences. An ability to generate images
based on text input in a privacy-preserving manner enables visual
personalization and adaptation of web applications and content. For example, a web
application can use as an input a natural language description on the web page
or a description provided by the user within a text prompt to produce an
image matching the text description. This text-to-image use case enabled by
latent diffusion model architecture [[LDM]] forms the basis for additional
text-to-image use cases. For example, inpainting where a portion of an existing
image on the web page is selectively modified using the newly generated content,
or the converse, outpainting, where an original image is extended beyond its
original dimensions filling the empty space with generated content.

### Machine Translation ### {#usecase-translation}

Multiple people from various countries are talking via a web-based real-time
text chat application. The application translates their conversation by using a
machine learning model such as [[GNMT]] or [[OpenNMT]], which translates every
text into different language.

### Emotion Analysis ### {#usecase-emotion-analysis}

A user is talking to her friend via a web-based real-time text chat application,
and she is wondering how the friend feels because she cannot see the friend's
face. The application analyses the friend's emotion by using a machine learning
model such as [[DeepMoji]], which infers emotion from input texts, and displays
an emoji that represents the estimated emotion.

### Video Summarization ### {#usecase-video-summalization}

A web-based video conferencing application records received video streams, and
it needs to reduce recorded video data to be stored. The application generates
the short version of the recorded video by using a machine learning model for
video summarization such as [[Video-Summarization-with-LSTM]].

### Noise Suppression ### {#usecase-noise-suppression}

A web-based video conferencing application records received audio streams, but
usually the background noise is everywhere. The application leverages real-time
noise suppression using Recurrent Neural Network such as [[RNNoise]] for
suppressing background dynamic noise like baby cry or dog barking to improve
audio experiences in video conferences.

### Speech Recognition ### {#usecase-speech-recognition}

Speech recognition, also known as speech to text, enables recognition and
translation of spoken language into text. Example applications of speech
recognition include transcription, automatic translation, multimodal interaction,
real-time captioning and virtual assistants. Speech recognition improves
accessibility of auditory content and makes it possible to interact with such
content in a privacy-preserving manner in a textual form. Examples of common
use cases include watching videos or participating in online meetings using
real-time captioning. Models such as [[Whisper]] approach humans in their accuracy
and robustness and are well positioned to improve accessibility of such use cases.

### Text Generation ### {#usecase-text-generation}

Various text generation use cases are enabled by large language models (LLM) that
are able to perform tasks where a general ability to predict the next item
in a text sequence is required. This class of models can translate texts, answer
questions based on a text input, summarize a larger body of text, or generate
text output based on a textual input. LLMs enable better performance compared to
older models based on RNN, CNN, or LSTM architectures and further improve the
performance of many other use cases discussed in this section.
Examples of LLMs include [[t5-small]], [[m2m100_418M]], [[gpt2]], and [[llama-2-7b]].

### Detecting fake video ### {#usecase-detecting-fake-video}

A user is exposed to realistic fake videos generated by ‘deepfake’ on the web.
The fake video can swap the speaker’s face into the president’s face to incite
a user politically or to manipulate user’s opinion. The deepfake detection
applications such as [[FaceForensics++]] analyze the videos and protect a user against
the fake videos or images. When she watches a fake video on the web, the
detection application alerts her of the fraud video in real-time.

## Framework Use Cases ## {#usecases-framework}

This section collects framework-level use cases for a dedicated low-level API
for neural network inference hardware acceleration. It is expected that Machine
Learning frameworks will be key consumers of the Web Neural Network API (WebNN
API) and the low-level details exposed through the WebNN API are abstracted out
from typical web developers. However, it is also expected that web developers
with specific interest and competence in Machine Learning will want to interface
with the WebNN API directly instead of a higher-level ML framework.

### Custom Layer ### {#usecase-custom-layer}

A web application developer wants to run a DNN model on the WebNN API. However,
she has found that some of activation functions like [[LeakyReLU]], [[ELU]],
etc. are not included in the WebNN API. To address this issue, she constructs
custom layers of the additional activation functions on top of the WebNN API.
Note that the scope of custom layers may include convolution, normalization,
etc. as well as activation.

### Network Concatenation ### {#usecase-network-concat}

A web application uses a DNN model, and its model data of upper convolutional
layers and lower fully-connected layers are stored in separate files, since
model data of the fully-connected layers are periodically updated due to fine
tuning at the server side.

Therefore, the application downloads both partial model files at first and
concatenates them into a single model. When the model is updated, the
application downloads fine-tuned part of the model and replace only the
fully-connected layers with it.

### Performance Adaptation ### {#usecase-perf-adapt}

A web application developer has a concern about performance of her DNN model on
mobile devices. She has confirmed that it may run too slow on mobile devices
which do not have GPU acceleration. To address this issue, her web application
refers to the WebNN API to confirm whether acceleration is available or not, so
that the application can display the warning for devices without acceleration.

After several weeks, she has developed a tiny DNN model that can even run on
CPU. In order to accommodate CPU execution, she modifies the application
so that the application loads the tiny model in the case of CPU-only devices.

### Operation Level Execution ### {#usecase-op-level-exec}

A JavaScript ML framework is responsible for loading, interpreting and executing a ML model. During the model execution phase, the framework iterates through the operations of the model and executes each operation on the hardware device, like CPU, GPU or ML accelerator. To avoid the unnecessary data copying across devices, the framework selects the same device to execute the operations. For a compute intensive operation, such as convolution 2D or matrix multiplication, the framework uses WebNN API to execute it with the ML-specific acceleration available on that selected device.

### Integration with real-time video processing ### {#usecase-real-time-video-processing}

The user experience of WebRTC-based video conferencing is enhanced using real-time video processing. For example, background blur implemented using a [[#usecase-segmentation]] model blurs the background in the user's live camera feed. To satisfy the performance requirements of this use case, the WebNN API integrates with primitives from other Web APIs that make up the media pipeline to allow WebNN API-based transformation of real-time video streams.

Security Considerations {#security}
===================================
This specification defines a low-level API for neural network inference hardware acceleration. This API is considered a powerful feature [[POWERFUL-FEATURES]] because it grants low-level access to a user's computer. To meet the authentication and confidentiality expectations of a powerful feature and to prevent man-in-the-middle attacks, all interfaces defined by this specification are only available in a secure context.

This API is disabled by default in all cross-origin frames using the [[#permissions-policy-integration]]. This prevents third-party content from using this API unless the embedding page explicitly sets a policy that grants permission.

This API allows creation of an {{MLContext}} from a {{GPUDevice}} defined by WebGPU specification. See <a href="https://gpuweb.github.io/gpuweb/#security-considerations">WebGPU Security Considerations</a> for more information regarding security characteristics of this context.

This API provides an abstraction across GPU, CPU, and dedicated ML accelerator hardware. When using a GPU, <a href="https://www.w3.org/TR/webgpu/#security-dos">denial of service</a> considerations similar to WebGPU apply. When using a CPU or a dedicated ML accelerator, the types of potential resource contention are different and mitigations will be implementation and configuration dependent. Implementations should use whatever mechanisms are available from the platform to prevent sites from using an unfair amount of system resources. These compute units are shared resources, and the use of any compute API will affect overall performance on a fully-loaded system.

Once the graph is fully constructed and compiled, the input shapes into each of the operations in the graph are inferred and finalized. The bounds checking occurs when the compute method is invoked that executes the graph against the actual data. No actual data is bound to the compiled graph before this stage. It is the implementation's responsibility to make sure proper bounds checking occurs against the shapes of the data already inferred by that time.

Issue: Document operations susceptible to out-of-bounds access as a guidance to implementers.

Implementations must defend against control-flow attacks based on changes to data considered to be constant. For example, optimizations in the underlying platform may assume that a weight remains unchanged throughout a computation. If the API allowed the contents of buffers holding weights to change during a computation then those optimization assumptions would be invalidated, causing undefined behavior in the underlying platform. The API mitigates this category of attacks from script by always copying or transferring buffers, but implementations should consider additional defenses such as process isolation of data assumed to be constant.

As a future-proofing measure, the API design allows certain operations that can be generically emulated to be deprecated for security, performance, or other reasons without breaking compatibility. This is made possible by high-level functions that are defined in terms of smaller primitive operations defined in this specifications. This enables a native implementation of a high-level function to be replaced with a polyfill implementation.

Issue: Investigate side channel attack feasibility considering the current state where CPU is shared between processes running renderers.

In order to not allow an attacker to target a specific implementation that may contain a flaw, the [[#programming-model-device-selection]] mechanism is a hint only, and the concrete device selection is left to the implementation - a user agent could for instance choose never to run a model on a device with known vulnerabilities. As a further mitigation, no device enumeration mechanism is defined.

Issue: Hinting partially mitigates the concern. Investigate additional mitigations.

The API design minimizes the attack surface for the compiled computational graph. The {{MLGraphBuilder}} interface that hosts the various operations is a data definition API and as such doesn't execute anything, only constructs data. What follows, is that the potential for an attack is limited to when binding the data to the graph before executing it by invoking the {{MLContext}}.{{MLContext/dispatch()}} method. This enables implementers to focus on hardening the {{MLContext}}.{{MLContext/dispatch()}} method. For example, by making sure it honors the boundary of data and fails appropriately when the bounds are not respected.

Purpose-built Web APIs for measuring high-resolution time mitigate against timing attacks using techniques such as resolution reduction, adding jitter, detection of abuse and API call throttling [[hr-time-3]]. The practical deployment of WebNN implementations are likely to bring enough jitter to make timing attacks impractical (e.g. because they would use IPC) but implementers are advised to consider and test their implementations against timing attacks.

## Guidelines for new operations ## {#security-new-ops}

*This section is non-normative.*

<div class=informative>

To ensure operations defined in this specification are shaped in a way they can be implemented securely, this section includes guidelines on how operations are expected to be defined to reduce potential for implementation problems. These guidelines are expected to evolve over time to align with industry best practices:

- Prefer simplicity of arguments
- Don't use parsers for complex data formats
- If an operation can be decomposed to low level primitives:
    - Add an informative emulation path
    - Prefer primitives over new high level operations but consider performance consequences
- Follow a consistent style for operation inputs and attributes
- Share API shape and options for operation families such as pooling and reduction
- Formalize failure cases into test cases whenever possible
- When in doubt, leave it out: keep the API surface as small as possible to satisfy the use cases, but no smaller
- Try to keep the API free of implementation details that might inhibit future evolution, do not overspecify
- Fail fast: the sooner the web developer is informed of an issue, the better

In general, always consider the security and privacy implications as documented in [[security-privacy-questionnaire]] by the Technical Architecture Group and the Privacy Interest Group when adding new features.

</div>

Privacy Considerations {#privacy}
===================================

This API enhances privacy compared to cloud-based inference, since input data such as locally sourced images or video streams stay within the browser's sandbox.

This API exposes the minimum amount of information necessary to address the identified [[#usecases]] for the best performance and reliability of results.

No information from the underlying platform is exposed directly. An execution time analysis may reveal indirectly the performance of the underlying platform's neural network hardware acceleration capabilities relative to another underlying platform.

Note: The group is <a href="https://github.com/webmachinelearning/webnn/issues/85">soliciting further input</a> on the proposed execution time analysis fingerprinting vector and will augment this section with more information and mitigations to inform the implementers of this API.

Unlike WebGPU, this API does not intrinsically support custom shader authoring; and as a result is not prone to timing attacks that rely on shader caches, or other persistent data. The API builds upon pre-existing shaders and lower level primitives of the browser or the underlying OS. Web developers who interface with {{GPUDevice}} are expected to be aware of <a href="https://gpuweb.github.io/gpuweb/#privacy-user-agent-state">WebGPU compilation cache considerations</a>.

The WebGPU API identifies <a href="https://gpuweb.github.io/gpuweb/#privacy-machine-artifacts">machine-specific artifacts</a> as a privacy consideration. Similarly, the WebNN API's compute unit scheduling may under certain circumstances introduce a fingerprint. However, similarly to WebGPU, such fingerprints are identical across most or all of the devices of each vendor, mitigating the concern. Furthermore, software implementations can be used to further eliminate such artifacts.

The WebNN API defines developer-settable preferences to help inform [[#programming-model-device-selection]] and allow the implementation to better select the underlying execution device for the workload. An {{MLPowerPreference}} indicates preference as related to the desired low power consumption or high performance, is considered a hint only and as such does not increase entropy of the fingerprint.

Issue(623): {{MLContextOptions}} is under active development, and the design is expected to change, informed by further implementation experience and new use cases from the wider web community.

If a future version of this specification introduces support for a new {{MLContextOptions}} member for supporting only a subset of {{MLOperandDataType}}s, that could introduce a new fingerprint.

In general, implementers of this API are expected to apply <a href="https://gpuweb.github.io/gpuweb/#privacy-considerations">WebGPU Privacy Considerations</a> to their implementations where applicable.


Ethical Considerations {#ethics}
===================================

The Working Group has started documenting ethical issues associated with using Machine Learning on the Web, to help identify what mitigations its normative specifications should take into account. The Working Group publishes and maintains an Ethical Principles for Web Machine Learning document [[webmachinelearning-ethics]] open to contributions from the wider community via a dedicated <a href="https://github.com/webmachinelearning/webmachinelearning-ethics">GitHub repository</a>.

# Programming Model # {#programming-model}
## Overview ## {#programming-model-overview}

At the heart of neural networks is a <dfn>computational graph</dfn> of mathematical operations.
These operations are the building blocks of modern machine learning technologies in
computer vision, natural language processing, and robotics.
The WebNN API is a specification for constructing, compiling, and executing computational
graphs of neural networks.

The {{MLGraph}} interface represents a compiled computational graph that is immutable (that is, a model).

The {{MLGraphBuilder}} interface serves as a builder (factory) to construct a [=computational graph=] (its <dfn for=MLGraphBuilder>graph</dfn>) that is then compiled to create an {{MLGraph}}.

In WebNN, a [=computational graph=] is composed of <dfn>operators</dfn> which act on data, and are the nodes of the graph. {{MLOperand}}s are a representation of data that flows within the computational graph, and are the edges of the graph. {{MLOperand}}s include a [=computational graph=]'s <dfn for="computational graph">input</dfn> values for inference, <dfn for="computational graph">constants</dfn> (including trained weights) used for inference, intermediate values (often referred to as activations) computed during inference, as well as the output values of inference. An [=operator=]'s <dfn for=operator>input</dfn> is one or more {{MLOperand}}s. An [=operator=]'s <dfn for=operator>output</dfn> is one or more {{MLOperand}}s. [=Operators=] have operator-specific parameters that control their behavior, which can include zero or more <dfn for=operator lt="activation|activation function">activation functions</dfn>.

A key part of the {{MLGraphBuilder}} interface are methods such as {{MLGraphBuilder/gemm()}} and {{MLGraphBuilder/relu()}} which create an [=operator=] which represents the actual operation to perform on the input data when the computation is run, and return a new {{MLOperand}} holding the operator. Methods that create an {{MLOperand}} connect any [=operator/inputs=] and [=operator/activations=] to the operator. Each method invocation returns a distinct new value, without changing the value of any other {{MLOperand}}.

An [=operator=] has a <dfn for=operator>label</dfn>, a string which may be included in diagnostics such as [=exception=] messages. When an [=operator=] is created its [=operator/label=] is initialized in an [=implementation-defined=] manner and may include the passed {{MLOperatorOptions/label}}.

Note: Implementations are encouraged to use the {{MLOperatorOptions/label}} provided by developers to enhance error messages and improve debuggability, including both synchronous errors during graph construction and for errors that occur during the asynchronous {{MLGraphBuilder/build()}} method.

ISSUE(778): Consider adding a mechanism for reporting errors during {{MLContext/dispatch()}}.

At inference time, every {{MLOperand}} will be bound to a tensor (the actual data), which are essentially multidimensional arrays. The representation of the tensors is implementation dependent, but it typically includes the array data stored in some buffer (memory) and some metadata describing the array data (such as its shape).

Operations within the computational graph have functional semantics. This allows the implementation
to potentially share the array data between multiple tensors. For example, the implementation
of operations such as reshape, or slice may return a view of its input tensor
that shares the same buffer as the input tensor. (In the case of reshape,
the entire data is shared, while in the case of slice, a part of the input data is shared.)
The implementation may use views, as above, for intermediate values.

Before the execution, the computation graph that is used to compute one or more specified outputs needs to be converted, compiled, and optimized. The key purpose of the compilation step is to enable optimizations that span two or more operations, such as operation or loop fusion. The user agent may also perform these optimizations during graph conversion.

The {{MLGraphBuilder}}.{{MLGraphBuilder/build()}} method compiles the graph in the background without blocking the calling thread, and returns a {{Promise}} that resolves to an {{MLGraph}}. Each {{MLGraphBuilder}} can build at most one {{MLGraph}}.

The {{MLGraph}} underlying implementation will be composed of platform-specific representations of operators and operands which correspond to the {{MLGraphBuilder}}'s [=operators=] and {{MLOperand}}s, but which are not script-visible and may be compositions or decompositions of the graph as constructed by script.

Once the {{MLGraph}} is constructed, the {{MLContext}}.{{MLContext/dispatch()}} method performs the execution of the graph asynchronously either on a parallel timeline in a separate worker thread for the CPU execution or on a GPU timeline in a GPU command queue. This method returns immediately without blocking the calling thread while the actual execution is offloaded to a different timeline. The caller supplies the input values using {{MLNamedTensors}}, binding the input {{MLOperand}}s to their values. The caller also supplies {{MLNamedTensors}} for output {{MLOperand}}s which will contain the result of graph execution, if successful, which may be read back to script using the {{MLContext}}.{{MLContext/readTensor(tensor)}} method. This type of execution supports CPU, GPU, and NPU devices.

## Device Selection ## {#programming-model-device-selection}

An {{MLContext}} interface represents a global state of neural network execution. One of the important context states is the underlying execution device that manages the resources and facilitates the compilation and the eventual execution of the neural network graph. In addition to the default method of creation with {{MLContextOptions}}, an {{MLContext}} could also be created from a specific {{GPUDevice}} that is already in use by the application.

In a situation when a GPU context executes a graph with a constant or an input in the system memory as an {{ArrayBufferView}}, the input content is automatically uploaded from the system memory to the GPU memory, and downloaded back to the system memory of an {{ArrayBufferView}} output buffer at the end of the graph execution. This data upload and download cycles will only occur whenever the execution device requires the data to be copied out of and back into the system memory, such as in the case of the GPU. It doesn't occur when the device is a CPU device. Additionally, the result of the graph execution is in a known layout format. While the execution may be optimized for a native memory access pattern in an intermediate result within the graph, the output of the last operation of the graph must convert the content back to a known layout format at the end of the graph in order to maintain the expected behavior from the caller's perspective.

<div class="note">
When an {{MLContext}} is created with {{MLContextOptions}}, the user agent selects and creates the underlying execution device by taking into account these options, currently only the {{MLPowerPreference}} option.

Depending on the underlying platform, the user agent <span class=allow-2119>may</span> select different combinations of CPU, NPU and GPU devices.
</div>

For a history and rationale of this design, please see the <a href="https://github.com/webmachinelearning/webnn/blob/master/device-selection-explainer.md">device selection explainer</a>.

## Task Source ## {#programming-model-task-source}

The <dfn>ML task source</dfn> is a [=task source=] to be used for all [=tasks=] related to asynchronous compilation and execution of {{MLGraph}}s and creation of {{MLContext}}s.

<div algorithm>
<p>To <dfn>queue an ML task</dfn> given a [=global object=] |global| and a series of steps |steps|, [=queue a global task=] on the [=ML task source=] with |global| and |steps|.
</div>

## Permissions Policy Integration ## {#permissions-policy-integration}

This specification defines a [=policy-controlled feature=] identified by the
string "<code><dfn data-lt="webnn-feature">webnn</dfn></code>".
Its [=policy-controlled feature/default allowlist=] is <code>'self'</code>.


API {#api}
=====================

## The navigator.ml interface ## {#api-navigator-ml}

An {{ML}} object is available in the {{Window}} and {{WorkerGlobalScope}} contexts through the {{Navigator}}
and {{WorkerNavigator}} interfaces respectively and is exposed via `navigator.ml`.

<script type=idl>
interface mixin NavigatorML {
  [SecureContext, SameObject] readonly attribute ML ml;
};
Navigator includes NavigatorML;
WorkerNavigator includes NavigatorML;
</script>

## {{ML}} interface ## {#api-ml}
<script type=idl>
enum MLPowerPreference {
  "default",
  "high-performance",
  "low-power"
};

dictionary MLContextOptions {
  MLPowerPreference powerPreference = "default";
};

[SecureContext, Exposed=(Window, Worker)]
interface ML {
  Promise<MLContext> createContext(optional MLContextOptions options = {});
  Promise<MLContext> createContext(GPUDevice gpuDevice);
};
</script>

### {{MLContextOptions}} ### {#api-mlcontextoptions}

Issue(623): {{MLContextOptions}} is under active development, and the design is expected to change, informed by further implementation experience and new use cases from the wider web community. The Working Group is considering additional API controls to allow the definition of a fallback device, multiple devices in a preferred order, or an exclusion of a specific device. Other considerations under discussion include error handling, ultimate fallback, and quantized operators. Feedback is welcome on any of these design considerations from web developers, library authors, OS and hardware vendors, and other stakeholders via GitHub:

The <dfn dfn-for=MLContextOptions dfn-type=dict-member>powerPreference</dfn> option is an <dfn dfn-type=enum>MLPowerPreference</dfn> and indicates the application's preference as related to power consumption. It is one of the following:
<dl dfn-for="MLPowerPreference">
<dt>"<dfn enum-value>default</dfn>"</dt>
<dd>Let the user agent select the most suitable behavior.</dd>
<dt>"<dfn enum-value>high-performance</dfn>"</dt>
<dd>Prioritizes execution speed over power consumption.</dd>
<dt>"<dfn enum-value>low-power</dfn>"</dt>
<dd>Prioritizes power consumption over other considerations such as execution speed.</dd>
</dl>

### {{ML/createContext()}} ### {#api-ml-createcontext}

<div dfn-for="ML/createContext(options), ML/createContext(gpuDevice)" dfn-type=argument>
    **Arguments:**
        - <dfn>options</dfn>: an {{MLContextOptions}}. Provides the application's preferences for the context.
        - <dfn>gpuDevice</dfn>: a {{GPUDevice}}. A specific device to use with the context.
    **Returns:** an {{MLContext}}.
</div>

<details open algorithm>
<summary>
    To <dfn>create a context</dfn> given [=realm=] |realm| and |options| (a {{GPUDevice}} or {{MLContextOptions}}), run these steps:
</summary>
    1. Let |context| be a new {{MLContext}} in |realm|.
    1. If |options| is a {{GPUDevice}} object:
        1. Set |context|.{{MLContext/[[contextType]]}} to "[=context type/webgpu=]".
        1. Set |context|.{{MLContext/[[powerPreference]]}} to {{MLPowerPreference/"default"}}.
    1. Otherwise:
        1. Set |context|.{{MLContext/[[contextType]]}} to "[=context type/default=]".
        1. Set |context|.{{MLContext/[[lost]]}} to [=a new promise=] in |realm|.
        1. If |options|["{{MLContextOptions/powerPreference}}"] [=map/exists=], then set |context|.{{MLContext/[[powerPreference]]}} to |options|["{{MLContextOptions/powerPreference}}"].
        1. Otherwise, set |context|.{{MLContext/[[powerPreference]]}} to {{MLPowerPreference/"default"}}.
    1. If the user agent cannot support |context|.{{MLContext/[[contextType]]}}, return failure.
    1. Return |context|.
</details>

<details open algorithm>
<summary>
    The <dfn method for=ML>createContext(|options|)</dfn> steps are:
</summary>
    1. Let |global| be [=this=]'s [=relevant global object=].
    1. Let |realm| be [=this=]'s [=relevant realm=].
    1. If |global|'s [=associated Document=] is not [=allowed to use=] the [=webnn-feature|webnn=] feature, return [=a new promise=] in |realm| [=rejected=] with a "{{SecurityError}}" {{DOMException}}.
    1. Let |promise| be [=a new promise=] in |realm|.
    1. Run the following steps [=in parallel=].
        1. Let |context| be the result of [=creating a context=] given |realm| and |options|. If that returns failure, then [=queue an ML task=] with |global| to [=reject=] |promise| with a "{{NotSupportedError}}" {{DOMException}} and abort these steps.
        1. [=Queue an ML task=] with |global| to [=resolve=] |promise| with |context|.
    1. Return |promise|.
</details>

<details open algorithm>
<summary>
    The <dfn method for=ML>createContext(|gpuDevice|)</dfn> method steps are:
</summary>
    1. Let |global| be [=this=]'s [=relevant global object=].
    1. Let |realm| be [=this=]'s [=relevant realm=].
    1. If |global|'s [=associated Document=] is not [=allowed to use=] the [=webnn-feature|webnn=] feature, return [=a new promise=] in |realm| [=rejected=] with a "{{SecurityError}}" {{DOMException}}.
    1. Let |promise| be [=a new promise=] in |realm|.
    1. Run the following steps [=in parallel=].
        1. Let |context| be the result of [=creating a context=] given |realm| and |gpuDevice|. If that returns failure, then [=queue an ML task=] with |global| to [=reject=] |promise| with a "{{NotSupportedError}}" {{DOMException}} and abort these steps.
        1. [=Queue an ML task=] with |global| to [=resolve=] |promise| with |context|.
    1. Return |promise|.
</details>

## {{MLContext}} interface ## {#api-mlcontext}
The {{MLContext}} interface represents a global state of neural network compute workload and execution processes. Each {{MLContext}} object has associated [=context type=] and {{MLPowerPreference}}.

<script type=idl>
typedef record<USVString, MLTensor> MLNamedTensors;

dictionary MLContextLostInfo {
  DOMString message;
};

[SecureContext, Exposed=(Window, Worker)]
interface MLContext {
  undefined dispatch(MLGraph graph, MLNamedTensors inputs, MLNamedTensors outputs);

  Promise<MLTensor> createTensor(MLTensorDescriptor descriptor);

  Promise<ArrayBuffer> readTensor(MLTensor tensor);
  Promise<undefined> readTensor(MLTensor tensor, AllowSharedBufferSource outputData);

  undefined writeTensor(MLTensor tensor, AllowSharedBufferSource inputData);

  MLOpSupportLimits opSupportLimits();

  undefined destroy();

  readonly attribute Promise<MLContextLostInfo> lost;
};
</script>

<div class=internal-slots>
{{MLContext}} has the following internal slots:
  <dl dfn-type=attribute dfn-for="MLContext">
    : <dfn>\[[contextType]]</dfn> of type [=context type=].
    ::
        The {{MLContext}}'s [=context type=].
    : <dfn>\[[powerPreference]]</dfn> of type {{MLPowerPreference}}.
    ::
        The {{MLContext}}'s {{MLPowerPreference}}.
    : <dfn>\[[lost]]</dfn> of type {{Promise}}<{{MLContextLostInfo}}>.
    ::
        A {{Promise}} that is resolved when the {{MLContext}}'s underlying execution device is no longer available.
    : <dfn>\[[timeline]]</dfn>
    ::
        A timeline associated with the execution of operations on the compute units of the {{MLContext}}. These operations include inferencing on [=computational graphs=] and modifying the {{MLTensor/[[data]]}} of {{MLTensor}}s.

        Issue(529): More rigorously define this timeline.
  </dl>
</div>

The <dfn>context type</dfn> is the type of the execution context that manages the resources and facilitates the compilation and execution of the neural network graph:
<dl dfn-for="context type">
<dt>"<dfn>default</dfn>"</dt>
<dd>Context created per user preference options.</dd>
<dt>"<dfn>webgpu</dfn>"</dt>
<dd>Context created from WebGPU device.</dd>
</dl>

<details open algorithm>
  <summary>
    To <dfn>validate buffer with descriptor</dfn> given {{AllowSharedBufferSource}} |bufferSource| and {{MLOperandDescriptor}} |descriptor|, run the following steps:
  </summary>
    1. If |bufferSource|'s [=BufferSource/byte length=] is not equal to |descriptor|'s [=MLOperandDescriptor/byte length=] return false.
    1. Switch on the type of |bufferSource|:
        <dl class=switch>
            : {{ArrayBuffer}}
            :: Return true.
            : {{SharedArrayBuffer}}
            :: Return true.
            : {{ArrayBufferView}}
            ::
                1. If |bufferSource| is a {{Uint8Array}} object, then return true.
                1. If |bufferSource| matches |descriptor|'s {{MLOperandDescriptor/dataType}} according to [this table](#appendices-mloperanddatatype-arraybufferview-compatibility), then return true.
                1. Return false.
        </dl>

    Note: Using {{Uint8Array}} regardless of the |descriptor|'s {{MLOperandDescriptor/dataType}} is supported as a generic way of representing a slice of an {{ArrayBuffer}}, for example part of a {{WebAssembly}}.{{Memory}} instance. Developers are encouraged to use more specific view types when authoring WebNN code for readability and maintainability.

</details>

<details open algorithm>
  <summary>
    To <dfn>validate tensors with descriptors</dfn> given an {{MLNamedTensors}} |namedTensors| with [=record=]&lt;{{USVString}}, {{MLOperandDescriptor}}&gt; |namedDescriptors|:
  </summary>
    1. If |namedTensors|'s [=map/size=] is not equal to |namedDescriptors|'s [=map/size=], then return false.
    1. [=map/For each=] |name| → |tensor| of |namedTensors|:
        1. If |namedDescriptors|[|name|] does not [=map/exist=], then return false.
        1. If |tensor|.{{MLTensor/[[descriptor]]}} is not [=MLOperandDescriptor/equal=] to |namedDescriptors|[|name|], then return false.
    1. Return true.
</details>

### {{MLContext/dispatch()}}  ### {#api-mlcontext-dispatch}

Schedules the computational workload of a compiled {{MLGraph}} on the {{MLContext}}'s {{MLContext/[[timeline]]}}.

<div dfn-for="MLContext/dispatch(graph, inputs, outputs)" dfn-type=argument>
    **Arguments:**
      - <dfn>graph</dfn>: an {{MLGraph}}. The computational graph to be executed.
      - <dfn>inputs</dfn>: an {{MLNamedTensors}}. The inputs to the computational graph.
      - <dfn>outputs</dfn>: an {{MLNamedTensors}}. The outputs of the computational graph.

    **Returns:** {{undefined}}.
</div>

Note: `dispatch()` itself provides no signal that graph execution has completed. Rather, callers can `await` the results of reading back the output tensors. See [[#api-mlcontext-dispatch-examples]] below.

<details open algorithm>
  <summary>
    The <dfn method for=MLContext>dispatch(|graph|, |inputs|, |outputs|)</dfn> method steps are:
  </summary>
    1. If |graph|.{{MLGraph/[[context]]}} is not [=this=], then [=exception/throw=] a {{TypeError}}.
    1. If |graph|.{{MLGraph/[[isDestroyed]]}} is true, then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. Let |allTensors| be a [=/list=] of {{MLTensor}}s consisting of |inputs|'s [=map/values=] [=list/extended=] by |outputs|'s [=map/values=].
    1. If |allTensors| contains any duplicate [=list/items=], then [=exception/throw=] a {{TypeError}}.
    1. [=list/For each=] |tensor| of |allTensors|:
        1. If |tensor|.{{MLTensor/[[context]]}} is not [=this=], then [=exception/throw=] a {{TypeError}}.
        1. If |tensor|.{{MLTensor/[[isDestroyed]]}} is true, then [=exception/throw=] a {{TypeError}}.
    1. If [=validating tensors with descriptors=] given |inputs| and |graph|.{{MLGraph/[[inputDescriptors]]}} returns false, then [=exception/throw=] a {{TypeError}}.
    1. If [=validating tensors with descriptors=] given |outputs| and |graph|.{{MLGraph/[[outputDescriptors]]}} returns false, then [=exception/throw=] a {{TypeError}}.
    1. Enqueue the following steps to |graph|.{{MLGraph/[[context]]}}.{{MLContext/[[timeline]]}}:
        1. Run these steps, but [=/abort when=] [=this=] [=MLContext/is lost=]:
            1. Issue a compute request to |graph|.{{MLGraph/[[implementation]]}} given |inputs| and |outputs|.

                Issue(778): Add a mechanism for reporting errors during graph execution.

    1. Return {{undefined}}.
</details>

#### Examples #### {#api-mlcontext-dispatch-examples}
<div class="example">
<details open>
  <summary>
    The following code showcases executing an {{MLGraph}} using {{MLTensor}}s.
  </summary>
  <pre highlight="js">
    const descriptor = {dataType: 'float32', shape: [2, 2]};
    const context = await navigator.ml.createContext();
    const builder = new MLGraphBuilder(context);

    // 1. Create a computational graph 'C = 0.2 * A + B'.
    const constant = builder.constant(descriptor, new Float32Array(4).fill(0.2));
    const A = builder.input('A', descriptor);
    const B = builder.input('B', descriptor);
    const C = builder.add(builder.mul(A, constant), B);

    // 2. Compile the graph.
    const graph = await builder.build({'C': C});

    // 3. Create reusable input and output tensors.
    const [inputTensorA, inputTensorB, outputTensorC] =
        await Promise.all([
          context.createTensor({
            dataType: A.dataType, shape: A.shape, writable: true
          }),
          context.createTensor({
            dataType: B.dataType, shape: B.shape, writable: true
          }),
          context.createTensor({
            dataType: C.dataType, shape: C.shape, readable: true
          })
        ]);

    // 4. Initialize the inputs.
    context.writeTensor(inputTensorA, new Float32Array(4).fill(1.0));
    context.writeTensor(inputTensorB, new Float32Array(4).fill(0.8));

    // 5. Execute the graph.
    const inputs = {
      'A': inputTensorA,
      'B': inputTensorB
    };
    const outputs = {
      'C': outputTensorC
    };
    context.dispatch(graph, inputs, outputs);

    // 6. Read back the computed result.
    const result = await context.readTensor(outputTensorC);
    console.log('Output value:', new Float32Array(result));  // [1, 1, 1, 1]
  </pre>
</details>
</div>

### {{MLContext/createTensor()}}  ### {#api-mlcontext-createtensor}

Creates an {{MLTensor}} associated with this {{MLContext}}.

<div dfn-for="MLContext/createTensor(descriptor)" dfn-type=argument>
    **Arguments:**
      - <dfn>descriptor</dfn>: an {{MLTensorDescriptor}}.

    **Returns:** {{Promise}}<{{MLTensor}}>.
</div>

<details open algorithm>
  <summary>
    The <dfn method for=MLContext>createTensor(|descriptor|)</dfn> method steps are:
  </summary>
    1. Let |global| be [=this=]'s [=relevant global object=].
    1. Let |realm| be [=this=]'s [=relevant realm=].
    1. If [=this=] [=MLContext/is lost=], then return [=a new promise=] in |realm| [=rejected=] with an "{{InvalidStateError}}" {{DOMException}}.
    1. Let |tensor| be the result of [=creating an MLTensor=] given [=this=], and |descriptor|.
    1. Let |promise| be [=a new promise=] in |realm|.
    1. Enqueue the following steps to [=this=].{{MLContext/[[timeline]]}}:
        1. Run these steps, but [=/abort when=] [=this=] [=MLContext/is lost=]:
            1. Create |tensor|.{{MLTensor/[[data]]}} given |descriptor| and initialize all bytes to zeros.
            1. If that fails, then [=queue an ML task=] with |global| to [=reject=] |promise| with an "{{UnknownError}}" {{DOMException}}, and abort these steps.
            1. Otherwise, [=queue an ML task=] with |global| to [=resolve=] |promise| with |tensor|.
        1. [=/If aborted=], then [=queue an ML task=] with |global| to [=reject=] |promise| with an "{{InvalidStateError}}" {{DOMException}}.
    1. Return |promise|.
</details>

### {{MLContext/readTensor(tensor)}}  ### {#api-mlcontext-readtensor}

Reads back the {{MLTensor/[[data]]}} of an {{MLTensor}} from the {{MLContext}}.{{MLContext/[[timeline]]}} to script.

<div dfn-for="MLContext/readTensor(tensor)" dfn-type=argument>
    **Arguments:**
      - <dfn>tensor</dfn>: an {{MLTensor}}. The tensor to be read.

    **Returns:** {{Promise}}<{{ArrayBuffer}}>. A buffer containing the result of the read.
</div>

<details open algorithm>
  <summary>
    The <dfn method for=MLContext>readTensor(|tensor|)</dfn> method steps are:
  </summary>
    1. Let |global| be [=this=]'s [=relevant global object=].
    1. Let |realm| be [=this=]'s [=relevant realm=].
    1. If |tensor|.{{MLTensor/[[context]]}} is not [=this=], then return [=a new promise=] in |realm| [=rejected=] with a {{TypeError}}.
    1. If |tensor|.{{MLTensor/[[isDestroyed]]}} is true, then return [=a new promise=] in |realm| [=rejected=] with a {{TypeError}}.
    1. If |tensor|.{{MLTensor/[[descriptor]]}}.{{MLTensorDescriptor/readable}} is false, then return [=a new promise=] in |realm| [=rejected=] with a {{TypeError}}.
    1. Let |promise| be [=a new promise=] in |realm|.
    1. [=set/Append=] |promise| to |tensor|.{{MLTensor/[[pendingPromises]]}}.
    1. Enqueue the following steps to |tensor|.{{MLTensor/[[context]]}}.{{MLContext/[[timeline]]}}:
        1. Run these steps, but [=/abort when=] [=this=] [=MLContext/is lost=]:
            1. Let |bytes| be a [=/byte sequence=] containing a copy of |tensor|.{{MLTensor/[[data]]}}.
            1. If that fails, then [=queue an ML task=] with |global| and the following steps:
                1. [=set/Remove=] |promise| from |tensor|.{{MLTensor/[[pendingPromises]]}}.
                1. [=Reject=] |promise| with an "{{UnknownError}}" {{DOMException}}, and abort these steps.
            1. Otherwise, [=queue an ML task=] with |global| and the following steps:
                1. [=set/Remove=] |promise| from |tensor|.{{MLTensor/[[pendingPromises]]}}.
                1. Let |buffer| be the result of [=ArrayBuffer/creating=] an {{ArrayBuffer}} from |bytes| in |realm|.
                1. [=Resolve=] |promise| with |buffer|.
        1. [=/If aborted=], then [=queue an ML task=] with |global| to [=reject=] |promise| with an "{{InvalidStateError}}" {{DOMException}}.
    1. Return |promise|.
</details>

### {{MLContext/readTensor(tensor, outputData)}}  ### {#api-mlcontext-readtensor-byob}

Bring-your-own-buffer variant of {{MLContext/readTensor(tensor)}}. Reads back the {{MLTensor/[[data]]}} of an {{MLTensor}} into the provided buffer.

<div dfn-for="MLContext/readTensor(tensor, outputData)" dfn-type=argument>
    **Arguments:**
      - <dfn>tensor</dfn>: an {{MLTensor}}. The tensor to be read.
      - <dfn>outputData</dfn>: an {{AllowSharedBufferSource}}. The buffer to read the result into.

    **Returns:** {{Promise}}<{{undefined}}>.
</div>

<details open algorithm>
  <summary>
    The <dfn method for=MLContext>readTensor(|tensor|, |outputData|)</dfn> method steps are:
  </summary>
    1. Let |global| be [=this=]'s [=relevant global object=].
    1. Let |realm| be [=this=]'s [=relevant realm=].
    1. If |tensor|.{{MLTensor/[[context]]}} is not [=this=], then return [=a new promise=] in |realm| [=rejected=] with a {{TypeError}}.
    1. If |tensor|.{{MLTensor/[[isDestroyed]]}} is true, then return [=a new promise=] in |realm| [=rejected=] with a {{TypeError}}.
    1. If |tensor|.{{MLTensor/[[descriptor]]}}.{{MLTensorDescriptor/readable}} is false, then return [=a new promise=] in |realm| [=rejected=] with a {{TypeError}}.
    1. If [=validating buffer with descriptor=] given |outputData| and |tensor|.{{MLTensor/[[descriptor]]}} returns false, then return [=a new promise=] in |realm| [=rejected=] with a {{TypeError}}.
    1. Let |promise| be [=a new promise=] in |realm|.
    1. [=set/Append=] |promise| to |tensor|.{{MLTensor/[[pendingPromises]]}}.
    1. Enqueue the following steps to |tensor|.{{MLTensor/[[context]]}}.{{MLContext/[[timeline]]}}:
        1. Run these steps, but [=/abort when=] [=this=] [=MLContext/is lost=]:
            1. Let |bytes| be a [=/byte sequence=] containing a copy of |tensor|.{{MLTensor/[[data]]}}.
            1. If that fails, then [=queue an ML task=] with |global| to run these steps:
                1. [=set/Remove=] |promise| from |tensor|.{{MLTensor/[[pendingPromises]]}}.
                1. [=Reject=] |promise| with an "{{UnknownError}}" {{DOMException}}, and abort these steps.
            1. Otherwise, [=queue an ML task=] with |global| to run these steps:
                1. [=set/Remove=] |promise| from |tensor|.{{MLTensor/[[pendingPromises]]}}.
                1. If |outputData| is [=BufferSource/detached=], [=reject=] |promise| with a {{TypeError}}, and abort these steps.

                    Note: [=Validating buffer with descriptor=] above will fail if |outputData| is detached, but it is possible that |outputData| could be detached between that step and this one.

                1. [=ArrayBuffer/Write=] |bytes| to |outputData|.
                1. [=Resolve=] |promise| with {{undefined}}.
        1. [=/If aborted=], then [=queue an ML task=] with |global| to [=reject=] |promise| with an "{{InvalidStateError}}" {{DOMException}}.
    1. Return |promise|.
</details>

### {{MLContext/writeTensor()}}  ### {#api-mlcontext-writetensor}

Writes data to the {{MLTensor/[[data]]}} of an {{MLTensor}} on the {{MLContext}}'s {{MLContext/[[timeline]]}}.

<div dfn-for="MLContext/writeTensor(tensor, inputData)" dfn-type=argument>
    **Arguments:**
      - <dfn>tensor</dfn>: an {{MLTensor}}. The tensor to be written to.
      - <dfn>inputData</dfn>: an {{AllowSharedBufferSource}}. The buffer whose bytes will be written into the tensor.

    **Returns:** {{undefined}}.
</div>

<details open algorithm>
  <summary>
    The <dfn method for=MLContext>writeTensor(|tensor|, |inputData|)</dfn> method steps are:
  </summary>
    1. If |tensor|.{{MLTensor/[[context]]}} is not [=this=], then [=exception/throw=] a {{TypeError}}.
    1. If |tensor|.{{MLTensor/[[isDestroyed]]}} is true, then [=exception/throw=] a {{TypeError}}.
    1. If |tensor|.{{MLTensor/[[descriptor]]}}.{{MLTensorDescriptor/writable}} is false, then [=exception/throw=] a {{TypeError}}.
    1. If [=validating buffer with descriptor=] given |inputData| and |tensor|.{{MLTensor/[[descriptor]]}} returns false, then [=exception/throw=] a {{TypeError}}.
    1. Let |bytes| be the result of [=getting a copy of the bytes held by the buffer source=] given |inputData|.
    1. [=Assert=]: |bytes|'s [=byte sequence/length=] is equal to |tensor|.{{MLTensor/[[descriptor]]}}'s [=MLOperandDescriptor/byte length=].
    1. Enqueue the following steps to |tensor|.{{MLTensor/[[context]]}}.{{MLContext/[[timeline]]}}:
        1. Run these steps, but [=/abort when=] [=this=] [=MLContext/is lost=]:
            1. Copy |bytes| to |tensor|.{{MLTensor/[[data]]}}.

                Issue(778): Add a mechanism for reporting errors while writing to a tensor.

    1. Return {{undefined}}.
</details>

Note: Similar to `dispatch()`, `writeTensor()` itself provides no signal that the write has completed. To inspect the contents of a tensor, callers can `await` the results of reading back the tensor.

### {{MLContext/opSupportLimits()}}  ### {#api-mlcontext-opsupportlimits}
The {{MLContext/opSupportLimits()}} exposes level of support that differs across implementations at operator level. Consumers of the WebNN API are encouraged to probe feature support level by using {{MLContext/opSupportLimits()}} to determine the optimal model architecture to be deployed for each target platform.

#### {{MLOpSupportLimits}} dictionary #### {#api-mlcontext-opsupportlimits-dictionary}
The {{MLOpSupportLimits}} has the following top level members, aside from these, each [=operator=] has a corresponding member defined in its builder method.
<script type="idl">
dictionary MLOpSupportLimits {
  MLInputOperandLayout preferredInputLayout;
  [EnforceRange] unsigned long long maxTensorByteLength;
  MLDataTypeLimits input;
  MLDataTypeLimits constant;
  MLDataTypeLimits output;
};
</script>

<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>preferredInputLayout</dfn>
    :: Preferred input layout for layout dependent operators like {{MLGraphBuilder/conv2d()}}.
    : <dfn>maxTensorByteLength</dfn>
    :: The maximum supported length of tensors, in bytes.
    : <dfn>input</dfn>
    :: Support limits for input {{MLOperand}}s for an {{MLGraph}}.
    : <dfn>constant</dfn>
    :: Support limits for constant {{MLOperand}}s for an {{MLGraph}}.
    : <dfn>output</dfn>
    :: Support limits for output {{MLOperand}}s for an {{MLGraph}}.
</dl>
#### {{MLDataTypeLimits}} dictionary #### {#api-mlcontext-datatypelimits-dictionary}
<script type="idl">
typedef sequence<MLOperandDataType> MLDataTypeList;

dictionary MLDataTypeLimits {
  MLDataTypeList dataTypes;
};
</script>
<dl dfn-type=dict-member dfn-for=MLDataTypeLimits>
    : <dfn>dataTypes</dfn>
    :: Supported data types.
</dl>

#### {{MLRankRange}} dictionary #### {#api-mlcontext-rankrange-dictionary}
<script type="idl">
dictionary MLRankRange {
  unsigned long min;
  unsigned long max;
};
</script>
<dl dfn-type=dict-member dfn-for=MLRankRange>
    : <dfn>min</dfn>
    :: Minimum supported rank.
    : <dfn>max</dfn>
    :: Maximum supported rank.
</dl>

#### {{MLTensorLimits}} dictionary #### {#api-mlcontext-tensorlimits-dictionary}
<script type="idl">
dictionary MLTensorLimits {
  MLDataTypeList dataTypes;
  MLRankRange rankRange;
};
</script>
<dl dfn-type=dict-member dfn-for=MLTensorLimits>
    : <dfn>dataTypes</dfn>
    :: Supported data types.
    : <dfn>rankRange</dfn>
    :: Minimum and maximum supported ranks.
</dl>

#### {{MLBinarySupportLimits}} dictionary #### {#api-mlcontext-binarysupportlimits-dictionary}
<script type="idl">
dictionary MLBinarySupportLimits {
  MLTensorLimits a;
  MLTensorLimits b;
  MLDataTypeLimits output;
};
</script>

<dl dfn-type=dict-member dfn-for=MLBinarySupportLimits>
    : <dfn>a</dfn>
    :: {{MLTensorLimits}} for a operand.
    : <dfn>b</dfn>
    :: {{MLTensorLimits}} for b operand.
    : <dfn>output</dfn>
    :: {{MLDataTypeLimits}} for output operand.
</dl>

#### {{MLSingleInputSupportLimits}} dictionary #### {#api-mlcontext-singleinputsupportlimits-dictionary}
<script type="idl">
dictionary MLSingleInputSupportLimits {
  MLTensorLimits input;
  MLDataTypeLimits output;
};
</script>

<dl dfn-type=dict-member dfn-for=MLSingleInputSupportLimits>
    : <dfn>input</dfn>
    :: {{MLTensorLimits}} for input operand.
    : <dfn>output</dfn>
    :: {{MLDataTypeLimits}} for output operand.
</dl>

### {{MLContext/destroy()}}  ### {#api-mlcontext-destroy}

The {{MLContext/destroy()}} method can be called to release all resources associated with the context. Any outstanding compute requests and {{MLTensor}} creation/read/write requests will fail.

<details open algorithm>
<summary>
    The <dfn method for=MLContext>destroy()</dfn> method steps are:
</summary>
    1. If [=this=] [=MLContext/is lost=], then abort these steps.
    1. Run the steps to [=MLContext/lose=] [=this=] with an [=/implementation-defined=] message.

        Note: A message indicating that `destroy()` was called can help developers distinguish the cause of the context loss.
</details>

### Errors ### {#api-mlcontext-errors}

When a user agent determines that an {{MLContext}} is no longer available to fulfill requests, it must run the [=context lost=] steps for it.

<details open algorithm>
<summary>
The <dfn>context lost</dfn> steps for {{MLContext}} |context|, are:
</summary>
    1. Let |global| be |context|'s [=relevant global object=].
    1. [=Queue an ML task=] with |global| to run these steps:
        1. [=MLContext/Lose=] |context|, with an [=/implementation-defined=] message.
</details>

<details open algorithm>
<summary>
To <dfn for=MLContext>lose</dfn> {{MLContext}} |context| with {{DOMString}} |message|:
</summary>
    1. Let |info| be a new {{MLContextLostInfo}}.
    1. Set |info|.{{MLContextLostInfo/message}} to |message|.
    1. [=Resolve=] |context|.{{MLContext/[[lost]]}} with |info|.
    1. For each {{MLGraph}} |graph| where |graph|.{{MLGraph/[[context]]}} equals [=this=]:
        1. Run the {{MLGraph/destroy()}} method steps for |graph| with |graph| as [=this=].
    1. For each {{MLTensor}} |tensor| where |tensor|.{{MLTensor/[[context]]}} equals [=this=]:
        1. Run the {{MLTensor/destroy()}} method steps for |tensor| with |tensor| as [=this=].
</details>

<dl dfn-type=dict-member dfn-for=MLContextLostInfo>
    : <dfn>message</dfn>
    :: An [=implementation-defined=] message providing information about the error that occurred.
</dl>

<div algorithm>
The <dfn attribute for=MLContext>lost</dfn> getter steps are to return [=this=]'s {{MLContext/[[lost]]}} {{Promise}}.
</div>

A {{MLContext}} <dfn for=MLContext lt="is lost|is not lost">is lost</dfn> if its {{MLContext/[[lost]]}} {{Promise}} is [=Promise/settled=].

## {{MLGraph}} interface ## {#api-mlgraph}
The {{MLGraph}} interface represents a compiled computational graph. A compiled graph once constructed is immutable and cannot be subsequently changed.

<script type=idl>
[SecureContext, Exposed=(Window, Worker)]
interface MLGraph {
  undefined destroy();
};
</script>

<div class=internal-slots>
{{MLGraph}} has the following internal slots:
  <dl dfn-type=attribute dfn-for="MLGraph">
    : <dfn>\[[context]]</dfn> of type {{MLContext}}
    ::
        The context of type {{MLContext}} associated with this {{MLGraph}}.

    : <dfn>\[[inputDescriptors]]</dfn> of type [=record=]&lt;{{USVString}}, {{MLOperandDescriptor}}&gt;
    ::
        Maps the name of an input {{MLOperand}} to its {{MLOperandDescriptor}} for all input {{MLOperand}}s of this {{MLGraph}}.

    : <dfn>\[[outputDescriptors]]</dfn> of type [=record=]&lt;{{USVString}}, {{MLOperandDescriptor}}&gt;
    ::
        Maps the name of an output {{MLOperand}} to its {{MLOperandDescriptor}} for all output {{MLOperand}}s of this {{MLGraph}}.

    : <dfn>\[[implementation]]</dfn>
    ::
        The underlying implementation provided by the User Agent.

    : <dfn>\[[isDestroyed]]</dfn> of type {{boolean}}
    ::
        Whether the {{MLGraph}}.{{MLGraph/destroy()}} method steps have been run. Once destroyed, the {{MLGraph}} can no longer be used.
  </dl>
</div>

### {{MLGraph/destroy()}}  ### {#api-mlgraph-destroy}

The {{MLGraph/destroy()}} method can be called to release all resources associated with the graph.

<details open algorithm>
<summary>
    The <dfn method for=MLGraph>destroy()</dfn> method steps are:
</summary>
    1. If [=this=].{{MLGraph/[[isDestroyed]]}} is true, then abort these steps.
    1. Set [=this=].{{MLGraph/[[isDestroyed]]}} to true.
    1. Queue a task on [=this=].{{MLGraph/[[context]]}}.{{MLContext/[[timeline]]}} to mark resources owned by this graph as freeable.

</details>

Note: Since no further workloads can be enqueued using this graph, implementations can free any additional resource allocations associated with this graph once all previously submitted workloads using it are complete.


## {{MLOperandDescriptor}} dictionary ## {#api-mloperanddescriptor}

An {{MLOperandDescriptor}} describes the shape (dimensions) and data type of an operand. They are used to describe the inputs and constants for an {{MLGraph}}, and every {{MLOperand}} has an internal {{MLOperandDescriptor}}.

<script type=idl>
enum MLInputOperandLayout {
  "nchw",
  "nhwc"
};

enum MLOperandDataType {
  "float32",
  "float16",
  "int32",
  "uint32",
  "int64",
  "uint64",
  "int8",
  "uint8"
};

dictionary MLOperandDescriptor {
  required MLOperandDataType dataType;
  required sequence<[EnforceRange] unsigned long> shape;
};
</script>

<dl dfn-type=dict-member dfn-for=MLOperandDescriptor>
    : <dfn>dataType</dfn>
    :: The operand data type.

    : <dfn>shape</dfn>
    :: The list of dimensions of the operand. It is empty for scalar operands.
</dl>

<div algorithm>
An {{MLOperandDescriptor}} |A| is <dfn for=MLOperandDescriptor>equal</dfn> to an {{MLOperandDescriptor}} |B| if |A|.{{MLOperandDescriptor/dataType}} equals |B|.{{MLOperandDescriptor/dataType}} and |A|.{{MLOperandDescriptor/shape}} [=list/equals=] |B|.{{MLOperandDescriptor/shape}}.
</div>

<details open algorithm>
  <summary>
  To <dfn>create an {{MLOperandDescriptor}}</dfn> given {{MLOperandDataType}} |dataType| and [=/list=] |shape|, run the following steps:
  </summary>
    1. Let |descriptor| be a new {{MLOperandDescriptor}}.
    1. Set |descriptor|.{{MLOperandDescriptor/dataType}} to |dataType|.
    1. Set |descriptor|.{{MLOperandDescriptor/shape}} to a [=list/clone=] of |shape|.
    1. Return |descriptor|.
</details>

<details open algorithm>
  <summary>
    The <dfn for="MLOperandDescriptor">byte length</dfn> of an {{MLOperandDescriptor}} |desc| is the value returned by the following steps:
  </summary>
    1. Let |elementLength| be 1.
    1. [=list/For each=] |dimension| of |desc|.{{MLOperandDescriptor/shape}}:
        1. Set |elementLength| to |elementLength| * |dimension|.
    1. Let |elementSize| be the [=element size=] of one of the {{ArrayBufferView}} types that matches |desc|.{{MLOperandDescriptor/dataType}} according to [this table](#appendices-mloperanddatatype-arraybufferview-compatibility).
    1. Return |elementLength| * |elementSize|.
</details>

<p>
A <dfn>valid dimension</dfn> is an integer greater than zero and in the range of {{long}}. Implementations may impose a smaller upper bound.
</p>

Issue(391): Should 0-size dimensions be supported?

<details open algorithm>
  <summary>
    To <dfn for="MLOperandDescriptor">check dimensions</dfn> given {{MLOperandDescriptor}} |descriptor|, run the following steps:
  </summary>
    1. If any [=list/item=] of |descriptor|.{{MLOperandDescriptor/shape}} is not a [=valid dimension=], return false.
    1. If |descriptor|.{{MLOperandDescriptor/shape}}'s [=list/size=] is too large to be supported by the implementation, return false.

        Issue(456): The maximum number of operand dimensions is not defined, but native ML APIs usually have a maximum supported size.

    1. If |descriptor|'s [=MLOperandDescriptor/byte length=] is not supported by the implementation, then return false.
    1. Return true.
</details>

## {{MLOperand}} interface ## {#api-mloperand}

An {{MLOperand}} represents an intermediary graph being constructed as a result of compositing parts of an operation into a fully composed operation.

For instance, an {{MLOperand}} can represent a constant feeding to an operation or the result from combining multiple constants together into an operation. See also [[#programming-model]].

<script type=idl>
[SecureContext, Exposed=(Window, Worker)]
interface MLOperand {
  readonly attribute MLOperandDataType dataType;
  readonly attribute FrozenArray<unsigned long> shape;
};

dictionary MLOperatorOptions {
  USVString label = "";
};

typedef (bigint or unrestricted double) MLNumber;
</script>

<div class=internal-slots>
{{MLOperand}} has the following internal slots:
  <dl dfn-type=attribute dfn-for="MLOperand">
    : <dfn>\[[builder]]</dfn> of type {{MLGraphBuilder}}
    ::
        The {{MLOperand}}'s associated builder object.

    : <dfn>\[[descriptor]]</dfn> of type {{MLOperandDescriptor}}
    ::
        The {{MLOperand}}'s descriptor.

    : <dfn>\[[name]]</dfn> of type [=string=]
    ::
        The {{MLOperand}}'s name (only for input operands).

    : <dfn>\[[operator]]</dfn> of type [=operator=]
    ::
        Reference to {{MLOperand}}'s corresponding [=operator=].
  </dl>
</div>

An {{MLOperand}}'s <dfn for=MLOperand>dataType</dfn> is its {{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/dataType}}.

An {{MLOperand}}'s <dfn for=MLOperand>shape</dfn> is its {{MLOperand/[[descriptor]]}}.{{MLOperandDescriptor/shape}}.

An {{MLOperand}}'s <dfn for=MLOperand>rank</dfn> is its [=MLOperand/shape=]'s [=list/size=].

The <dfn attribute for=MLOperand>dataType</dfn> [=getter steps=] are to return [=this=]'s [=MLOperand/dataType=].

The <dfn attribute for=MLOperand>shape</dfn> [=getter steps=] are to return [=this=]'s [=MLOperand/shape=].

Since the {{MLOperand/[[builder]]}} object is bound by the {{MLGraphBuilder/constructor()}} constructor to an {{MLContext}} object, an {{MLOperand}} is also always bound to the same {{MLContext}} object.

If an operation supports only a subset of {{MLOperandDataType}}s, the <dfn>allowed data types</dfn> for each of the operation's input operands, including both positional arguments and options, are given as either an explicit list of {{MLOperandDataType}}s, or a constraint that the operand's [=MLOperand/dataType=] must be the <dfn lt="same type as">same as</dfn> the [=MLOperand/dataType=] of another input operand, or <dfn lt="any data type">any</dfn> to allow any {{MLOperandDataType}}.

Implementations may support fewer data types for operands than specified. This can be queried for each operation using the {{MLContext/opSupportLimits()}} method on {{MLContext}} and inspecting the {{MLDataTypeLimits/dataTypes}} value of the corresponding member for the operation.

Issue: Should we specify the subset of data types that must be supported for each operator?

If an operation requires input operands with a particular [=MLOperand/rank=], the <dfn>allowed ranks</dfn> for each of the operation's input operands, including both positional arguments and options, are given as an explicit rank (e.g. 1), or <dfn lt="any rank">N</dfn> to allow any dimensionality, or the <dfn lt="same rank as">same as</dfn> another operand. More specific constraints are common, such as when an input operand's shape must be [=/unidirectionally broadcastable=] to or [=/bidirectionally broadcastable=] with another input operand; in these cases, the [=/allowed ranks=] are listed as a range, with specific validation given as steps in the operation.

Implementations may impose a more restricted lower bound and/or upper bound on the [=MLOperand/rank=] of operands than specified. This can be queried for each operation using the {{MLContext/opSupportLimits()}} method on {{MLContext}} and inspecting the {{MLTensorLimits/rankRange}}.{{MLRankRange/min}} and {{MLTensorLimits/rankRange}}.{{MLRankRange/max}} values of the corresponding member for the operation.

{{MLOperatorOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLOperatorOptions>
    : <dfn>label</dfn>
    ::
        Optionally provided when an [=operator=] is created using {{MLGraphBuilder}} methods that create {{MLOperand}}s. The implementation may use this value to initialize the [=operator=]'s [=operator/label=].
</dl>

### Creating an {{MLOperand}} ### {#api-mloperand-create}
The {{MLOperand}} objects are created by the methods of {{MLGraphBuilder}}, internally using the following algorithms.

<details open algorithm>
  <summary>
    To <dfn>create an MLOperand</dfn> given {{MLGraphBuilder}} |builder| and {{MLOperandDescriptor}} |desc|, run the following steps:
  </summary>
    1. Let |realm| be |builder|'s [=relevant realm=].
    1. Let |operand| be a new {{MLOperand}} in |realm|.
    1. Set |operand|.{{MLOperand/[[builder]]}} to |builder|.
    1. Set |operand|.{{MLOperand/[[descriptor]]}} to |desc|.
    1. Return |operand|.
</details>

<details open algorithm>
  <summary>
    To <dfn>copy an MLOperand</dfn> given {{MLOperand}} |operand|, run the following steps:
  </summary>
    1. Let |builder| be |operand|.{{MLOperand/[[builder]]}}.
    1. Let |realm| be |builder|'s [=relevant realm=].
    1. Let |result| be a new {{MLOperand}} in |realm|.
    1. Set |result|.{{MLOperand/[[builder]]}} to |builder|.
    1. Set |result|.{{MLOperand/[[descriptor]]}} to |operand|.{{MLOperand/[[descriptor]]}}.
    1. If |operand|.{{MLOperand/[[name]]}} [=map/exists=], then set |result|.{{MLOperand/[[name]]}} to |operand|.{{MLOperand/[[name]]}}.
    1. Return |result|.
</details>

<p algorithm>
To <dfn for="MLGraphBuilder">validate operand</dfn> given {{MLGraphBuilder}} |builder| and {{MLOperand}} |operand|, return true if |operand|.{{MLOperand/[[builder]]}} is |builder|, and false otherwise.
</p>

#### {{MLNumber}} #### {#api-mlnumber-typedef}

<dfn typedef>MLNumber</dfn> is used when specifying the type of a numeric option for an {{MLOperand}} which can be of any {{MLOperandDataType}}, including both 64-bit integer types ({{MLOperandDataType/"uint64"}} and {{MLOperandDataType/"int64"}}) and 32-bit floating point ({{MLOperandDataType/"float32"}}). Implementations process the value according to the corresponding {{MLOperandDataType}}. For example, if {{MLGraphBuilder/clamp(input, options)}} is called with an {{MLOperand}} with [=MLOperand/dataType=] {{MLOperandDataType/"uint32"}}, the {{MLNumber}} parameters are explicitly [=cast=] to {{unsigned long}}.

<div class="note">
  Specifying the option as {{double}} would lose accuracy when passing values over 2<sup>53</sup>, and specifying {{long long}} would disallow values over 2<sup>63</sup>.
</div>

Issue(whatwg/webidl#1388): Support for unions of {{bigint}} and [=numeric types=] is new in [[WEBIDL]], and implementation support is also limited. Prototype implementations are encouraged to provide feedback for this approach.

## {{MLTensorDescriptor}} dictionary ## {#api-mltensordescriptor}

An {{MLTensorDescriptor}} describes the characteristics and capabilities of an {{MLTensor}}.

<script type=idl>
dictionary MLTensorDescriptor : MLOperandDescriptor {
  boolean readable = false;
  boolean writable = false;
};
</script>

<dl dfn-type=dict-member dfn-for=MLTensorDescriptor>
    : <dfn>readable</dfn>
    :: Whether the tensor's contents can be read via {{MLContext/readTensor(tensor)}} or {{MLContext/readTensor(tensor, outputData)}}.

    : <dfn>writable</dfn>
    :: Whether the tensor's contents can be written to via {{MLContext/writeTensor()}}.
</dl>

## {{MLTensor}} interface ## {#api-mltensor}

The {{MLTensor}} interface represents a tensor which may be used as an input or output to an {{MLGraph}}. The memory backing an {{MLTensor}} should be allocated in an [=implementation-defined=] fashion according to the requirements of the {{MLContext}} and the {{MLTensorDescriptor}} used to create it. Operations involving the {{MLTensor/[[data]]}} of an {{MLTensor}} occur on the {{MLContext/[[timeline]]}} of its associated {{MLContext}}.

The [=implementation-defined=] requirements of how an {{MLTensor}} is allocated may include constraints such as that the memory is allocated with a particular byte alignment or in a particular memory pool.

<script type=idl>
[SecureContext, Exposed=(Window, Worker)]
interface MLTensor {
  readonly attribute MLOperandDataType dataType;
  readonly attribute FrozenArray<unsigned long> shape;
  readonly attribute boolean readable;
  readonly attribute boolean writable;

  undefined destroy();
};
</script>

<div class=internal-slots>
{{MLTensor}} has the following internal slots:
  <dl dfn-type=attribute dfn-for="MLTensor">
    : <dfn>\[[context]]</dfn> of type {{MLContext}}
    ::
        The {{MLTensor}}'s associated context.

    : <dfn>\[[descriptor]]</dfn> of type {{MLTensorDescriptor}}
    ::
        The {{MLTensor}}'s descriptor.

    : <dfn>\[[pendingPromises]]</dfn> of type [=/set=] of {{Promise}}s
    ::
        Promises corresponding to {{MLContext}}.{{MLContext/readTensor(tensor)}} method calls which are in-progress and have yet to resolve. All pending promises will be rejected when the {{MLTensor}} is destroyed.

    : <dfn>\[[isDestroyed]]</dfn> of type {{boolean}}
    ::
        Whether the {{MLTensor}}.{{MLTensor/destroy()}} steps have been run. Once destroyed, the {{MLTensor}} can no longer be used.

    : <dfn>\[[data]]</dfn> of an [=implementation-defined=] type
    ::
        The bytes backing the {{MLTensor}}. This data may only be accessed or modified from the {{MLTensor/[[context]]}}.{{MLContext/[[timeline]]}}.
  </dl>
</div>

An {{MLTensor}}'s <dfn for=MLTensor>dataType</dfn> is its {{MLTensor/[[descriptor]]}}'s {{MLOperandDescriptor/dataType}}.

An {{MLTensor}}'s <dfn for=MLTensor>shape</dfn> is its {{MLTensor/[[descriptor]]}}'s {{MLOperandDescriptor/shape}}.

The <dfn attribute for=MLTensor>dataType</dfn> [=getter steps=] are to return [=this=]'s [=MLTensor/dataType=].

The <dfn attribute for=MLTensor>shape</dfn> [=getter steps=] are to return [=this=]'s [=MLTensor/shape=].

The <dfn attribute for=MLTensor>readable</dfn> [=getter steps=] are to return [=this=].{{MLTensor/[[descriptor]]}}.{{MLTensorDescriptor/readable}}.

The <dfn attribute for=MLTensor>writable</dfn> [=getter steps=] are to return [=this=].{{MLTensor/[[descriptor]]}}.{{MLTensorDescriptor/writable}}.

### Creating an {{MLTensor}} ### {#api-mltensor-create}

An {{MLTensor}} is created by its associated {{MLContext}}.

<details open algorithm>
  <summary>
    To <dfn>create an MLTensor</dfn> given {{MLContext}} |context| and {{MLTensorDescriptor}} |descriptor|, run the following steps:
  </summary>
    1. Let |realm| be |context|'s [=relevant realm=].
    1. Let |tensor| be a new {{MLTensor}} in |realm|.
    1. Set |tensor|.{{MLTensor/[[context]]}} to |context|.
    1. Set |tensor|.{{MLTensor/[[descriptor]]}} to |descriptor|.
    1. Set |tensor|.{{MLTensor/[[isDestroyed]]}} to false.
    1. Return |tensor|.
</details>

### {{MLTensor/destroy()}} ### {#api-mltensor-destroy}

Releases the resources associated with the {{MLTensor}}. This method is idempotent.

<div dfn-for="MLTensor/destroy()" dfn-type=argument>
    **Returns:** {{undefined}}.
</div>

<details open algorithm>
  <summary>
    The <dfn method for=MLTensor>destroy()</dfn> method steps are:
  </summary>
    1. Set [=this=].{{MLTensor/[[isDestroyed]]}} to true.
    1. [=set/For each=] |promise| in [=this=].{{MLTensor/[[pendingPromises]]}}:
        1. [=set/Remove=] |promise| from [=this=].{{MLTensor/[[pendingPromises]]}}.
        1. [=Reject=] |promise| with an "{{InvalidStateError}}" {{DOMException}}.
    1. Enqueue the following steps to [=this=].{{MLTensor/[[context]]}}.{{MLContext/[[timeline]]}}:
        1. Release [=this=].{{MLTensor/[[data]]}}.
    1. Return {{undefined}}.
</details>

Note: Since no further operations can be enqueued using this tensor, implementations can free any additional resource allocations associated with this tensor once all previously submitted operations using it are complete.

## {{MLGraphBuilder}} interface ## {#api-mlgraphbuilder}

The {{MLGraphBuilder}} interface defines a set of operations as identified by the [[#usecases]] that can be composed into a computational graph. It also represents the intermediate state of a graph building session.

<script type=idl>
typedef record<USVString, MLOperand> MLNamedOperands;

[SecureContext, Exposed=(Window, Worker)]
interface MLGraphBuilder {
  // Construct the graph builder from the context.
  constructor(MLContext context);

  // Create an operand for a graph input.
  MLOperand input(USVString name, MLOperandDescriptor descriptor);

  // Create an operand for a graph constant.
  MLOperand constant(MLOperandDescriptor descriptor,
                     AllowSharedBufferSource buffer);

  // Create a scalar operand from the specified number of the specified type.
  MLOperand constant(MLOperandDataType type, MLNumber value);

  // Compile the graph up to the specified output operands asynchronously.
  Promise<MLGraph> build(MLNamedOperands outputs);
};
</script>

<div class="note">
The {{MLGraphBuilder}}.{{MLGraphBuilder/build()}} method compiles the graph builder state up to the specified output operands into a compiled graph according to the type of {{MLContext}} that creates it. When the {{MLContext/[[contextType]]}} of the {{MLContext}} is set to "[=context type/default=]", the compiled graph is initialized right before the {{MLGraph}} is returned. This graph initialization stage is important for optimal performance of the subsequent graph executions. It typically involves a process known as "weight preprocessing" where all the constant inputs to the graph are preprocessed and cached at the operating system level for subsequent graph execution calls. The initializing inputs are typically the constant weight data specified through the {{MLGraphBuilder/constant(descriptor, buffer)|constant()}} method as constant operands during graph construction time.
</div>

<div class=internal-slots>
{{MLGraphBuilder}} has the following internal slots:
  <dl dfn-type=attribute dfn-for="MLGraphBuilder">
    : <dfn>\[[context]]</dfn> of type {{MLContext}}
    ::
        The context of type {{MLContext}} associated with this {{MLGraphBuilder}}.
    : <dfn>\[[hasBuilt]]</dfn> of type {{boolean}}
    ::
        Whether {{MLGraphBuilder}}.{{MLGraphBuilder/build()}} has been called. Once built, the {{MLGraphBuilder}} can no longer create [=operators=] or compile {{MLGraph}}s.
  </dl>
</div>

<div>
An {{MLGraphBuilder}} <dfn for=MLGraphBuilder lt="can build|can not build">can build</dfn> if its {{MLGraphBuilder/[[hasBuilt]]}} is false and its {{MLGraphBuilder/[[context]]}} [=MLContext/is not lost=].
</div>


### {{MLGraphBuilder}} constructor ### {#api-mlgraphbuilder-constructor}

<div dfn-for="MLGraphBuilder/constructor(context)" dfn-type=argument>
    **Arguments:**
      - <dfn>context</dfn>: an {{MLContext}}. The context to associate with the {{MLGraphBuilder}}.
</div>

<details open algorithm>
  <summary>
    The [=new=] <dfn constructor for=MLGraphBuilder lt="MLGraphBuilder(context)">MLGraphBuilder(|context|)</dfn> constructor steps are:
  </summary>
    1. If [=this=]'s [=relevant global object=]'s [=associated Document=] is not [=allowed to use=] the [=webnn-feature|webnn=] feature, then [=exception/throw=] a "{{SecurityError}}" {{DOMException}}.
    1. If |context| [=MLContext/is lost=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. Set [=this=].{{MLGraphBuilder/[[context]]}} to |context|.
    1. Set [=this=].{{MLGraphBuilder/[[hasBuilt]]}} to false.
</details>

### input operands ### {#api-mlgraphbuilder-input}

Create a named {{MLOperand}} based on a descriptor, that can be used as an input.

<div dfn-for="MLGraphBuilder/input(name, descriptor)" dfn-type=argument>
    **Arguments:**
        - <dfn>name</dfn>: a [=string=] name of the input.
        - <dfn>descriptor</dfn>: an {{MLOperandDescriptor}} object.
    **Returns:** an {{MLOperand}}.
</div>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>input(|name|, |descriptor|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If |name| is empty, then [=exception/throw=] a {{TypeError}}.
    1. If any {{MLOperand}}s in [=this=]'s [=MLGraphBuilder/graph=]'s [=computational graph/inputs=] have a {{MLOperand/[[name]]}} equal to |name|, then [=exception/throw=] a {{TypeError}}.
    1. If [=MLOperandDescriptor/checking dimensions=] given |descriptor| returns false, then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |operand| be the result of [=creating an MLOperand=] given [=this=] and |descriptor|.
        1. Set |operand|.{{MLOperand/[[name]]}} to |name|.
        1. Add |operand| to [=this=]'s [=MLGraphBuilder/graph=]'s [=computational graph/inputs=].
    1. Return |operand|.
</details>

<div class="note">
  The {{MLGraphBuilder}} API allows creating an {{MLGraph}} without input operands. If the underlying platform doesn't support that, implementations can add a stub input, or pass constants as inputs to the graph.
</div>

### constant operands ### {#api-mlgraphbuilder-constant}
Create a constant {{MLOperand}} that can be used in {{MLGraphBuilder}} methods.

#### {{MLGraphBuilder/constant(descriptor, buffer)}} #### {#api-mlgraphbuilder-constant-buffer}
Create a constant {{MLOperand}} of the specified data type and shape that contains the initializing data.

<div dfn-for="MLGraphBuilder/constant(descriptor, buffer)" dfn-type=argument>
    **Arguments:**
        - <dfn>descriptor</dfn>: an {{MLOperandDescriptor}}. The descriptor of the output tensor.
        - <dfn>buffer</dfn>: an {{AllowSharedBufferSource}}. The buffer containing the initializing data.
    **Returns:** an {{MLOperand}}. The constant output tensor.
</div>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>constant(|descriptor|, |buffer|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLOperandDescriptor/checking dimensions=] given |descriptor| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If [=validating buffer with descriptor=] given |buffer| and |descriptor| returns false, then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |operand| be the result of [=creating an MLOperand=] given [=this=] and |descriptor|.
        1. Let |bytes| be the result of [=getting a copy of the bytes held by the buffer source=] given |buffer|.
        1. Add |operand| to [=this=]'s [=MLGraphBuilder/graph=]'s [=computational graph/constants=] with |bytes| as value.
    1. Return |operand|.
</details>

#### {{MLGraphBuilder/constant(type, value)}} #### {#api-mlgraphbuilder-constant-type-value}
Create a scalar constant {{MLOperand}} of the specified value and data type.

<div class="note">
Data truncation will occur when the specified value exceeds the range of the specified output data type e.g. when a floating point value is assigned to an {{MLOperandDataType/"int8"}} data type, etc.
</div>

<div dfn-for="MLGraphBuilder/constant(type, value)" dfn-type=argument>
    **Arguments:**
        - <dfn>type</dfn>: an {{MLOperandDataType}}.
        - <dfn>value</dfn>: an {{MLNumber}}. The value of the constant.
    **Returns:** an {{MLOperand}}. The constant output.
</div>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>constant(|type|, |value|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. Set |value| to the result of [=casting=] |value| to |type|.
    1. Let |descriptor| be the result of [=creating an MLOperandDescriptor=] given |type| and « ».
    1. *Make graph connections:*
        1. Let |operand| be the result of [=creating an MLOperand=] given [=this=] and |descriptor|.
        1. Add |operand| to [=this=]'s [=MLGraphBuilder/graph=]'s [=computational graph/constants=] with |value| as value.
    1. Return |operand|.
</details>

### build method ### {#api-mlgraphbuilder-build}
Build a composed graph up to a given output operand into a computational graph asynchronously.

<div dfn-for="MLGraphBuilder/build(outputs)" dfn-type=argument>
    **Arguments:**
        - <dfn>outputs</dfn>: an {{MLNamedOperands}}. Identifies the {{MLOperand}}s that will be the outputs of the graph.
    **Returns:** Promise<{{MLGraph}}>.
</div>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>build(|outputs|)</dfn> method steps are:
  </summary>
    1. Let |realm| be [=this=]'s [=relevant realm=].
    1. If [=this=] [=MLGraphBuilder/can not build=], then return [=a new promise=] in |realm| [=rejected=] with an "{{InvalidStateError}}" {{DOMException}}.
    1. If |outputs| is empty, then return [=a new promise=] in |realm| [=rejected=] with a {{TypeError}}.
    1. [=map/For each=] |name| → |operand| of |outputs|:
        1. If |name| is empty, then return [=a new promise=] in |realm| [=rejected=] with a {{TypeError}}.
        1. If [=MLGraphBuilder/validating operand=] given [=this=] and |operand| returns false, then return [=a new promise=] in |realm| [=rejected=] with a {{TypeError}}.
        1. If |operand| is in [=this=]'s [=MLGraphBuilder/graph=]'s [=computational graph/inputs=] or [=computational graph/constants=], then return [=a new promise=] in |realm| [=rejected=] with a {{TypeError}}.
    1. Let |operands| be a new empty [=/set=].
    1. Let |operators| be a new empty [=/set=].
    1. Let |inputs| be a new empty [=/set=].
    1. Let |queue| be a new [=queue=] containing |outputs|'s [=map/values=].
    1. While |queue| [=queue/is not empty=]:
        1. [=queue/Dequeue=] |operand| from |queue|.
        1. [=set/Append=] |operand| to |operands|.
        1. [=set/Append=] |operand|.{{MLOperand/[[operator]]}} to |operators|.
        1. If |operand| is in [=this=]'s [=MLGraphBuilder/graph=]'s [=computational graph/inputs=], [=set/append=] |operand| to |inputs|.
        1. [=list/For each=] |input| of |operand|.{{MLOperand/[[operator]]}}'s [=operator/inputs=]:
            1. [=queue/Enqueue=] |input| to |queue|.
    1. Let |global| be [=this=]'s [=relevant global object=].
    1. Let |graph| be a new {{MLGraph}} in |realm|.
    1. Set |graph|.{{MLGraph/[[context]]}} to [=this=].{{MLGraphBuilder/[[context]]}}.
    1. Set |graph|.{{MLGraph/[[isDestroyed]]}} to false.
    1. [=set/For each=] |operand| in |inputs|:
        1. Set |graph|.{{MLGraph/[[inputDescriptors]]}}[|operand|.{{MLOperand/[[name]]}}] to |operand|.{{MLOperand/[[descriptor]]}}.
    1. [=map/For each=] |name| → |operand| of |outputs|:
        1. Set |graph|.{{MLGraph/[[outputDescriptors]]}}[|name|] to |operand|.{{MLOperand/[[descriptor]]}}.
    1. Set [=this=].{{MLGraphBuilder/[[hasBuilt]]}} to true.
    1. Let |promise| be [=a new promise=] in |realm|.
    1. Run the following steps [=in parallel=]:
        1. Run these steps, but [=/abort when=] |graph|.{{MLGraph/[[context]]}} [=MLContext/is lost=]:
            1. Let |graphImpl| be the result of converting [=this=]'s [=MLGraphBuilder/graph=] with |operands|, |operators|, |inputs|, and |outputs|'s [=map/values=] into an [=implementation-defined=] format which can be interpreted by the underlying platform.
            1. If the previous step failed, then [=queue an ML task=] with |global| to [=reject=] |promise| with an "{{OperationError}}" {{DOMException}}, and abort these steps.
            1. Set |graph|.{{MLGraph/[[implementation]]}} to |graphImpl|.
            1. [=Queue an ML task=] with |global| to [=resolve=] |promise| with |graph|.
        1. [=/If aborted=], then [=queue an ML task=] with |global| to [=reject=] |promise| with an "{{InvalidStateError}}" {{DOMException}}.
    1. Return |promise|.
</details>

NOTE: Specifying an [=computational graph/input=] operand or [=computational graph/constant=] operand as a graph {{MLGraphBuilder/build(outputs)/outputs|output}} results in an error, as this is usually an incorrect usage of the API. Callers can work around this by introducing an {{MLGraphBuilder/identity()}} operator.

### argMin/argMax operations ### {#api-mlgraphbuilder-argminmax}
Return the index location of the minimum or maximum values of all the input values along the axis. In case of ties, the identity of the return value is implementation dependent.

<script type=idl>
dictionary MLArgMinMaxOptions : MLOperatorOptions {
  boolean keepDimensions = false;
  MLOperandDataType outputDataType = "int32";
};

partial interface MLGraphBuilder {
  MLOperand argMin(MLOperand input, [EnforceRange] unsigned long axis,
                   optional MLArgMinMaxOptions options = {});
  MLOperand argMax(MLOperand input, [EnforceRange] unsigned long axis,
                   optional MLArgMinMaxOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits argMin;
  MLSingleInputSupportLimits argMax;
};
</script>

{{MLArgMinMaxOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLArgMinMaxOptions>
    : <dfn>keepDimensions</dfn>
    ::
        If true, retains reduced dimensions with [=list/size=] 1.

    : <dfn>outputDataType</dfn>
    ::
        An {{MLOperandDataType}}. The output data type.
</dl>

<div dfn-for="MLGraphBuilder/argMin(input, axis, options), MLGraphBuilder/argMax(input, axis, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input N-D tensor.
        - <dfn>axis</dfn>: The dimension to reduce. The value must be in the range [0, N-1] where N is the [=MLOperand/rank=] of the input tensor.
        - <dfn>options</dfn>: an optional {{MLArgMinMaxOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The N-D tensor of the reduced shape. The values must be of type {{MLArgMinMaxOptions/outputDataType}} in the range [0, N-1] where N is the size of the input dimension specified by {{MLGraphBuilder/argMin(input, axis, options)/axis}}.
</div>

<table id=constraints-argMin-argMax class='data' link-for="MLGraphBuilder/argMin(input, axis, options), MLGraphBuilder/argMax(input, axis, options)">
  <caption>Constraints for {{MLGraphBuilder/argMin()}}/{{MLGraphBuilder/argMax()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>{{MLArgMinMaxOptions/outputDataType}}</td>
    <td>{{input}}'s [=MLOperand/rank=] - 1 to {{input}}'s [=MLOperand/rank=]</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following members for {{MLGraphBuilder/argMin()}} and {{MLGraphBuilder/argMax()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>argMin</dfn>
    :: Support limits for operator {{MLGraphBuilder/argMin()}}.
    : <dfn>argMax</dfn>
    :: Support limits for operator {{MLGraphBuilder/argMax()}}.
</dl>

<details open algorithm>
  <summary>
    To <dfn for="MLGraphBuilder" data-lt="argminmax-op">create argMin/argMax operation</dfn> given [=string=] |op|, {{MLOperand}} |input|, {{unsigned long}} |axis|, and {{MLArgMinMaxOptions}} |options|, run the following steps:
  </summary>
    1. [=Assert=]: |op| is one of "argMin", "argMax".
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/shape=][|axis|] is greater than |options|.{{MLArgMinMaxOptions/outputDataType}}'s maximum value, [=exception/throw=] a {{TypeError}}.
    1. Let |outputShape| be the result of [=MLGraphBuilder/calculating reduction output sizes=] given |input|'s [=MLOperand/shape=], « |axis| », and |options|.{{MLArgMinMaxOptions/keepDimensions}}. If that returns failure, then [=exception/throw=] a {{TypeError}}.
    1. Let |desc| be the result of [=creating an MLOperandDescriptor=] given |options|.{{MLArgMinMaxOptions/outputDataType}} and |outputShape|.
    1. *Make graph connections:*
        1. Let |operator| be an [=operator=] for the |op| operation, given |options|.
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<details open>
  <summary>
    The following argMin/argMax algorithms are supported.
  </summary>
    <div algorithm>
    The <dfn method for=MLGraphBuilder>argMin(|input|, |axis|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/argminmax-op | create argMin/argMax operation=] given "argMin", |input|, |axis| and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>argMax(|input|, |axis|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/argminmax-op | create argMin/argMax operation=] given "argMax", |input|, |axis| and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>
</details>

### batchNormalization ### {#api-mlgraphbuilder-batchnorm}
Normalize the values of the input tensor using [[Batch-Normalization]]. For each input feature, the mean and variance values of that feature are computed across all the samples in the batch dimension while the model is trained. These mean and variance values are then subsequently given to this operation during model inference.

<script type=idl>
dictionary MLBatchNormalizationOptions : MLOperatorOptions {
  MLOperand scale;
  MLOperand bias;
  [EnforceRange] unsigned long axis = 1;
  double epsilon = 1e-5;
};

partial interface MLGraphBuilder {
  MLOperand batchNormalization(MLOperand input, MLOperand mean, MLOperand variance,
                               optional MLBatchNormalizationOptions options = {});
};

dictionary MLBatchNormalizationSupportLimits {
  MLTensorLimits input;
  MLTensorLimits mean;
  MLTensorLimits variance;
  MLTensorLimits scale;
  MLTensorLimits bias;
  MLDataTypeLimits output;
};

partial dictionary MLOpSupportLimits {
  MLBatchNormalizationSupportLimits batchNormalization;
};
</script>

{{MLBatchNormalizationOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLBatchNormalizationOptions>
    : <dfn>scale</dfn>
    ::
        The 1-D tensor of the scaling values whose [=list/size=] is equal to the size of the input dimension denoted by {{MLBatchNormalizationOptions/axis}}.

    : <dfn>bias</dfn>
    ::
        The 1-D tensor of the bias values whose [=list/size=] is equal to the size of the input dimension denoted by {{MLBatchNormalizationOptions/axis}}.

    : <dfn>axis</dfn>
    ::
        The index to the feature count dimension of the input shape for which the mean and variance values are. Its value must be in the range [0, N-1] where N is the [=MLOperand/rank=] of the input tensor. The default value is 1, corresponding to the channel (*"c"*) dimension in the {{MLInputOperandLayout/"nchw"}} data layout.

    : <dfn>epsilon</dfn>
    ::
        A small value to prevent computational error due to divide-by-zero.
</dl>

<div dfn-for="MLGraphBuilder/batchNormalization(input, mean, variance, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input N-D tensor.
        - <dfn>mean</dfn>: an {{MLOperand}}. Specifies the 1-D tensor of the mean values of the input features across the batch. Its [=list/size=] is equal to the size of the input dimension denoted by  {{MLBatchNormalizationOptions/axis}}.
        - <dfn>variance</dfn>: an {{MLOperand}}. The 1-D tensor of the variance values of the input features across the batch whose [=list/size=] is equal to the size of the input dimension denoted by {{MLBatchNormalizationOptions/axis}}.
        - <dfn>options</dfn>: an optional {{MLBatchNormalizationOptions}}. Specifies the optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The batch-normalized N-D tensor of the same shape as {{MLGraphBuilder/batchNormalization(input, mean, variance, options)/input}}.
</div>

<table id=constraints-batchNormalization class='data' link-for="MLGraphBuilder/batchNormalization(input, mean, variance, options)">
  <caption>Constraints for {{MLGraphBuilder/batchNormalization()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>{{mean}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>1</td>
  </tr>
  <tr>
    <td>{{variance}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>1</td>
  </tr>
  <tr>
    <td>{{MLBatchNormalizationOptions/scale}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>1</td>
  </tr>
  <tr>
    <td>{{MLBatchNormalizationOptions/bias}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>1</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLBatchNormalizationSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLBatchNormalizationSupportLimits>
    : <dfn>input</dfn>
    :: {{MLTensorLimits}} for input operand.
    : <dfn>mean</dfn>
    :: {{MLTensorLimits}} for mean operand.
    : <dfn>variance</dfn>
    :: {{MLTensorLimits}} for variance operand.
    : <dfn>scale</dfn>
    :: {{MLTensorLimits}} for scale operand.
    : <dfn>bias</dfn>
    :: {{MLTensorLimits}} for bias operand.
    : <dfn>output</dfn>
    :: {{MLTensorLimits}} for output operand.
</dl>

{{MLOpSupportLimits}} has the following members for {{MLGraphBuilder/batchNormalization()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>batchNormalization</dfn>
    :: Support limits for operator {{MLGraphBuilder/batchNormalization()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>batchNormalization(|input|, |mean|, |variance|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input|, |mean|, |variance|, |options|.{{MLBatchNormalizationOptions/scale}} (if it [=map/exists=]), and |options|.{{MLBatchNormalizationOptions/bias}} (if it [=map/exists=]) returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-batchNormalization)), then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLBatchNormalizationOptions/axis}} is not in [=the range=] 0 to |input|'s [=MLOperand/rank=], exclusive, then [=exception/throw=] a {{TypeError}}.
    1. If |mean|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-batchNormalization)), then [=exception/throw=] a {{TypeError}}.
    1. If |mean|'s [=MLOperand/shape=] is not [=list/equal=] to « |input|'s [=MLOperand/shape=][|options|.{{MLBatchNormalizationOptions/axis}}] », then [=exception/throw=] a {{TypeError}}.
    1. If |variance|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-batchNormalization)), then [=exception/throw=] a {{TypeError}}.
    1. If |variance|'s [=MLOperand/shape=] is not [=list/equal=] to « |input|'s [=MLOperand/shape=][|options|.{{MLBatchNormalizationOptions/axis}}] », then [=exception/throw=] a {{TypeError}}.
    1. Set |options|.{{MLBatchNormalizationOptions/epsilon}} to the result of [=casting=] |options|.{{MLBatchNormalizationOptions/epsilon}} to |input|'s [=MLOperand/dataType=].
    1. If |options|.{{MLBatchNormalizationOptions/scale}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-batchNormalization)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « |input|'s [=MLOperand/shape=][|options|.{{MLBatchNormalizationOptions/axis}}] », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLBatchNormalizationOptions/bias}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-batchNormalization)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « |input|'s [=MLOperand/shape=][|options|.{{MLBatchNormalizationOptions/axis}}] », then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |operator| be an [=operator=] for the "batchNormalization" operation, given |input|, |mean|, |variance| and |options|.
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |input|.{{MLOperand/[[descriptor]]}}.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |input|, |mean|, and |variance|.
        1. If |options|.{{MLBatchNormalizationOptions/scale}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. If |options|.{{MLBatchNormalizationOptions/bias}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation when the input tensor is 4-D of the {{MLInputOperandLayout/"nchw"}} layout can be [EMULATED]
    </summary>
    <pre highlight="js">
    function batchNormalization(builder, input, mean, variance, options) {
      const shape = [1, input.shape[options.axis], 1, 1];
      return builder.add(
        builder.mul(
          builder.reshape(options.scale, shape),
          builder.div(
            builder.sub(input, builder.reshape(mean, shape)),
            builder.sqrt(builder.add(
              builder.reshape(variance, shape),
              builder.constant(input.dataType, options.epsilon))))),
        builder.reshape(options.bias, shape));
    }
    </pre>
  </details>
</div>


### cast ### {#api-mlgraphbuilder-cast}
Cast each element in the input tensor to the target data type.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand cast(MLOperand input,
                 MLOperandDataType type,
                 optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits cast;
};
</script>
<div dfn-for="MLGraphBuilder/cast(input, type, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input N-D tensor.
        - <dfn>type</dfn>: an {{MLOperandDataType}}. The target data type.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The N-D tensor of the same shape as {{MLGraphBuilder/cast(input, type, options)/input}} with each element casted to the target data type.
</div>

<table id=constraints-cast class='data' link-for="MLGraphBuilder/cast(input, type, options)">
  <caption>Constraints for {{MLGraphBuilder/cast()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>{{type}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following members for {{MLGraphBuilder/cast()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>cast</dfn>
    :: Support limits for operator {{MLGraphBuilder/cast()}}.
</dl>

Casting between {{MLOperandDataType}}s is specified for some cases and [=implementation-defined=] in other cases, according to the following table:

<table class=grid>
  <caption>
    Behavior of the {{MLGraphBuilder/cast()}} operation given the {{MLGraphBuilder/cast(input, type, options)/input}}'s [=MLOperand/dataType=] (rows) and target {{MLGraphBuilder/cast(input, type, options)/type}} (columns).
  </caption>
  <tr>
    <th class=split>
      <span class=top-right>Target type</span>
      <span class=bottom-left>Input type</span>
    </th>
    <th>
      {{MLOperandDataType/"float32"}},
      {{MLOperandDataType/"float16"}}
    </th>
    <th>
      {{MLOperandDataType/"int32"}},
      {{MLOperandDataType/"uint32"}},
      {{MLOperandDataType/"int64"}},
      {{MLOperandDataType/"uint64"}},
      {{MLOperandDataType/"int8"}},
      {{MLOperandDataType/"uint8"}}
    </th>
  </tr>
  <tr>
    <th>
      {{MLOperandDataType/"float32"}},
      {{MLOperandDataType/"float16"}}
    </th>
    <td>
      If in range, nearest representable value.

      If out of range, +/-Infinity.
    </td>
    <td>
      If in range, truncated.

      If out of range, [=implementation-defined=].
    </td>
  </tr>
  <tr>
    <th>
      {{MLOperandDataType/"int32"}},
      {{MLOperandDataType/"uint32"}},
      {{MLOperandDataType/"int64"}},
      {{MLOperandDataType/"uint64"}},
      {{MLOperandDataType/"int8"}},
      {{MLOperandDataType/"uint8"}}
    </th>
    <td>
      If in range, nearest representable value.

      If out of range, +/-Infinity.
    </td>
    <td>
      If in range, same value.

      If out of range, lowest N bits reinterpreted as target type, assuming two's complement for signed types.
    </td>
  </tr>
</table>

NOTE: For example, casting -1 from {{MLOperandDataType/"int8"}} to {{MLOperandDataType/"uint8"}} is specified to yield 255. But casting -1 from {{MLOperandDataType/"float32"}} to {{MLOperandDataType/"uint8"}} is [=implementation-defined=].

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>cast(|input|, |type|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |operator| be an [=operator=] for the "cast" operation, given |type| and |options|.
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

### clamp ### {#api-mlgraphbuilder-clamp}
Clamp the input tensor element-wise within a range specified by the minimum and maximum values.
<script type=idl>
dictionary MLClampOptions : MLOperatorOptions {
  MLNumber minValue;
  MLNumber maxValue;
};

partial interface MLGraphBuilder {
  MLOperand clamp(MLOperand input, optional MLClampOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits clamp;
};
</script>

{{MLClampOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLClampOptions>
    : <dfn>minValue</dfn>
    :: The minimum value of the range. When it is not specified, the clamping is not performed on the lower limit of the range.

    : <dfn>maxValue</dfn>
    :: The maximum value of the range. When it is not specified, the clamping is not performed on the upper limit of the range.
</dl>

<div dfn-for="MLGraphBuilder/clamp(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an optional {{MLClampOptions}}. The optional parameters of the operation.
    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/clamp(input, options)/input}}.
</div>

<table id=constraints-clamp class='data' link-for="MLGraphBuilder/clamp(input, options)">
  <caption>Constraints for {{MLGraphBuilder/clamp()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/clamp()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>clamp</dfn>
    :: Support limits for operator {{MLGraphBuilder/clamp()}}.
</dl>
<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>clamp(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. Let |minValue| be the |options|.{{MLClampOptions/minValue}} if given, or Infinity otherwise.
    1. Set |options|.{{MLClampOptions/minValue}} to the result of [=casting=] |minValue| to |input|'s [=MLOperand/dataType=].
    1. Let |maxValue| be the |options|.{{MLClampOptions/maxValue}} if given, or -Infinity otherwise.
    1. Set |options|.{{MLClampOptions/maxValue}} to the result of [=casting=] |maxValue| to |input|'s [=MLOperand/dataType=].
    1. If |options|.{{MLClampOptions/minValue}} is greater than |options|.{{MLClampOptions/maxValue}}, then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "clamp" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation can be [EMULATED]
  </summary>
  <pre highlight="js">
    function clamp(builder, input, options) {
      if (options.minValue === undefined) {
        if (options.maxValue === undefined) {
          return input;
        } else {
          return builder.min(
            input, builder.constant(input.dataType, options.maxValue));
        }
      } else {
        if (options.maxValue === undefined) {
          return builder.max(
            input, builder.constant(input.dataType, options.minValue));
        } else {
          return builder.min(
            builder.max(input, builder.constant(input.dataType, options.minValue)),
            builder.constant(input.dataType, options.maxValue));
        }
      }
    }
  </pre>
</details>
</div>

### concat ### {#api-mlgraphbuilder-concat}
Concatenates the input tensors along a given axis.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand concat(sequence<MLOperand> inputs,
                   [EnforceRange] unsigned long axis,
                   optional MLOperatorOptions options = {});
};

dictionary MLConcatSupportLimits {
  MLTensorLimits inputs;
  MLDataTypeLimits output;
};

partial dictionary MLOpSupportLimits {
  MLConcatSupportLimits concat;
};
</script>
<div dfn-for="MLGraphBuilder/concat(inputs, axis, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>inputs</dfn>: a [=sequence=]<{{MLOperand}}>. All input tensors must have the
            same shape, except for the size of the dimension to concatenate on.
        - <dfn>axis</dfn>: an {{unsigned long}} scalar. The axis that the inputs concatenate along. Its value must be in the range [0, N-1] where N is the [=MLOperand/rank=] of the input tensors.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The concatenated tensor of all the inputs along
    the {{MLGraphBuilder/concat(inputs, axis, options)/axis}}. The output tensor has the same shape except on the dimension
    that all the inputs concatenated along. The size of that dimension is
    computed as the sum of all the input sizes of the same dimension.
</div>

<table id=constraints-concat class='data' link-for="MLGraphBuilder/concat(inputs, axis, options)">
  <caption>Constraints for {{MLGraphBuilder/concat()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{inputs}}'s [=list/items=]</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{inputs}}'s [=list/items=]</td>
    <td>[=/same rank as|same as=] {{inputs}}'s [=list/items=]</td>
  </tr>
</table>

{{MLConcatSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLConcatSupportLimits>
    : <dfn>inputs</dfn>
    :: {{MLTensorLimits}} for all input operands.
    : <dfn>output</dfn>
    :: {{MLDataTypeLimits}} for output operand.
</dl>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/concat()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>concat</dfn>
    :: Support limits for operator {{MLGraphBuilder/concat()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>concat(|inputs|, |axis|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any [=list/item=] in |inputs| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |inputs| [=list/is empty=], then [=exception/throw=] a {{TypeError}}.
    1. Let |first| be |inputs|[0].
    1. If |axis| is greater than or equal to |first|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
    1. Let |desc| be the result of [=creating an MLOperandDescriptor=] given |first|'s [=MLOperand/dataType=] and |first|'s [=MLOperand/shape=].
    1. Set |desc|.{{MLOperandDescriptor/shape}}[|axis|] to |first|'s [=MLOperand/shape=][|axis|].
    1. [=list/For each=] |index| in [=the range=] 1 to |inputs|'s [=list/size=], exclusive:
        1. Let |input| be |inputs|[|index|].
        1. If |input|'s [=MLOperand/dataType=] is not equal to |first|'s [=MLOperand/dataType=], then [=exception/throw=] a {{TypeError}}.
        1. If |input|'s [=MLOperand/rank=] is not equal to |first|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
        1. [=list/For each=] |dim| in [=the range=] 0 to |input|'s [=MLOperand/rank=], exclusive:
            <div class="note">
                If the shape of each corresponding dimension and type of the operands, except for those of the dimension given by |axis|, is not the same, fail.
            </div>
            1. If |dim| is not equal to |axis| and if |input|'s [=MLOperand/shape=][|dim|] is not equal to |first|'s [=MLOperand/shape=][|dim|], then [=exception/throw=] a {{TypeError}}.
            1. If |dim| is equal to |axis|:
                1. Let |size| be the sum of |desc|.{{MLOperandDescriptor/shape}}[|axis|] and |input|'s [=MLOperand/shape=][|dim|].
                1. If |size| is not a [=valid dimension=], then [=exception/throw=] a {{TypeError}}.
                1. Set |desc|.{{MLOperandDescriptor/shape}}[|axis|] to |size|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Let |operator| be an [=operator=] for the "concat" operation, given |inputs|, |axis|, and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |inputs|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

### conv2d ### {#api-mlgraphbuilder-conv2d}
Compute a 2-D convolution given 4-D input and filter tensors
<script type=idl>
enum MLConv2dFilterOperandLayout {
  "oihw",
  "hwio",
  "ohwi",
  "ihwo"
};

dictionary MLConv2dOptions : MLOperatorOptions {
  sequence<[EnforceRange] unsigned long> padding;
  sequence<[EnforceRange] unsigned long> strides;
  sequence<[EnforceRange] unsigned long> dilations;
  [EnforceRange] unsigned long groups = 1;
  MLInputOperandLayout inputLayout = "nchw";
  MLConv2dFilterOperandLayout filterLayout = "oihw";
  MLOperand bias;
};

partial interface MLGraphBuilder {
  MLOperand conv2d(MLOperand input,
                   MLOperand filter,
                   optional MLConv2dOptions options = {});
};

dictionary MLConv2dSupportLimits {
  MLTensorLimits input;
  MLTensorLimits filter;
  MLTensorLimits bias;
  MLDataTypeLimits output;
};

partial dictionary MLOpSupportLimits {
  MLConv2dSupportLimits conv2d;
};
</script>

{{MLConv2dOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLConv2dOptions>
    : <dfn>padding</dfn>
    ::
        A list of length 4: *[beginningHeight, endingHeight, beginningWidth, endingWidth]*.
        Specifies the additional rows and columns added to the beginning and ending of each spatial dimension of the convolution input.
        The default value is [0, 0, 0, 0].

    : <dfn>strides</dfn>
    ::
        A list of length 2: *[strideHeight, strideWidth]*.
        Specifies the stride of the sliding window for each spatial dimension of the convolution input.
        The default value is [1, 1].

    : <dfn>dilations</dfn>
    ::
        A list of length 2: *[dilationHeight, dilationWidth]*. Specifies the dilation factor for each spatial dimension applied on the convolution filter (kernel).
        The default value is [1, 1].

    : <dfn>groups</dfn>
    ::
        The number of groups that input channels and output channels are divided into.

    : <dfn>inputLayout</dfn>
    ::
        Specifies the layout format of the input and output tensor as follows:
            - {{MLInputOperandLayout/"nchw"}}
                - input tensor: *[batches, inputChannels, height, width]*
                - output tensor: *[batches, outputChannels, height, width]*
            - {{MLInputOperandLayout/"nhwc"}}:
                - input tensor: *[batches, height, width, inputChannels]*
                - output tensor: *[batches, height, width, outputChannels]*

    : <dfn>filterLayout</dfn>
    ::
          Specifies the layout format of the filter tensor as follows:
              - {{MLConv2dFilterOperandLayout/"oihw"}}: *[outputChannels, inputChannels/groups, height, width]*
              - {{MLConv2dFilterOperandLayout/"hwio"}}: *[height, width, inputChannels/groups, outputChannels]*
              - {{MLConv2dFilterOperandLayout/"ohwi"}}: *[outputChannels, height, width, inputChannels/groups]*
              - {{MLConv2dFilterOperandLayout/"ihwo"}}: *[inputChannels/groups, height, width, outputChannels]*

    : <dfn>bias</dfn>
    ::
          An additional 1-D tensor with the shape of *[outputChannels]* whose values are to be added to the convolution result.
</dl>

<div dfn-for="MLGraphBuilder/conv2d(input, filter, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input 4-D tensor. The logical shape
            is interpreted according to the value of {{MLConv2dOptions/inputLayout}}.
        - <dfn>filter</dfn>: an {{MLOperand}}. The filter 4-D tensor. The logical shape is
            interpreted according to the value of {{MLConv2dOptions/filterLayout}} and {{MLConv2dOptions/groups}}.
        - <dfn>options</dfn>: an {{MLConv2dOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output 4-D tensor that contains the convolution result. The output shape is interpreted according to {{MLConv2dOptions/inputLayout}}. More specifically, the spatial dimensions or the sizes of the last two dimensions of the output tensor for the {{MLInputOperandLayout/"nchw"}} input layout can be calculated as follows:

    `outputSize = 1 + (inputSize - (filterSize - 1) * dilation - 1 + beginningPadding + endingPadding) / stride`
</div>

<table id=constraints-conv2d class='data' link-for="MLGraphBuilder/conv2d(input, filter, options)">
  <caption>Constraints for {{MLGraphBuilder/conv2d()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>4</td>
  </tr>
  <tr>
    <td>{{filter}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>4</td>
  </tr>
  <tr>
    <td>{{MLConv2dOptions/bias}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>1</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>4</td>
  </tr>
</table>

{{MLConv2dSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLConv2dSupportLimits>
    : <dfn>input</dfn>
    :: {{MLTensorLimits}} for input operand.
    : <dfn>filter</dfn>
    :: {{MLTensorLimits}} for filter operand.
    : <dfn>bias</dfn>
    :: {{MLTensorLimits}} for bias operand.
    : <dfn>output</dfn>
    :: {{MLDataTypeLimits}} for output operand.
</dl>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/conv2d()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>conv2d</dfn>
    :: Support limits for operator {{MLGraphBuilder/conv2d()}}.
</dl>

<div class="note">
    A *depthwise* conv2d operation is a variant of grouped convolution, used in models like the MobileNet, where the {{MLConv2dOptions/groups}} = *inputChannels* = *outputChannels* and the shape of filter tensor is *[options.groups, 1, height, width]*
    for {{MLConv2dFilterOperandLayout/"oihw"}} layout, *[height, width, 1, options.groups]* for {{MLConv2dFilterOperandLayout/"hwio"}} layout, *[options.groups, height, width, 1]* for {{MLConv2dFilterOperandLayout/"ohwi"}} layout and *[1, height, width, options.groups]* for {{MLConv2dFilterOperandLayout/"ihwo"}} layout.
</div>

<details open algorithm>
  <summary>
    To <dfn for=MLGraphBuilder>calculate conv output size</dfn> given unsigned integers |inputSize|, |filterSize|, |beginningPadding|, |endingPadding|, |stride| and |dilation|, perform these steps. They return a number.
  </summary>
    1. Let |effectiveFilterSize| be ( |filterSize| - 1 ) * |dilation| + 1.
    1. Let |outputSize| be ( |inputSize| - |effectiveFilterSize| + |beginningPadding| + |endingPadding| ) / |stride| + 1.
    1. Return |outputSize|.
</details>

<details open algorithm>
  <summary>
    To <dfn for=MLGraphBuilder>calculate conv2d output sizes</dfn> given unsigned integers |inputHeight|, |inputWidth|, |filterHeight| and |filterWidth|, [=/list=] of 4 unsigned integers |padding|, [=/list=] of 2 unsigned integers |strides|, and [=/list=] of 2 unsigned integers |dilations|, perform these steps. They return a [=/list=] of 2 numbers.
  </summary>
    1. Let |outputHeight| be the result of [=MLGraphBuilder/calculating conv output size=] given |inputHeight|, |filterHeight|, |padding|[0], |padding|[1], |strides|[0] and |dilations|[0].
    1. Let |outputWidth| be the result of [=MLGraphBuilder/calculating conv output size=] given |inputWidth|, |filterWidth|, |padding|[2], |padding|[3], |strides|[1] and |dilations|[1].
    1. Return « |outputHeight|, |outputWidth| ».
</details>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>conv2d(|input|, |filter|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input|, |filter|, and |options|.{{MLConv2dOptions/bias}} (if it [=map/exists=]) returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-conv2d)), then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/rank=] is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. If |filter|'s [=MLOperand/rank=] is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. If |filter|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-conv2d)), then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLConv2dOptions/padding}} does not [=map/exist=], set it to the [=/list=] « 0, 0, 0, 0 ».
    1. Otherwise, if |options|.{{MLConv2dOptions/padding}}'s [=list/size=] is not 4, then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLConv2dOptions/strides}} does not [=map/exist=], set it to the [=/list=] « 1, 1 ».
    1. Otherwise, if |options|.{{MLConv2dOptions/strides}}'s [=list/size=] is not 2, then [=exception/throw=] a {{TypeError}}.
    1. If any [=list/item=] in |options|.{{MLConv2dOptions/strides}} is equal to 0, then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLConv2dOptions/dilations}} does not [=map/exist=], set it to the [=/list=] « 1, 1 ».
    1. Otherwise, if |options|.{{MLConv2dOptions/dilations}}'s [=list/size=] is not 2, then [=exception/throw=] a {{TypeError}}.
    1. If any [=list/item=] in |options|.{{MLConv2dOptions/dilations}} is equal to 0, then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLConv2dOptions/groups}} is 0, then [=exception/throw=] a {{TypeError}}.
    1. *Calculate the output shape:*
        1. Let |inputShape| be |input|'s [=MLOperand/shape=].
        1. Switch on |options|.{{MLConv2dOptions/inputLayout}}:
            <dl class=switch>
                : {{MLInputOperandLayout/"nchw"}}
                :: Let « |batches|, |inputChannels|, |inputHeight|, |inputWidth| » be |inputShape|.
                : {{MLInputOperandLayout/"nhwc"}}
                :: Let « |batches|, |inputHeight|, |inputWidth|, |inputChannels| » be |inputShape|.
            </dl>
        1. Let |filterShape| be |filter|'s [=MLOperand/shape=].
        1. Switch on |options|.{{MLConv2dOptions/filterLayout}}:
            <dl class=switch>
                : {{MLConv2dFilterOperandLayout/"hwio"}}
                :: Let « |filterHeight|, |filterWidth|, |filterInputChannels|, |outputChannels| » be |filterShape|.
                : {{MLConv2dFilterOperandLayout/"ohwi"}}
                :: Let « |outputChannels|, |filterHeight|, |filterWidth|, |filterInputChannels| » be |filterShape|.
                : {{MLConv2dFilterOperandLayout/"ihwo"}}
                :: Let « |filterInputChannels|, |filterHeight|, |filterWidth|, |outputChannels| » be |filterShape|.
                : {{MLConv2dFilterOperandLayout/"oihw"}}
                :: Let « |outputChannels|, |filterInputChannels|, |filterHeight|, |filterWidth| » be |filterShape|.
            </dl>
        1. If |inputChannels| % |options|.{{MLConv2dOptions/groups}} is not 0, then [=exception/throw=] a {{TypeError}}.
        1. Otherwise, if |inputChannels| / |options|.{{MLConv2dOptions/groups}} is not equal to |filterInputChannels|, then [=exception/throw=] a {{TypeError}}.
        1. If |options|.{{MLConv2dOptions/bias}} [=map/exists=]:
            1. If its [=MLOperand/shape=] is not [=list/equal=] to « |outputChannels| », then [=exception/throw=] a {{TypeError}}.
            1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-conv2d)), then [=exception/throw=] a {{TypeError}}.
        1. Let « |outputHeight|, |outputWidth| » be the result of [=MLGraphBuilder/calculating conv2d output sizes=] given |inputHeight|, |inputWidth|, |filterHeight|, |filterWidth|, |options|.{{MLConv2dOptions/padding}}, |options|.{{MLConv2dOptions/strides}}, and |options|.{{MLConv2dOptions/dilations}}.
        1. Set |outputHeight| to floor( |outputHeight| ).
        1. Set |outputWidth| to floor( |outputWidth| ).
        1. If either |outputHeight| or |outputWidth| is not a [=valid dimension=], then [=exception/throw=] a {{TypeError}}.
        1. Switch on |options|.{{MLConv2dOptions/inputLayout}}:
            <dl class=switch>
                : {{MLInputOperandLayout/"nchw"}}
                :: Let |outputShape| be « |batches|, |outputChannels|, |outputHeight|, |outputWidth| ».
                : {{MLInputOperandLayout/"nhwc"}}
                :: Let |outputShape| be « |batches|, |outputHeight|, |outputWidth|, |outputChannels|  ».
            </dl>
        1. Let |desc| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Let |operator| be an [=operator=] for the "conv2d" operation, given |options| and |filter|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |input| and |filter|.
        1. If |options|.{{MLConv2dOptions/bias}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

### convTranspose2d ### {#api-mlgraphbuilder-convtranspose2d}
Compute a 2-D transposed convolution given 4-D input and filter tensors
<script type=idl>

enum MLConvTranspose2dFilterOperandLayout {
  "iohw",
  "hwoi",
  "ohwi"
};

dictionary MLConvTranspose2dOptions : MLOperatorOptions {
  sequence<[EnforceRange] unsigned long> padding;
  sequence<[EnforceRange] unsigned long> strides;
  sequence<[EnforceRange] unsigned long> dilations;
  sequence<[EnforceRange] unsigned long> outputPadding;
  sequence<[EnforceRange] unsigned long> outputSizes;
  [EnforceRange] unsigned long groups = 1;
  MLInputOperandLayout inputLayout = "nchw";
  MLConvTranspose2dFilterOperandLayout filterLayout = "iohw";
  MLOperand bias;
};

partial interface MLGraphBuilder {
  MLOperand convTranspose2d(MLOperand input, MLOperand filter,
                            optional MLConvTranspose2dOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLConv2dSupportLimits convTranspose2d;
};
</script>

{{MLConvTranspose2dOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLConvTranspose2dOptions>
    : <dfn>padding</dfn>
    ::
        A list of length 4: *[beginningHeight, endingHeight, beginningWidth, endingWidth]*.
        Specifies the additional rows and columns added to the beginning and ending of each spatial dimension of the convolution input.
        The default value is [0, 0, 0, 0].

    : <dfn>strides</dfn>
    ::
        A list of length 2: *[strideHeight, strideWidth]*.
        Specifies the stride of the sliding window for each spatial dimension of the convolution input.
        The default value is [1, 1].

    : <dfn>dilations</dfn>
    ::
        A list of length 2: *[dilationHeight, dilationWidth]*. Specifies the dilation factor for each spatial dimension applied on the convolution filter (kernel).
        The default value is [1, 1].

    : <dfn>outputPadding</dfn>
    ::
        A list of length 2.
        Specifies the padding values applied to each spatial dimension of the output tensor. The explicit padding values are needed to disambiguate the output tensor shape for transposed convolution when the value of the {{MLConvTranspose2dOptions/strides}} is greater than 1.

        Note that these values are only used to disambiguate output shape when needed; it does not necessarily cause any padding value to be written to the output tensor.

        The default value is [0, 0].

    : <dfn>outputSizes</dfn>
    ::
        A list of length 2.
        Specifies the sizes of the last two dimensions of the output tensor. When the output sizes are explicitly specified, the output padding values in {{MLConvTranspose2dOptions/outputPadding}} are ignored.

        If not specified, the output sizes are automatically computed.

    : <dfn>groups</dfn>
    ::
        The number of groups that input channels and output channels are divided into.

    : <dfn>inputLayout</dfn>
    ::
        Specifies the layout format of the input and output tensor as follows:
            - {{MLInputOperandLayout/"nchw"}}
                - input tensor: *[batches, inputChannels, height, width]*
                - output tensor: *[batches, outputChannels, height, width]*
            - {{MLInputOperandLayout/"nhwc"}}:
                - input tensor: *[batches, height, width, inputChannels]*
                - output tensor: *[batches, height, width, outputChannels]*

    : <dfn>filterLayout</dfn>
    ::
        Specifies the layout format of the filter tensor as follows:
            - {{MLConvTranspose2dFilterOperandLayout/"iohw"}}: *[inputChannels, outputChannels/groups, height, width]*
            - {{MLConvTranspose2dFilterOperandLayout/"hwoi"}}: *[height, width, outputChannels/groups, inputChannels]*
            - {{MLConvTranspose2dFilterOperandLayout/"ohwi"}}: *[outputChannels/groups, height, width, inputChannels]*

    : <dfn>bias</dfn>
    ::
        An additional 1-D tensor with the shape of *[outputChannels]* whose values are to be added to the convolution result.
</dl>

<div dfn-for="MLGraphBuilder/convTranspose2d(input, filter, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input 4-D tensor. The logical shape
            is interpreted according to the value of {{MLConvTranspose2dOptions/inputLayout}}.
        - <dfn>filter</dfn>: an {{MLOperand}}. The filter 4-D tensor. The logical shape is
            interpreted according to the value of {{MLConvTranspose2dOptions/filterLayout}} and {{MLConvTranspose2dOptions/groups}}.
        - <dfn>options</dfn>: an optional {{MLConvTranspose2dOptions}}.

    **Returns:** an {{MLOperand}}. The output 4-D tensor that contains the transposed convolution result. The output shape is interpreted according to {{MLConvTranspose2dOptions/inputLayout}}. More specifically, unless {{MLConvTranspose2dOptions/outputSizes}} is explicitly specified, {{MLConvTranspose2dOptions/outputPadding}} is needed to compute the spatial dimension values of the output tensor as follows:

    `outputSize = (inputSize - 1) * stride + (filterSize - 1) * dilation + 1 - beginningPadding - endingPadding + outputPadding`
</div>

<table id=constraints-convTranspose2d class='data' link-for="MLGraphBuilder/convTranspose2d(input, filter, options)">
  <caption>Constraints for {{MLGraphBuilder/convTranspose2d()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>4</td>
  </tr>
  <tr>
    <td>{{filter}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>4</td>
  </tr>
  <tr>
    <td>{{MLConv2dOptions/bias}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>1</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>4</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/convTranspose2d()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>convTranspose2d</dfn>
    :: Support limits for operator {{MLGraphBuilder/convTranspose2d()}}.
</dl>

<details open algorithm>
  <summary>
    To <dfn for=MLGraphBuilder>calculate convtranspose output size</dfn> given unsigned integers |inputSize|, |filterSize|, |beginningPadding|, |endingPadding|, |stride|, and |dilation|, perform these steps. They return a number.
  </summary>
    1. Let |effectiveFilterSize| be ( |filterSize| - 1 ) * |dilation| + 1.
    1. Let |outputSize| be ( |inputSize| - 1 ) * |stride| + |effectiveFilterSize| - |beginningPadding| - |endingPadding|.
    1. Return |outputSize|.
</details>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>convTranspose2d(|input|, |filter|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input|, |filter|, and |options|.{{MLConvTranspose2dOptions/bias}} (if it [=map/exists=]) returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/rank=] is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-convTranspose2d)), then [=exception/throw=] a {{TypeError}}.
    1. If |filter|'s [=MLOperand/rank=] is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. If |filter|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-convTranspose2d)), then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLConvTranspose2dOptions/padding}} does not [=map/exist=], set it to the [=/list=] « 0, 0, 0, 0 ».
    1. Otherwise, if |options|.{{MLConvTranspose2dOptions/padding}}'s [=list/size=] is not 4, then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLConvTranspose2dOptions/strides}} does not [=map/exist=], set it to the [=/list=] « 1, 1 ».
    1. Otherwise, if |options|.{{MLConvTranspose2dOptions/strides}}'s [=list/size=] is not 2, then [=exception/throw=] a {{TypeError}}.
    1. If any [=list/item=] in |options|.{{MLConv2dOptions/strides}} is equal to 0, then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLConvTranspose2dOptions/dilations}} does not [=map/exist=], set it to the [=/list=] « 1, 1 ».
    1. Otherwise, if |options|.{{MLConvTranspose2dOptions/dilations}}'s [=list/size=] is not 2, then [=exception/throw=] a {{TypeError}}.
    1. If any [=list/item=] in |options|.{{MLConvTranspose2dOptions/dilations}} is equal to 0, then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLConvTranspose2dOptions/outputPadding}} does not [=map/exist=], set it to the [=/list=] « 0, 0 ».
    1. Otherwise, if |options|.{{MLConvTranspose2dOptions/outputPadding}}'s [=list/size=] is not 2, then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLConvTranspose2dOptions/outputSizes}} [=map/exists=]:
        1. If its [=list/size=] is not 2, then [=exception/throw=] a {{TypeError}}.
    1. Otherwise:
        1. If |options|.{{MLConvTranspose2dOptions/outputPadding}}[0] is greater than or equal to |options|.{{MLConvTranspose2dOptions/strides}}[0], or |options|.{{MLConvTranspose2dOptions/outputPadding}}[1] is greater than or equal to |options|.{{MLConvTranspose2dOptions/strides}}[1], then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLConvTranspose2dOptions/groups}} is 0, then [=exception/throw=] a {{TypeError}}.
    1. *Calculate the output shape:*
        1. Let |inputShape| be |input|'s [=MLOperand/shape=].
        1. Switch on |options|.{{MLConvTranspose2dOptions/inputLayout}}:
            <dl class=switch>
                : {{MLInputOperandLayout/"nchw"}}
                :: Let « |batches|, |inputChannels|, |inputHeight|, |inputWidth| » be |inputShape|.
                : {{MLInputOperandLayout/"nhwc"}}
                :: Let « |batches|, |inputHeight|, |inputWidth|, |inputChannels| » be |inputShape|.
            </dl>
        1. Let |filterShape| be |filter|'s [=MLOperand/shape=].
        1. Switch on |options|.{{MLConvTranspose2dOptions/filterLayout}}:
            <dl class=switch>
                : {{MLConvTranspose2dFilterOperandLayout/"iohw"}}
                :: Let « |filterInputChannels|, |filterOutputChannels|, |filterHeight|, |filterWidth| » be |filterShape|.
                : {{MLConvTranspose2dFilterOperandLayout/"hwoi"}}
                :: Let « |filterHeight|, |filterWidth|, |filterOutputChannels|, |filterInputChannels| » be |filterShape|.
                : {{MLConvTranspose2dFilterOperandLayout/"ohwi"}}
                :: Let « |filterOutputChannels|, |filterHeight|, |filterWidth|, |filterInputChannels| » be |filterShape|.
            </dl>
        1. If |inputChannels| is not equal to |filterInputChannels|, then [=exception/throw=] a {{TypeError}}.
        1. Let |outputChannels| be |filterOutputChannels| * |options|.{{MLConvTranspose2dOptions/groups}}.
        1. If |outputChannels| is not a [=valid dimension=], then [=exception/throw=] a {{TypeError}}.
        1. If |options|.{{MLConvTranspose2dOptions/bias}} [=map/exists=]:
            1. If its [=MLOperand/shape=] is not [=list/equal=] to « |outputChannels| », then [=exception/throw=] a {{TypeError}}.
            1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-convTranspose2d)), then [=exception/throw=] a {{TypeError}}.
        1. Let |calculatedOutputHeight| be the result of [=MLGraphBuilder/calculating convtranspose output size=] given |inputHeight|, |filterHeight|, |padding|[0], |padding|[1], |strides|[0] and |dilations|[0].
        1. Let |calculatedOutputWidth| be the result of [=MLGraphBuilder/calculating convtranspose output size=] given |inputWidth|, |filterWidth|, |padding|[2], |padding|[3], |strides|[1] and |dilations|[1].
        1. If |options|.{{MLConvTranspose2dOptions/outputSizes}} [=map/exists=], then:
            1. Let « |outputHeight|, |outputWidth| » be |options|.{{MLConvTranspose2dOptions/outputSizes}}.
            1. If |outputHeight| is less than |calculatedOutputHeight|, or |outputHeight| is greater than or equal to |calculatedOutputHeight| + |strides|[0], then [=exception/throw=] a {{TypeError}}.
            1. If |outputWidth| is less than |calculatedOutputWidth|, or |outputWidth| is greater than or equal to |calculatedOutputWidth| + |strides|[1], then [=exception/throw=] a {{TypeError}}.
        1. Otherwise:
            1. Let |outputHeight| be |calculatedOutputHeight| + |options|.{{MLConvTranspose2dOptions/outputPadding}}[0].
            1. Let |outputWidth| be |calculatedOutputWidth| + |options|.{{MLConvTranspose2dOptions/outputPadding}}[1].
        1. If either |outputHeight| or |outputWidth| is not a [=valid dimension=], then [=exception/throw=] a {{TypeError}}.
        1. Switch on |options|.{{MLConvTranspose2dOptions/inputLayout}}:
            <dl class=switch>
                : {{MLInputOperandLayout/"nchw"}}
                :: Let |outputShape| be « |batches|, |outputChannels|, floor( |outputHeight| ), floor( |outputWidth| ) ».
                : {{MLInputOperandLayout/"nhwc"}}
                :: Let |outputShape| be « |batches|, floor( |outputHeight| ), floor( |outputWidth| ), |outputChannels| ».
            </dl>
        1. Let |desc| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Let |operator| be an [=operator=] for the "convTranspose2d" operation, given |options| and |filter|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |input| and |filter|.
        1. If |options|.{{MLConv2dOptions/bias}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

### cumulativeSum ### {#api-mlgraphbuilder-cumulativesum}
Compute the accumulated sum of a series of values along the given axis, either including or excluding the current value.

<script type=idl>
dictionary MLCumulativeSumOptions : MLOperatorOptions {
  boolean exclusive = false;
  boolean reversed = false;
};

partial interface MLGraphBuilder {
  MLOperand cumulativeSum(MLOperand input,
                          unsigned long axis,
                          optional MLCumulativeSumOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits cumulativeSum;
};
</script>

<table id=constraints-cumulativesum class='data' link-for="MLGraphBuilder/cumulativeSum(input, axis, options)">
  <caption>Constraints for {{MLGraphBuilder/cumulativeSum()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLCumulativeSumOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLCumulativeSumOptions>
    : <dfn>exclusive</dfn>
    ::
        Whether to include or exclude the current value in the output, meaning inclusive prefix sum or exclusive prefix sum [[Prefix-sum]]. Given input *[1,2,3,4]*, inclusive summation would yield an output of *[1,3,6,10]* whereas exclusive would yield *[0,1,3,6]*. The default is inclusive.

    : <dfn>reversed</dfn>
    ::
        Whether to reverse the summation direction along the active axis to instead start from the high coordinate to low coordinate. Given input *[1,2,3,4]*, inclusive forward summation would yield an output of *[1,3,6,10]* whereas inclusive backward summation would yield *[10,9,7,4]*. The default is forward.
</dl>

<div dfn-for="MLGraphBuilder/cumulativeSum(input, axis, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>axis</dfn>: an {{unsigned long}} scalar. The axis the summation will be performed on. Its value must be in the range [0, N-1] where N is {{MLGraphBuilder/cumulativeSum(input, axis, options)/input}}'s [=MLOperand/rank=].
        - <dfn>options</dfn>: an {{MLCumulativeSumOptions}}. Specifies the optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/cumulativeSum(input, axis, options)/input}}.
</div>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/cumulativeSum()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>cumulativeSum</dfn>
    :: Support limits for operator {{MLGraphBuilder/cumulativeSum()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>cumulativeSum(|input|, |axis|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-cumulativesum)), then [=exception/throw=] a {{TypeError}}.
    1. If |axis| is greater than or equal to |input|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "cumulativeSum" operation and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>


### Element-wise binary operations ### {#api-mlgraphbuilder-binary}
Compute the element-wise binary addition, subtraction, multiplication, division, power, maximum and minimum of the two input tensors.

The operation will be [=broadcast=] according to [[!numpy-broadcasting-rule]]. The input tensors must be [=bidirectionally broadcastable=]. The [=MLOperand/rank=] of the output tensor is the maximum [=MLOperand/rank=] of the input tensors. For each dimension of the output tensor, its size is the maximum size along that dimension of the input tensors.

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand add(MLOperand a, MLOperand b, optional MLOperatorOptions options = {});
  MLOperand sub(MLOperand a, MLOperand b, optional MLOperatorOptions options = {});
  MLOperand mul(MLOperand a, MLOperand b, optional MLOperatorOptions options = {});
  MLOperand div(MLOperand a, MLOperand b, optional MLOperatorOptions options = {});
  MLOperand max(MLOperand a, MLOperand b, optional MLOperatorOptions options = {});
  MLOperand min(MLOperand a, MLOperand b, optional MLOperatorOptions options = {});
  MLOperand pow(MLOperand a, MLOperand b, optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLBinarySupportLimits add;
  MLBinarySupportLimits sub;
  MLBinarySupportLimits mul;
  MLBinarySupportLimits div;
  MLBinarySupportLimits max;
  MLBinarySupportLimits min;
  MLBinarySupportLimits pow;
};
</script>

<div dfn-for="MLGraphBuilder/add(a, b, options), MLGraphBuilder/sub(a, b, options), MLGraphBuilder/mul(a, b, options), MLGraphBuilder/div(a, b, options), MLGraphBuilder/max(a, b, options), MLGraphBuilder/min(a, b, options), MLGraphBuilder/pow(a, b, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>a</dfn>: an {{MLOperand}}. The first input tensor.
        - <dfn>b</dfn>: an {{MLOperand}}. The second input tensor.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output tensor that contains the result of
    element-wise binary operation of the two input tensors.
</div>
<div>
    **Operation types:**
        - *add*: Add the values of the two input tensors, element-wise.
        - *sub*: Subtract the values of the second input tensor from the values of the first input tensor, element-wise.
        - *mul*: Multiply the values of the two input tensors, element-wise.
        - *div*: Divide the values of the first input tensor with the values of the second tensor, element-wise.
        - *max*: Select the greater values of the two input tensors, element-wise.
        - *min*: Select the lesser values of the two input tensors, element-wise.
        - *pow*: Compute the values of the values of the first input tensor to the power of the values of the second input tensor, element-wise.
</div>

<table id=constraints-elementwise-binary class='data' link-for="MLGraphBuilder/add(a, b, options), MLGraphBuilder/sub(a, b, options), MLGraphBuilder/mul(a, b, options), MLGraphBuilder/div(a, b, options), MLGraphBuilder/max(a, b, options), MLGraphBuilder/min(a, b, options), MLGraphBuilder/pow(a, b, options)">
  <caption>Constraints for element-wise binary options</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{a}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>{{b}}</td>
    <td>[=/same type as|same as=] {{a}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{a}}</td>
    <td>maximum of {{a}}'s [=MLOperand/rank=] and {{b}}'s [=MLOperand/rank=]</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following members for element-wise binary operations:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>add</dfn>
    :: Support limits for operator {{MLGraphBuilder/add()}}.
    : <dfn>sub</dfn>
    :: Support limits for operator {{MLGraphBuilder/sub()}}.
    : <dfn>mul</dfn>
    :: Support limits for operator {{MLGraphBuilder/mul()}}.
    : <dfn>div</dfn>
    :: Support limits for operator {{MLGraphBuilder/div()}}.
    : <dfn>max</dfn>
    :: Support limits for operator {{MLGraphBuilder/max()}}.
    : <dfn>min</dfn>
    :: Support limits for operator {{MLGraphBuilder/min()}}.
    : <dfn>pow</dfn>
    :: Support limits for operator {{MLGraphBuilder/pow()}}.
</dl>

<details open algorithm>
  <summary>
    To <dfn for="MLGraphBuilder" data-lt="element-wise-binary-op">create element-wise binary operation</dfn> given [=string=] |op|, {{MLOperand}} |a|, {{MLOperand}} |b|, and {{MLOperatorOptions}} |options|, run the following steps:
  </summary>
    1. [=Assert=]: |op| is one of "add", "sub", "mul", "div", "max", "min", "pow".
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |a| and |b| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |a|'s [=MLOperand/dataType=] is not equal to |b|'s [=MLOperand/dataType=], then [=exception/throw=] a {{TypeError}}.
    1. Let |outputShape| be the result of [=bidirectionally broadcasting=] |a|'s [=MLOperand/shape=] and |b|'s [=MLOperand/shape=].
        1. If that returns failure, then [=exception/throw=] a {{TypeError}}.
    1. Let |descriptor| be the result of [=creating an MLOperandDescriptor=] given |a|'s [=MLOperand/dataType=] and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |descriptor|.
        1. Let |operator| be an [=operator=] for the |op| operation, given |a|, |b|, and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |a| and |b|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<details open>
  <summary>
    The element-wise binary operation algorithms invoke the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation=] steps as follows.
  </summary>
    <div algorithm>
    The <dfn method for=MLGraphBuilder>add(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation=] given "add", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>sub(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation=] given "sub", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>mul(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation=] given "mul", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>div(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation=] given "div", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>max(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation=] given "max", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>min(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation=] given "min", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>pow(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-binary-op | create element-wise binary operation=] given "pow", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>
</details>

### Element-wise logical operations ### {#api-mlgraphbuilder-logical}
Compare input tensors element-wise and return a {{MLOperandDataType/"uint8"}} tensor of values 0 (false) or 1 (true) for the comparisons. For single-operand operations, return the logical results of the operation.

For multiple-operand operations, the operation will be [=broadcast=] according to [[!numpy-broadcasting-rule]]. The input tensors must be [=bidirectionally broadcastable=]. The [=MLOperand/rank=] of the output tensor is the maximum [=MLOperand/rank=] of the input tensors. For each dimension of the output tensor, its size is the maximum size along that dimension of the input tensors.

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand equal(MLOperand a,
                  MLOperand b,
                  optional MLOperatorOptions options = {});
  MLOperand notEqual(MLOperand a,
                     MLOperand b,
                     optional MLOperatorOptions options = {});
  MLOperand greater(MLOperand a,
                    MLOperand b,
                    optional MLOperatorOptions options = {});
  MLOperand greaterOrEqual(MLOperand a,
                           MLOperand b,
                           optional MLOperatorOptions options = {});
  MLOperand lesser(MLOperand a,
                   MLOperand b,
                   optional MLOperatorOptions options = {});
  MLOperand lesserOrEqual(MLOperand a,
                          MLOperand b,
                          optional MLOperatorOptions options = {});
  MLOperand logicalNot(MLOperand a, optional MLOperatorOptions options = {});
  MLOperand logicalAnd(MLOperand a,
                       MLOperand b,
                       optional MLOperatorOptions options = {});
  MLOperand logicalOr(MLOperand a,
                      MLOperand b,
                      optional MLOperatorOptions options = {});
  MLOperand logicalXor(MLOperand a,
                       MLOperand b,
                       optional MLOperatorOptions options = {});
};

dictionary MLLogicalNotSupportLimits {
  MLTensorLimits a;
  MLDataTypeLimits output;
};

partial dictionary MLOpSupportLimits {
  MLBinarySupportLimits equal;
  MLBinarySupportLimits notEqual;
  MLBinarySupportLimits greater;
  MLBinarySupportLimits greaterOrEqual;
  MLBinarySupportLimits lesser;
  MLBinarySupportLimits lesserOrEqual;
  MLLogicalNotSupportLimits logicalNot;
  MLBinarySupportLimits logicalAnd;
  MLBinarySupportLimits logicalOr;
  MLBinarySupportLimits logicalXor;
};
</script>

<div dfn-for="MLGraphBuilder/equal(a, b, options), MLGraphBuilder/notEqual(a, b, options), MLGraphBuilder/greater(a, b, options), MLGraphBuilder/greaterOrEqual(a, b, options), MLGraphBuilder/lesser(a, b, options), MLGraphBuilder/lesserOrEqual(a, b, options), MLGraphBuilder/logicalNot(a, options), MLGraphBuilder/logicalAnd(a, b, options), MLGraphBuilder/logicalOr(a, b, options), MLGraphBuilder/logicalXor(a, b, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>a</dfn>: an {{MLOperand}}. The first input tensor.
        - <dfn>b</dfn>: an {{MLOperand}}. The second input tensor when specified.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output tensor that contains the result of element-wise comparison of the two input tensors.
</div>

<table id=constraints-elementwise-logical class='data' link-for="MLGraphBuilder/equal(a, b, options), MLGraphBuilder/notEqual(a, b, options), MLGraphBuilder/greater(a, b, options), MLGraphBuilder/greaterOrEqual(a, b, options), MLGraphBuilder/lesser(a, b, options), MLGraphBuilder/lesserOrEqual(a, b, options), MLGraphBuilder/logicalNot(a, options), MLGraphBuilder/logicalAnd(a, b, options), MLGraphBuilder/logicalOr(a, b, options), MLGraphBuilder/logicalXor(a, b, options)">
  <caption>Constraints for element-wise logical options</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{a}}</td>
    <td>specified as part of operation steps</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>{{b}}</td>
    <td>[=/same type as|same as=] {{a}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{a}}</td>
    <td>maximum of {{a}}'s [=MLOperand/rank=] and {{b}}'s [=MLOperand/rank=]</td>
  </tr>
</table>


{{MLLogicalNotSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLLogicalNotSupportLimits>
    : <dfn>a</dfn>
    :: {{MLTensorLimits}} for a operand.
    : <dfn>output</dfn>
    :: {{MLDataTypeLimits}} for output operand.
</dl>

{{MLOpSupportLimits}} has the following members for element-wise logical operations:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>equal</dfn>
    :: Support limits for operator {{MLGraphBuilder/equal()}}.
    : <dfn>notEqual</dfn>
    :: Support limits for operator {{MLGraphBuilder/notEqual()}}.
    : <dfn>greater</dfn>
    :: Support limits for operator {{MLGraphBuilder/greater()}}.
    : <dfn>greaterOrEqual</dfn>
    :: Support limits for operator {{MLGraphBuilder/greaterOrEqual()}}.
    : <dfn>lesser</dfn>
    :: Support limits for operator {{MLGraphBuilder/lesser()}}.
    : <dfn>lesserOrEqual</dfn>
    :: Support limits for operator {{MLGraphBuilder/lesserOrEqual()}}.
    : <dfn>logicalNot</dfn>
    :: Support limits for operator {{MLGraphBuilder/logicalNot()}}.
    : <dfn>logicalAnd</dfn>
    :: Support limits for operator {{MLGraphBuilder/logicalAnd()}}.
    : <dfn>logicalOr</dfn>
    :: Support limits for operator {{MLGraphBuilder/logicalOr()}}.
    : <dfn>logicalXor</dfn>
    :: Support limits for operator {{MLGraphBuilder/logicalXor()}}.
</dl>

<div>
    **Operation types:**
        - *equal*: Compare if the values of the two input tensors are equal, element-wise.
        - *notEqual*: Compare if the values of the two input tensors are not equal, element-wise.
        - *greater*: Compare if the values of the first input tensor is greater, element-wise.
        - *greaterOrEqual*: Compare if the values of the first input tensor is greater or equal, element-wise.
        - *lesser*: Compare if the values of the first input tensor is lesser, element-wise.
        - *lesserOrEqual*: Compare if the values of the first input tensor is lesser or equal, element-wise.
        - *logicalNot*: Invert the values of the input tensor to values 0 or 1, element-wise. Specifically, when the input value is non-zero, invert it to 0. Conversely, for a zero input value, invert it to 1.
        - *logicalAnd*: Compute the logical *and* of the two input tensors, element-wise, treating any non-zero value as true and returning elements of 0 or 1.
        - *logicalOr*: Compute the logical *or* of the two input tensors, element-wise, treating any non-zero value as true and returning elements of 0 or 1.
        - *logicalXor*: Compute the logical *xor* of the two input tensors, element-wise, treating any non-zero value as true and returning elements of 0 or 1.
</div>

<div class="note">
Although operations {{MLGraphBuilder/greaterOrEqual()}} and {{MLGraphBuilder/lesserOrEqual()}} can each be implemented in terms of operations {{MLGraphBuilder/logicalNot()}}, {{MLGraphBuilder/lesser()}}, and {{MLGraphBuilder/greater()}} (in other words `builder.greaterOrEqual(a, b)` is `builder.logicalNot(builder.lesser(a, b))`), they are specifically defined to handle NaN cases and for performance reason to avoid double comparisons.
</div>

<details open algorithm>
  <summary>
    To <dfn for="MLGraphBuilder" data-lt="element-wise-logical-op">create element-wise logical operation</dfn> given [=string=] |op|, {{MLOperand}} |a|, an optional {{MLOperand}} |b|, and {{MLOperatorOptions}} |options|, run the following steps:
  </summary>
    1. [=Assert=]: |op| is one of "equal", "notEqual", "greater", "greaterOrEqual", "lesser", "lesserOrEqual", "logicalNot", "logicalAnd", "logicalOr", "logicalXor".
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |a| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |op| is one of "logicalNot", "logicalAnd", "logicalOr", "logicalXor":
        1. If |a|'s [=MLOperand/dataType=] is not {{MLOperandDataType/"uint8"}}, then [=exception/throw=] a {{TypeError}}.
    1. If |b| is passed:
        1. If [=MLGraphBuilder/validating operand=] with [=this=] and |b| returns false, then [=exception/throw=] a {{TypeError}}.
        1. If |a|'s [=MLOperand/dataType=] is not equal to |b|'s [=MLOperand/dataType=], then [=exception/throw=] a {{TypeError}}.
        1. Let |outputShape| be the result of [=bidirectionally broadcasting=] |a|'s [=MLOperand/shape=] and |b|'s [=MLOperand/shape=]. If that returns failure, then [=exception/throw=] a {{TypeError}}.
    1. Otherwise:
        1. Let |outputShape| be a [=list/clone=] of |a|'s [=MLOperand/shape=].
    1. Let |descriptor| be the result of [=creating an MLOperandDescriptor=] given {{MLOperandDataType/"uint8"}} and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |descriptor|.
        1. Let |operator| be an [=operator=] for the |op| operation, given |a| and (if |b| is passed) |b|, and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |a| and (if |b| is passed) |b|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<details open>
  <summary>
    The element-wise logical operation algorithms invoke the [=MLGraphBuilder/element-wise-logical-op | create element-wise logical operation=] steps as follows.
  </summary>
    <div algorithm>
    The <dfn method for=MLGraphBuilder>equal(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-logical-op | create element-wise logical operation=] given "equal", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>notEqual(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-logical-op | create element-wise logical operation=] given "notEqual", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>greater(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-logical-op | create element-wise logical operation=] given "greater", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>greaterOrEqual(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-logical-op | create element-wise logical operation=] given "greaterOrEqual", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>lesser(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-logical-op | create element-wise logical operation=] given "lesser", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>lesserOrEqual(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-logical-op | create element-wise logical operation=] given "lesserOrEqual", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>logicalNot(|a|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-logical-op | create element-wise logical operation=] given "logicalNot", |a|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>logicalAnd(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-logical-op | create element-wise logical operation=] given "logicalAnd", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>logicalOr(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-logical-op | create element-wise logical operation=] given "logicalOr", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>logicalXor(|a|, |b|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-logical-op | create element-wise logical operation=] given "logicalXor", |a|, |b|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>
</details>

### Element-wise unary operations ### {#api-mlgraphbuilder-unary}
Compute the element-wise unary operation for input tensor.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand abs(MLOperand input, optional MLOperatorOptions options = {});
  MLOperand ceil(MLOperand input, optional MLOperatorOptions options = {});
  MLOperand cos(MLOperand input, optional MLOperatorOptions options = {});
  MLOperand erf(MLOperand input, optional MLOperatorOptions options = {});
  MLOperand exp(MLOperand input, optional MLOperatorOptions options = {});
  MLOperand floor(MLOperand input, optional MLOperatorOptions options = {});
  MLOperand identity(MLOperand input, optional MLOperatorOptions options = {});
  MLOperand log(MLOperand input, optional MLOperatorOptions options = {});
  MLOperand neg(MLOperand input, optional MLOperatorOptions options = {});
  MLOperand reciprocal(MLOperand input, optional MLOperatorOptions options = {});
  MLOperand sin(MLOperand input, optional MLOperatorOptions options = {});
  MLOperand sign(MLOperand input, optional MLOperatorOptions options = {});
  MLOperand sqrt(MLOperand input, optional MLOperatorOptions options = {});
  MLOperand tan(MLOperand input, optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits abs;
  MLSingleInputSupportLimits ceil;
  MLSingleInputSupportLimits cos;
  MLSingleInputSupportLimits erf;
  MLSingleInputSupportLimits exp;
  MLSingleInputSupportLimits floor;
  MLSingleInputSupportLimits identity;
  MLSingleInputSupportLimits log;
  MLSingleInputSupportLimits neg;
  MLSingleInputSupportLimits reciprocal;
  MLSingleInputSupportLimits sin;
  MLSingleInputSupportLimits sign;
  MLSingleInputSupportLimits sqrt;
  MLSingleInputSupportLimits tan;
};
</script>

<div dfn-for="MLGraphBuilder/abs(input, options), MLGraphBuilder/ceil(input, options), MLGraphBuilder/cos(input, options), MLGraphBuilder/erf(input, options), MLGraphBuilder/exp(input, options), MLGraphBuilder/floor(input, options), MLGraphBuilder/identity(input, options), MLGraphBuilder/log(input, options), MLGraphBuilder/neg(input, options), MLGraphBuilder/reciprocal(input, options), MLGraphBuilder/sin(input, options), MLGraphBuilder/sign(input, options), MLGraphBuilder/sqrt(input, options), MLGraphBuilder/tan(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output tensor that contains the result of
    element-wise unary operation of the input tensor. The shape of the output
    tensor is the same as the shape of input tensor.
</div>

<table id=constraints-elementwise-unary class='data' link-for="MLGraphBuilder/abs(input, options), MLGraphBuilder/ceil(input, options), MLGraphBuilder/cos(input, options), MLGraphBuilder/erf(input, options), MLGraphBuilder/exp(input, options), MLGraphBuilder/floor(input, options), MLGraphBuilder/identity(input, options), MLGraphBuilder/log(input, options), MLGraphBuilder/neg(input, options), MLGraphBuilder/reciprocal(input, options), MLGraphBuilder/sin(input, options), MLGraphBuilder/sign(input, options), MLGraphBuilder/sqrt(input, options), MLGraphBuilder/tan(input, options)">
  <caption>Constraints for element-wise unary options</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>specified as part of operation steps</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>


{{MLOpSupportLimits}} has the following members for element-wise unary operations:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>abs</dfn>
    :: Support limits for operator {{MLGraphBuilder/abs()}}.
    : <dfn>ceil</dfn>
    :: Support limits for operator {{MLGraphBuilder/ceil()}}.
    : <dfn>cos</dfn>
    :: Support limits for operator {{MLGraphBuilder/cos()}}.
    : <dfn>erf</dfn>
    :: Support limits for operator {{MLGraphBuilder/erf()}}.
    : <dfn>exp</dfn>
    :: Support limits for operator {{MLGraphBuilder/exp()}}.
    : <dfn>floor</dfn>
    :: Support limits for operator {{MLGraphBuilder/floor()}}.
    : <dfn>identity</dfn>
    :: Support limits for operator {{MLGraphBuilder/identity()}}.
    : <dfn>log</dfn>
    :: Support limits for operator {{MLGraphBuilder/log()}}.
    : <dfn>neg</dfn>
    :: Support limits for operator {{MLGraphBuilder/neg()}}.
    : <dfn>reciprocal</dfn>
    :: Support limits for operator {{MLGraphBuilder/reciprocal()}}.
    : <dfn>sin</dfn>
    :: Support limits for operator {{MLGraphBuilder/sin()}}.
    : <dfn>sign</dfn>
    :: Support limits for operator {{MLGraphBuilder/sign()}}.
    : <dfn>sqrt</dfn>
    :: Support limits for operator {{MLGraphBuilder/sqrt()}}.
    : <dfn>tan</dfn>
    :: Support limits for operator {{MLGraphBuilder/tan()}}.
</dl>

<div>
    **Operation types:**
        - *abs*: Compute the absolute value of the input tensor, element-wise.
        - *ceil*: Compute the ceiling of the input tensor, element-wise.
        - *cos*: Compute the cosine of the input tensor, element-wise.
        - *erf*: Compute the error function [[Error-Function]] of the input tensor, element-wise.
        - *exp*: Compute the exponential of the input tensor, element-wise.
        - *floor*: Compute the floor of the input tensor, element-wise.
        - *identity*: Copy the value of the input tensor to the output tensor, element-wise.
        - *log*: Compute the natural logarithm of the input tensor, element-wise.
        - *neg*: Compute the numerical negative value of the input tensor, element-wise.
        - *reciprocal*: Compute the reciprocal of the input tensor, element-wise.
        - *sin*: Compute the sine of the input tensor, element-wise.
        - *sign*: Compute the sign (-1, 0, 1) of the input tensor, element-wise, returning 1 if > 0, -1 if < 0, and 0 otherwise.
        - *sqrt*: Compute the square root of the input tensor, element-wise.
        - *tan*: Compute the tangent of the input tensor, element-wise.
</div>

<details open algorithm>
  <summary>
    To <dfn for="MLGraphBuilder" data-lt="element-wise-unary-op">create element-wise unary operation</dfn> given [=string=] |op|, {{MLOperand}} |input|, optional [=/list=] |allowedDataTypes|, and |options|, run the following steps:
  </summary>
    1. [=Assert=]: |op| is one of "abs", "ceil", "cos", "erf", "exp", "floor", "identity", "log", "neg", "reciprocal", "sin", "sign", "sqrt", "tan".
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |allowedDataTypes| is given and it does not [=list/contain=] |input|'s [=MLOperand/dataType=], then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the |op| operation given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<details open>
  <summary>
    The element-wise unary operation algorithms invoke the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] steps as follows.
  </summary>
    <div algorithm>
    The <dfn method for=MLGraphBuilder>abs(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] given "abs", |input|, « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}, {{MLOperandDataType/"int32"}}, {{MLOperandDataType/"int8"}} », and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>ceil(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] given "ceil", |input|, « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} », and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>cos(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] given "cos", |input|, « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} », and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>erf(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] given "erf", |input|, « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} », and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>exp(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] given "exp", |input|, « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} », and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>floor(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] given "floor", |input|, « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} », and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>identity(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] given "identity" |input|, and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>log(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] given "log", |input|, « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} », and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>neg(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] given "neg", |input|, « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}, {{MLOperandDataType/"int32"}}, {{MLOperandDataType/"int8"}} », and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>reciprocal(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] given "reciprocal", |input|, « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} », and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>sin(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] given "sin", |input|, « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} », and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>sign(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] given "sign", |input|, « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}, {{MLOperandDataType/"int32"}}, {{MLOperandDataType/"int8"}} », and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>sqrt(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] given "sqrt", |input|, « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} », and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>tan(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/element-wise-unary-op | create element-wise unary operation=] given "tan", |input|, « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} », and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of the {{MLGraphBuilder/sign()}} operation can be [EMULATED]
    </summary>
    <pre highlight="js">
    function sign(builder, input, options) {
      const zero = builder.constant(input.dataType, 0);
      const positiveOne = builder.constant(input.dataType, 1);
      const negativeOne = builder.constant(input.dataType, -1);

      return builder.where(
        builder.greater(input, zero),
        positiveOne,
        builder.where(
          builder.lesser(input, zero),
          negativeOne,
          zero));
    }
    </pre>
  </details>
</div>


### dequantizeLinear ### {#api-mlgraphbuilder-dequantizelinear}
Dequantizes an integer tensor to floating point tensor using the scale and zero-point bias, where `output = (input - zeroPoint) * scale`. The {{MLGraphBuilder/dequantizeLinear(input, scale, zeroPoint, options)/scale}} and {{MLGraphBuilder/dequantizeLinear(input, scale, zeroPoint, options)/zeroPoint}} tensors can be smaller than the {{MLGraphBuilder/dequantizeLinear(input, scale, zeroPoint, options)/input}} tensor as they are [=blockwise broadcastable=].

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand dequantizeLinear(MLOperand input,
                             MLOperand scale,
                             MLOperand zeroPoint,
                             optional MLOperatorOptions options = {});
};

dictionary MLQuantizeDequantizeLinearSupportLimits {
  MLTensorLimits input;
  MLTensorLimits scale;
  MLTensorLimits zeroPoint;
  MLDataTypeLimits output;
};

partial dictionary MLOpSupportLimits {
  MLQuantizeDequantizeLinearSupportLimits dequantizeLinear;
};
</script>

<div dfn-for="MLGraphBuilder/dequantizeLinear(input, scale, zeroPoint, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>scale</dfn>: an {{MLOperand}}. The scale tensor to multiply each input value by after adjusting by the zero point. It must be [=blockwise broadcastable=] with the input.
        - <dfn>zeroPoint</dfn>: an {{MLOperand}}. The zero point tensor to subtract from each input value. It has the same [=MLOperand/shape=] as the scale.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output tensor that contains the dequantized values.
</div>

<table id=constraints-dequantizelinear class='data' link-for="MLGraphBuilder/dequantizeLinear(input, scale, zeroPoint, options)">
  <caption>Constraints for {{MLGraphBuilder/dequantizeLinear()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"uint8"}}, {{MLOperandDataType/"int8"}}, {{MLOperandDataType/"uint32"}}, {{MLOperandDataType/"int32"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>{{scale}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
  <tr>
    <td>{{zeroPoint}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{scale}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLQuantizeDequantizeLinearSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLQuantizeDequantizeLinearSupportLimits>
    : <dfn>input</dfn>
    :: {{MLTensorLimits}} for input operand.
    : <dfn>scale</dfn>
    :: {{MLTensorLimits}} for scale operand.
    : <dfn>zeroPoint</dfn>
    :: {{MLTensorLimits}} for zeroPoint operand.
    : <dfn>output</dfn>
    :: {{MLDataTypeLimits}} for output operand.
</dl>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/dequantizeLinear()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>dequantizeLinear</dfn>
    :: Support limits for operator {{MLGraphBuilder/dequantizeLinear()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>dequantizeLinear(|input|, |scale|, |zeroPoint|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=].{{MLGraphBuilder/[[hasBuilt]]}} is true, then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input|, |scale|, and |zeroPoint| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-dequantizelinear)), then [=exception/throw=] a {{TypeError}}.
    1. If |scale|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-dequantizelinear)), then [=exception/throw=] a {{TypeError}}.
    1. If |zeroPoint|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-dequantizelinear)), then [=exception/throw=] a {{TypeError}}.
    1. If |scale|'s [=MLOperand/rank=] or |zeroPoint|'s [=MLOperand/rank=] is not equal to |input|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
    1. If |scale|'s [=MLOperand/shape=] is not [=list/equal=] to |zeroPoint|'s [=MLOperand/shape=], then [=exception/throw=] a {{TypeError}}.
    1. If [=blockwise broadcasting=] |scale|'s [=MLOperand/shape=] and |input|'s [=MLOperand/shape=] returns false, then [=exception/throw=] a {{TypeError}}.
    1. If [=blockwise broadcasting=] |zeroPoint|'s [=MLOperand/shape=] and |input|'s [=MLOperand/shape=] returns false, then [=exception/throw=] a {{TypeError}}.
    1. Let |outputDescriptor| be the result of [=creating an MLOperandDescriptor=] given |scale|'s [=MLOperand/dataType=] and |input|'s [=MLOperand/shape=].
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |outputDescriptor|.
        1. Let |operator| be an [=operator=] for the "dequantizeLinear" operation, given |input|, |scale|, |zeroPoint|, and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be [EMULATED]
    </summary>
    <pre highlight="js">
    function dequantizeLinear(builder, input, scale, zeroPoint, options) {
      // output = (input - zeroPoint) * scale
      const floatInput = builder.cast(input, scale.dataType);
      const floatZeroPoint = builder.cast(zeroPoint, scale.dataType);
      const upsampledScale = blockwiseExpand(builder, scale, input.shape);
      const upsampledZeroPoint = blockwiseExpand(builder, floatZeroPoint, input.shape);
      return builder.mul(builder.sub(floatInput, upsampledZeroPoint), upsampledScale);
    }

    function blockwiseExpand(builder, input, outputShape) {
      // Given the original input and a desired output shape, this expands each axis
      // by repeating the block the number of times per that axis. Though, backend
      // implementations might have much more efficient upsampling operators that
      // can accept multiple dimensions to upsample all dimensions at once by
      // integer multiples (like tile) using nearest neighbor resampling:
      // output = resample(scale, {sizes: input.shape})

      let output = input;

      for (let axis = 0; axis < input.shape.length; ++axis) {
        const oldShape = output.shape;
        const oldDimensionLength = oldShape[axis];
        const newDimensionLength = outputShape[axis];

        if (newDimensionLength != oldDimensionLength) {
          // Since tile/expand can only accept repetitions of entire dimension
          // slices (not repeating individual elements along an axis), temporarily
          // reshape the tensor to enable them to broadcast the elements up to the
          // full block size, utilizing an inserted dimension of size 1.
          const elementRepeatCount = newDimensionLength / oldDimensionLength;
          const flattenedShape = getFlattenedShapeAroundAxis(oldShape, axis);
          const unexpandedShape = [flattenedShape[0], flattenedShape[1], 1, flattenedShape[2]];
          const expandedShape = [flattenedShape[0], flattenedShape[1], elementRepeatCount, flattenedShape[2]];
          const reshapedInput = builder.reshape(output, unexpandedShape);
          output = builder.expand(reshapedInput, expandedShape);

          let newShape = [...oldShape];
          newShape[axis] = newDimensionLength;
          output = builder.reshape(output, newShape);
        }
      }

      return output;
    }

    // Compute the flattened shape before and after the given axis, yielding a 3-element list.
    // e.g. inputShape = [2,3,4,5,6] with axis = 2 yields shape [6,4,30].
    // e.g. inputShape = [4] with axis = 0 yields shape [1,4,1].
    function getFlattenedShapeAroundAxis(inputShape, axis) {
      axis = Math.max(Math.min(axis, input.shape.length - 1), 0);
      const countBefore = axis.slice(0, axis).reduce((a, b) => a * b, 1);
      const countAfter = axis.slice(axis + 1, input.shape.length).reduce((a, b) => a * b, 1);
      return [countBefore, inputShape[axis], countAfter];
    }
    </pre>
  </details>
</div>


### quantizeLinear ### {#api-mlgraphbuilder-quantizelinear}
Quantizes a floating point tensor to integer tensor using the scale and zero-point bias (e.g. `output = clamp(roundEven(input / scale) + zeroPoint, 0, 255)` for "uint8").  The *scale* and *zeroPoint* tensors can be smaller than the *input* tensor as they are [=blockwise broadcast=].

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand quantizeLinear(MLOperand input,
                           MLOperand scale,
                           MLOperand zeroPoint,
                           optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLQuantizeDequantizeLinearSupportLimits quantizeLinear;
};
</script>

<div dfn-for="MLGraphBuilder/quantizeLinear(input, scale, zeroPoint, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>scale</dfn>: an {{MLOperand}}. The scale tensor to divide each input value by before adjusting by the zero point. It must be [=blockwise broadcastable=] with the input.
        - <dfn>zeroPoint</dfn>: an {{MLOperand}}. The zero point tensor to add to each rescaled input value. It has the same [=MLOperand/shape=] as the scale.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output tensor that contains the quantized values.
</div>

<table id=constraints-quantizelinear class='data' link-for="MLGraphBuilder/quantizeLinear(input, scale, zeroPoint, options)">
  <caption>Constraints for {{MLGraphBuilder/quantizeLinear()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>{{scale}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
  <tr>
    <td>{{zeroPoint}}</td>
    <td>{{MLOperandDataType/"uint8"}}, {{MLOperandDataType/"int8"}}, {{MLOperandDataType/"uint32"}}, {{MLOperandDataType/"int32"}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{zeroPoint}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/quantizeLinear()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>quantizeLinear</dfn>
    :: Support limits for operator {{MLGraphBuilder/quantizeLinear()}}.
</dl>


<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>quantizeLinear(|input|, |scale|, |zeroPoint|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=].{{MLGraphBuilder/[[hasBuilt]]}} is true, then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input|, |scale|, and |zeroPoint| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-quantizelinear)), then [=exception/throw=] a {{TypeError}}.
    1. If |scale|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-quantizelinear)), then [=exception/throw=] a {{TypeError}}.
    1. If |zeroPoint|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-quantizelinear)), then [=exception/throw=] a {{TypeError}}.
    1. If |scale|'s [=MLOperand/rank=] or |zeroPoint|'s [=MLOperand/rank=] is not equal to |input|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
    1. If |scale|'s [=MLOperand/shape=] is not [=list/equal=] to |zeroPoint|'s [=MLOperand/shape=], then [=exception/throw=] a {{TypeError}}.
    1. If [=blockwise broadcasting=] |scale|'s [=MLOperand/shape=] and |input|'s [=MLOperand/shape=] returns false, then [=exception/throw=] a {{TypeError}}.
    1. If [=blockwise broadcasting=] |zeroPoint|'s [=MLOperand/shape=] and |input|'s [=MLOperand/shape=] returns false, then [=exception/throw=] a {{TypeError}}.
    1. Let |outputDescriptor| be the result of [=creating an MLOperandDescriptor=] given |zeroPoint|'s [=MLOperand/dataType=] and |input|'s [=MLOperand/shape=].
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |outputDescriptor|.
        1. Let |operator| be an [=operator=] for the "quantizeLinear" operation, given |input|, |scale|, |zeroPoint|, and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be [EMULATED]
    </summary>
    This emulation relies on a pending `roundEven` operator in <#817>.
    <pre highlight="js">
    function quantizeLinear(builder, input, scale, zeroPoint, options) {
      // output = clamp(roundEven(input / scale) + zeroPoint, 0, 255)
      // Note blockwiseExpand is defined in dequantizeLinear.

      const floatZeroPoint = builder.cast(zeroPoint, scale.dataType);
      const upsampledScale = blockwiseExpand(builder, scale, input.shape);
      const upsampledZeroPoint = blockwiseExpand(builder, floatZeroPoint, input.shape);
      const quantizedInput = builder.roundEven(builder.div(input, upsampledScale));
      const zeroPointAdjustedInput = builder.add(quantizedInput, upsampledZeroPoint);
      const clampedInput = builder.clamp(zeroPointAdjustedInput, {'minValue': 0, 'maxValue': 255});
      return builder.cast(clampedInput, zeroPoint.dataType);
    }
    </pre>
  </details>
</div>


### elu ### {#api-mlgraphbuilder-elu}
Calculate the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#ELU"> exponential linear unit function</a> (ELU) on the input tensor element-wise. The calculation follows the expression `max(0, x) + alpha * (exp(min(0, x)) - 1)`.

<script type=idl>
dictionary MLEluOptions : MLOperatorOptions {
  double alpha = 1;
};

partial interface MLGraphBuilder {
  MLOperand elu(MLOperand input, optional MLEluOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits elu;
};
</script>

{{MLEluOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLEluOptions>
    : <dfn>alpha</dfn>
    :: A scalar multiplier.
</dl>

<div dfn-for="MLGraphBuilder/elu(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an optional {{MLEluOptions}}. The optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/elu(input, options)/input}}.
</div>

<table id=constraints-elu class='data' link-for="MLGraphBuilder/elu(input, options)">
  <caption>Constraints for {{MLGraphBuilder/elu()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following members for {{MLGraphBuilder/elu()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>elu</dfn>
    :: Support limits for operator {{MLGraphBuilder/elu()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>elu(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-elu)), then [=exception/throw=] a {{TypeError}}.
    1. Set |options|.{{MLEluOptions/alpha}} to the result of [=casting=] |options|.{{MLEluOptions/alpha}} to |input|'s [=MLOperand/dataType=].
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "elu" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be [EMULATED]
    </summary>
    <pre highlight="js">
    function elu(builder, input, options) {
      return builder.add(
        builder.max(builder.constant(input.dataType, 0), input),
        builder.mul(
          builder.constant(input.dataType, options.alpha),
          builder.sub(
            builder.exp(builder.min(builder.constant(input.dataType, 0), input)),
            builder.constant(input.dataType, 1))));
    }
    </pre>
  </details>
</div>

### expand ### {#api-mlgraphbuilder-expand}
Expand any dimension of size 1 of the input tensor to a larger size according to the new shape. The expansion is consistent with [[!numpy-broadcasting-rule]]. The input tensor must be [=unidirectionally broadcastable=] to the new shape; each dimension must be of size 1 or match the sizes of the corresponding output dimensions according to the new shape.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand expand(MLOperand input,
                   sequence<[EnforceRange] unsigned long> newShape,
                   optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits expand;
};
</script>
<div dfn-for="MLGraphBuilder/expand(input, newShape, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. An input tensor
        - <dfn>newShape</dfn>: [=sequence=]<{{unsigned long}}>. The new shape the input tensor is expanded to.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The tensor with expanded size shape.
</div>

<table id=constraints-expand class='data' link-for="MLGraphBuilder/expand(input, newShape, options)">
  <caption>Constraints for {{MLGraphBuilder/expand()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>{{newShape}}'s [=list/size=]</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following members for {{MLGraphBuilder/expand()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>expand</dfn>
    :: Support limits for operator {{MLGraphBuilder/expand()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>expand(|input|, |newShape|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. Let |outputShape| be the result of [=unidirectionally broadcasting=] |input|'s [=MLOperand/shape=] and |newShape|.
        1. If that returns failure, then [=exception/throw=] a {{TypeError}}.
    1. Let |outputDescriptor| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |outputDescriptor|.
        1. Let |operator| be an [=operator=] for the "expand" operation, given |input|, |newShape|, and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

### gather ### {#api-mlgraphbuilder-gather}
Gather values of the input tensor along an axis according to the indices.
<script type=idl>
dictionary MLGatherOptions : MLOperatorOptions {
  [EnforceRange] unsigned long axis = 0;
};

partial interface MLGraphBuilder {
  MLOperand gather(MLOperand input,
                   MLOperand indices,
                   optional MLGatherOptions options = {});
};

dictionary MLGatherSupportLimits {
  MLTensorLimits input;
  MLTensorLimits indices;
  MLDataTypeLimits output;
};

partial dictionary MLOpSupportLimits {
  MLGatherSupportLimits gather;
};
</script>

{{MLGatherOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLGatherOptions>
    : <dfn>axis</dfn>
    ::
        The axis along which the gathered values are obtained. Its value must be in the range [0, N-1] where N is the [=MLOperand/rank=] of the input tensor.
</dl>

<div dfn-for="MLGraphBuilder/gather(input, indices, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input N-D tensor from which the values are gathered.
        - <dfn>indices</dfn>: an {{MLOperand}}. The indices N-D tensor of the input values to gather. The values must be of type {{MLOperandDataType/"int32"}}, {{MLOperandDataType/"uint32"}}, or {{MLOperandDataType/"int64"}}, and must be in the range -N (inclusive) to N (exclusive) where N is the size of the input dimension indexed by {{MLGatherOptions/axis}}, and a negative index means indexing from the end of the dimension.
        - <dfn>options</dfn>: an optional {{MLGatherOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output N-D tensor of [=MLOperand/rank=] equal to the [=MLOperand/rank=] of {{MLGraphBuilder/gather(input, indices, options)/input}} + the [=MLOperand/rank=] of {{MLGraphBuilder/gather(input, indices, options)/indices}} - 1.
</div>

<div class="note">
  The {{MLGraphBuilder/gather(input, indices, options)/indices}} parameter to {{MLGraphBuilder/gather()}} can not be clamped to the allowed range when the graph is built because the inputs are not known until execution. Implementations can introduce {{MLGraphBuilder/clamp()}} in the compiled graph if the specified clamping behavior is not provided by the underlying platform. Similarly, if the underlying platform does not support negative indices, the implementation can introduce operations in the compiled graph to transform a negative index from the end of the dimension into a positive index.
</div>

<table id=constraints-gather class='data' link-for="MLGraphBuilder/gather(input, indices, options)">
  <caption>Constraints for {{MLGraphBuilder/gather()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>{{indices}}</td>
    <td>{{MLOperandDataType/"int32"}}, {{MLOperandDataType/"uint32"}}, {{MLOperandDataType/"int64"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>{{input}}'s [=MLOperand/rank=] + {{indices}}'s [=MLOperand/rank=] - 1</td>
  </tr>
</table>

{{MLGatherSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLGatherSupportLimits>
    : <dfn>input</dfn>
    :: {{MLTensorLimits}} for input operand.
    : <dfn>indices</dfn>
    :: {{MLTensorLimits}} for indices operand.
    : <dfn>output</dfn>
    :: {{MLDataTypeLimits}} for output operand.
</dl>

{{MLOpSupportLimits}} has the following members for {{MLGraphBuilder/gather()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>gather</dfn>
    :: Support limits for operator {{MLGraphBuilder/gather()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>gather(|input|, |indices|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input| and |indices| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |indices|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-gather)), then [=exception/throw=] a {{TypeError}}.
    1. Let |inputShape| be |input|'s [=MLOperand/shape=] and |inputRank| be |input|'s [=MLOperand/rank=].
    1. Let |indicesShape| be |indices|'s [=MLOperand/shape=].
    1. Let |axis| be |options|.{{MLGatherOptions/axis}}.
    1. If |axis| is greater than or equal to |inputRank|, then [=exception/throw=] a {{TypeError}}.
    1. Let |dimCount| be zero.
    1. Let |outputRank| be zero.
    1. Let |outputShape| be an empty list.
    1. [=list/For each=] |size| of |inputShape|:
        1. If |dimCount| is equal to |axis| then [=iteration/break=].
        1. Set |outputShape|[|dimCount|] to |size|.
        1. Increment |dimCount| by one.
    1. Set |outputRank| to |dimCount|.
    1. Let |dimCount| be zero.
    1. [=list/For each=] |size| of |indicesShape|:
        1. Set |outputShape|[|outputRank| + |dimCount|] to |size|.
        1. Increment |dimCount| by one.
    1. Set |outputRank| to |outputRank| + |dimCount|.
    1. Let |dimCount| be zero.
    1. [=list/For each=] |size| of |inputShape|:
        1. If |dimCount| is less than or equal to |axis| then [=iteration/continue=].
        1. Set |outputShape|[|outputRank| + |dimCount| - |axis| - 1] to |size|.
        1. Increment |dimCount| by one.
    1. Let |desc| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given |desc|.
        1. Let |operator| be an [=operator=] for the "gather" operation, given |input|, |indices|, and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |input| and |indices|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="example">
<details open>
  <summary>
    Examples of how gather works in different slicing schemes.
  </summary>
  <pre highlight="js">
    // input of shape [4,3]:
    //   [[ 0,  1,  2],
    //    [10, 11, 12],
    //    [20, 21, 22],
    //    [30, 31, 32]]
    const input = builder.constant(
      {dataType: 'float32', shape: [4, 3]},
      new Float32Array([0, 1, 2, 10, 11, 12, 20, 21, 22, 30, 31, 32]));

    // axis = 0 (default)
    // indices of shape [2]:
    //   [3,1]
    // output of shape [2,3]:
    //   [[30, 31, 32],
    //    [10, 11, 12]]

    const indices1 =
      builder.constant({dataType: 'uint32', shape: [2]}, new Uint32Array([3, 1]));

    const output1 = builder.gather(input, indices1);

    // axis = 1
    // indices of shape [3]:
    //   [2,1,1]
    // output of shape [4,3]:
    //   [[ 2,  1,  1],
    //    [12, 11, 11],
    //    [22, 21, 21],
    //    [32, 31, 31]]

    const indices2 = builder.constant(
      {dataType: 'uint32', shape: [3]}, new Uint32Array([2, 1, 1]));

    const output2 = builder.gather(input, indices2, {axis: 1});

    // axis = 1
    // indices of shape [2,2]:
    //   [[0, 1],
    //    [1, 2]]
    // output of shape [4,2,2]:
    //   [[[ 0,  1], [ 1,  2]],
    //    [[10, 11], [11, 12]],
    //    [[20, 21], [21, 22]],
    //    [[30, 31], [31, 32]]]

    const indices3 = builder.constant(
      {dataType: 'uint32', shape: [2, 2]}, new Uint32Array([0, 1, 1, 2]));

    const output3 = builder.gather(input, indices3, {axis: 1});
  </pre>
</details>
</div>

### gatherElements ### {#api-mlgraphbuilder-gatherelements}
Gather values of the input tensor along an axis according to the indices.

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand gatherElements(MLOperand input,
                           MLOperand indices,
                           optional MLGatherOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLGatherSupportLimits gatherElements;
};
</script>

<div dfn-for="MLGraphBuilder/gatherElements(input, indices, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input N-D tensor from which the values are gathered.
        - <dfn>indices</dfn>: an {{MLOperand}}. The indices N-D tensor of the input values to gather. The values must be of type {{MLOperandDataType/"int32"}}, {{MLOperandDataType/"uint32"}}, or {{MLOperandDataType/"int64"}}, and must be in the range -N (inclusive) to N (exclusive) where N is the size of the input dimension indexed by *options.axis*, and a negative index means indexing from the end of the dimension.
        - <dfn>options</dfn>: an optional {{MLGatherOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output N-D tensor of [=MLOperand/rank=] equal to {{MLGraphBuilder/gatherElements(input, indices, options)/input}}'s [=MLOperand/rank=].
</div>

<table id=constraints-gatherelements class='data' link-for="MLGraphBuilder/gatherElements(input, indices, options)">
  <caption>Constraints for {{MLGraphBuilder/gatherElements()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>1 to [=/any rank|N=]</td>
  </tr>
  <tr>
    <td>{{indices}}</td>
    <td>{{MLOperandDataType/"int32"}}, {{MLOperandDataType/"uint32"}}, {{MLOperandDataType/"int64"}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following members for {{MLGraphBuilder/gatherElements()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>gatherElements</dfn>
    :: Support limits for operator {{MLGraphBuilder/gatherElements()}}.
</dl>

<div class="note">
  The {{MLGraphBuilder/gatherElements(input, indices, options)/indices}} parameter to {{MLGraphBuilder/gatherElements()}} can not be clamped to the allowed range when the graph is built because the inputs are not known until execution. Implementations can introduce {{MLGraphBuilder/clamp()}} in the compiled graph if the specified clamping behavior is not provided by the underlying platform. Similarly, if the underlying platform does not support negative indices, the implementation can introduce operations in the compiled graph to transform a negative index from the end of the dimension into a positive index.
</div>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>gatherElements(|input|, |indices|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input| and |indices| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |indices|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-gatherelements)), then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/rank=] of any of |input| or |indices| is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. Let |axis| be |options|.{{MLGatherOptions/axis}}.
    1. If |axis| is greater than or equal to |input|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
    1. Let |indicesShapeExpected| be a copy of |input|'s [=MLOperand/shape=].
    1. Set |indicesShapeExpected|[|axis|] to |indices|'s [=MLOperand/shape=][|axis|].
    1. If |indices|'s [=MLOperand/shape=] is not equal to |indicesShapeExpected| then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "gatherElements" operation, given |input|, |indices|, and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |input| and |indices|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="example">
<details open>
  <summary>
    Examples of how gatherElements works in different slicing schemes.
  </summary>
  <pre highlight="js">
    // input of shape [4,3]:
    //   [[ 0,  1,  2],
    //    [10, 11, 12],
    //    [20, 21, 22],
    //    [30, 31, 32]]
    // indices of shape [2,3]:
    //   [[3, 1, 1],
    //    [2, 0, 3]]
    // axis = 0 (default)
    // output of shape [2,3]:
    //   [[30, 11, 12],
    //    [20,  1, 32]]

    const input1 = builder.constant(
      {dataType: 'float32', shape: [4, 3]},
      new Float32Array([0, 1, 2, 10, 11, 12, 20, 21, 22, 30, 31, 32]));

    const indices1 = builder.constant(
      {dataType: 'uint32', shape: [2, 3]},
      new Uint32Array([3, 1, 1, 2, 0, 3]));

    const output1 = builder.gatherElements(input1, indices1);

    // input of shape [4,3]:
    //   [[ 0,  1,  2],
    //    [10, 11, 12],
    //    [20, 21, 22],
    //    [30, 31, 32]]
    // indices of shape [4,1]:
    //   [[2],
    //    [1],
    //    [0],
    //    [2]],
    // axis = 1
    // output of shape [4,1]:
    //   [[ 2],
    //    [11],
    //    [20],
    //    [32]]

    const indices2 = builder.constant(
      {dataType: 'uint32', shape: [4, 1]},
      new Uint32Array([2, 1, 0, 2]));

    const output2 = builder.gatherElements(input1, indices2, {axis: 1});

    // input of shape [4,2,2]:
    //   [[[  0,   1],
    //     [ 10,  11]],
    //    [[100, 101],
    //     [110, 111]],
    //    [[200, 201],
    //     [210, 211]],
    //    [[300, 301],
    //     [310, 311]],]
    // indices of shape [1,2,2]:
    //   [[[0, 2],
    //     [1, 3]]],
    // axis = 0
    // output of shape [1,2,2]:
    //   [[[  0, 201],
    //     [110, 311]]]

    const input3 = builder.constant(
      {dataType: 'float32', shape: [4, 2, 2]},
      new Float32Array([0, 1, 10, 11, 100, 101, 110, 111, 200, 201, 210, 211, 300, 301, 310, 311]));

    const indices3 = builder.constant(
      {dataType: 'uint32', shape: [1, 2, 2]},
      new Uint32Array([0, 2, 1, 3]));

    const output3 = builder.gatherElements(input3, indices3, {axis: 0});
  </pre>
</details>
</div>

### gatherND ### {#api-mlgraphbuilder-gathernd}
Gather slices of the input tensor according to the indices.

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand gatherND(MLOperand input,
                     MLOperand indices,
                     optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLGatherSupportLimits gatherND;
};
</script>

<div dfn-for="MLGraphBuilder/gatherND(input, indices, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input N-D tensor from which the values are gathered.
        - <dfn>indices</dfn>: an {{MLOperand}}. The indices array contains entire coordinates into the input tensor, with the rightmost dimension holding the number of dimensions per coordinate. So an indices tensor of shape [10,1] holds 10 single-axis indices, and a shape of [4,3] holds 4 indices of 3D coordinates. The values must be of type {{MLOperandDataType/"int32"}}, {{MLOperandDataType/"uint32"}}, or {{MLOperandDataType/"int64"}}, and each must be in the range -N (inclusive) to N (exclusive) where N is the size of the corresponding input dimension, and a negative index means indexing from the end of the corresponding dimension.
        - <dfn>options</dfn>: an optional {{MLOperatorOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output N-D tensor of [=MLOperand/rank=] equal to the {{MLGraphBuilder/gatherND(input, indices, options)/input}}'s [=MLOperand/rank=] + {{MLGraphBuilder/gatherND(input, indices, options)/indices}}'s [=MLOperand/rank=] - {{MLGraphBuilder/gatherND(input, indices, options)/indices}}'s [=MLOperand/shape=][-1] - 1.
</div>

<table id=constraints-gathernd class='data' link-for="MLGraphBuilder/gatherND(input, indices, options)">
  <caption>Constraints for {{MLGraphBuilder/gatherND()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>1 to [=/any rank|N=]</td>
  </tr>
  <tr>
    <td>{{indices}}</td>
    <td>{{MLOperandDataType/"int32"}}, {{MLOperandDataType/"uint32"}}, {{MLOperandDataType/"int64"}}</td>
    <td>1 to [=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>{{input}}'s [=MLOperand/rank=] + {{indices}}'s [=MLOperand/rank=] - {{indices}}'s [=MLOperand/shape=][-1] - 1</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following members for {{MLGraphBuilder/gatherND()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>gatherND</dfn>
    :: Support limits for operator {{MLGraphBuilder/gatherND()}}.
</dl>

<div class="note">
  The {{MLGraphBuilder/gatherND(input, indices, options)/indices}} parameter to {{MLGraphBuilder/gatherND()}} can not be clamped to the allowed range when the graph is built because the inputs are not known until execution. Implementations can introduce {{MLGraphBuilder/clamp()}} in the compiled graph if the specified clamping behavior is not provided by the underlying platform. Similarly, if the underlying platform does not support negative indices, the implementation can introduce operations in the compiled graph to transform a negative index from the end of the dimension into a positive index.
</div>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>gatherND(|input|, |indices|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input| and |indices| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |indices|'s [=MLOperand/dataType=]'s is not one of the [=/allowed data types=] (according to [this table](#constraints-gathernd)), then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/rank=] of any of |input| or |indices| is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. Let |inputShape| be |input|'s [=MLOperand/shape=] and |inputRank| be |input|'s [=MLOperand/rank=].
    1. Let |indicesShape| be |indices|'s [=MLOperand/shape=] and |indicesRank| be |indices|'s [=MLOperand/rank=].
    1. If the [=MLOperand/rank=] of any of |input| or |indices| is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. Let |indexableSize| be |indicesRank| - 1.
    1. Let |coordinateSize| be |indicesShape|[|indexableSize|].
    1. If |coordinateSize| is greater than |inputRank|, then [=exception/throw=] a {{TypeError}}.
    1. Let |outputShape| be an empty list.
    1. [=list/For each=] |index| in [=the range=] 0 to |indexableSize|, exclusive:
        1. [=list/Append=] |indicesShape|[|index|] to |outputShape|.
    1. [=list/For each=] |index| in [=the range=] |coordinateSize| to |inputRank|, exclusive:
        1. [=list/Append=] |inputShape|[|index|] to |outputShape|.
    1. Let |outputDesc| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given |outputDesc|.
        1. Let |operator| be an [=operator=] for the "gatherND" operation, given |input|, |indices|, and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |input| and |indices|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="example">
<details open>
  <summary>
    Examples of how gatherND works in different slicing schemes.
  </summary>
  <pre highlight="js">
    // input of shape [2,2]:
    //   [[0, 1],
    //    [2, 3]]
    // indices of shape [3,2]:
    //   [[0, 0],
    //    [1, 1],
    //    [1, 0]]
    // output of shape [3]:
    //   [0, 3, 2]

    const input1 = builder.constant(
      {dataType: 'float32', shape: [2, 2]},
      new Float32Array([0, 1, 2, 3]));

    const indices1 = builder.constant(
      {dataType: 'uint32', shape: [3, 2]},
      new Uint32Array([0, 0, 1, 1, 1, 0]));

    const output1 = builder.gatherND(input1, indices1);

    // input of shape [2,2]:
    //   [[0, 1],
    //    [2, 3]]
    // indices of shape [2,1]:
    //   [[1],
    //    [0]]
    // output of shape [2,2]:
    //   [[2, 3]    <= row [2, 3] from input coordinates [1, *]
    //    [0, 1]]   <= row [0, 1] from input coordinates [0, *]

    const indices2 = builder.constant(
      {dataType: 'uint32', shape: [2, 1]},
      new Uint32Array([1, 0]));

    const output2 = builder.gatherND(input1, indices2);

    // input of shape [2,2,2]:
    //   [[[0, 1],
    //     [2, 3]],
    //    [[4, 5],
    //     [6, 7]]]
    // indices of shape [2,2]:
    //   [[0, 1],
    //    [1, 0]]
    // output of shape [2,2]:
    //   [[2, 3],   <= row [2, 3] from input coordinates [0, 1, *]
    //    [4, 5]]   <= row [4, 5] from input coordinates [1, 0, *]

    const input2 = builder.constant(
      {dataType: 'float32', shape: [2, 2, 2]},
      new Float32Array([0, 1, 2, 3, 4, 5, 6, 7]));

    const indices3 = builder.constant(
      {dataType: 'uint32', shape: [2, 2]},
      new Uint32Array([0, 1, 1, 0]));

    const output3 = builder.gatherND(input2, indices3);

    // input of shape [2,2,2]:
    //   [[[0, 1],
    //     [2, 3]],
    //    [[4, 5],
    //     [6, 7]]]
    // indices of shape [3,1]:
    //   [[1],
    //    [0],
    //    [1]]
    // output of shape [3,2,2]:
    //   [[[4, 5],   <= block [[4, 5], [6, 7]] from input coordinates [1, *, *]
    //     [6, 7]],
    //    [[0, 1],   <= block [[0, 1], [2, 3]] from input coordinates [0, *, *]
    //     [2, 3]],
    //    [[4, 5],   <= block [[4, 5], [6, 7]] from input coordinates [1, *, *]
    //     [6, 7]]]

    const indices4 = builder.constant(
      {dataType: 'uint32', shape: [3, 1]},
      new Uint32Array([1, 0, 1]));

    const output4 = builder.gatherND(input2, indices4);

    // input of shape [2,2,2]:
    //   [[[0, 1],
    //     [2, 3]],
    //    [[4, 5],
    //     [6, 7]]]
    // indices of shape [5,3]:
    //   [[0,0,1],
    //    [0,1,0],
    //    [1,0,0],
    //    [1,1,0],
    //    [1,1,1]]
    // output of shape [5]:
    //   [1,2,4,6,7]

    const indices5 = builder.constant(
      {dataType: 'uint32', shape: [5, 3]},
      new Uint32Array([0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1]));

    const output5 = builder.gatherND(input2, indices5);
  </pre>
</details>
</div>

### gelu ### {#api-mlgraphbuilder-gelu-method}
Compute the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Gaussian-error_linear_unit_(GELU)">gaussian error linear unit function</a> (GELU) of the input tensor. The calculation follows the expression `0.5 * x * (1 + erf(x / sqrt(2)))`.

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand gelu(MLOperand input, optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits gelu;
};
</script>

<div dfn-for="MLGraphBuilder/gelu(input, options)" dfn-type="argument">
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/gelu(input, options)/input}}.
</div>

<table id=constraints-gelu class='data' link-for="MLGraphBuilder/gelu(input, options)">
  <caption>Constraints for {{MLGraphBuilder/gelu()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/gelu()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>gelu</dfn>
    :: Support limits for operator {{MLGraphBuilder/gelu()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>gelu(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-gelu)), then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "gelu" operation given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be [EMULATED]
    </summary>
    <pre highlight="js">
    function gelu(builder, input) {
      return builder.mul(
        builder.mul(input, builder.constant(input.dataType, 0.5)),
        builder.add(
          builder.constant(input.dataType, 1),
          builder.erf(builder.div(
            input, builder.sqrt(builder.constant(input.dataType, 2))))));
    }
    </pre>
  </details>
</div>

### gemm ### {#api-mlgraphbuilder-gemm}
Calculate the [general matrix multiplication of the Basic Linear Algebra Subprograms](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3). The calculation follows the expression `alpha * A * B + beta * C`, where `A` is a 2-D tensor with shape *[M, K]* or *[K, M]*, `B` is a 2-D tensor with shape *[K, N]* or *[N, K]*, and `C` is [=unidirectionally broadcastable=] to the shape *[M, N]*. `A` and `B` can optionally be transposed prior to the calculation.

<script type=idl>
dictionary MLGemmOptions : MLOperatorOptions {
  MLOperand c;
  double alpha = 1.0;
  double beta = 1.0;
  boolean aTranspose = false;
  boolean bTranspose = false;
};

partial interface MLGraphBuilder {
  MLOperand gemm(MLOperand a, MLOperand b, optional MLGemmOptions options = {});
};

dictionary MLGemmSupportLimits {
  MLTensorLimits a;
  MLTensorLimits b;
  MLTensorLimits c;
  MLDataTypeLimits output;
};

partial dictionary MLOpSupportLimits {
  MLGemmSupportLimits gemm;
};
</script>

{{MLGemmOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLGemmOptions>
    : <dfn>c</dfn>
    ::
        The third input tensor. It is either a scalar, or of the shape that is [=unidirectionally broadcastable=] to the shape *[M, N]*. When it is not specified, the computation is done as if {{MLGemmOptions/c}} is a scalar 0.0.

    : <dfn>alpha</dfn>
    ::
        A multiplier for the first input.

    : <dfn>beta</dfn>
    ::
        A multiplier for the third input {{MLGemmOptions/c}}.

    : <dfn>aTranspose</dfn>
    ::
        Indicates if the first input is transposed prior to calculating the output.

    : <dfn>bTranspose</dfn>
    ::
        Indicates if the second input is transposed prior to calculating the output.
</dl>

<div dfn-for="MLGraphBuilder/gemm(a, b, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>a</dfn>: an {{MLOperand}}. The first input 2-D tensor with shape *[M, K]* if {{MLGemmOptions/aTranspose}} is false, or *[K, M]* if {{MLGemmOptions/aTranspose}} is true.
        - <dfn>b</dfn>: an {{MLOperand}}. The second input 2-D tensor with shape *[K, N]* if {{MLGemmOptions/bTranspose}} is false, or *[N, K]* if {{MLGemmOptions/bTranspose}} is true.
        - <dfn>options</dfn>: an optional {{MLGemmOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output 2-D tensor of shape *[M, N]* that contains the calculated product of all the inputs.
</div>

<table id=constraints-gemm class='data' link-for="MLGraphBuilder/gemm(a, b, options)">
  <caption>Constraints for {{MLGraphBuilder/gemm()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{a}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{b}}</td>
    <td>[=/same type as|same as=] {{a}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{MLGemmOptions/c}}</td>
    <td>[=/same type as|same as=] {{a}}</td>
    <td>0 to 2</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{a}}</td>
    <td>2</td>
  </tr>
</table>

{{MLGemmSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLGemmSupportLimits>
    : <dfn>a</dfn>
    :: {{MLTensorLimits}} for a operand.
    : <dfn>b</dfn>
    :: {{MLTensorLimits}} for b operand.
    : <dfn>c</dfn>
    :: {{MLTensorLimits}} for c operand.
    : <dfn>output</dfn>
    :: {{MLDataTypeLimits}} for output operand.
</dl>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/gemm()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>gemm</dfn>
    :: Support limits for operator {{MLGraphBuilder/gemm()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>gemm(|a|, |b|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |a| and |b| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/dataType=] of any of |a| or |b| is not one of its [=/allowed data types=] (according to [this table](#constraints-gemm)), then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/rank=] of any of |a| or |b| is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. Set |options|.{{MLGemmOptions/alpha}} to the result of [=casting=] |options|.{{MLGemmOptions/alpha}} to |a|'s [=MLOperand/dataType=].
    1. Set |options|.{{MLGemmOptions/beta}} to the result of [=casting=] |options|.{{MLGemmOptions/beta}} to |a|'s [=MLOperand/dataType=].
    1. Let |shapeA| be a [=list/clone=] of |a|'s [=MLOperand/shape=].
    1. Let |shapeB| be a [=list/clone=] of |b|'s [=MLOperand/shape=].
    1. If |options|.{{MLGemmOptions/aTranspose}} is true, then reverse the order of the items in |shapeA|.
    1. If |options|.{{MLGemmOptions/bTranspose}} is true, then reverse the order of the items in |shapeB|.
    1. If |shapeA|[1] is not equal to |shapeB|[0], then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLGemmOptions/c}} [=map/exists=]:
        1. If it is not [=unidirectionally broadcastable=] to the shape « |shapeA|[0], |shapeB|[1] », then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-gemm)), then [=exception/throw=] a {{TypeError}}.
    1. Let |desc| be the result of [=creating an MLOperandDescriptor=] given |a|'s [=MLOperand/dataType=] and « |shapeA|[0], |shapeB|[1] ».
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Let |operator| be an [=operator=] for the "gemm" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |a| and |b|.
        1. If |options|.{{MLGemmOptions/c}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation can be [EMULATED]
  </summary>
  <pre highlight="js">
    function gemm(builder, a, b, options) {
      if (options.aTranspose)
        a = builder.transpose(a);

      if (options.bTranspose)
        b = builder.transpose(b);

      let ab = builder.matmul(
        builder.mul(builder.constant(a.dataType, options.alpha), a), b);
      return (
        options.c ?
          builder.add(
            ab,
            builder.mul(builder.constant(a.dataType, options.beta), options.c)) :
          ab);
    }
  </pre>
</details>
</div>

### gru ### {#api-mlgraphbuilder-gru}
Gated Recurrent Unit [[GRU]] recurrent network uses an update, reset, and new gate to compute the output state that rolls into the output across the temporal sequence of the network.
<script type=idl>
enum MLGruWeightLayout {
  "zrn",  // update-reset-new gate ordering
  "rzn"   // reset-update-new gate ordering
};

enum MLRecurrentNetworkActivation {
  "relu",
  "sigmoid",
  "tanh"
};

enum MLRecurrentNetworkDirection {
  "forward",
  "backward",
  "both"
};

dictionary MLGruOptions : MLOperatorOptions {
  MLOperand bias;
  MLOperand recurrentBias;
  MLOperand initialHiddenState;
  boolean resetAfter = true;
  boolean returnSequence = false;
  MLRecurrentNetworkDirection direction = "forward";
  MLGruWeightLayout layout = "zrn";
  sequence<MLRecurrentNetworkActivation> activations;
};

partial interface MLGraphBuilder {
  sequence<MLOperand> gru(MLOperand input,
                          MLOperand weight,
                          MLOperand recurrentWeight,
                          [EnforceRange] unsigned long steps,
                          [EnforceRange] unsigned long hiddenSize,
                          optional MLGruOptions options = {});
};

dictionary MLGruSupportLimits {
  MLTensorLimits input;
  MLTensorLimits weight;
  MLTensorLimits recurrentWeight;
  MLTensorLimits bias;
  MLTensorLimits recurrentBias;
  MLTensorLimits initialHiddenState;
  MLDataTypeLimits outputs;
};

partial dictionary MLOpSupportLimits {
  MLGruSupportLimits gru;
};
</script>

{{MLGruOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLGruOptions>
    : <dfn>bias</dfn>
    ::
        The 2-D input bias tensor of shape *[numDirections, 3 * hiddenSize]*. The ordering of the bias vectors in the second dimension of the tensor shape is specified according to {{MLGruOptions/layout}}.

    : <dfn>recurrentBias</dfn>
    ::
        The 2-D recurrent bias tensor of shape *[numDirections, 3 * hiddenSize]*. The ordering of the bias vectors in the second dimension of the tensor shape is specified according to {{MLGruOptions/layout}}.

    : <dfn>initialHiddenState</dfn>
    ::
        The 3-D initial hidden state tensor of shape *[numDirections, batchSize, hiddenSize]*.
        When not specified, implementations must use a tensor filled with zero.

    : <dfn>resetAfter</dfn>
    ::
        Indicates whether to apply the reset gate after or before matrix multiplication.

    : <dfn>returnSequence</dfn>
    ::
        Indicates whether to also return the entire sequence with every output from each time step in it in addition to the output of the last time step.

    : <dfn>direction</dfn>
    ::
        The processing direction of the input sequence. When set to {{MLRecurrentNetworkDirection/"both"}}, the size of the first dimension of the weight and the bias tensor shapes must be 2, and the input is processed in both directions.

    : <dfn>layout</dfn>
    ::
        The ordering of the weight and bias vectors for the internal gates of GRU, specifically the `update (z)`, `reset (r)`, and `new (n)` gate, as indicated in the second dimension of the weight and bias tensor shape.

    : <dfn>activations</dfn>
    ::
        Specifies a pair of [=operator/activation functions=] with the first function used for the update and reset gate, and the second used for the new gate. When not specified, defaults to the {{MLRecurrentNetworkActivation/"sigmoid"}} and {{MLRecurrentNetworkActivation/"tanh"}} functions, respectively.
</dl>

<div dfn-for="MLGraphBuilder/gru(input, weight, recurrentWeight, steps, hiddenSize, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input 3-D tensor of shape *[steps, batchSize, inputSize]*.
        - <dfn>weight</dfn>: an {{MLOperand}}. The 3-D input weight tensor of shape *[numDirections, 3 * hiddenSize, inputSize]*. The ordering of the weight vectors in the second dimension of the tensor shape is specified according to {{MLGruOptions/layout}}.
        - <dfn>recurrentWeight</dfn>: an {{MLOperand}}. The 3-D recurrent weight tensor of shape *[numDirections, 3 * hiddenSize, hiddenSize]*. The ordering of the weight vectors in the second dimension of the tensor shape is specified according to {{MLGruOptions/layout}}.
        - <dfn>steps</dfn>: an {{unsigned long}} scalar. The number of time steps in the recurrent network. The value must be greater than 0.
        - <dfn>hiddenSize</dfn>: an {{unsigned long}} scalar. The value of the third dimension of the cell output tensor shape. It indicates the number of features in the hidden state.
        - <dfn>options</dfn>: an optional {{MLGruOptions}}. The optional parameters of the operation.

    **Returns:** [=sequence=]<{{MLOperand}}>. The first element is a 3-D tensor of shape *[numDirections, batchSize, hiddenSize]*, the cell output from the last time step of the network. Additionally, if {{MLGruOptions/returnSequence}} is set to true, the second element is the 4-D output tensor of shape *[steps, numDirections, batchSize, hiddenSize]* containing every cell outputs from each time step in the temporal sequence.
</div>

<table id=constraints-gru class='data' link-for="MLGraphBuilder/gru(input, weight, recurrentWeight, steps, hiddenSize, options)">
  <caption>Constraints for {{MLGraphBuilder/gru()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>3</td>
  </tr>
  <tr>
    <td>{{weight}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>3</td>
  </tr>
  <tr>
    <td>{{recurrentWeight}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>3</td>
  </tr>
  <tr>
    <td>{{MLGruOptions/bias}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{MLGruOptions/recurrentBias}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{MLGruOptions/initialHiddenState}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>3</td>
  </tr>
  <tr>
    <td>*outputs[0]*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>3</td>
  </tr>
  <tr>
    <td>*outputs[1]* if {{MLGruOptions/returnSequence}} is true</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>4</td>
  </tr>
</table>

{{MLGruSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLGruSupportLimits>
    : <dfn>input</dfn>
    :: {{MLTensorLimits}} for input operand.
    : <dfn>weight</dfn>
    :: {{MLTensorLimits}} for weight operand.
    : <dfn>recurrentWeight</dfn>
    :: {{MLTensorLimits}} for recurrentWeight operand.
    : <dfn>bias</dfn>
    :: {{MLTensorLimits}} for bias operand.
    : <dfn>recurrentBias</dfn>
    :: {{MLTensorLimits}} for recurrentBias operand.
    : <dfn>initialHiddenState</dfn>
    :: {{MLTensorLimits}} for initialHiddenState operand.
    : <dfn>outputs</dfn>
    :: {{MLDataTypeLimits}} for all the output operands.
</dl>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/gru()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>gru</dfn>
    :: Support limits for operator {{MLGraphBuilder/gru()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>gru(|input|, |weight|, |recurrentWeight|, |steps|, |hiddenSize|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input|, |weight|, |recurrentWeight|, |options|.{{MLGruOptions/bias}} (if it [=map/exists=]), |options|.{{MLGruOptions/recurrentBias}} (if it [=map/exists=]), and |options|.{{MLGruOptions/initialHiddenState}} (if it [=map/exists=]) returns false, then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/dataType=] of any of |input|, |weight| or |recurrentWeight| is not one of its [=/allowed data types=] (according to [this table](#constraints-gru)), then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/rank=] of any of |input|, |weight| or |recurrentWeight| is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/shape=][0] is not equal to |steps|, then [=exception/throw=] a {{TypeError}}.
    1. Let |batchSize| be |input|'s [=MLOperand/shape=][1].
    1. Let |inputSize| be |input|'s [=MLOperand/shape=][2].
    1. Let |numDirections| be 2 if |options|.{{MLGruOptions/direction}} is {{MLRecurrentNetworkDirection/"both"}}, or 1 otherwise.
    1. If |weight|'s [=MLOperand/shape=] is not [=list/equal=] to « |numDirections|, 3 * |hiddenSize|, |inputSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |recurrentWeight|'s [=MLOperand/shape=] is not [=list/equal=] to « |numDirections|, 3 * |hiddenSize|, |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |hiddenSize| * 6 is not a [=valid dimension=], then [=exception/throw=] a {{TypeError}}.
        <details class=note>
          <summary>Why |hiddenSize| * 6 ?</summary>
          Some underlying platforms operate on a single bias tensor which is a concatenation of {{MLGruOptions/bias}} and {{MLGruOptions/recurrentBias}}. Therefore, 3 * |hiddenSize| + 3 * |hiddenSize| also needs to be a [=valid dimension=].
        </details>
    1. If |options|.{{MLGruOptions/bias}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-gru)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « |numDirections|, 3 * |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLGruOptions/recurrentBias}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-gru)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « |numDirections|, 3 * |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLGruOptions/initialHiddenState}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-gru)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « |numDirections|, |batchSize|, |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLGruOptions/activations}} [=map/exists=]:
        1. If its [=list/size=] is not 2, then [=exception/throw=] a {{TypeError}}.
        1. Let |activations| be a [=list/clone=] of |options|.{{MLGruOptions/activations}}.
    1. Otherwise:
        1. Let |activations| be « {{MLRecurrentNetworkActivation/"sigmoid"}}, {{MLRecurrentNetworkActivation/"tanh"}} ».
    1. *Calculate the output shape:*
        1. Let |desc0| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and « |numDirections|, |batchSize|, |hiddenSize| ».
        1. If |options|.{{MLGruOptions/returnSequence}} is true:
            1. Let |desc1| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and « |steps|, |numDirections|, |batchSize|, |hiddenSize| ».
    1. *Make graph connections:*
        1. Let |operator| be an [=operator=] for the "gru" operation, given |weight|, |recurrentWeight|, |steps|, |hiddenSize| and |options|.
        1. Let |output0| be the result of [=creating an MLOperand=] given [=this=] and |desc0|.
        1. If |options|.{{MLGruOptions/returnSequence}} is true:
            1. Let |output1| be the result of [=creating an MLOperand=] given [=this=] and |desc1|.
            1. Let |output| be the [=/list=] « |output0|, |output1| ».
            1. Set |output0|.{{MLOperand/[[operator]]}} and |output1|.{{MLOperand/[[operator]]}} to |operator|.
        1. Otherwise:
            1. Let |output| be the [=/list=] « |output0| ».
            1. Set |output0|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |input|, |weight|, and |recurrentWeight|.
        1. If |options|.{{MLGruOptions/bias}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. If |options|.{{MLGruOptions/recurrentBias}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. If |options|.{{MLGruOptions/initialHiddenState}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. Set |operator|'s [=operator/activation functions=] to a [=list/clone=] of |activations|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
<details open>
  <summary>
    Using a [[#emulation-squeeze|squeeze()]] helper, the behavior of this operation can be [EMULATED]
  </summary>
  <pre highlight="js">
    function gru(
      builder, input, weight, recurrentWeight, steps, hiddenSize, options) {
      const batchSize = input.shape[1];
      const inputSize = input.shape[2];
      const direction = options.direction || 'forward';
      const numDirections = (direction == 'both' ? 2 : 1);
      let hiddenState = options.initialHiddenState;

      if (!hiddenState) {
        const desc = {
          dataType: 'float32',
          shape: [numDirections, batchSize, hiddenSize]
        };
        const totalSize = numDirections * batchSize * hiddenSize;
        hiddenState = builder.constant(desc, new Float32Array(totalSize).fill(0));
      }

      let currentWeight = [];
      let currentRecurrentWeight = [];
      let currentBias = [];
      let currentRecurrentBias = [];
      let forwardSequence = null;
      let backwardSequence = null;
      let outputHidden = null;

      for (let dir = 0; dir < numDirections; ++dir) {
        currentWeight.push(squeeze(
          builder,
          builder.slice(weight, [dir, 0, 0], [1, 3 * hiddenSize, inputSize])));
        currentRecurrentWeight.push(squeeze(
          builder,
          builder.slice(
            recurrentWeight, [dir, 0, 0], [1, 3 * hiddenSize, hiddenSize])));
        currentBias.push(
          options.bias ?
            (squeeze(
              builder,
              builder.slice(options.bias, [dir, 0], [1, 3 * hiddenSize]))) :
            null);
        currentRecurrentBias.push(
          options.recurrentBias ?
            (squeeze(
              builder,
              builder.slice(
                options.recurrentBias, [dir, 0], [1, 3 * hiddenSize]))) :
            null);
        let currentHidden = squeeze(
          builder,
          builder.slice(hiddenState, [dir, 0, 0], [1, batchSize, hiddenSize]));

        for (let step = 0; step < steps; ++step) {
          const slice =
            (dir == 1 || direction == 'backward' ? steps - step - 1 : step);
          const currentInput = squeeze(
            builder,
            builder.slice(input, [slice, 0, 0], [1, batchSize, inputSize]));

          currentHidden = builder.gruCell(
            currentInput,
            currentWeight[dir],
            currentRecurrentWeight[dir],
            currentHidden,
            hiddenSize,
            {
              bias: currentBias[dir],
              recurrentBias: currentRecurrentBias[dir],
              resetAfter: options.resetAfter,
              layout: options.layout,
              activations: options.activations
            });

          if (options.returnSequence) {
            // Expand currentHidden of 2D([batchSize, hiddenSize])
            // to 4D([steps, numDirections, batchSize, hiddenSize])
            const expandedHiddenAs4D =
              builder.reshape(currentHidden, [1, 1, batchSize, hiddenSize]);

            if (direction == 'forward' || (dir == 0 && direction == 'both')) {
              forwardSequence = forwardSequence ?
                builder.concat([forwardSequence, expandedHiddenAs4D], 0) :
                expandedHiddenAs4D;
            } else if (
              direction == 'backward' || (dir == 1 && direction == 'both')) {
              backwardSequence = backwardSequence ?
                builder.concat([expandedHiddenAs4D, backwardSequence], 0) :
                expandedHiddenAs4D;
            }
          }
        }

        // Expand currentHidden of 2D([batchSize, hiddenSize])
        // to 3D([numDirections, batchSize, hiddenSize])
        const expandedHiddenAs3D =
          builder.reshape(currentHidden, [1, batchSize, hiddenSize]);
        outputHidden = outputHidden ?
          builder.concat([outputHidden, expandedHiddenAs3D], 0) :
          expandedHiddenAs3D;
      }

      if (options.returnSequence) {
        let outputSequence = null;

        if (direction == 'forward') {
          outputSequence = forwardSequence;
        } else if (direction == 'backward') {
          outputSequence = backwardSequence;
        } else if (direction == 'both') {
          // Concat along axis 1 (numDirections dimension)
          outputSequence = builder.concat([forwardSequence, backwardSequence], 1);
        }

        return [outputHidden, outputSequence];
      } else {
        return [outputHidden];
      }
    }
  </pre>
</details>
</div>

### gruCell ### {#api-mlgraphbuilder-grucell}
A single time step of the Gated Recurrent Unit [[GRU]] recurrent network using an update gate and a reset gate to compute the hidden state that rolls into the output across the temporal sequence of a recurrent network.

<script type=idl>
dictionary MLGruCellOptions : MLOperatorOptions {
  MLOperand bias;
  MLOperand recurrentBias;
  boolean resetAfter = true;
  MLGruWeightLayout layout = "zrn";
  sequence<MLRecurrentNetworkActivation> activations;
};

partial interface MLGraphBuilder {
  MLOperand gruCell(MLOperand input,
                    MLOperand weight,
                    MLOperand recurrentWeight,
                    MLOperand hiddenState,
                    [EnforceRange] unsigned long hiddenSize,
                    optional MLGruCellOptions options = {});
};

dictionary MLGruCellSupportLimits {
  MLTensorLimits input;
  MLTensorLimits weight;
  MLTensorLimits recurrentWeight;
  MLTensorLimits hiddenState;
  MLTensorLimits bias;
  MLTensorLimits recurrentBias;
  MLDataTypeLimits output;
};

partial dictionary MLOpSupportLimits {
  MLGruCellSupportLimits gruCell;
};
</script>

{{MLGruCellOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLGruCellOptions>
    : <dfn>bias</dfn>
    ::
        The 1-D input bias tensor of shape *[3 * hiddenSize]*. The ordering of the bias vectors in the second dimension of the tensor shape is specified according to {{MLGruOptions/layout}}.

    : <dfn>recurrentBias</dfn>
    ::
        The 1-D recurrent bias tensor of shape *[3 * hiddenSize]*. The ordering of the bias vectors in the second dimension of the tensor shape is specified according to {{MLGruOptions/layout}}.

    : <dfn>resetAfter</dfn>
    ::
        Indicates whether to apply the reset gate after or before matrix multiplication.

    : <dfn>layout</dfn>
    ::
        The ordering of the weight and bias vectors for the internal gates of GRU, specifically the `update (z)`, `reset (r)`, and `new (n)` gate, as indicated in the second dimension of the weight and bias tensor shape.

    : <dfn>activations</dfn>
    ::
        Specifies a pair of [=operator/activation functions=] with the first function used for the update and reset gate, and the second used for the new gate. When not specified, defaults to the {{MLRecurrentNetworkActivation/"sigmoid"}} and {{MLRecurrentNetworkActivation/"tanh"}} functions, respectively.
</dl>

<div dfn-for="MLGraphBuilder/gruCell(input, weight, recurrentWeight, hiddenState, hiddenSize, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input 2-D tensor of shape *[batchSize, inputSize]*.
        - <dfn>weight</dfn>: an {{MLOperand}}. The 2-D input weight tensor of shape *[3 * hiddenSize, inputSize]*. The ordering of the weight vectors in the first dimension of the tensor shape is specified according to {{MLGruCellOptions/layout}}.
        - <dfn>recurrentWeight</dfn>: an {{MLOperand}}. The 2-D recurrent weight tensor of shape *[3 * hiddenSize, hiddenSize]*. The ordering of the weight vectors in the first dimension of the tensor shape is specified according to {{MLGruCellOptions/layout}}.
        - <dfn>hiddenState</dfn>: an {{MLOperand}}. The 2-D input hidden state tensor of shape *[batchSize, hiddenSize]*.
        - <dfn>hiddenSize</dfn>: an {{unsigned long}} scalar. The value of the second dimension of the output tensor shape. It indicates the number of features in the hidden state.
        - <dfn>options</dfn>: an optional {{MLGruCellOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The 2-D tensor of shape *[batchSize, hiddenSize]*, the cell output hidden state of a single time step of the recurrent network.
</div>

<table id=constraints-gruCell class='data' link-for="MLGraphBuilder/gruCell(input, weight, recurrentWeight, hiddenState, hiddenSize, options)">
  <caption>Constraints for {{MLGraphBuilder/gruCell()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{weight}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{recurrentWeight}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{MLGruCellOptions/bias}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>1</td>
  </tr>
  <tr>
    <td>{{MLGruCellOptions/recurrentBias}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>1</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>2</td>
  </tr>
</table>

{{MLGruCellSupportLimits}} has the following members;
<dl dfn-type=dict-member dfn-for=MLGruCellSupportLimits>
    : <dfn>input</dfn>
    :: {{MLTensorLimits}} for input operand.
    : <dfn>weight</dfn>
    :: {{MLTensorLimits}} for weight operand.
    : <dfn>recurrentWeight</dfn>
    :: {{MLTensorLimits}} for recurrentWeight operand.
    : <dfn>hiddenState</dfn>
    :: {{MLTensorLimits}} for hiddenState operand.
    : <dfn>bias</dfn>
    :: {{MLTensorLimits}} for bias operand.
    : <dfn>recurrentBias</dfn>
    :: {{MLTensorLimits}} for recurrentBias operand.
    : <dfn>output</dfn>
    :: {{MLDataTypeLimits}} for output operand.
</dl>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/gruCell()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>gruCell</dfn>
    :: Support limits for operator {{MLGraphBuilder/gruCell()}}.
</dl>

<details open algorithm>
  <summary>
     The <dfn method for=MLGraphBuilder>gruCell(|input|, |weight|, |recurrentWeight|, |hiddenState|, |hiddenSize|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input|, |weight|, |recurrentWeight|, |hiddenState|, |options|.{{MLGruCellOptions/bias}} (if it [=map/exists=]), and |options|.{{MLGruCellOptions/recurrentBias}} (if it [=map/exists=]) returns false, then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/dataType=] of any of |input|, |weight|, |recurrentWeight|, or |hiddenState| is not one of its [=/allowed data types=] (according to [this table](#constraints-gruCell)), then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/rank=] of any of |input|, |weight|, |recurrentWeight| or |hiddenState| is not its [=/allowed ranks=] (according to [this table](#constraints-gruCell)), then [=exception/throw=] a {{TypeError}}.
    1. Let |batchSize| be |input|'s [=MLOperand/shape=][0].
    1. Let |inputSize| be |input|'s [=MLOperand/shape=][1].
    1. If |weight|'s [=MLOperand/shape=] is not [=list/equal=] to « 3 * |hiddenSize|, |inputSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |recurrentWeight|'s [=MLOperand/shape=] is not [=list/equal=] to « 3 * |hiddenSize|, |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |hiddenState|'s [=MLOperand/shape=] is not [=list/equal=] to « |batchSize|, |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |hiddenSize| * 6 is not a [=valid dimension=], then [=exception/throw=] a {{TypeError}}.
        <details class=note>
          <summary>Why |hiddenSize| * 6 ?</summary>
          Some underlying platforms operate on a single bias tensor which is a concatenation of {{MLGruCellOptions/bias}} and {{MLGruCellOptions/recurrentBias}}. Therefore, 3 * |hiddenSize| + 3 * |hiddenSize| also needs to be a [=valid dimension=].
        </details>
    1. If |options|.{{MLGruCellOptions/bias}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-gruCell)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « 3 * |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLGruCellOptions/recurrentBias}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-gruCell)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « 3 * |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLGruCellOptions/activations}} [=map/exists=]:
        1. If its [=list/size=] is not 2, then [=exception/throw=] a {{TypeError}}.
        1. Let |activations| be a [=list/clone=] of |options|.{{MLGruCellOptions/activations}}.
    1. Otherwise:
        1. Let |activations| be « {{MLRecurrentNetworkActivation/"sigmoid"}}, {{MLRecurrentNetworkActivation/"tanh"}} ».
    1. Let |desc| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and « |batchSize|, |hiddenSize| ».
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Let |operator| be an [=operator=] for the "gruCell" operation, given |weight|, |recurrentWeight|, |hiddenState|, |hiddenSize| and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |input|, |weight|, |recurrentWeight|, and |hiddenState|.
        1. If |options|.{{MLGruCellOptions/bias}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. If |options|.{{MLGruCellOptions/recurrentBias}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. Set |operator|'s [=operator/activation functions=] to a [=list/clone=] of |activations|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation when the weight layout is the default {{MLGruWeightLayout/"zrn"}} layout, and the [=operator/activation functions=] of the update/reset gate and new gate are {{MLGraphBuilder/sigmoid()}} and {{MLGraphBuilder/tanh()}} respectively can be [EMULATED]
  </summary>
  <pre highlight="js">
    function gruCell(
      builder, input, weight, recurrentWeight, hiddenState, hiddenSize, options) {
      const one = builder.constant(input.dataType, 1);
      const zero = builder.constant(input.dataType, 0);

      const inputSize = input.shape[1];

      // update gate (z)
      let z = builder.sigmoid(builder.add(
        builder.add(
          (options.bias ? builder.slice(options.bias, [0], [hiddenSize]) : zero),
          (options.recurrentBias ?
             builder.slice(options.recurrentBias, [0], [hiddenSize]) :
             zero)),
        builder.add(
          builder.matmul(
            input,
            builder.transpose(
              builder.slice(weight, [0, 0], [hiddenSize, inputSize]))),
          builder.matmul(
            hiddenState,
            builder.transpose(
              builder.slice(recurrentWeight, [0, 0], [hiddenSize, hiddenSize]))))));

      // reset gate (r)
      let r = builder.sigmoid(builder.add(
        builder.add(
          (options.bias ? builder.slice(options.bias, [hiddenSize], [hiddenSize]) :
                          zero),
          (options.recurrentBias ?
             builder.slice(options.recurrentBias, [hiddenSize], [hiddenSize]) :
             zero)),
        builder.add(
          builder.matmul(
            input,
            builder.transpose(
              builder.slice(weight, [hiddenSize, 0], [hiddenSize, inputSize]))),
          builder.matmul(
            hiddenState,
            builder.transpose(builder.slice(
              recurrentWeight, [hiddenSize, 0], [hiddenSize, hiddenSize]))))));

      // new gate (n)
      let n;
      if (options.resetAfter) {
        n = builder.tanh(builder.add(
          (options.bias ?
             builder.slice(options.bias, [2 * hiddenSize], [hiddenSize]) :
             zero),
          builder.add(
            builder.matmul(
              input,
              builder.transpose(builder.slice(
                weight, [2 * hiddenSize, 0], [hiddenSize, inputSize]))),
            builder.mul(
              r,
              builder.add(
                (options.recurrentBias ?
                   builder.slice(
                     options.recurrentBias, [2 * hiddenSize], [hiddenSize]) :
                   zero),
                builder.matmul(
                  hiddenState,
                  builder.transpose(builder.slice(
                    recurrentWeight,
                    [2 * hiddenSize, 0],
                    [hiddenSize, hiddenSize]))))))));
      } else {
        n = builder.tanh(builder.add(
          builder.add(
            (options.bias ?
               builder.slice(options.bias, [2 * hiddenSize], [hiddenSize]) :
               zero),
            (options.recurrentBias ?
               builder.slice(
                 options.recurrentBias, [2 * hiddenSize], [hiddenSize]) :
               zero)),
          builder.add(
            builder.matmul(
              input,
              builder.transpose(builder.slice(
                weight, [2 * hiddenSize, 0], [hiddenSize, inputSize]))),
            builder.matmul(
              builder.mul(r, hiddenState),
              builder.transpose(builder.slice(
                recurrentWeight,
                [2 * hiddenSize, 0],
                [hiddenSize, hiddenSize]))))));
      }

      // compute the new hidden state
      return builder.add(
        builder.mul(z, hiddenState), builder.mul(n, builder.sub(one, z)));
    }
  </pre>
</details>
</div>

### hardSigmoid ### {#api-mlgraphbuilder-hard-sigmoid}
Calculate the non-smooth <a href="https://en.wikipedia.org/wiki/Hard_sigmoid">hard sigmoid function</a> on the input tensor, used instead of the sigmoid function for faster computation.
<script type=idl>
dictionary MLHardSigmoidOptions : MLOperatorOptions {
  double alpha = 0.2;
  double beta = 0.5;
};

partial interface MLGraphBuilder {
  MLOperand hardSigmoid(MLOperand input, optional MLHardSigmoidOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits hardSigmoid;
};
</script>

{{MLHardSigmoidOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLHardSigmoidOptions>
    : <dfn>alpha</dfn>
    ::
         A scalar multiplier.
    : <dfn>beta</dfn>
    ::
         A scalar addition.
</dl>

<div dfn-for="MLGraphBuilder/hardSigmoid(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an optional {{MLHardSigmoidOptions}}. The optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/hardSigmoid(input, options)/input}}.
</div>

<table id=constraints-hardSigmoid class='data' link-for="MLGraphBuilder/hardSigmoid(input, options)">
  <caption>Constraints for {{MLGraphBuilder/hardSigmoid()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/hardSigmoid()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>hardSigmoid</dfn>
    :: Support limits for operator {{MLGraphBuilder/hardSigmoid()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>hardSigmoid(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-hardSigmoid)), then [=exception/throw=] a {{TypeError}}.
    1. Set |options|.{{MLHardSigmoidOptions/alpha}} to the result of [=casting=] |options|.{{MLHardSigmoidOptions/alpha}} to |input|'s [=MLOperand/dataType=].
    1. Set |options|.{{MLHardSigmoidOptions/beta}} to the result of [=casting=] |options|.{{MLHardSigmoidOptions/beta}} to |input|'s [=MLOperand/dataType=].
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "hardSigmoid" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be [EMULATED]
    </summary>
    <pre highlight="js">
    function hardSigmoid(builder, input, options) {
      return builder.max(
        builder.min(
          builder.add(
            builder.mul(builder.constant(input.dataType, options.alpha), input),
            builder.constant(input.dataType, options.beta)),
          builder.constant(input.dataType, 1)),
        builder.constant(input.dataType, 0));
    }
    </pre>
  </details>
</div>

### hardSwish ### {#api-mlgraphbuilder-hard-swish}
Computes the nonlinear function `y = x * max(0, min(6, (x + 3))) / 6` that is introduced by [[MobileNetV3]] on the input tensor element-wise.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand hardSwish(MLOperand input, optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits hardSwish;
};
</script>

<div dfn-for="MLGraphBuilder/hardSwish(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/hardSwish(input, options)/input}}.
</div>

<table id=constraints-hardSwish class='data' link-for="MLGraphBuilder/hardSwish(input, options)">
  <caption>Constraints for {{MLGraphBuilder/hardSwish()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/hardSwish()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>hardSwish</dfn>
    :: Support limits for operator {{MLGraphBuilder/hardSwish()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>hardSwish(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-hardSwish)), then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "hardSwish" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation can be [EMULATED]
  </summary>
  <pre highlight="js">
    function hardSwish(builder, input, options) {
      return builder.div(
        builder.mul(
          input,
          builder.max(
            builder.constant(input.dataType, 0),
            builder.min(
              builder.constant(input.dataType, 6),
              builder.add(input, builder.constant(input.dataType, 3))))),
        builder.constant(input.dataType, 6));
    }
  </pre>
</details>
</div>

### instanceNormalization ### {#api-mlgraphbuilder-instancenorm}
Normalize the input using [[Instance-Normalization]]. Unlike {{MLGraphBuilder/batchNormalization()}} where the mean and variance values used in the normalization are computed across all the samples in the batch dimension while the model is trained, the mean and variance values used in the instance normalization are computed on the fly for each input feature of each individual sample in the batch.

<script type=idl>
dictionary MLInstanceNormalizationOptions : MLOperatorOptions {
  MLOperand scale;
  MLOperand bias;
  double epsilon = 1e-5;
  MLInputOperandLayout layout = "nchw";
};

partial interface MLGraphBuilder {
  MLOperand instanceNormalization(MLOperand input,
                                  optional MLInstanceNormalizationOptions options = {});
};

dictionary MLNormalizationSupportLimits {
  MLTensorLimits input;
  MLTensorLimits scale;
  MLTensorLimits bias;
  MLDataTypeLimits output;
};

partial dictionary MLOpSupportLimits {
  MLNormalizationSupportLimits instanceNormalization;
};
</script>

{{MLInstanceNormalizationOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLInstanceNormalizationOptions>
    : <dfn>scale</dfn>
    ::
        The 1-D tensor of the scaling values whose [=list/size=] is equal to the number of channels, i.e. the size of the feature dimension of the input. For example, for an {{MLGraphBuilder/instanceNormalization(input, options)/input}} tensor with {{MLInputOperandLayout/"nchw"}} layout, the [=list/size=] is equal to {{MLGraphBuilder/instanceNormalization(input, options)/input}}'s [=MLOperand/shape=][1].

    : <dfn>bias</dfn>
    ::
        The 1-D tensor of the bias values whose [=list/size=] is equal to the size of the feature dimension of the input. For example, for an {{MLGraphBuilder/instanceNormalization(input, options)/input}} tensor with {{MLInputOperandLayout/"nchw"}} layout, the [=list/size=] is equal to {{MLGraphBuilder/instanceNormalization(input, options)/input}}'s [=MLOperand/shape=][1].

    : <dfn>epsilon</dfn>
    ::
        A small value to prevent computational error due to divide-by-zero.

    : <dfn>layout</dfn>
    ::
        The layout format of the input.

</dl>

<div dfn-for="MLGraphBuilder/instanceNormalization(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input 4-D tensor.
        - <dfn>options</dfn>: an optional {{MLInstanceNormalizationOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The instance-normalized 4-D tensor of the same shape as {{MLGraphBuilder/instanceNormalization(input, options)/input}}.
</div>

<table id=constraints-instanceNormalization class='data' link-for="MLGraphBuilder/instanceNormalization(input, options)">
  <caption>Constraints for {{MLGraphBuilder/instanceNormalization()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>4</td>
  </tr>
  <tr>
    <td>{{MLInstanceNormalizationOptions/scale}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>1</td>
  </tr>
  <tr>
    <td>{{MLInstanceNormalizationOptions/bias}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>1</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>4</td>
  </tr>
</table>

{{MLNormalizationSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLNormalizationSupportLimits>
    : <dfn>input</dfn>
    :: {{MLTensorLimits}} for input operand.
    : <dfn>scale</dfn>
    :: {{MLTensorLimits}} for scale operand.
    : <dfn>bias</dfn>
    :: {{MLTensorLimits}} for bias operand.
    : <dfn>output</dfn>
    :: {{MLDataTypeLimits}} for output operand.
</dl>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/instanceNormalization()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>instanceNormalization</dfn>
    :: Support limits for operator {{MLGraphBuilder/instanceNormalization()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>instanceNormalization(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input|, |options|.{{MLInstanceNormalizationOptions/scale}} (if it [=map/exists=]), and |options|.{{MLInstanceNormalizationOptions/bias}} (if it [=map/exists=]) returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-instanceNormalization)), then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/rank=] is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. Set |options|.{{MLInstanceNormalizationOptions/epsilon}} to the result of [=casting=] |options|.{{MLInstanceNormalizationOptions/epsilon}} to |input|'s [=MLOperand/dataType=].
    1. Let |axis| be 1 if |options|.{{MLInstanceNormalizationOptions/layout}} is {{MLInputOperandLayout/"nchw"}}, and 3 otherwise.
    1. If |options|.{{MLInstanceNormalizationOptions/scale}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-instanceNormalization)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « |input|'s [=MLOperand/shape=][|axis|] », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLInstanceNormalizationOptions/bias}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-instanceNormalization)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « |input|'s [=MLOperand/shape=][|axis|] », then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "instanceNormalization" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. If |options|.{{MLInstanceNormalizationOptions/scale}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. If |options|.{{MLInstanceNormalizationOptions/bias}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation when the input tensor is 4-D of the {{MLInputOperandLayout/"nchw"}} layout can be [EMULATED]
  </summary>
  <pre highlight="js">
    function instanceNormalization(builder, input, options) {
      // The reduction of the mean and variance values happens over the spatial
      // dimensions of the input e.g. axis 2 and 3 of the input tensor.
      const reduceOptions = {axes: [2, 3], keepDimensions: true};
      const mean = builder.reduceMean(input, reduceOptions);
      const variance = builder.reduceMean(
        builder.pow(builder.sub(input, mean), builder.constant(input.dataType, 2)),
        reduceOptions);

      // The scale and bias values are applied per input feature
      // e.g. axis 1 of the input tensor.
      const shape = [1, input.shape[1], 1, 1];
      return builder.add(
        builder.mul(
          builder.reshape(options.scale, shape),
          builder.div(
            builder.sub(input, mean),
            builder.sqrt(builder.add(variance, options.epsilon)))),
        builder.reshape(options.bias, shape));
    }
  </pre>
</details>
</div>

### layerNormalization ### {#api-mlgraphbuilder-layernorm}
Normalize the input using [[Layer-Normalization]]. Unlike {{MLGraphBuilder/batchNormalization()}} where the mean and variance values are computed across all the samples in the batch dimension while the model is trained, and in {{MLGraphBuilder/instanceNormalization()}} where the mean and variance values are computed on the fly for each input feature of each individual sample in the batch, the means and variance values of the layer normalization are computed on the fly across all the input features of each individual sample in the batch.

<script type=idl>
dictionary MLLayerNormalizationOptions : MLOperatorOptions {
  MLOperand scale;
  MLOperand bias;
  sequence<[EnforceRange] unsigned long> axes;
  double epsilon = 1e-5;
};

partial interface MLGraphBuilder {
  MLOperand layerNormalization(MLOperand input,
                               optional MLLayerNormalizationOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLNormalizationSupportLimits layerNormalization;
};
</script>

{{MLLayerNormalizationOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLLayerNormalizationOptions>
    : <dfn>scale</dfn>
    ::
        The N-D tensor of the scaling values whose shape is determined by the {{MLLayerNormalizationOptions/axes}} member in that each value in {{MLLayerNormalizationOptions/axes}} indicates the dimension of the input tensor with scaling values. For example, for an {{MLLayerNormalizationOptions/axes}} values of [1,2,3], the shape of this tensor is the list of the corresponding sizes of the input dimension 1, 2 and 3. When this member is not present, the scaling value is assumed to be 1.

    : <dfn>bias</dfn>
    ::
        The N-D tensor of the bias values whose shape is determined by the {{MLLayerNormalizationOptions/axes}} member in that each value in {{MLLayerNormalizationOptions/axes}} indicates the dimension of the input tensor with bias values. For example, for an {{MLLayerNormalizationOptions/axes}} values of [1,2,3], the shape of this tensor is the list of the corresponding sizes of the input dimension 1, 2 and 3. When this member is not present, the bias value is assumed to be 0.

    : <dfn>axes</dfn>
    ::
        The indices to the input dimensions to reduce. When this member is not present, it is treated as if all dimensions except the first were given (e.g. for a 4-D input tensor, {{MLLayerNormalizationOptions/axes}} = [1,2,3]). That is, the reduction for the mean and variance values are calculated across all the input features for each independent batch. If empty, no dimensions are reduced.
    : <dfn>epsilon</dfn>
    ::
        A small value to prevent computational error due to divide-by-zero.
</dl>

<div dfn-for="MLGraphBuilder/layerNormalization(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input N-D tensor.
        - <dfn>options</dfn>: an optional {{MLLayerNormalizationOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The layer-normalized N-D tensor of the same shape as {{MLGraphBuilder/layerNormalization(input, options)/input}}.
</div>

<table id=constraints-layerNormalization class='data' link-for="MLGraphBuilder/layerNormalization(input, options)">
  <caption>Constraints for {{MLGraphBuilder/layerNormalization()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>{{MLLayerNormalizationOptions/scale}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>0 to {{input}}'s [=MLOperand/rank=]</td>
  </tr>
  <tr>
    <td>{{MLLayerNormalizationOptions/bias}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>0 to {{input}}'s [=MLOperand/rank=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/layerNormalization()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>layerNormalization</dfn>
    :: Support limits for operator {{MLGraphBuilder/layerNormalization()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>layerNormalization(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input|, |options|.{{MLLayerNormalizationOptions/scale}} (if it [=map/exists=]), and |options|.{{MLLayerNormalizationOptions/bias}} (if it [=map/exists=]) returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-layerNormalization)), then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLLayerNormalizationOptions/axes}} does not [=map/exist=], then set |options|.{{MLLayerNormalizationOptions/axes}} to a new [=/list=], either [=the range=] from 1 to |input|'s [=MLOperand/rank=], exclusive, if |input|'s [=MLOperand/rank=] is greater than 1, or an empty [=/list=] otherwise.
    1. Otherwise, if |options|.{{MLLayerNormalizationOptions/axes}} contains duplicate values, or if any of its [=list/items=] is not in [=the range=] 0 to |input|'s [=MLOperand/rank=], exclusive, then [=exception/throw=] a {{TypeError}}.
    1. Set |options|.{{MLLayerNormalizationOptions/epsilon}} to the result of [=casting=] |options|.{{MLLayerNormalizationOptions/epsilon}} to |input|'s [=MLOperand/dataType=].
    1. If |options|.{{MLLayerNormalizationOptions/scale}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-layerNormalization)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/rank=] is not equal to |options|.{{MLLayerNormalizationOptions/axes}}'s [=list/size=], then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLLayerNormalizationOptions/bias}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-layerNormalization)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/rank=] is not equal to |options|.{{MLLayerNormalizationOptions/axes}}'s [=list/size=], then [=exception/throw=] a {{TypeError}}.
    1. [=list/For each=] |index| in [=the range=] 0 to |options|.{{MLLayerNormalizationOptions/axes}}'s [=list/size=], exclusive:
        1. Let |axis| be |options|.{{MLLayerNormalizationOptions/axes}}[|index|].
        1. If |axis| is greater or equal to |input|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
        1. Let |size| be |input|'s [=MLOperand/shape=][|axis|].
        1. If |options|.{{MLLayerNormalizationOptions/scale}} [=map/exists=]:
            1. If its [=MLOperand/shape=][|index|] is not equal to |size|, then [=exception/throw=] a {{TypeError}}.
        1. If |options|.{{MLLayerNormalizationOptions/bias}} [=map/exists=]:
            1. If its [=MLOperand/shape=][|index|] is not equal to |size|, then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "layerNormalization" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. If |options|.{{MLLayerNormalizationOptions/scale}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. If |options|.{{MLLayerNormalizationOptions/bias}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation when the axes parameter is set to [1,2,3] can be [EMULATED]
  </summary>
  <pre highlight="js">
    function layerNormalization(builder, input, options) {
      // The reduction of the mean and variance values happens over the spatial
      // dimensions across all the input features (i.e. all channels) of the input
      // tensor.
      const reduceOptions = {axes: [1, 2, 3], keepDimensions: true};
      const mean = builder.reduceMean(input, reduceOptions);
      const variance = builder.reduceMean(
        builder.pow(builder.sub(input, mean), builder.constant(input.dataType, 2)),
        reduceOptions);

      // The scale and bias tensors are of the shape of the input
      // specified by the values in the axes parameter (i.e. [1,2,3]).
      return builder.add(
        builder.mul(
          options.scale,
          builder.div(
            builder.sub(input, mean),
            builder.sqrt(builder.add(variance, options.epsilon)))),
        options.bias);
    }
  </pre>
</details>
</div>

### leakyRelu ### {#api-mlgraphbuilder-leakyrelu}
Calculate the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Leaky_ReLU"> leaky version of rectified linear function</a> on the input tensor element-wise. The calculation follows the expression `max(0, x) + alpha * min(0, x)`.

<script type=idl>
dictionary MLLeakyReluOptions : MLOperatorOptions {
  double alpha = 0.01;
};

partial interface MLGraphBuilder {
  MLOperand leakyRelu(MLOperand input, optional MLLeakyReluOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits leakyRelu;
};
</script>

{{MLLeakyReluOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLLeakyReluOptions>
    : <dfn>alpha</dfn>
    ::
         A scalar multiplier.
</dl>

<div dfn-for="MLGraphBuilder/leakyRelu(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an optional {{MLLeakyReluOptions}}. The optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/leakyRelu(input, options)/input}}.
</div>

<table id=constraints-leakyRelu class='data' link-for="MLGraphBuilder/leakyRelu(input, options)">
  <caption>Constraints for {{MLGraphBuilder/leakyRelu()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/leakyRelu()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>leakyRelu</dfn>
    :: Support limits for operator {{MLGraphBuilder/leakyRelu()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>leakyRelu(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-leakyRelu)), then [=exception/throw=] a {{TypeError}}.
    1. Set |options|.{{MLLeakyReluOptions/alpha}} to the result of [=casting=] |options|.{{MLLeakyReluOptions/alpha}} to |input|'s [=MLOperand/dataType=].
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "leakyRelu" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be [EMULATED]
    </summary>
    <pre highlight="js">
    function leakyRelu(builder, input, options) {
      return builder.add(
        builder.max(builder.constant(input.dataType, 0), input),
        builder.mul(
          builder.constant(input.dataType, options.alpha),
          builder.min(builder.constant(input.dataType, 0), input)));
    }
    </pre>
  </details>
</div>

### linear ### {#api-mlgraphbuilder-linear}
Calculate a linear function `y = alpha * x + beta` on the input tensor.

<script type=idl>
dictionary MLLinearOptions : MLOperatorOptions {
  double alpha = 1;
  double beta = 0;
};

partial interface MLGraphBuilder {
  MLOperand linear(MLOperand input, optional MLLinearOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits linear;
};
</script>

{{MLLinearOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLLinearOptions>
    : <dfn>alpha</dfn>
    ::
         A scalar multiplier.
    : <dfn>beta</dfn>
    ::
         A scalar addition.
</dl>

<div dfn-for="MLGraphBuilder/linear(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an optional {{MLLinearOptions}}. The optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/linear(input, options)/input}}.
</div>

<table id=constraints-linear class='data' link-for="MLGraphBuilder/linear(input, options)">
  <caption>Constraints for {{MLGraphBuilder/linear()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/linear()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>linear</dfn>
    :: Support limits for operator {{MLGraphBuilder/linear()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>linear(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-linear)), then [=exception/throw=] a {{TypeError}}.
    1. Set |options|.{{MLLinearOptions/alpha}} to the result of [=casting=] |options|.{{MLLinearOptions/alpha}} to |input|'s [=MLOperand/dataType=].
    1. Set |options|.{{MLLinearOptions/beta}} to the result of [=casting=] |options|.{{MLLinearOptions/beta}} to |input|'s [=MLOperand/dataType=].
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "linear" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be [EMULATED]
    </summary>
    <pre highlight="js">
    function linear(builder, input, options) {
      return builder.add(
        builder.mul(input, builder.constant(input.dataType, options.alpha)),
        builder.constant(input.dataType, options.beta));
    }
    </pre>
  </details>
</div>

### lstm ### {#api-mlgraphbuilder-lstm}
Long Short-Term Memory [[LSTM]] recurrent network uses an input, output, forget, and cell gate to compute the output state that rolls into the output across the temporal sequence of the network.

<script type=idl>
enum MLLstmWeightLayout {
  "iofg", // input-output-forget-cell gate ordering
  "ifgo"  // input-forget-cell-output gate ordering
};

dictionary MLLstmOptions : MLOperatorOptions {
  MLOperand bias;
  MLOperand recurrentBias;
  MLOperand peepholeWeight;
  MLOperand initialHiddenState;
  MLOperand initialCellState;
  boolean returnSequence = false;
  MLRecurrentNetworkDirection direction = "forward";
  MLLstmWeightLayout layout = "iofg";
  sequence<MLRecurrentNetworkActivation> activations;
};

partial interface MLGraphBuilder {
  sequence<MLOperand> lstm(MLOperand input,
                           MLOperand weight,
                           MLOperand recurrentWeight,
                           [EnforceRange] unsigned long steps,
                           [EnforceRange] unsigned long hiddenSize,
                           optional MLLstmOptions options = {});
};

dictionary MLLstmSupportLimits {
  MLTensorLimits input;
  MLTensorLimits weight;
  MLTensorLimits recurrentWeight;
  MLTensorLimits bias;
  MLTensorLimits recurrentBias;
  MLTensorLimits peepholeWeight;
  MLTensorLimits initialHiddenState;
  MLTensorLimits initialCellState;
  MLDataTypeLimits outputs;
};

partial dictionary MLOpSupportLimits {
  MLLstmSupportLimits lstm;
};

</script>

{{MLLstmOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLLstmOptions>
    : <dfn>bias</dfn>
    ::
        The 2-D input bias tensor of shape *[numDirections, 4 * hiddenSize]*. The ordering of the bias vectors in the second dimension of the tensor shape is specified according to {{MLLstmOptions/layout}}.

    : <dfn>recurrentBias</dfn>
    ::
        The 2-D recurrent bias tensor of shape *[numDirections, 4 * hiddenSize]*. The ordering of the bias vectors in the first dimension of the tensor shape is specified according to {{MLLstmOptions/layout}}.

    : <dfn>peepholeWeight</dfn>
    ::
        The 2-D weight tensor for peepholes of shape *[numDirections, 3 * hiddenSize]*. The pack ordering of the weight vectors is for the `input (i)`, `output (o)`, and `forget (f)` gate, respectively.

    : <dfn>initialHiddenState</dfn>
    ::
        The 3-D initial hidden state tensor of shape *[numDirections, batchSize, hiddenSize]*. When not specified, implementations must use a tensor filled with zero.

    : <dfn>initialCellState</dfn>
    ::
        The 3-D initial hidden state tensor of shape *[numDirections, batchSize, hiddenSize]*. When not specified, implementations must use a tensor filled with zero.

    : <dfn>returnSequence</dfn>
    ::
         Indicates whether to also return the entire sequence with every output from each time step in it in addition to the output of the last time step.

    : <dfn>direction</dfn>
    ::
        The processing direction of the input sequence. When set to {{MLRecurrentNetworkDirection/"both"}}, the size of the first dimension of the weight and the bias tensor shapes must be 2, and the input is processed in both directions.

    : <dfn>layout</dfn>
    ::
        The ordering of the weight and bias vectors for the internal gates of LSTM, specifically the `input (i)`, `output (o)`, `forget (f)`, and `cell (g)` gate, as indicated in the first dimension of the weight and bias tensor shapes.

    : <dfn>activations</dfn>
    ::
        A list of three [=operator/activation functions=], the first one is used for the `input (i)`, `forget (f)`, and `output (o)` gate, the second one is used for the `cell (g)` gate, and the last used for filtering the output cell state before combining it with the result of the output gate to form the output hidden state. When not specified, defaults to a sequence of the {{MLRecurrentNetworkActivation/"sigmoid"}}, {{MLRecurrentNetworkActivation/"tanh"}}, and {{MLRecurrentNetworkActivation/"tanh"}} functions, respectively.
</dl>

<div dfn-for="MLGraphBuilder/lstm(input, weight, recurrentWeight, steps, hiddenSize, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input 3-D tensor of shape *[steps, batchSize, inputSize]*.
        - <dfn>weight</dfn>: an {{MLOperand}}. The 3-D input weight tensor of shape *[numDirections, 4 * hiddenSize, inputSize]*. The ordering of the weight vectors in the second dimension of the tensor shape is specified according to {{MLLstmOptions/layout}}.
        - <dfn>recurrentWeight</dfn>: an {{MLOperand}}. The 3-D recurrent weight tensor of shape *[numDirections, 4 * hiddenSize, hiddenSize]*. The ordering of the weight vectors in the second dimension of the tensor shape is specified according to {{MLLstmOptions/layout}}.
        - <dfn>steps</dfn>: an {{unsigned long}} scalar. The number of time steps in the recurrent network. The value must be greater than 0.
        - <dfn>hiddenSize</dfn>: an {{unsigned long}} scalar. The value of the third dimension of the cell output tensor shape. It indicates the number of features in the hidden state.
        - <dfn>options</dfn>: an optional {{MLLstmOptions}}. The optional parameters of the operation.

    **Returns:** [=sequence=]<{{MLOperand}}>. The first element is a 3-D tensor of shape *[numDirections, batchSize, hiddenSize]*, the output hidden state from the last time step of the network. The second element is a 3-D tensor of shape *[numDirections, batchSize, hiddenSize]*, the output cell state from the last time step of the network. Additionally, if {{MLLstmOptions/returnSequence}} is set to true, the third element is the 4-D output tensor of shape *[steps, numDirections, batchSize, hiddenSize]* containing every output from each time step in the temporal sequence.
</div>

<table id=constraints-lstm class='data' link-for="MLGraphBuilder/lstm(input, weight, recurrentWeight, steps, hiddenSize, options)">
  <caption>Constraints for {{MLGraphBuilder/lstm()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>3</td>
  </tr>
  <tr>
    <td>{{weight}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>3</td>
  </tr>
  <tr>
    <td>{{recurrentWeight}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>3</td>
  </tr>
  <tr>
    <td>{{MLLstmOptions/bias}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{MLLstmOptions/recurrentBias}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{MLLstmOptions/peepholeWeight}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{MLLstmOptions/initialHiddenState}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>3</td>
  </tr>
  <tr>
    <td>{{MLLstmOptions/initialCellState}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>3</td>
  </tr>
  <tr>
    <td>*outputs[0]*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>3</td>
  </tr>
  <tr>
    <td>*outputs[1]*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>3</td>
  </tr>
  <tr>
    <td>*outputs[2]* if {{MLLstmOptions/returnSequence}} is true</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>4</td>
  </tr>
</table>

{{MLLstmSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLLstmSupportLimits>
    : <dfn>input</dfn>
    :: {{MLTensorLimits}} for input operand.
    : <dfn>weight</dfn>
    :: {{MLTensorLimits}} for weight operand.
    : <dfn>recurrentWeight</dfn>
    :: {{MLTensorLimits}} for recurrentWeight operand.
    : <dfn>bias</dfn>
    :: {{MLTensorLimits}} for bias operand.
    : <dfn>recurrentBias</dfn>
    :: {{MLTensorLimits}} for recurrentBias operand.
    : <dfn>peepholeWeight</dfn>
    :: {{MLTensorLimits}} for peepholeWeight operand.
    : <dfn>initialHiddenState</dfn>
    :: {{MLTensorLimits}} for initialHiddenState operand.
    : <dfn>initialCellState</dfn>
    :: {{MLTensorLimits}} for initialCellState operand.
    : <dfn>outputs</dfn>
    :: {{MLDataTypeLimits}} for all the output operands.
</dl>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/lstm()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>lstm</dfn>
    :: Support limits for operator {{MLGraphBuilder/lstm()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>lstm(|input|, |weight|, |recurrentWeight|, |steps|, |hiddenSize|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input|, |weight|, |recurrentWeight|, |options|.{{MLLstmOptions/bias}} (if it [=map/exists=]), |options|.{{MLLstmOptions/recurrentBias}} (if it [=map/exists=]), |options|.{{MLLstmOptions/peepholeWeight}} (if it [=map/exists=]), |options|.{{MLLstmOptions/initialHiddenState}} (if it [=map/exists=]), and |options|.{{MLLstmOptions/initialCellState}} (if it [=map/exists=]) returns false, then [=exception/throw=] a {{TypeError}}.
    1. Let |numDirections| be 2 if |options|.{{MLLstmOptions/direction}} is {{MLRecurrentNetworkDirection/"both"}}, or 1 otherwise.
    1. If the [=MLOperand/dataType=] of any of |input|, |weight| or |recurrentWeight| is not one of its [=/allowed data types=] (according to [this table](#constraints-lstm)), then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/rank=] of any of |input|, |weight| or |recurrentWeight| is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. If |steps| is 0, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/shape=][0] is not equal to |steps|, then [=exception/throw=] a {{TypeError}}.
    1. Let |batchSize| be |input|'s [=MLOperand/shape=][1].
    1. Let |inputSize| be |input|'s [=MLOperand/shape=][2].
    1. If |weight|'s [=MLOperand/shape=] is not [=list/equal=] to « |numDirections|, 4 * |hiddenSize|, |inputSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |recurrentWeight|'s [=MLOperand/shape=] is not [=list/equal=] to « |numDirections|, 4 * |hiddenSize|, |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |hiddenSize| * 8 is not a [=valid dimension=], then [=exception/throw=] a {{TypeError}}.
        <details class=note>
          <summary>Why |hiddenSize| * 8 ?</summary>
          Some underlying platforms operate on a single bias tensor which is a concatenation of {{MLLstmOptions/bias}} and {{MLLstmOptions/recurrentBias}}. Therefore, 4 * |hiddenSize| + 4 * |hiddenSize| also needs to be a [=valid dimension=].
        </details>
    1. If |options|.{{MLLstmOptions/bias}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-lstm)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « |numDirections|, 4 * |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLLstmOptions/recurrentBias}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-lstm)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « |numDirections|, 4 * |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLLstmOptions/peepholeWeight}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-lstm)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « |numDirections|, 3 * |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLLstmOptions/initialHiddenState}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-lstm)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « |numDirections|, |batchSize|, |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLLstmOptions/initialCellState}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-lstm)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « |numDirections|, |batchSize|, |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLLstmOptions/activations}} [=map/exists=]:
        1. If its [=list/size=] is not 3, then [=exception/throw=] a {{TypeError}}.
        1. Let |activations| be a [=list/clone=] of |options|.{{MLLstmOptions/activations}}.
    1. Otherwise:
        1. Let |activations| be « {{MLRecurrentNetworkActivation/"sigmoid"}}, {{MLRecurrentNetworkActivation/"tanh"}}, {{MLRecurrentNetworkActivation/"tanh"}} ».
    1. *Calculate the output shape:*
        1. Let |desc| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and « |numDirections|, |batchSize|, |hiddenSize| ».
        1. If |options|.{{MLLstmOptions/returnSequence}} is true:
            1. Let |desc2| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and « |steps|, |numDirections|, |batchSize|, |hiddenSize| ».
    1. *Make graph connections:*
        1. Let |operator| be an [=operator=] for the "lstm" operation, given |weight|, |recurrentWeight|, |steps|, |hiddenSize| and |options|.
        1. Let |output0| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Let |output1| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. If |options|.{{MLLstmOptions/returnSequence}} is true:
            1. Let |output2| be the result of [=creating an MLOperand=] given [=this=] and |desc2|.
            1. Let |output| be the [=/list=] « |output0|, |output1|, |output2| ».
            1. Set |output0|.{{MLOperand/[[operator]]}}, |output1|.{{MLOperand/[[operator]]}} and |output2|.{{MLOperand/[[operator]]}} to |operator|.
        1. Otherwise:
            1. Let |output| be the [=/list=] « |output0|, |output1| ».
            1. Set |output0|.{{MLOperand/[[operator]]}} and |output1|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |input|, |weight|, and |recurrentWeight|.
        1. If |options|.{{MLLstmOptions/bias}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. If |options|.{{MLLstmOptions/recurrentBias}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. If |options|.{{MLLstmOptions/peepholeWeight}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. If |options|.{{MLLstmOptions/initialHiddenState}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. If |options|.{{MLLstmOptions/initialCellState}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. Set |operator|'s [=operator/activation functions=] to a [=list/clone=] of |activations|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
<details open>
  <summary>
    Using a [[#emulation-squeeze|squeeze()]] helper, the behavior of this operation can be [EMULATED]
  </summary>
  <pre highlight="js">
    function lstm(
      builder, input, weight, recurrentWeight, steps, hiddenSize, options) {
      const batchSize = input.shape[1];
      const inputSize = input.shape[2];
      const direction = options.direction || 'forward';
      const numDirections = (direction == 'both' ? 2 : 1);
      let hiddenState = options.initialHiddenState;
      let cellState = options.initialCellState;

      if (!hiddenState) {
        const desc = {
          dataType: 'float32',
          shape: [numDirections, batchSize, hiddenSize]
        };
        const totalSize = numDirections * batchSize * hiddenSize;
        hiddenState = builder.constant(desc, new Float32Array(totalSize).fill(0));
      }

      if (!cellState) {
        const desc = {
          dataType: 'float32',
          shape: [numDirections, batchSize, hiddenSize]
        };
        const totalSize = numDirections * batchSize * hiddenSize;
        cellState = builder.constant(desc, new Float32Array(totalSize).fill(0));
      }

      let currentWeight = [];
      let currentRecurrentWeight = [];
      let currentBias = [];
      let currentRecurrentBias = [];
      let currentPeepholeWeight = [];
      let forwardSequence = null;
      let backwardSequence = null;
      let outputHidden = null;
      let outputCell = null;

      for (let dir = 0; dir < numDirections; ++dir) {
        currentWeight.push(squeeze(
          builder,
          builder.slice(weight, [dir, 0, 0], [1, 4 * hiddenSize, inputSize])));
        currentRecurrentWeight.push(squeeze(
          builder,
          builder.slice(
            recurrentWeight, [dir, 0, 0], [1, 4 * hiddenSize, hiddenSize])));
        currentBias.push(
          options.bias ?
            (squeeze(
              builder,
              builder.slice(options.bias, [dir, 0], [1, 4 * hiddenSize]))) :
            null);
        currentRecurrentBias.push(
          options.recurrentBias ?
            (squeeze(
              builder,
              builder.slice(
                options.recurrentBias, [dir, 0], [1, 4 * hiddenSize]))) :
            null);
        currentPeepholeWeight.push(
          options.peepholeWeight ?
            (squeeze(
              builder,
              builder.slice(
                options.peepholeWeight, [dir, 0], [1, 3 * hiddenSize]))) :
            null);

        let currentHidden = squeeze(
          builder,
          builder.slice(hiddenState, [dir, 0, 0], [1, batchSize, hiddenSize]));
        let currentCell = squeeze(
          builder,
          builder.slice(cellState, [dir, 0, 0], [1, batchSize, hiddenSize]));

        for (let step = 0; step < steps; ++step) {
          const slice =
            (dir == 1 || direction == 'backward' ? steps - step - 1 : step);
          const currentInput = squeeze(
            builder,
            builder.slice(input, [slice, 0, 0], [1, batchSize, inputSize]));

          [currentHidden, currentCell] = builder.lstmCell(
            currentInput,
            currentWeight[dir],
            currentRecurrentWeight[dir],
            currentHidden,
            currentCell,
            hiddenSize,
            {
              bias: currentBias[dir],
              recurrentBias: currentRecurrentBias[dir],
              peepholeWeight: currentPeepholeWeight[dir],
              layout: options.layout,
              activations: options.activations
            });

          if (options.returnSequence) {
            // Expand currentHidden of 2D([batchSize, hiddenSize])
            // to 4D([steps, numDirections, batchSize, hiddenSize])
            const expandedHiddenAs4D =
              builder.reshape(currentHidden, [1, 1, batchSize, hiddenSize]);

            if (direction == 'forward' || (dir == 0 && direction == 'both')) {
              forwardSequence = forwardSequence ?
                builder.concat([forwardSequence, expandedHiddenAs4D], 0) :
                expandedHiddenAs4D;
            } else if (
              direction == 'backward' || (dir == 1 && direction == 'both')) {
              backwardSequence = backwardSequence ?
                builder.concat([expandedHiddenAs4D, backwardSequence], 0) :
                expandedHiddenAs4D;
            }
          }
        }

        // Expand currentHidden of 2D([batchSize, hiddenSize])
        // to 3D([numDirections, batchSize, hiddenSize])
        const expandedHiddenAs3D =
          builder.reshape(currentHidden, [1, batchSize, hiddenSize]);
        outputHidden = outputHidden ?
          builder.concat([outputHidden, expandedHiddenAs3D], 0) :
          expandedHiddenAs3D;

        // Expand currentCell of 2D([batchSize, hiddenSize])
        // to 3D([numDirections, batchSize, hiddenSize])
        const expandedCellAs3D =
          builder.reshape(currentCell, [1, batchSize, hiddenSize]);
        outputCell = outputCell ?
          builder.concat([outputCell, expandedCellAs3D], 0) :
          expandedCellAs3D;
      }

      if (options.returnSequence) {
        let outputSequence = null;

        if (direction == 'forward') {
          outputSequence = forwardSequence;
        } else if (direction == 'backward') {
          outputSequence = backwardSequence;
        } else if (direction == 'both') {
          // Concat along axis 1 (numDirections dimension)
          outputSequence = builder.concat([forwardSequence, backwardSequence], 1);
        }

        return [outputHidden, outputCell, outputSequence];
      } else {
        return [outputHidden, outputCell];
      }
    }
  </pre>
</details>
</div>

### lstmCell ### {#api-mlgraphbuilder-lstmcell}
A single time step of the Long Short-Term Memory [[LSTM]] recurrent network using a cell state, an input, output, and forget gate to compute the cell state and the hidden state of the next time step that rolls into the output across the temporal sequence of the network.

<script type=idl>
dictionary MLLstmCellOptions : MLOperatorOptions {
  MLOperand bias;
  MLOperand recurrentBias;
  MLOperand peepholeWeight;
  MLLstmWeightLayout layout = "iofg";
  sequence<MLRecurrentNetworkActivation> activations;
};

partial interface MLGraphBuilder {
  sequence<MLOperand> lstmCell(MLOperand input,
                               MLOperand weight,
                               MLOperand recurrentWeight,
                               MLOperand hiddenState,
                               MLOperand cellState,
                               [EnforceRange] unsigned long hiddenSize,
                               optional MLLstmCellOptions options = {});
};

dictionary MLLstmCellSupportLimits {
  MLTensorLimits input;
  MLTensorLimits weight;
  MLTensorLimits recurrentWeight;
  MLTensorLimits hiddenState;
  MLTensorLimits cellState;
  MLTensorLimits bias;
  MLTensorLimits recurrentBias;
  MLTensorLimits peepholeWeight;
  MLDataTypeLimits outputs;
};

partial dictionary MLOpSupportLimits {
  MLLstmCellSupportLimits lstmCell;
};
</script>

{{MLLstmCellOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLLstmCellOptions>
    : <dfn>bias</dfn>
    ::
        The 1-D input bias tensor of shape *[4 * hiddenSize]*. The ordering of the bias vectors in the first dimension of the tensor shape is specified according to {{MLLstmCellOptions/layout}}.

    : <dfn>recurrentBias</dfn>
    ::
        The 1-D recurrent bias tensor of shape *[4 * hiddenSize]*. The ordering of the bias vectors in the first dimension of the tensor shape is specified according to {{MLLstmCellOptions/layout}}.

    : <dfn>peepholeWeight</dfn>
    ::
        The 1-D weight tensor for peepholes of shape *[3 * hiddenSize]*. The pack ordering of the weight vectors is for the `input (i)`, `output (o)`, and `forget (f)` gate, respectively.

    : <dfn>layout</dfn>
    ::
        The ordering of the weight and bias vectors for the internal gates of LSTM, specifically the `input (i)`, `output (o)`, `forget (f)`, and `cell (g)` gate, as indicated in the first dimension of the weight and bias tensor shapes.

    : <dfn>activations</dfn>
    ::
        A list of three [=operator/activation functions=], the first one is used for the `input (i)`, `forget (f)`, and `output (o)` gate, the second one is used for the `cell (g)` gate, and the last used for filtering the output cell state before combining it with the result of the output gate to form the output hidden state. When not specified, defaults to a sequence of the {{MLRecurrentNetworkActivation/"sigmoid"}}, {{MLRecurrentNetworkActivation/"tanh"}}, and {{MLRecurrentNetworkActivation/"tanh"}} functions, respectively.
</dl>

<div dfn-for="MLGraphBuilder/lstmCell(input, weight, recurrentWeight, hiddenState, cellState, hiddenSize, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input 2-D tensor of shape *[batchSize, inputSize]*.
        - <dfn>weight</dfn>: an {{MLOperand}}. The 2-D input weight tensor of shape *[4 * hiddenSize, inputSize]*. The ordering of the weight vectors in the first dimension of the tensor shape is specified according to {{MLLstmCellOptions/layout}}.
        - <dfn>recurrentWeight</dfn>: an {{MLOperand}}. The 2-D recurrent weight tensor of shape *[4 * hiddenSize, hiddenSize]*. The ordering of the weight vectors in the first dimension of the tensor shape is specified according to {{MLLstmCellOptions/layout}}.
        - <dfn>hiddenState</dfn>: an {{MLOperand}}. The 2-D input hidden state tensor of shape *[batchSize, hiddenSize]*.
        - <dfn>cellState</dfn>: an {{MLOperand}}. The 2-D input cell state tensor of shape *[batchSize, hiddenSize]*.
        - <dfn>hiddenSize</dfn>: an {{unsigned long}} scalar. The value of the second dimension of the output tensor shape. It indicates the number of features in the hidden state.
        - <dfn>options</dfn>: an optional {{MLLstmCellOptions}}. The optional parameters of the operation.

    **Returns:** [=sequence=]<{{MLOperand}}>. The first element is the output hidden state of the current time step of the recurrent network. The following element is the output cell state. Both elements are 2-D tensors of shape *[batchSize, hiddenSize]*.
</div>

<table id=constraints-lstmCell class='data' link-for="MLGraphBuilder/lstmCell(input, weight, recurrentWeight, hiddenState, cellState, hiddenSize, options)">
  <caption>Constraints for {{MLGraphBuilder/lstmCell()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{weight}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{recurrentWeight}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{hiddenState}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{cellState}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>{{MLLstmCellOptions/bias}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>1</td>
  </tr>
  <tr>
    <td>{{MLLstmCellOptions/recurrentBias}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>1</td>
  </tr>
  <tr>
    <td>{{MLLstmCellOptions/peepholeWeight}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>1</td>
  </tr>
  <tr>
    <td>*outputs[0]*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>2</td>
  </tr>
  <tr>
    <td>*outputs[1]*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>2</td>
  </tr>
</table>

{{MLLstmCellSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLLstmCellSupportLimits>
    : <dfn>input</dfn>
    :: {{MLTensorLimits}} for input operand.
    : <dfn>weight</dfn>
    :: {{MLTensorLimits}} for weight operand.
    : <dfn>recurrentWeight</dfn>
    :: {{MLTensorLimits}} for recurrentWeight operand.
    : <dfn>hiddenState</dfn>
    :: {{MLTensorLimits}} for hiddenState operand.
    : <dfn>cellState</dfn>
    :: {{MLTensorLimits}} for cellState operand.
    : <dfn>bias</dfn>
    :: {{MLTensorLimits}} for bias operand.
    : <dfn>recurrentBias</dfn>
    :: {{MLTensorLimits}} for recurrentBias operand.
    : <dfn>peepholeWeight</dfn>
    :: {{MLTensorLimits}} for peepholeWeight operand.
    : <dfn>outputs</dfn>
    :: {{MLDataTypeLimits}} for all the output operands.
</dl>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/lstmCell()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>lstmCell</dfn>
    :: Support limits for operator {{MLGraphBuilder/lstmCell()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>lstmCell(|input|, |weight|, |recurrentWeight|, |hiddenState|, |cellState|, |hiddenSize|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input|, |weight|, |recurrentWeight|, |hiddenState|, |cellState|, |options|.{{MLLstmCellOptions/bias}} (if it [=map/exists=]), |options|.{{MLLstmCellOptions/recurrentBias}} (if it [=map/exists=]), and |options|.{{MLLstmCellOptions/peepholeWeight}} (if it [=map/exists=]) returns false, then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/dataType=] of any of |input|, |weight|, |recurrentWeight|, |hiddenState| or |cellState| is not one of its [=/allowed data types=] (according to [this table](#constraints-lstmCell)), then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/rank=] of any of |input|, |weight|, |recurrentWeight|, |hiddenState| or |cellState| is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. Let |batchSize| be |input|'s [=MLOperand/shape=][0].
    1. Let |inputSize| be |input|'s [=MLOperand/shape=][1].
    1. If |weight|'s [=MLOperand/shape=] is not [=list/equal=] to « 4 * |hiddenSize|, |inputSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |recurrentWeight|'s [=MLOperand/shape=] is not [=list/equal=] to « 4 * |hiddenSize|, |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |hiddenState|'s [=MLOperand/shape=] is not [=list/equal=] to « |batchSize|, |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |cellState|'s [=MLOperand/shape=] is not [=list/equal=] to « |batchSize|, |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |hiddenSize| * 8 is not a [=valid dimension=], then [=exception/throw=] a {{TypeError}}.
        <details class=note>
          <summary>Why |hiddenSize| * 8 ?</summary>
          Some underlying platforms operate on a single bias tensor which is a concatenation of {{MLLstmCellOptions/bias}} and {{MLLstmCellOptions/recurrentBias}}. Therefore, 4 * |hiddenSize| + 4 * |hiddenSize| also needs to be a [=valid dimension=].
        </details>
    1. If |options|.{{MLLstmCellOptions/bias}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-lstmCell)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « 4 * |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLLstmCellOptions/recurrentBias}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-lstmCell)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « 4 * |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLLstmCellOptions/peepholeWeight}} [=map/exists=]:
        1. If its [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-lstmCell)), then [=exception/throw=] a {{TypeError}}.
        1. If its [=MLOperand/shape=] is not [=list/equal=] to « 3 * |hiddenSize| », then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLLstmCellOptions/activations}} [=map/exists=]:
        1. If its [=list/size=] is not 3, then [=exception/throw=] a {{TypeError}}.
        1. Let |activations| be a [=list/clone=] of |options|.{{MLLstmCellOptions/activations}}.
    1. Otherwise:
        1. Let |activations| be « {{MLRecurrentNetworkActivation/"sigmoid"}}, {{MLRecurrentNetworkActivation/"tanh"}}, {{MLRecurrentNetworkActivation/"tanh"}} ».
    1. Let |desc| be a new {{MLOperandDescriptor}}.
    1. Set |desc|.{{MLOperandDescriptor/shape}} to the [=/list=] « |batchSize|, |hiddenSize| ».
    1. Set |desc|.{{MLOperandDescriptor/dataType}} to |input|'s [=MLOperand/dataType=].
       1. *Make graph connections:*
        1. Let |output0| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Let |output1| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Let |output| be the [=/list=] « |output0|, |output1| ».
        1. Let |operator| be an [=operator=] for the "lstmCell" operation, given |weight|, |recurrentWeight|, |hiddenState|, |cellState|, |hiddenSize| and |options|.
        1. Set |output0|.{{MLOperand/[[operator]]}} and |output1|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |input|, |weight|, |recurrentWeight|, |hiddenState|, and |cellState|.
        1. If |options|.{{MLLstmCellOptions/bias}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. If |options|.{{MLLstmCellOptions/recurrentBias}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. If |options|.{{MLLstmCellOptions/peepholeWeight}} [=map/exists=], then add it to |operator|'s [=operator/inputs=].
        1. Set |operator|'s [=operator/activation functions=] to a [=list/clone=] of |activations|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation when the weight layout is the default {{MLLstmWeightLayout/"iofg"}} layout, and the [=operator/activation functions=] of the input/forget/output gate and the cell gate/the cell state's filter for the output hidden state are {{MLGraphBuilder/sigmoid()}} and {{MLGraphBuilder/tanh()}} respectively can be [EMULATED]
  </summary>
  <pre highlight="js">
    function lstmCell(
      builder,
      input,
      weight,
      recurrentWeight,
      hiddenState,
      cellState,
      hiddenSize,
      options) {
      const zero = builder.constant(input.dataType, 0);

      const inputSize = input.shape[1];

      // input gate (i)
      let i = builder.sigmoid(builder.add(
        builder.mul(
          cellState,
          (options.peepholeWeight ?
             builder.slice(options.peepholeWeight, [0], [hiddenSize]) :
             zero)),
        builder.add(
          builder.add(
            (options.bias ? builder.slice(options.bias, [0], [hiddenSize]) : zero),
            (options.recurrentBias ?
               builder.slice(options.recurrentBias, [0], [hiddenSize]) :
               zero)),
          builder.add(
            builder.matmul(
              input,
              builder.transpose(
                builder.slice(weight, [0, 0], [hiddenSize, inputSize]))),
            builder.matmul(
              hiddenState,
              builder.transpose(builder.slice(
                recurrentWeight, [0, 0], [hiddenSize, hiddenSize])))))));

      // forget gate (f)
      let f = builder.sigmoid(builder.add(
        builder.mul(
          cellState,
          (options.peepholeWeight ?
             builder.slice(options.peepholeWeight, [2 * hiddenSize], [hiddenSize]) :
             zero)),
        builder.add(
          builder.add(
            (options.bias ?
               builder.slice(options.bias, [2 * hiddenSize], [hiddenSize]) :
               zero),
            (options.recurrentBias ?
               builder.slice(
                 options.recurrentBias, [2 * hiddenSize], [hiddenSize]) :
               zero)),
          builder.add(
            builder.matmul(
              input,
              builder.transpose(builder.slice(
                weight, [2 * hiddenSize, 0], [hiddenSize, inputSize]))),
            builder.matmul(
              hiddenState,
              builder.transpose(builder.slice(
                recurrentWeight,
                [2 * hiddenSize, 0],
                [hiddenSize, hiddenSize])))))));

      // cell gate (g)
      let g = builder.tanh(builder.add(
        builder.add(
          (options.bias ?
             builder.slice(options.bias, [3 * hiddenSize], [hiddenSize]) :
             zero),
          (options.recurrentBias ?
             builder.slice(options.recurrentBias, [3 * hiddenSize], [hiddenSize]) :
             zero)),
        builder.add(
          builder.matmul(
            input,
            builder.transpose(
              builder.slice(weight, [3 * hiddenSize, 0], [hiddenSize, inputSize]))),
          builder.matmul(
            hiddenState,
            builder.transpose(builder.slice(
              recurrentWeight, [3 * hiddenSize, 0], [hiddenSize, hiddenSize]))))));

      // output gate (o)
      let o = builder.sigmoid(builder.add(
        builder.mul(
          cellState,
          (options.peepholeWeight ?
             builder.slice(options.peepholeWeight, [hiddenSize], [hiddenSize]) :
             zero)),
        builder.add(
          builder.add(
            (options.bias ?
               builder.slice(options.bias, [hiddenSize], [hiddenSize]) :
               zero),
            (options.recurrentBias ?
               builder.slice(options.recurrentBias, [hiddenSize], [hiddenSize]) :
               zero)),
          builder.add(
            builder.matmul(
              input,
              builder.transpose(
                builder.slice(weight, [hiddenSize, 0], [hiddenSize, inputSize]))),
            builder.matmul(
              hiddenState,
              builder.transpose(builder.slice(
                recurrentWeight, [hiddenSize, 0], [hiddenSize, hiddenSize])))))));

      // output cell state (ct)
      let ct = builder.add(builder.mul(f, cellState), builder.mul(i, g));

      // output hidden state (ht)
      let ht = builder.mul(o, builder.tanh(ct));

      return [ht, ct];
    }
  </pre>
</details>
</div>

### matmul ### {#api-mlgraphbuilder-matmul}
Compute the matrix product of two input tensors.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand matmul(MLOperand a, MLOperand b, optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLBinarySupportLimits matmul;
};
</script>

<div dfn-for="MLGraphBuilder/matmul(a, b, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>a</dfn>: an {{MLOperand}}. The first input tensor which is at least 2-D.
        - <dfn>b</dfn>: an {{MLOperand}}. The second input tensor which is at least 2-D.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output tensor that contains the matrix
    product of two input tensors.
</div>
<div>
    Computes the matrix product of two input tensors as follows:
        - If both {{MLGraphBuilder/matmul(a, b, options)/a}} and {{MLGraphBuilder/matmul(a, b, options)/b}} are 2-dimensional, they are multiplied like conventional
            matrices and produce a 2-dimensional tensor as the output.
        - If either {{MLGraphBuilder/matmul(a, b, options)/a}} or {{MLGraphBuilder/matmul(a, b, options)/b}} is `N`-dimensional where `N > 2`, it is treated as a stack of matrices with dimensions corresponding to the last two indices. The matrix multiplication will be [=broadcast=] according to [[!numpy-broadcasting-rule]]. The shapes of {{MLGraphBuilder/matmul(a, b, options)/a}} and {{MLGraphBuilder/matmul(a, b, options)/b}}, except the last two dimensions, must be [=bidirectionally broadcastable=]. The output is a `N`-dimensional tensor whose rank is the maximum [=MLOperand/rank=] of the input tensors. For each dimension, except the last two, of the output tensor, its size is the maximum size along that dimension of the input tensors.
</div>

<table id=constraints-matmul class='data' link-for="MLGraphBuilder/matmul(a, b, options)">
  <caption>Constraints for {{MLGraphBuilder/matmul()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{a}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>2 or greater</td>
  </tr>
  <tr>
    <td>{{b}}</td>
    <td>[=/same type as|same as=] {{a}}</td>
    <td>2 or greater</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{a}}</td>
    <td>maximum of {{a}}'s [=MLOperand/rank=] and {{b}}'s [=MLOperand/rank=]</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/matmul()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>matmul</dfn>
    :: Support limits for operator {{MLGraphBuilder/matmul()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>matmul(|a|, |b|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |a| and |b| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/dataType=] of any of |a| or |b| is not one of its [=/allowed data types=] (according to [this table](#constraints-matmul)), then [=exception/throw=] a {{TypeError}}.
    1. *Calculate the output shape:*
        1. Let |shapeA| be a [=list/clone=] of |a|'s [=MLOperand/shape=].
        1. Let |rankA| be |a|'s [=MLOperand/rank=].
        1. Let |shapeB| be a [=list/clone=] of |b|'s [=MLOperand/shape=].
        1. Let |rankB| be |b|'s [=MLOperand/rank=].
        1. If either |rankA| or |rankB| is less than 2, then [=exception/throw=] a {{TypeError}}.
        1. Let |colsA| be |shapeA|[|rankA| - 1].
        1. Let |rowsA| be |shapeA|[|rankA| - 2].
        1. Let |colsB| be |shapeB|[|rankB| - 1].
        1. Let |rowsB| be |shapeB|[|rankB| - 2].
        1. If |colsA| is not equal to |rowsB|, then [=exception/throw=] a {{TypeError}}.
        1. Let |batchShapeA| be a [=list/clone=] of |shapeA| with the spatial dimensions (last 2 items) [=list/removed=].
        1. Let |batchShapeB| be a [=list/clone=] of |shapeB| with the spatial dimensions (last 2 items) [=list/removed=].
        1. Let |outputShape| be the result of [=bidirectionally broadcasting=] |batchShapeA| and |batchShapeB|. If that returns failure, then [=exception/throw=] a {{TypeError}}.
        1. [=list/Append=] « |rowsA|, |colsB| » to |outputShape|.
        1. Let |desc| be the result of [=creating an MLOperandDescriptor=] given |a|'s [=MLOperand/dataType=] and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Let |operator| be an [=operator=] for the "matmul" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |a| and |b|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

### pad ### {#api-mlgraphbuilder-pad}
Inflate the tensor with constant or mirrored values on the edges.
<script type=idl>
enum MLPaddingMode {
  "constant",
  "edge",
  "reflection",
  "symmetric"
};

dictionary MLPadOptions : MLOperatorOptions {
  MLPaddingMode mode = "constant";
  MLNumber value = 0;
};

partial interface MLGraphBuilder {
  MLOperand pad(MLOperand input,
                sequence<[EnforceRange] unsigned long> beginningPadding,
                sequence<[EnforceRange] unsigned long> endingPadding,
                optional MLPadOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits pad;
};
</script>

{{MLPadOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLPadOptions>
    : <dfn>mode</dfn>
    ::
        The different ways to pad the tensor.

    : <dfn>value</dfn>
    ::
        The padding value when {{MLPadOptions/mode}} is set to {{MLPaddingMode/"constant"}}.
</dl>

<div dfn-for="MLGraphBuilder/pad(input, beginningPadding, endingPadding, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>beginningPadding</dfn>: [=sequence=]<{{unsigned long}}>. The number of padding values to add at the beginning of each input dimension, of length *N* where *N* is the [=MLOperand/rank=] of the input tensor. For each dimension *d* of {{MLGraphBuilder/pad(input, beginningPadding, endingPadding, options)/input}}, {{MLGraphBuilder/pad(input, beginningPadding, endingPadding, options)/beginningPadding}}[*d*] indicates how many values to add before the content in that dimension.
        - <dfn>endingPadding</dfn>: [=sequence=]<{{unsigned long}}>. The number of padding values to add at the ending of each input dimension, of length *N* where *N* is the [=MLOperand/rank=] of the input tensor. For each dimension *d* of {{MLGraphBuilder/pad(input, beginningPadding, endingPadding, options)/input}}, {{MLGraphBuilder/pad(input, beginningPadding, endingPadding, options)/endingPadding}}[*d*] indicates how many values to add after the content in that dimension.
        - <dfn>options</dfn>: an optional {{MLPadOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The padded output tensor. Each dimension of the output tensor can be calculated as follows:

    `output size = beginning padding + input size + ending padding`
</div>

<table id=constraints-pad class='data' link-for="MLGraphBuilder/pad(input, beginningPadding, endingPadding, options)">
  <caption>Constraints for {{MLGraphBuilder/pad()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/pad()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>pad</dfn>
    :: Support limits for operator {{MLGraphBuilder/pad()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>pad(|input|, |beginningPadding|, |endingPadding|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/rank=] is 0, then [=exception/throw=] a {{TypeError}}.
    1. If |beginningPadding|'s [=list/size=] and |endingPadding|'s [=list/size=] are not both equal to |input|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
    1. Let |desc| be a copy of |input|.{{MLOperand/[[descriptor]]}}.
    1. Let |outputShape| be a copy of |input|'s [=MLOperand/shape=].
    1. [=list/For each=] |index| in [=the range=] 0 to |outputShape|'s [=MLOperand/rank=], exclusive:
        1. Add to |outputShape|[|index|] the value of |beginningPadding|[|index|].
        1. Add to |outputShape|[|index|] the value of |endingPadding|[|index|].
    1. If any [=list/item=] in |outputShape| is not a [=valid dimension=], then [=exception/throw=] a {{TypeError}}.
    1. Set |options|.{{MLPadOptions/value}} to the result of [=casting=] |options|.{{MLPadOptions/value}} to |input|'s [=MLOperand/dataType=].
    1. Set |desc|.{{MLOperandDescriptor/shape}} to |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Let |operator| be an [=operator=] for the "padding" operation, given |beginningPadding|, |endingPadding| and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="example">
<details open>
  <summary>
    Examples for constant, edge, reflection and symmetric padding:
  </summary>
  <pre highlight="js">
    // input: [[1,2,3], [4,5,6]]
    const input = builder.constant(
      {dataType: 'float32', shape: [2, 3]}, new Float32Array([1, 2, 3, 4, 5, 6]));

    const beginningPadding = [1, 2];
    const endingPadding = [1, 2];

    // "constant" padded:
    //    [[0,0,0,0,0,0,0],
    //     [0,0,1,2,3,0,0],
    //     [0,0,4,5,6,0,0],
    //     [0,0,0,0,0,0,0]]
    builder.pad(input, beginningPadding, endingPadding);

    // "edge" padded:
    //    [[1,1,1,2,3,3,3],
    //     [1,1,1,2,3,3,3],
    //     [4,4,4,5,6,6,6],
    //     [4,4,4,5,6,6,6]]
    builder.pad(input, beginningPadding, endingPadding, {mode: 'edge'});

    // "reflection" padded:
    //    [[6,5,4,5,6,5,4],
    //     [3,2,1,2,3,2,1],
    //     [6,5,4,5,6,5,4],
    //     [3,2,1,2,3,2,1]]
    builder.pad(input, beginningPadding, endingPadding, {mode: 'reflection'});

    // "symmetric" padded:
    //    [[2,1,1,2,3,3,2],
    //     [2,1,1,2,3,3,2],
    //     [5,4,4,5,6,6,5],
    //     [5,4,4,5,6,6,5]]
    builder.pad(input, beginningPadding, endingPadding, {mode: 'symmetric'});
  </pre>
</details>
</div>

### Pooling operations ### {#api-mlgraphbuilder-pool2d}
Compute a pooling operation across all the elements within the moving window over the input tensor.
<script type=idl>
enum MLRoundingType {
  "floor",
  "ceil"
};

dictionary MLPool2dOptions : MLOperatorOptions {
  sequence<[EnforceRange] unsigned long> windowDimensions;
  sequence<[EnforceRange] unsigned long> padding;
  sequence<[EnforceRange] unsigned long> strides;
  sequence<[EnforceRange] unsigned long> dilations;
  MLInputOperandLayout layout = "nchw";
  MLRoundingType roundingType = "floor";
  sequence<[EnforceRange] unsigned long> outputSizes;
};

partial interface MLGraphBuilder {
  MLOperand averagePool2d(MLOperand input, optional MLPool2dOptions options = {});
  MLOperand l2Pool2d(MLOperand input, optional MLPool2dOptions options = {});
  MLOperand maxPool2d(MLOperand input, optional MLPool2dOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits averagePool2d;
  MLSingleInputSupportLimits l2Pool2d;
  MLSingleInputSupportLimits maxPool2d;
};
</script>

{{MLPool2dOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLPool2dOptions>
    : <dfn>windowDimensions</dfn>
    ::
         A list of length 2: *[windowHeight, windowWidth]*.
         Specifies the dimensions of the sliding window.
         The default value for the window dimensions are the height and width dimensions of the input shape.

    : <dfn>padding</dfn>
    ::
        A list of length 4: *[beginningHeight, endingHeight, beginningWidth, endingWidth]*.
        Specifies the additional rows and columns added to the beginning and ending of each spatial dimension of the convolution input.
        The default value is [0,0,0,0].

    : <dfn>strides</dfn>
    ::
        A list of length 2: *[strideHeight, strideWidth]*.
        Specifies the stride of the sliding window for each spatial dimension of the convolution input.
        The default value is [1,1].

    : <dfn>dilations</dfn>
    ::
        A list of length 2: *[dilationHeight, dilationWidth]*. Specifies the dilation factor for each spatial dimension applied on the convolution filter (kernel).
        The default value is [1,1].

    : <dfn>layout</dfn>
    ::
        Specifies the layout format of the input and output tensor as follows:
            - {{MLInputOperandLayout/"nchw"}}
                - input tensor: *[batches, inputChannels, height, width]*
                - output tensor: *[batches, outputChannels, height, width]*
            - {{MLInputOperandLayout/"nhwc"}}:
                - input tensor: *[batches, height, width, inputChannels]*
                - output tensor: *[batches, height, width, outputChannels]*

    : <dfn>roundingType</dfn>
    ::
        The rounding function used to compute the output shape.

    : <dfn>outputSizes</dfn>
    ::
        A list of length 2.
        Specifies the sizes of the two spacial dimensions of the output tensor. When the output sizes are explicitly specified, the {{MLPool2dOptions/roundingType}} is ignored.

        If not specified, the output sizes are automatically computed.
</dl>

<div dfn-for="MLGraphBuilder/averagePool2d(input, options), MLGraphBuilder/l2Pool2d(input, options), MLGraphBuilder/maxPool2d(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input 4-D tensor. The logical shape
            is interpreted according to the value of {{MLPool2dOptions/layout}}.
        - <dfn>options</dfn>: an optional {{MLPool2dOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output 4-D tensor that contains the
    result of the reduction. The logical shape is interpreted according to the
    value of {{MLPool2dOptions/layout}}. More specifically, if the {{MLPool2dOptions/roundingType}} is {{MLRoundingType/"floor"}}, the spatial dimensions of the output tensor can be calculated as follows:

    `output size = floor(1 + (input size - filter size + beginning padding + ending padding) / stride)`

    or if {{MLPool2dOptions/roundingType}} is {{MLRoundingType/"ceil"}}:

    `output size = ceil(1 + (input size - filter size + beginning padding + ending padding) / stride)`
</div>

<table id=constraints-pooling class='data' link-for="MLGraphBuilder/averagePool2d(input, options), MLGraphBuilder/l2Pool2d(input, options), MLGraphBuilder/maxPool2d(input, options)">
  <caption>Constraints for pooling operations</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>specified as part of operation steps</td>
    <td>4</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>4</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following members for pooling operations:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>averagePool2d</dfn>
    :: Support limits for operator {{MLGraphBuilder/averagePool2d()}}.
    : <dfn>l2Pool2d</dfn>
    :: Support limits for operator {{MLGraphBuilder/l2Pool2d()}}.
    : <dfn>maxPool2d</dfn>
    :: Support limits for operator {{MLGraphBuilder/maxPool2d()}}.
</dl>

<div class="note">
    A *global* pooling operation such as one for the max pooling operation is a variant of pooling where the window dimensions is the spatial dimensions (last two dimensions) of the input shape, as follows.
    <pre highlight="js">
    // 'global' max pooling
    builder.maxPool2d(input);
    </pre>
</div>

<details open algorithm>
  <summary>
    To <dfn for="MLGraphBuilder" data-lt="pooling-op">create pooling operation</dfn> given [=string=] |op|, {{MLOperand}} |input|, {{MLPool2dOptions}} |options|, and optional [=/list=] |allowedDataTypes|, run the following steps:
  </summary>
    1. [=Assert=]: |op| is one of "averagePool2d", "l2Pool2d", "maxPool2d".
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |allowedDataTypes| is given and it does not [=list/contain=] |input|'s [=MLOperand/dataType=], then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/rank=] is not 4, then [=exception/throw=] a {{TypeError}}.
    1. Switch on |options|.{{MLPool2dOptions/layout}}:
        <dl class=switch>
            : {{MLInputOperandLayout/"nchw"}}
            :: Let « |batches|, |channels|, |inputHeight|, |inputWidth| » be |input|'s [=MLOperand/shape=].
            : {{MLInputOperandLayout/"nhwc"}}
            :: Let « |batches|, |inputHeight|, |inputWidth|, |channels| » be |input|'s [=MLOperand/shape=].
        </dl>
    1. If |options|.{{MLPool2dOptions/windowDimensions}} does not [=map/exist=], set |options|.{{MLPool2dOptions/windowDimensions}} to « |inputHeight|, |inputWidth| ».
    1. If |options|.{{MLPool2dOptions/windowDimensions}}'s [=list/size=] is not 2, then [=exception/throw=] a {{TypeError}}.
    1. If any [=list/item=] in |options|.{{MLPool2dOptions/windowDimensions}} is equal to 0, then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLPool2dOptions/outputSizes}} [=map/exists=], or if |options|.{{MLPool2dOptions/padding}} does not [=map/exist=], set |options|.{{MLPool2dOptions/padding}} to the [=/list=] « 0, 0, 0, 0 ».
    1. If |options|.{{MLPool2dOptions/padding}}'s [=list/size=] is not 4, then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLPool2dOptions/strides}} does not [=map/exist=], set |options|.{{MLPool2dOptions/strides}} to the [=/list=] « 1, 1 ».
    1. If |options|.{{MLPool2dOptions/strides}}'s [=list/size=] is not 2, then [=exception/throw=] a {{TypeError}}.
    1. If any value in |options|.{{MLPool2dOptions/strides}} is not greater than 0, then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLPool2dOptions/outputSizes}} [=map/exists=]:
        1. If its [=list/size=] is not 2, then [=exception/throw=] a {{TypeError}}.
        1. If its [=list/items=] are not smaller than the [=list/items=] at the same dimension (index) for |options|.{{MLPool2dOptions/strides}}, then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLPool2dOptions/dilations}} does not [=map/exist=], set |options|.{{MLPool2dOptions/dilations}} to the [=/list=] « 1, 1 ».
    1. If |options|.{{MLPool2dOptions/dilations}}'s [=list/size=] is not 2, then [=exception/throw=] a {{TypeError}}.
    1. If any value in |options|.{{MLPool2dOptions/dilations}} is not greater than 0, then [=exception/throw=] a {{TypeError}}.
    1. Let |desc| be a copy of |input|.{{MLOperand/[[descriptor]]}}.
    1. *Calculate the output shape:*
        1. Let « |windowHeight|, |windowWidth| » be |options|.{{MLPool2dOptions/windowDimensions}}.
        1. Let « |calculatedOutputHeight|, |calculatedOutputWidth| » be the result of [=MLGraphBuilder/calculating conv2d output sizes=] given |inputHeight|, |inputWidth|, |windowHeight|, |windowWidth|, |options|.{{MLPool2dOptions/padding}}, |options|.{{MLPool2dOptions/strides}}, and |options|.{{MLPool2dOptions/dilations}}.
        1. If |options|.{{MLPool2dOptions/outputSizes}} [=map/exists=], then:
            1. Let « |outputHeight|, |outputWidth| » be |options|.{{MLPool2dOptions/outputSizes}}.
            1. If neither |outputHeight| equals floor( |calculatedOutputHeight| ) and |outputWidth| equals floor( |calculatedOutputWidth| ), nor |outputHeight| equals ceil( |calculatedOutputHeight| ) and |outputWidth| equals ceil( |calculatedOutputWidth| ), then [=exception/throw=] a {{TypeError}}.
        1. Otherwise:
            1. Let « |outputHeight|, |outputWidth| » be « |calculatedOutputHeight|, |calculatedOutputWidth| ».
            1. Switch on |options|.{{MLPool2dOptions/roundingType}}:
                <dl class=switch>
                    : {{MLRoundingType/"floor"}}
                    ::
                        1. Set |outputWidth| to floor(|outputWidth|).
                        1. Set |outputHeight| to floor(|outputHeight|).
                    : {{MLRoundingType/"ceil"}}
                    ::
                        1. Set |outputWidth| to ceiling(|outputWidth|).
                        1. Set |outputHeight| to ceiling(|outputHeight|).
                </dl>
        1. If either |outputHeight| or |outputWidth| is not a [=valid dimension=], then [=exception/throw=] a {{TypeError}}.
        1. Switch on |options|.{{MLPool2dOptions/layout}}:
            <dl class=switch>
                : {{MLInputOperandLayout/"nchw"}}
                :: Let |outputShape| be « |batches|, |channels|, |outputHeight|, |outputWidth| ».
                : {{MLInputOperandLayout/"nhwc"}}
                :: Let |outputShape| be « |batches|, |outputHeight|, |outputWidth|, |channels| ».
            </dl>
        1. Set |desc|.{{MLOperandDescriptor/shape}} to |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Let |operator| be an [=operator=] for the |op| operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<details open>
  <summary>
    The following pooling algorithms are supported.
  </summary>
    <div algorithm>
    The <dfn method for=MLGraphBuilder>averagePool2d(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/pooling-op | create pooling operation=] given "averagePool2d", |input|, |options|, and « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} ».
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>l2Pool2d(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/pooling-op | create pooling operation=] given "l2Pool2d", |input|, |options|, and « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} ».
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>maxPool2d(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of running the [=MLGraphBuilder/pooling-op | create pooling operation=] given "maxPool2d", |input| and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>
</details>

#### averagePool2d #### {#api-mlgraphbuilder-pool2d-average}
Calculate the average value for patches of a feature map, and use it to create a pooled feature map. See [[#api-mlgraphbuilder-pool2d]] for more detail.

#### l2Pool2d #### {#api-mlgraphbuilder-pool2d-l2}
Apply the L2 norm function to a region of the input feature map. The L2 norm is the square root of the sum of the squares of its elements. See [[#api-mlgraphbuilder-pool2d]] for more detail.

#### maxPool2d #### {#api-mlgraphbuilder-pool2d-max}
Calculate the maximum value for patches of a feature map, and use it to create a pooled feature map. See [[#api-mlgraphbuilder-pool2d]] for more detail.

### prelu ### {#api-mlgraphbuilder-prelu}
Calculate the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Parametric_ReLU">parametric version of rectified linear function (Parametric ReLU)</a> on the input tensor element-wise. Parametric ReLU is a type of leaky ReLU that, instead of having a scalar slope like 0.01, making the slope (coefficient of leakage) into a parameter that is learned during the model training phase of this operation. The calculation follows the expression `max(0, x) + slope * min(0, x)`.

The operation will be [=broadcast=] according to [[!numpy-broadcasting-rule]]. The input tensors must be [=bidirectionally broadcastable=]. The [=MLOperand/rank=] of the output tensor is the maximum [=MLOperand/rank=] of the input tensors. For each dimension of the output tensor, its size is the maximum size along that dimension of the input tensors.

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand prelu(MLOperand input,
                  MLOperand slope,
                  optional MLOperatorOptions options = {});
};

dictionary MLPreluSupportLimits {
  MLTensorLimits input;
  MLTensorLimits slope;
  MLDataTypeLimits output;
};

partial dictionary MLOpSupportLimits {
  MLPreluSupportLimits prelu;
};
</script>

<div dfn-for="MLGraphBuilder/prelu(input, slope, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>slope</dfn>: an {{MLOperand}}. The slope tensor. Its shape must be [=bidirectionally broadcastable=] to the shape of {{MLGraphBuilder/prelu(input, slope, options)/input}}.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/prelu(input, slope, options)/input}}.
</div>

<table id=constraints-prelu class='data' link-for="MLGraphBuilder/prelu(input, slope, options)">
  <caption>Constraints for {{MLGraphBuilder/prelu()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}, {{MLOperandDataType/"int32"}}, {{MLOperandDataType/"int8"}}</td>
    <td>[=/any rank|N=]</td>
  <tr>
    <td>{{slope}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>maximum of {{input}}'s [=MLOperand/rank=] and {{slope}}'s [=MLOperand/rank=]</td>
  </tr>
</table>

{{MLPreluSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLPreluSupportLimits>
    : <dfn>input</dfn>
    :: {{MLTensorLimits}} for input operand.
    : <dfn>slope</dfn>
    :: {{MLTensorLimits}} for slope operand.
    : <dfn>output</dfn>
    :: {{MLDataTypeLimits}} for output operand.
</dl>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/prelu()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>prelu</dfn>
    :: Support limits for operator {{MLGraphBuilder/prelu()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>prelu(|input|, |slope|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input| and |slope| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/dataType=] of any of |input| or |slope| is not one of its [=/allowed data types=] (according to [this table](#constraints-prelu)), then [=exception/throw=] a {{TypeError}}.
    1. Let |outputShape| be to the result of [=bidirectionally broadcasting=] |slope|'s [=MLOperand/shape=] and |input|'s [=MLOperand/shape=].
        1. If that returns failure, then [=exception/throw=] a {{TypeError}}.
    1. Let |descriptor| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |descriptor|.
        1. Let |operator| be an [=operator=] for the "prelu" operation, given |slope| and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |input| and |slope|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be [EMULATED]
    </summary>
    <pre highlight="js">
    function prelu(builder, input, slope) {
      return builder.add(
        builder.max(builder.constant(input.dataType, 0), input),
        builder.mul(
          slope, builder.min(builder.constant(input.dataType, 0), input)));
    }
    </pre>
  </details>
</div>

### Reduction operations ### {#api-mlgraphbuilder-reduce}
Reduce the input tensor along all dimensions, or along the axes specified in the {{MLReduceOptions/axes}} array parameter. For each specified axis, the dimension with that index is reduced, i.e. the resulting tensor will not contain it, unless {{MLReduceOptions/keepDimensions}} is specified. The values of the resulting tensor are calculated using the specified reduction function that takes as parameters all the input values across the reduced dimensions.

<script type=idl>
dictionary MLReduceOptions : MLOperatorOptions {
  sequence<[EnforceRange] unsigned long> axes;
  boolean keepDimensions = false;
};

partial interface MLGraphBuilder {
  MLOperand reduceL1(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceL2(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceLogSum(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceLogSumExp(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceMax(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceMean(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceMin(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceProduct(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceSum(MLOperand input, optional MLReduceOptions options = {});
  MLOperand reduceSumSquare(MLOperand input, optional MLReduceOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits reduceL1;
  MLSingleInputSupportLimits reduceL2;
  MLSingleInputSupportLimits reduceLogSum;
  MLSingleInputSupportLimits reduceLogSumExp;
  MLSingleInputSupportLimits reduceMax;
  MLSingleInputSupportLimits reduceMean;
  MLSingleInputSupportLimits reduceMin;
  MLSingleInputSupportLimits reduceProduct;
  MLSingleInputSupportLimits reduceSum;
  MLSingleInputSupportLimits reduceSumSquare;
};
</script>

{{MLReduceOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLReduceOptions>
    : <dfn>axes</dfn>
    ::
        The dimensions to reduce, which also specifies which of the values in the input tensor are used with the reduction function. The axes in the list must be in the range [0, N-1] where N is the [=MLOperand/rank=] of the input tensor.

        If not present, all dimensions are reduced. The input values for the reduction function are all of the values in the input tensor.

        If present and not empty, the input values for the reduction function are all the values for the specified dimensions of the input tensor.

        If present and empty, no dimensions are reduced, and the shape of the output tensor is the same as the shape of the input tensor; the reduction function is applied to each value in the tensor individually.

    : <dfn>keepDimensions</dfn>
    ::
        If true, the output has the same rank as the input, setting any reduced dimensions to size 1.
</dl>

<div dfn-for="MLGraphBuilder/reduceL1(input, options), MLGraphBuilder/reduceL2(input, options), MLGraphBuilder/reduceLogSum(input, options), MLGraphBuilder/reduceLogSumExp(input, options), MLGraphBuilder/reduceMax(input, options), MLGraphBuilder/reduceMean(input, options), MLGraphBuilder/reduceMin(input, options), MLGraphBuilder/reduceProduct(input, options), MLGraphBuilder/reduceSum(input, options), MLGraphBuilder/reduceSumSquare(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an optional {{MLReduceOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The reduced output tensor. If the input operand is a scalar, the reduction function is applied to the scalar value, and the output is also a scalar.
</div>

<table id=constraints-reduction class='data' link-for="MLGraphBuilder/reduceL1(input, options), MLGraphBuilder/reduceL2(input, options), MLGraphBuilder/reduceLogSum(input, options), MLGraphBuilder/reduceLogSumExp(input, options), MLGraphBuilder/reduceMax(input, options), MLGraphBuilder/reduceMean(input, options), MLGraphBuilder/reduceMin(input, options), MLGraphBuilder/reduceProduct(input, options), MLGraphBuilder/reduceSum(input, options), MLGraphBuilder/reduceSumSquare(input, options)">
  <caption>Constraints for reduction-operations</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>specified as part of operation steps</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>0 to {{input}}'s [=MLOperand/rank=], depending on {{MLReduceOptions/axes}} and {{MLReduceOptions/keepDimensions}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following members for reduction operations:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>reduceL1</dfn>
    :: Support limits for operator {{MLGraphBuilder/reduceL1()}}.
    : <dfn>reduceL2</dfn>
    :: Support limits for operator {{MLGraphBuilder/reduceL2()}}.
    : <dfn>reduceLogSum</dfn>
    :: Support limits for operator {{MLGraphBuilder/reduceLogSum()}}.
    : <dfn>reduceLogSumExp</dfn>
    :: Support limits for operator {{MLGraphBuilder/reduceLogSumExp()}}.
    : <dfn>reduceMax</dfn>
    :: Support limits for operator {{MLGraphBuilder/reduceMax()}}.
    : <dfn>reduceMean</dfn>
    :: Support limits for operator {{MLGraphBuilder/reduceMean()}}.
    : <dfn>reduceMin</dfn>
    :: Support limits for operator {{MLGraphBuilder/reduceMin()}}.
    : <dfn>reduceProduct</dfn>
    :: Support limits for operator {{MLGraphBuilder/reduceProduct()}}.
    : <dfn>reduceSum</dfn>
    :: Support limits for operator {{MLGraphBuilder/reduceSum()}}.
    : <dfn>reduceSumSquare</dfn>
    :: Support limits for operator {{MLGraphBuilder/reduceSumSquare()}}.
</dl>

<div>
    **Reduction types:**
        - *L1*: Compute the <a href="https://mathworld.wolfram.com/L1-Norm.html">L1 norm</a>, the sum of the absolute value of the input values.
        - *L2*: Compute the <a href="https://mathworld.wolfram.com/L2-Norm.html">L2 norm</a>, the square root of the sum of the square of the input values.
        - *LogSum*: Compute the log value of the sum of the input values.
        - *LogSumExp*: Compute the log value of the sum of the exponent of the input values.
        - *Max*: Compute the maximum value of the input values.
        - *Mean*: Compute the average value of the input values.
        - *Min*: Compute the minimum value of the input values.
        - *Product*: Compute the product of the input values.
        - *Sum*: Compute the sum of the input values.
        - *SumSquare*: Compute the sum of the square of the input values.
</div>

<details open algorithm>
  <summary>
    To <dfn for="MLGraphBuilder">calculate reduction output sizes</dfn>, given a [=/list=] of unsigned integers |inputShape|, a optional [=/list=] of unsigned integers |axes|, and [=/boolean=] |keepDimensions|, perform the following steps. They return a new [=/list=] of unsigned integers, or failure.
  </summary>
    1. Let |inputRank| be |inputShape|'s [=list/size=].
    1. If |axes| is not given, let |axes| be [=the range=] 0 to |inputRank|, exclusive.
    1. Otherwise, if |axes| contains duplicate values, or if any of its [=list/items=] is not in [=the range=] 0 to |inputRank|, exclusive, then return failure.
    1. If |keepDimensions| is true, then:
        1. Let |outputShape| be a [=list/clone=] of |inputShape|.
        1. [=list/For each=] |axis| of |axes|:
            1. Set |outputShape|[|axis|] to 1.
    1. Otherwise:
        1. Let |outputShape| be an empty [=/list=].
        1. [=list/For each=] |index| in [=the range=] 0 to |inputRank|, exclusive:
            1. If |axes| does not [=list/contain=] |index|, then [=list/append=] |inputShape|[|index|] to |outputShape|.
    1. Return |outputShape|.
</details>

<details open algorithm>
  <summary>
    To <dfn for="MLGraphBuilder">create reduction operation</dfn> given [=string=] |op|, {{MLOperand}} |input|, {{MLReduceOptions}} |options|, and optional [=/list=] |allowedDataTypes|, run the following steps:
  </summary>
    1. [=Assert=]: |op| is one of "reduceL1", "reduceL2", "reduceLogSum", "reduceLogSumExp", "reduceMax", "reduceMean", "reduceMin", "reduceProduct", "reduceSum", "reduceSumSquare".
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |allowedDataTypes| is given and it does not [=list/contain=] |input|'s [=MLOperand/dataType=], then [=exception/throw=] a {{TypeError}}.
    1. Let |outputShape| be the result of [=MLGraphBuilder/calculating reduction output sizes=] given |input|'s [=MLOperand/shape=], |options|.{{MLReduceOptions/axes}} (if it [=map/exists=]), and |options|.{{MLReduceOptions/keepDimensions}}. If that returns failure, then [=exception/throw=] a {{TypeError}}.
    1. Let |desc| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Let |operator| be an [=operator=] for the |op| operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<details open>
  <summary>
    The following reduction algorithms are supported.
  </summary>
    <div algorithm>
    The <dfn method for=MLGraphBuilder>reduceL1(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of [=MLGraphBuilder/creating reduction operation=] given "reduceL1", |input|, |options|, and « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}, {{MLOperandDataType/"int32"}}, {{MLOperandDataType/"uint32"}} ».
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>reduceL2(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of [=MLGraphBuilder/creating reduction operation=] given "reduceL2", |input|, |options|, and « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} ».
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>reduceLogSum(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of [=MLGraphBuilder/creating reduction operation=] given "reduceLogSum", |input|, |options|, and « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} ».
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>reduceLogSumExp(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of [=MLGraphBuilder/creating reduction operation=] given "reduceLogSumExp", |input|, |options|, and « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} ».
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>reduceMax(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of [=MLGraphBuilder/creating reduction operation=] given "reduceMax", |input| and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>reduceMean(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of [=MLGraphBuilder/creating reduction operation=] given "reduceMean", |input|, |options|, and « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}} ».
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>reduceMin(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of [=MLGraphBuilder/creating reduction operation=] given "reduceMin", |input| and |options|.
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>reduceProduct(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of [=MLGraphBuilder/creating reduction operation=] given "reduceProduct", |input|, |options|, and « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}, {{MLOperandDataType/"int32"}}, {{MLOperandDataType/"uint32"}} ».
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>reduceSum(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of [=MLGraphBuilder/creating reduction operation=] given "reduceSum", |input|, |options|, and « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}, {{MLOperandDataType/"int32"}}, {{MLOperandDataType/"uint32"}} ».
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>

    <div algorithm>
    The <dfn method for=MLGraphBuilder>reduceSumSquare(|input|, |options|)</dfn> method steps are:
        1. Let |output| be the result of [=MLGraphBuilder/creating reduction operation=] given "reduceSumSquare", |input|, |options|, and « {{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}, {{MLOperandDataType/"int32"}}, {{MLOperandDataType/"uint32"}} ».
            1. If that [=exception/throws=] an error, then re-[=exception/throw=] the error.
        1. Return |output|.
    </div>
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of several reduction operations can be [EMULATED]
    </summary>
    <pre highlight="js">
    function reduceLogSum(builder, input, options) {
      return builder.log(builder.reduceSum(input, options));
    }

    function reduceLogSumExp(builder, input, options) {
      return builder.log(builder.reduceSum(builder.exp(input), options));
    }

    function reduceSumSquare(builder, input, options) {
      return builder.reduceSum(builder.pow(input, 2), options);
    }
    </pre>
  </details>
</div>

<div class="note">
  Some underlying platforms do not support an option like {{MLReduceOptions/keepDimensions}} directly. This does not affect the underlying tensor data, only the shape. For example, if the input shape is *[2, 3, 4]*, the axis is 1, and {{MLReduceOptions/keepDimensions}} is true, the expected output shape is *[2, 1 ,4]*. If the underlying platform never keeps reduced dimensions it will produce an output shape of *[2, 4]*. The implementation can introduce a no-op reshape to *[2, 1, 4]*. A similar no-op reshape can be introduced if {{MLReduceOptions/keepDimensions}} is false but the underlying platform always keeps reduced dimensions.
</div>

### relu ### {#api-mlgraphbuilder-relu-method}
Compute the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">rectified linear function</a> of the input tensor.

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand relu(MLOperand input, optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits relu;
};
</script>

<div dfn-for="MLGraphBuilder/relu(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/relu(input, options)/input}}.
</div>

<table id=constraints-relu class='data' link-for="MLGraphBuilder/relu(input, options)">
  <caption>Constraints for {{MLGraphBuilder/relu()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}, {{MLOperandDataType/"int32"}}, {{MLOperandDataType/"int8"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/relu()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>relu</dfn>
    :: Support limits for operator {{MLGraphBuilder/relu()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>relu(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-relu)), then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "relu" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be [EMULATED]
    </summary>
    <pre highlight="js">
    function relu(builder, input) {
      return builder.max(builder.constant(input.dataType, 0), input);
    }
    </pre>
  </details>
</div>

### resample2d ### {#api-mlgraphbuilder-resample2d-method}
Resample the tensor values from the source to the destination dimensions according to the axes and scaling factors.
<script type=idl>
enum MLInterpolationMode {
  "nearest-neighbor",
  "linear"
};

dictionary MLResample2dOptions : MLOperatorOptions {
  MLInterpolationMode mode = "nearest-neighbor";
  sequence<float> scales;
  sequence<[EnforceRange] unsigned long> sizes;
  sequence<[EnforceRange] unsigned long> axes;
};

partial interface MLGraphBuilder {
  MLOperand resample2d(MLOperand input, optional MLResample2dOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits resample2d;
};
</script>
<div dfn-for="MLGraphBuilder/resample2d(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input 4-D tensor.
        - <dfn>options</dfn>: an optional {{MLResample2dOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output 4-D tensor.
</div>

{{MLResample2dOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLResample2dOptions>
    : <dfn>mode</dfn>
    ::
        The interpolation algorithm used to fill the output tensor values.

        Both algorithms start with these inputs, computed for each spatial axis (based on {{MLResample2dOptions/axes}}), where `inputSize` is given by the {{MLGraphBuilder/resample2d(input, options)/input}} tensor's [=MLTensor/shape=], `outputSize` is given by {{MLResample2dOptions/sizes}} or {{MLResample2dOptions/scales}}, and `outputCoordinate` identifies the element in the output tensor being computed.
        ```
        scale = outputSize / inputSize
        unclampedCoordinate = (outputCoordinate + 0.5) / scale - 0.5
        inputCoordinate = clamp(unclampedCoordinate, 0, inputSize - 1)
        ```
        For a given `outputCoordinate.x` and `outputCoordinate.y` location in the output tensor, the above equations give a rational `inputCoordinate.x` and `inputCoordinate.y`.

        <dl dfn-type=enum-value dfn-for=MLInterpolationMode>
        : <dfn>nearest-neighbor</dfn>
        ::
            The `inputCoordinate.x` and `inputCoordinate.y` computed above are used as inputs to a nearest-neighbor sampling algorithm to compute the output tensor value as follows:
            ```
            x = ceil(inputCoordinate.x - 0.5)
            y = ceil(inputCoordinate.y - 0.5)
            output tensor value = input tensor value at (x, y)
            ```

        : <dfn>linear</dfn>
        ::
            The `inputCoordinate.x` and `inputCoordinate.y` computed above are used as inputs to a bilinear sampling algorithm to compute the output tensor value as follows:
            ```
            x0 = floor(inputCoordinate.x)
            x1 = ceil(inputCoordinate.x)
            y0 = floor(inputCoordinate.y)
            y1 = ceil(inputCoordinate.y)
            vx0y0 = input tensor value at (x0, y0)
            vx1y0 = input tensor value at (x1, y0)
            vx0y1 = input tensor value at (x0, y1)
            vx1y1 = input tensor value at (x1, y1)
            tx = inputCoordinate.x - x0
            ty = inputCoordinate.y - y0

            vy0 = vx0y0 * (1 - tx) + vx1y0 * tx
            vy1 = vx0y1 * (1 - tx) + vx1y1 * tx
            output tensor value = vy0 * (1 - ty) + vy1 * ty
            ```
        </dl>

    : <dfn>scales</dfn>
    ::
        A list of length 2.
        Specifies the scaling factor for each input dimension from {{MLResample2dOptions/axes}}: *[scaleForFirstAxis, scaleForSecondAxis]*.
        The default value is [1.0, 1.0].

    : <dfn>sizes</dfn>
    ::
        A list of length 2.
        Specifies the target sizes for each input dimension from {{MLResample2dOptions/axes}}: *[sizeForFirstAxis, sizeForSecondAxis]*. When {{MLResample2dOptions/sizes}} is specified, {{MLResample2dOptions/scales}} is ignored, since the scaling factor values are derived from the target sizes of the input.

    : <dfn>axes</dfn>
    ::
        A list of length 2.
        Specifies the two dimensions of the input tensor to which the interpolation algorithm applies.
        The default value is [2, 3].
</dl>

<table id=constraints-resample2d class='data' link-for="MLGraphBuilder/resample2d(input, options)">
  <caption>Constraints for {{MLGraphBuilder/resample2d()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>4</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>4</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/resample2d()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>resample2d</dfn>
    :: Support limits for operator {{MLGraphBuilder/resample2d()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>resample2d(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-resample2d)), then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/rank=] is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLResample2dOptions/scales}} does not [=map/exist=], set it to the [=/list=] « 1.0, 1.0 ».
    1. Otherwise, if any of its values is not greater than 0, or if its [=list/size=] is not 2, then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLResample2dOptions/sizes}} [=map/exists=], and if its size is not 2, or if any of its values is not greater than 0, then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLResample2dOptions/axes}} does not [=map/exists=], set it to the [=/list=] « 2, 3 ».
    1. Otherwise, if |options|.{{MLResample2dOptions/axes}} contains duplicate values, or if any of its [=list/items=] is not in [=the range=] 0 to |input|'s [=MLOperand/rank=], exclusive, then [=exception/throw=] a {{TypeError}}.
    1. *Calculate the output shape:*
        1. Let |inputDescriptor| be |input|.{{MLOperand/[[descriptor]]}}.
        1. Let |outputShape| be a [=list/clone=] of |inputDescriptor|.{{MLOperandDescriptor/shape}}.
        1. [=list/For each=] |index| in [=the range=] 0 to |options|.{{MLResample2dOptions/axes}}'s [=list/size=], exclusive:
            1. If |options|.{{MLResample2dOptions/sizes}} [=map/exists=], then let |size| be |options|.{{MLResample2dOptions/sizes}}[|index|].
            1. Otherwise, let |size| be floor(|input|'s [=MLOperand/shape=][|options|.{{MLResample2dOptions/axes}}[|index|]] * |options|.{{MLResample2dOptions/scales}}[|index|]).
            1. If |size| is not a [=valid dimension=], then [=exception/throw=] a {{TypeError}}.
            1. Set |outputShape|[|options|.{{MLResample2dOptions/axes}}[|index|]] to |size|.
        1. Let |desc| be the result of [=creating an MLOperandDescriptor=] given |inputDescriptor|.{{MLOperandDescriptor/dataType}} and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Let |operator| be an [=operator=] for the "resample2d" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>


<div class="note">
  The specific sampling algorithms are based on those widely used in existing Machine Learning frameworks. For example, when performing {{MLInterpolationMode/linear}} resampling from the following *[4, 4]* input tensor (considering only spatial dimensions):

  ```
  [   0   1   2   3  ]
  [   0   1   2   3  ]
  [  12  13  14  15  ]
  [  12  13  14  15  ]
  ```

  For an *[8, 8]* output tensor, the expected values are:

  ```
  [   0   0.25   0.75   1.25   1.75   2.25   2.75   3  ]
  [   0   0.25   0.75   1.25   1.75   2.25   2.75   3  ]
  [   0   0.25   0.75   1.25   1.75   2.25   2.75   3  ]
  [   3   3.25   3.75   4.25   4.75   5.25   5.75   6  ]
  [   9   9.25   9.75  10.25  10.75  11.25  11.75  12  ]
  [  12  12.25  12.75  13.25  13.75  14.25  14.75  15  ]
  [  12  12.25  12.75  13.25  13.75  14.25  14.75  15  ]
  [  12  12.25  12.75  13.25  13.75  14.25  14.75  15  ]
  ```

  This has the convenient properties that the sampling is evenly distributed, symmetric, robust to image mirroring, and the corner values are aligned.
</div>

### reshape ### {#api-mlgraphbuilder-reshape-method}
Alter the shape of a tensor to a new shape. Reshape does not copy or change the content of the tensor. It just changes the tensor's logical shape for the subsequent operations.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand reshape(MLOperand input,
                    sequence<[EnforceRange] unsigned long> newShape,
                    optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits reshape;
};
</script>
<div dfn-for="MLGraphBuilder/reshape(input, newShape, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>newShape</dfn>: [=sequence=]<{{unsigned long}}>. The shape of the output tensor.
            The number of elements implied by {{MLGraphBuilder/reshape(input, newShape, options)/newShape}} must be the same as the
            number of elements in the input tensor.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output tensor. The values of the output
    tensor are the same as values of the input tensor. The shape of the output
    tensor is specified by {{MLGraphBuilder/reshape(input, newShape, options)/newShape}}.
</div>

<table id=constraints-reshape class='data' link-for="MLGraphBuilder/reshape(input, newShape, options)">
  <caption>Constraints for {{MLGraphBuilder/reshape()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>{{newShape}}'s [=list/size=]</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/reshape()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>reshape</dfn>
    :: Support limits for operator {{MLGraphBuilder/reshape()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>reshape(|input|, |newShape|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. Let |outputShape| be an empty array of {{unsigned long}}.
    1. If |newShape|'s [=list/size=] is 0, set |outputShape| to an empty [=/list=] for a scalar.
    1. If any [=list/item=] in |newShape| is not a [=valid dimension=], then [=exception/throw=] a {{TypeError}}.
    1. Let |inputElementCount| be the product of all [=list/items=] in |input|'s [=MLOperand/shape=]. Empty dimensions yield an |inputElementCount| of 1.
    1. If product of all values in |newShape| is not equal to |inputElementCount|, then [=exception/throw=] a {{TypeError}}.
    1. Let |desc| be a copy of |input|.{{MLOperand/[[descriptor]]}}.
    1. Set |desc|.{{MLOperandDescriptor/shape}} to |newShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |desc|.
        1. Let |operator| be an [=operator=] for the "reshape" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

### reverse ### {#api-mlgraphbuilder-reverse-method}
Reverse a tensor along the given axes.

<script type=idl>
dictionary MLReverseOptions : MLOperatorOptions {
  sequence<[EnforceRange] unsigned long> axes;
};

partial interface MLGraphBuilder {
  MLOperand reverse(MLOperand input, optional MLReverseOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits reverse;
};
</script>

{{MLReverseOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLReverseOptions>
    : <dfn>axes</dfn>
    ::
        The indices to the input dimensions to reverse. When this member is not present, it is treated as if all dimensions are reversed. If explicitly passed as empty, no dimensions are reversed.
</dl>

<div dfn-for="MLGraphBuilder/reverse(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/reverse(input, options)/input}}.
</div>

<table id=constraints-reverse class='data' link-for="MLGraphBuilder/reverse(input, options)">
  <caption>Constraints for {{MLGraphBuilder/reverse()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/reverse()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>reverse</dfn>
    :: Support limits for operator {{MLGraphBuilder/reverse()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>reverse(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-reverse)), then [=exception/throw=] a {{TypeError}}.
    1. Let |inputRank| be |input|'s [=MLOperand/rank=].
    1. If |axes| is not given, let |axes| be [=the range=] 0 to |inputRank|, exclusive.
    1. Otherwise, if |axes| contains duplicate values, or if any of its elements is not in [=the range=] 0 to |inputRank|, exclusive, then return failure.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "reverse" operation and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

### scatterElements ### {#api-mlgraphbuilder-scatterelements}
Scatter values from the updates tensor atop a copy of the input tensor the along an axis according to the indices.

<script type=idl>
dictionary MLScatterOptions : MLOperatorOptions {
  [EnforceRange] unsigned long axis = 0;
};

partial interface MLGraphBuilder {
  MLOperand scatterElements(MLOperand input,
                            MLOperand indices,
                            MLOperand updates,
                            optional MLScatterOptions options = {});
};

dictionary MLScatterSupportLimits {
  MLTensorLimits input;
  MLTensorLimits indices;
  MLTensorLimits updates;
  MLDataTypeLimits output;
};

partial dictionary MLOpSupportLimits {
  MLScatterSupportLimits scatterElements;
};
</script>

{{MLScatterOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLScatterOptions>
    : <dfn>axis</dfn>
    ::
        The axis along which the scattered values are obtained. Its value must be in the range [0, N-1] where N is the [=MLOperand/rank=] of the input tensor.
</dl>

<div dfn-for="MLGraphBuilder/scatterElements(input, indices, updates, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input N-D tensor from to initialize the output with.
        - <dfn>indices</dfn>: an {{MLOperand}}. The indices N-D tensor of the input values to scatter over. The values must be of type {{MLOperandDataType/"int32"}}, {{MLOperandDataType/"uint32"}}, or {{MLOperandDataType/"int64"}}, and must be in the range -N (inclusive) to N (exclusive) where N is the size of the input dimension indexed by *options.axis*, and a negative index means indexing from the end of the dimension.
        - <dfn>updates</dfn>: an {{MLOperand}}. New values to replace atop the input, with the same shape as the indices.
        - <dfn>options</dfn>: an optional {{MLScatterOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output N-D tensor of [=MLOperand/rank=] equal to {{MLGraphBuilder/scatterElements(input, indices, updates, options)/input}}'s [=MLOperand/rank=].
</div>

<table id=constraints-scatterelements class='data' link-for="MLGraphBuilder/scatterElements(input, indices, updates, options)">
  <caption>Constraints for {{MLGraphBuilder/scatterElements()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>1 to [=/any rank|N=]</td>
  </tr>
  <tr>
    <td>{{indices}}</td>
    <td>{{MLOperandDataType/"int32"}}, {{MLOperandDataType/"uint32"}}, {{MLOperandDataType/"int64"}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
  <tr>
    <td>{{updates}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLScatterSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLScatterSupportLimits>
    : <dfn>input</dfn>
    :: {{MLTensorLimits}} for input operand.
    : <dfn>indices</dfn>
    :: {{MLTensorLimits}} for indices operand.
    : <dfn>updates</dfn>
    :: {{MLTensorLimits}} for updates operand.
    : <dfn>output</dfn>
    :: {{MLDataTypeLimits}} for output operand.
</dl>

{{MLOpSupportLimits}} has the following members for {{MLGraphBuilder/scatterElements()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>scatterElements</dfn>
    :: Support limits for operator {{MLGraphBuilder/scatterElements()}}.
</dl>

<div class="note">
  The {{MLGraphBuilder/scatterElements(input, indices, updates, options)/indices}} parameter to {{MLGraphBuilder/scatterElements()}} can not be clamped to the allowed range when the graph is built because the inputs are not known until execution. Implementations can introduce {{MLGraphBuilder/clamp()}} in the compiled graph if the specified clamping behavior is not provided by the underlying platform. Similarly, if the underlying platform does not support negative indices, the implementation can introduce operations in the compiled graph to transform a negative index from the end of the dimension into a positive index.
</div>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>scatterElements(|input|, |indices|, |updates|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input| and |indices| and |updates| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |indices|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-scatterelements)), then [=exception/throw=] a {{TypeError}}.
    1. If |updates|'s [=MLOperand/dataType=] is not equal to |input|'s [=MLOperand/dataType=], then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/rank=] of any of |input|, |indices|, or |updates| is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. Let |axis| be |options|.{{MLGatherOptions/axis}}.
    1. If |axis| is greater than or equal to |input|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
    1. Let |indicesShapeExpected| be a copy of |input|'s [=MLOperand/shape=].
    1. Set |indicesShapeExpected|[|axis|] to |indices|'s [=MLOperand/shape=][|axis|].
    1. If |indices|'s [=MLOperand/shape=] is not [=list/equal=] to |indicesShapeExpected|, then [=exception/throw=] a {{TypeError}}.
    1. If |updates|'s [=MLOperand/shape=] is not [=list/equal=] to |indices|'s [=MLOperand/shape=], then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "scatterElements" operation, given |input|, |indices|, |updates|, and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |input|, |indices|, and |updates|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="example">
<details open>
  <summary>
    Examples of how scatterElements works in different slicing schemes.
  </summary>
  <pre highlight="js">
    // input of shape [4,3]:
    //   [[ 0,  1,  2],
    //    [10, 11, 12],
    //    [20, 21, 22],
    //    [30, 31, 32]]
    // indices of shape [2,3]:
    //   [[3, 1, 1],
    //    [2, 0, 3]]
    // updates of shape [2,3]:
    //   [[-1, -2, -3],
    //    [-4, -5, -6]]
    // axis = 0 (default)
    // output of shape [4,3]:
    //   [[ 0, -5,  2],
    //    [10, -2, -3],
    //    [-4, 21, 22],
    //    [-1, 31, -6]]

    const input1 = builder.constant(
      {dataType: 'float32', shape: [4, 3]},
      new Float32Array([0, 1, 2, 10, 11, 12, 20, 21, 22, 30, 31, 32]));

    const indices1 = builder.constant(
      {dataType: 'uint32', shape: [2, 3]},
      new Uint32Array([3, 1, 1, 2, 0, 3]));

    const updates1 = builder.constant(
      {dataType: 'float32', shape: [2, 3]},
      new Uint32Array([-1, -2, -3, -4, -5, -6]));

    const output1 = builder.scatterElements(input1, indices1, updates1);

    // input of shape [4,3]:
    //   [[ 0,  1,  2],
    //    [10, 11, 12],
    //    [20, 21, 22],
    //    [30, 31, 32]]
    // indices of shape [4,1]:
    //   [[2],
    //    [1],
    //    [0],
    //    [2]],
    // updates of shape [4,1]:
    //   [[-1],
    //    [-2],
    //    [-3],
    //    [-4]],
    // axis = 1
    // output of shape [4,3]:
    //   [[ 0,  1, -1],
    //    [10, -2, 12],
    //    [-3, 21, 22],
    //    [30, 31, -4]]

    const indices2 = builder.constant(
      {dataType: 'uint32', shape: [4, 1]},
      new Uint32Array([2, 1, 0, 2]));

    const updates2 =
      builder.constant({dataType: 'float32', shape: [4, 1]},
      new Uint32Array([-1, -2, -3, -4]));

    const output2 = builder.scatterElements(input1, indices2, updates2, {axis: 1});

    // input of shape [4,2,2]:
    //   [[[  0,   1],
    //     [ 10,  11]],
    //    [[100, 101],
    //     [110, 111]],
    //    [[200, 201],
    //     [210, 211]],
    //    [[300, 301],
    //     [310, 311]],]
    // indices of shape [1,2,2]:
    //   [[[0, 2],
    //     [1, 3]]],
    // updates of shape [1,2,2]:
    //   [[[-1, -2],
    //     [-3, -4]]],
    // axis = 0
    // output of shape [4,2,2]:
    //   [[[ -1,   1],
    //     [ 10,  11]],
    //    [[100, 101],
    //     [ -3, 111]],
    //    [[200,  -2],
    //     [210, 211]],
    //    [[300, 301],
    //     [310,  -4]],]

    const input3 = builder.constant(
      {dataType: 'float32', shape: [4, 2, 2]},
      new Float32Array([0, 1, 10, 11, 100, 101, 110, 111, 200, 201, 210, 211, 300, 301, 310, 311]));

    const indices3 = builder.constant(
      {dataType: 'uint32', shape: [1, 2, 2]},
      new Uint32Array([0, 2, 1, 3]));

    const updates3 =
      builder.constant({dataType: 'float32', shape: [1, 2, 2]},
      new Uint32Array([-1, -2, -3, -4]));

    const output3 = builder.scatterElements(input3, indices3, updates3, {axis: 0});
  </pre>
</details>
</div>

### scatterND ### {#api-mlgraphbuilder-scatternd}
Scatter slices of values from the update tensor atop a copy of the input tensor according to the indices.

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand scatterND(MLOperand input,
                      MLOperand indices,
                      MLOperand updates,
                      optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLScatterSupportLimits scatterND;
};
</script>

<div dfn-for="MLGraphBuilder/scatterND(input, indices, updates, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input N-D tensor from to initialize the output with.
        - <dfn>indices</dfn>: an {{MLOperand}}. The indices array contains entire coordinates into the output tensor, with the rightmost dimension holding the number of dimensions per coordinate. So an indices tensor of shape [10,1] holds 10 single-axis indices, and a shape of [4,3] holds 4 indices of 3D coordinates. The values must be of type {{MLOperandDataType/"int32"}}, {{MLOperandDataType/"uint32"}}, or {{MLOperandDataType/"int64"}}, and each must be in the range -N (inclusive) to N (exclusive) where N is the size of the corresponding output dimension, and a negative index means indexing from the end of the corresponding dimension.
        - <dfn>updates</dfn>: an {{MLOperand}}. New values to replace atop the input.
        - <dfn>options</dfn>: an optional {{MLScatterOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output N-D tensor of [=MLOperand/rank=] equal to the [=MLOperand/rank=] of {{MLGraphBuilder/scatterND(input, indices, updates, options)/input}}'s [=MLOperand/rank=] + {{MLGraphBuilder/scatterND(input, indices, updates, options)/indices}}'s [=MLOperand/rank=] - {{MLGraphBuilder/scatterND(input, indices, updates, options)/indices}}'s [=MLOperand/shape=][-1] - 1.
</div>

<table id=constraints-scatternd class='data' link-for="MLGraphBuilder/scatterND(input, indices, updates, options)">
  <caption>Constraints for {{MLGraphBuilder/scatterND()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>1 to [=/any rank|N=]</td>
  </tr>
  <tr>
    <td>{{indices}}</td>
    <td>{{MLOperandDataType/"int32"}}, {{MLOperandDataType/"uint32"}}, {{MLOperandDataType/"int64"}}</td>
    <td>1 to [=/any rank|N=]</td>
  </tr>
  <tr>
    <td>{{updates}}</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>{{input}}'s [=MLOperand/rank=] + {{indices}}'s [=MLOperand/rank=] - {{indices}}'s [=MLOperand/shape=][-1] - 1</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>1 to [=/any rank|N=]</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following members for {{MLGraphBuilder/scatterND()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>scatterND</dfn>
    :: Support limits for operator {{MLGraphBuilder/scatterND()}}.
</dl>

<div class="note">
  The {{MLGraphBuilder/scatterND(input, indices, updates, options)/indices}} parameter to {{MLGraphBuilder/scatterND()}} can not be clamped to the allowed range when the graph is built because the inputs are not known until execution. Implementations can introduce {{MLGraphBuilder/clamp()}} in the compiled graph if the specified clamping behavior is not provided by the underlying platform. Similarly, if the underlying platform does not support negative indices, the implementation can introduce operations in the compiled graph to transform a negative index from the end of the dimension into a positive index.
</div>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>scatterND(|input|, |indices|, |updates|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |input|, |indices|, and |updates| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |indices|'s [=MLOperand/dataType=]'s is not one of the [=/allowed data types=] (according to [this table](#constraints-scatternd)), then [=exception/throw=] a {{TypeError}}.
    1. If |updates|'s [=MLOperand/dataType=] is not equal to |input|'s [=MLOperand/dataType=], then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/rank=] of any of |input|, |indices|, or |updates| is not its [=/allowed rank=], then [=exception/throw=] a {{TypeError}}.
    1. Let |inputShape| be |input|'s [=MLOperand/shape=] and |inputRank| be |input|'s [=MLOperand/rank=].
    1. Let |indicesShape| be |indices|'s [=MLOperand/shape=] and |indicesRank| be |indices|'s [=MLOperand/rank=].
    1. Let |indexableSize| be |indicesRank| - 1.
    1. Let |coordinateSize| be |indicesShape|[|indexableSize|].
    1. If |coordinateSize| is greater than |inputRank|, then [=exception/throw=] a {{TypeError}}.
    1. Let |expectedUpdatesShape| be an empty list.
    1. [=list/For each=] |index| in [=the range=] 0 to |indexableSize|, exclusive:
        1. [=list/Append=] |indicesShape|[|index|] to |expectedUpdatesShape|.
    1. [=list/For each=] |index| in [=the range=] |coordinateSize| to |inputRank|, exclusive:
        1. [=list/Append=] |inputShape|[|index|] to |expectedUpdatesShape|.
    1. If |updates|'s [=MLOperand/shape=] is not [=list/equal=] to |expectedUpdatesShape|, then [=exception/throw=] a {{TypeError}}.
    1. Let |outputShape| be a copy of |input|'s [=MLOperand/shape=].
    1. Let |outputDesc| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given |outputDesc|.
        1. Let |operator| be an [=operator=] for the "scatterND" operation, given |input|, |indices|, |updates|, and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |input|, |indices|, and |updates|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="example">
<details open>
  <summary>
    Examples of how scatterND works in different slicing schemes.
  </summary>
  <pre highlight="js">
    // input of shape [8]:
    //   [0, 1, 2, 3, 4, 5, 6, 7]
    // indices of shape [4, 1]:
    //   [[4],
    //    [3],
    //    [1],
    //    [7]]
    // updates of shape [4]:
    //   [-1, -2, -3, -4]
    // output of shape [8]:
    //   [0, -3, 2, -2, -1, 5, 6, -4]

    const input1 = builder.constant(
      {dataType: 'float32', shape: [8]},
      new Float32Array([0, 1, 2, 3, 4, 5, 6, 7]));

    const indices1 = builder.constant(
      {dataType: 'uint32', shape: [4, 1]},
      new Uint32Array([4, 3, 1, 7]));

    const updates1 = builder.constant(
      {dataType: 'uint32', shape: [4]},
      new Uint32Array([-1, -2, -3, -4]));

    const output1 = builder.scatterND(input1, indices1, updates1);

    // input of shape [2,2]:
    //   [[0, 1],
    //    [2, 3]]
    // indices of shape [2,2]:
    //   [[0, 0],
    //    [1, 1]]
    // updates of shape [2]:
    //   [-1, -2]
    // output of shape [2,2]:
    //   [[-1,  1],   <= -1 written to output coordinate [0, 0]
    //    [ 2, -2]]   <= -2 written to output coordinate [1, 1]

    const input2 = builder.constant(
      {dataType: 'float32', shape: [2, 2]},
      new Float32Array([0, 1, 2, 3]));

    const indices2 = builder.constant(
      {dataType: 'uint32', shape: [2, 2]},
      new Uint32Array([0, 0, 1, 1]));

    const updates2 = builder.constant(
      {dataType: 'uint32', shape: [2]},
      new Uint32Array([-1, -2]));

    const output2 = builder.scatterND(input2, indices2, updates2);

    // input of shape [3,2]:
    //   [[0, 1],
    //    [2, 3],
    //    [4, 5]]
    // indices of shape [2,1]:
    //   [[2],
    //    [0]]
    // updates of shape [2,2]:
    //   [[-1, -2],
    //    [-3, -4]]
    // output of shape [3,2]:
    //   [[-3 ,-4],    <= [-3, -4] written to output coordinates [0, *]
    //    [ 2,  3],
    //    [-1, -2]]    <= [-1, -2] written to output coordinates [2, *]

    const input3 = builder.constant(
      {dataType: 'float32', shape: [3, 2]},
      new Float32Array([0, 1, 2, 3, 4, 5]));

    const indices3 = builder.constant(
      {dataType: 'uint32', shape: [2, 1]},
      new Uint32Array([1, 0]));

    const updates3 = builder.constant(
      {dataType: 'uint32', shape: [2, 2]},
      new Uint32Array([-1, -2, -3, 4]));

    const output3 = builder.scatterND(input3, indices3, updates3);

    // input of shape [2,2,2]:
    //   [[[0, 1],
    //     [2, 3]],
    //    [[4, 5],
    //     [6, 7]]]
    // indices of shape [2,2]:
    //   [[0, 1],
    //    [1, 0]]
    // updates of shape [2,2]:
    //   [[-1, -2],
    //    [-3, -4]]
    // output of shape [2,2,2]:
    //   [[[ 0,  1],
    //     [-1, -2]],   <= [-1, -2] written to output coordinates [0, 1, *]
    //    [[-3, -4],    <= [-3, -4] written to output coordinates [1, 0, *]
    //     [ 6,  7]]]

    const input4 = builder.constant(
      {dataType: 'float32', shape: [2, 2, 2]},
      new Float32Array([0, 1, 2, 3, 4, 5, 6, 7]));

    const indices4 = builder.constant(
      {dataType: 'uint32', shape: [2, 2]},
      new Uint32Array([0, 1, 1, 0]));

    const updates4 = builder.constant(
      {dataType: 'uint32', shape: [2, 2]},
      new Uint32Array([-1, -2, -3, 4]));

    const output4 = builder.scatterND(input4, indices4, updates4);
  </pre>
</details>
</div>


### sigmoid ### {#api-mlgraphbuilder-sigmoid-method}
Compute the <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid function</a> of the input tensor. The calculation follows the expression `1 / (exp(-x) + 1)`.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand sigmoid(MLOperand input, optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits sigmoid;
};
</script>

<div dfn-for="MLGraphBuilder/sigmoid(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/sigmoid(input, options)/input}}.
</div>

<table id=constraints-sigmoid class='data' link-for="MLGraphBuilder/sigmoid(input, options)">
  <caption>Constraints for {{MLGraphBuilder/sigmoid()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/sigmoid()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>sigmoid</dfn>
    :: Support limits for operator {{MLGraphBuilder/sigmoid()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>sigmoid(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-sigmoid)), then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "sigmoid" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be [EMULATED]
    </summary>
    <pre highlight="js">
    function sigmoid(builder, input) {
      return builder.div(
        builder.constant(input.dataType, 1),
        builder.add(
          builder.exp(builder.neg(input)), builder.constant(input.dataType, 1)));
    }
    </pre>
  </details>
</div>

### slice ### {#api-mlgraphbuilder-slice}
Produce a slice of the input tensor.
<script type=idl>
dictionary MLSliceOptions : MLOperatorOptions {
  sequence<[EnforceRange] unsigned long> strides;
};

partial interface MLGraphBuilder {
  MLOperand slice(MLOperand input,
                  sequence<[EnforceRange] unsigned long> starts,
                  sequence<[EnforceRange] unsigned long> sizes,
                  optional MLSliceOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits slice;
};
</script>

{{MLSliceOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLSliceOptions>
    : <dfn>strides</dfn>
    ::
        The stride to step over each input along each axis.
        The length of the strides array must equal the [=MLOperand/rank=] of the input tensor.
        The default is an array of length [=MLOperand/rank=] consisting of all 1's.
        e.g. [1,1,1] for a 3-D tensor.
        Strides must be greater than zero.
</dl>

<div dfn-for="MLGraphBuilder/slice(input, starts, sizes, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>starts</dfn>: a [=sequence=]<{{unsigned long}}>. The starting index to slice of each input dimension, of length N where N is the [=MLOperand/rank=] of the input tensor. For each dimension *d* of {{MLGraphBuilder/slice(input, starts, sizes, options)/input}}, {{MLGraphBuilder/slice(input, starts, sizes, options)/starts}}[*d*] indicates the starting index to slice in that dimension. The starting index must be in the range [0, input size - 1] in that dimension.
        - <dfn>sizes</dfn>: a [=sequence=]<{{unsigned long}}>. The number of elements to slice of each input dimension, of length N where N is the [=MLOperand/rank=] of the input tensor. For each dimension *d* of {{MLGraphBuilder/slice(input, starts, sizes, options)/input}}, {{MLGraphBuilder/slice(input, starts, sizes, options)/sizes}}[*d*] indicates the number of elements to slice in that dimension. The size must not be 0 and must satisfy the constraint `starting index + size <= input size` in that dimension.
        - <dfn>options</dfn>: an {{MLSliceOptions}}. Specifies the optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output tensor of the same rank as the input tensor with tensor values stripped to the specified starting and ending indices in each dimension.
</div>

<table id=constraints-slice class='data' link-for="MLGraphBuilder/slice(input, starts, sizes, options)">
  <caption>Constraints for {{MLGraphBuilder/slice()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/slice()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>slice</dfn>
    :: Support limits for operator {{MLGraphBuilder/slice()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>slice(|input|, |starts|, |sizes|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If any of |sizes|'s [=list/items=] are 0, then [=exception/throw=] a {{TypeError}}.
    1. If |starts|'s [=list/size=] and |sizes|'s [=list/size=] are not both equal to |input|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
    1. Let |strides| be a new [=/list=].
    1. If |options|.{{MLSliceOptions/strides}} [=map/exists=]:
        1. Set |strides| to |options|.{{MLSliceOptions/strides}}.
        1. If |strides|'s [=list/size=] is not equal to |input|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
    1. Let |inputShape| be |input|'s [=MLOperand/shape=] and |inputRank| be |input|'s [=MLOperand/rank=].
    1. Let |outputShape| be a new [=/list=].
    1. [=list/For each=] |index| in [=the range=] 0 to |inputRank|, exclusive:
        1. Let |inputSize| be |inputShape|[|index|].
        1. Let |inputSliceSize| be |sizes|[|index|].
        1. Let |stride| be |strides|[|index|] if it is not empty, or 1 otherwise:
        1. If |inputSliceSize| is 0, then [=exception/throw=] a {{TypeError}}.

            Issue(391): If 0-size dimensions are allowed, revise these steps.

        1. If |stride| is less than 1, then [=exception/throw=] a {{TypeError}}.
        1. If |starts|[|index|] is greater than |inputSize|, then [=exception/throw=] a {{TypeError}}.
        1. If |starts|[|index|] + |inputSliceSize| is greater than |inputSize|, then [=exception/throw=] a {{TypeError}}.
        1. Let |outputSizeRoundingExcess| be 1 if |inputSliceSize| % |stride| != 0, or 0 otherwise.
        1. Let |outputSize| be floor(|inputSliceSize| / |stride|) + |outputSizeRoundingExcess|:
        1. [=list/Append=] |outputSize| to |outputShape|.
    1. Let |outputDesc| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given |outputDesc|.
        1. Let |operator| be an [=operator=] for the "slice" operation, given |starts|, |sizes|, and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

### softmax ### {#api-mlgraphbuilder-softmax-method}
Compute the [softmax](https://en.wikipedia.org/wiki/Softmax_function) values of
the N-D input tensor along the given axis.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand softmax(MLOperand input,
                    [EnforceRange] unsigned long axis,
                    optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits softmax;
};
</script>

<div dfn-for="MLGraphBuilder/softmax(input, axis, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input N-D tensor.
        - <dfn>axis</dfn>: an {{unsigned long}} scalar. The dimension the reduction will be performed on.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output N-D tensor that contains the softmax results, of the same shape as {{MLGraphBuilder/softmax(input, axis, options)/input}}.
</div>

<table id=constraints-softmax class='data' link-for="MLGraphBuilder/softmax(input, axis, options)">
  <caption>Constraints for {{MLGraphBuilder/softmax()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/softmax()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>softmax</dfn>
    :: Support limits for operator {{MLGraphBuilder/softmax()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>softmax(|input|, |axis|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-softmax)), then [=exception/throw=] a {{TypeError}}.
    1. If |axis| is greater than or equal to |input|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "softmax" operation, given |axis| and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation can be [EMULATED]
  </summary>
  <pre highlight="js">
    function softmax(builder, input, axis) {
      // This sample deploys a well-known implementation trick [1] to compute the
      // exponentials of the distances to the max value, instead of the exponentials
      // of the input values itself, in order to increase the numerical stability of
      // the result.
      // [1]: https://cs231n.github.io/linear-classify/#softmax
      const maxX = builder.reduceMax(input, {axes: [axis], keepDimensions: true});
      const expX = builder.exp(builder.sub(input, maxX));
      return builder.div(
        expX, builder.reduceSum(expX, {axes: [axis], keepDimensions: true}));
    }
  </pre>
</details>
</div>


### softplus ### {#api-mlgraphbuilder-softplus-method}
Compute the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Softplus">softplus function</a> of the input tensor. The calculation follows the expression `ln(1 + exp(x))`.

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand softplus(MLOperand input, optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits softplus;
};
</script>

<div dfn-for="MLGraphBuilder/softplus(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/softplus(input, options)/input}}.
</div>

<table id=constraints-softplus class='data' link-for="MLGraphBuilder/softplus(input, options)">
  <caption>Constraints for {{MLGraphBuilder/softplus()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/softplus()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>softplus</dfn>
    :: Support limits for operator {{MLGraphBuilder/softplus()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>softplus(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-softplus)), then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "softplus" operation and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be [EMULATED]
    </summary>
    <pre highlight="js">
    function softplus(builder, input) {
      return builder.log(
        builder.add(builder.exp(input), builder.constant(input.dataType, 1)));
    }
    </pre>
  </details>
</div>

### softsign ### {#api-mlgraphbuilder-softsign-method}
Compute the <a href="https://pytorch.org/docs/stable/generated/torch.nn.Softsign.html">softsign function</a> of the input tensor. The calculation follows the expression `x / (1 + |x|)`.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand softsign(MLOperand input, optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits softsign;
};
</script>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be [EMULATED]
    </summary>
    <pre highlight="js">
    function softsign(builder, input) {
      return builder.div(
        input,
        builder.add(builder.constant(input.dataType, 1), builder.abs(input)));
    }
    </pre>
  </details>
</div>

<div dfn-for="MLGraphBuilder/softsign(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/softsign(input, options)/input}}.
</div>

<table id=constraints-softsign class='data' link-for="MLGraphBuilder/softsign(input, options)">
  <caption>Constraints for {{MLGraphBuilder/softsign()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/softsign()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>softsign</dfn>
    :: Support limits for operator {{MLGraphBuilder/softsign()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>softsign(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-softsign)), then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "softsign" operation and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

### split ### {#api-mlgraphbuilder-split}
Split the input tensor into a number of sub tensors along the given axis.
<script type=idl>
dictionary MLSplitOptions : MLOperatorOptions {
  [EnforceRange] unsigned long axis = 0;
};

partial interface MLGraphBuilder {
  sequence<MLOperand> split(
      MLOperand input,
      ([EnforceRange] unsigned long or sequence<[EnforceRange] unsigned long>) splits,
      optional MLSplitOptions options = {});
};

dictionary MLSplitSupportLimits {
  MLTensorLimits input;
  MLDataTypeLimits outputs;
};

partial dictionary MLOpSupportLimits {
  MLSplitSupportLimits split;
};
</script>

<div dfn-for="MLGraphBuilder/split(input, splits, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>splits</dfn>: an {{unsigned long}} or [=sequence=]<{{unsigned long}}>. If an {{unsigned long}}, it specifies the number of output tensors along the axis. The number must evenly divide the dimension size of {{MLGraphBuilder/split(input, splits, options)/input}} along {{MLSplitOptions/axis}}. If a [=sequence=]<{{unsigned long}}>, it specifies the sizes of each output tensor along the {{MLSplitOptions/axis}}. The sum of sizes must equal to the dimension size of {{MLGraphBuilder/split(input, splits, options)/input}} along {{MLSplitOptions/axis}}.
        - <dfn>options</dfn>: an optional {{MLSplitOptions}}. The optional parameters of the operation.

    **Returns:** [=sequence=]<{{MLOperand}}>. The split output tensors. If {{MLGraphBuilder/split(input, splits, options)/splits}} is an {{unsigned long}}, the [=list/size=] of the output is equal to {{MLGraphBuilder/split(input, splits, options)/splits}}. The shape of each output tensor is the same as {{MLGraphBuilder/split(input, splits, options)/input}} except the dimension size of {{MLSplitOptions/axis}} equals to the quotient of dividing the dimension size of {{MLGraphBuilder/split(input, splits, options)/input}} along {{MLSplitOptions/axis}} by {{MLGraphBuilder/split(input, splits, options)/splits}}. If {{MLGraphBuilder/split(input, splits, options)/splits}} is a [=sequence=]<{{unsigned long}}>, the [=list/size=] of the output equals the [=list/size=] of {{MLGraphBuilder/split(input, splits, options)/splits}}. The shape of the *i*-th output tensor is the same as {{MLGraphBuilder/split(input, splits, options)/input}} except along {{MLSplitOptions/axis}} where the dimension size is {{MLGraphBuilder/split(input, splits, options)/splits}}[*i*].
</div>

{{MLSplitOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLSplitOptions>
    : <dfn>axis</dfn>
    ::
        The dimension along which to split. Its value must be in the range [0, N-1] where N is the [=MLOperand/rank=] of the input tensor.
</dl>

<table id=constraints-split class='data' link-for="MLGraphBuilder/split(input, splits, options)">
  <caption>Constraints for {{MLGraphBuilder/split()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*outputs*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLSplitSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLSplitSupportLimits>
    : <dfn>input</dfn>
    :: {{MLTensorLimits}} for input operand.
    : <dfn>outputs</dfn>
    :: {{MLDataTypeLimits}} for all the output operands.
</dl>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/split()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>split</dfn>
    :: Support limits for operator {{MLGraphBuilder/split()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>split(|input|, |splits|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. Let |axis| be |options|.{{MLSplitOptions/axis}}.
    1. If |axis| is greater than or equal to |input|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
    1. If |splits| is an {{unsigned long}}:
        1. If |splits| is 0, then [=exception/throw=] a {{TypeError}}.
        1. If |input|'s [=MLOperand/shape=][|axis|] % |splits| is not 0, then [=exception/throw=] a {{TypeError}}.
        1. Otherwise, let |splitCount| be |splits|.
    1. If |splits| is a [=sequence=]<{{unsigned long}}>:
        1. If any of its [=list/items=] is equal to 0, then [=exception/throw=] a {{TypeError}}.

            Issue(391): If 0-size dimensions are allowed, revise the above step.

        1. If the sum of its [=list/items=] is not equal to |input|'s [=MLOperand/shape=][|axis|], then [=exception/throw=] a {{TypeError}}.
        1. Otherwise, let |splitCount| be |splits|'s [=list/size=].
    1. *Make graph connections:*
        1. Let |operator| be an [=operator=] for the "split" operation, given |splits| and |options|.
        1. Let |outputs| be a new [=/list=].
        1. [=list/For each=] |index| in [=the range=] 0 to |splitCount|, exclusive:
            1. Let |operand| be the result of [=copying an MLOperand=] given |input|.
            1. If |splits| is an {{unsigned long}}, then let |newDimension| be |operand|'s [=MLOperand/shape=][|axis|] / |splits|.
            1. Otherwise, let |newDimension| be |splits|[|index|].
            1. Set |operand|'s [=MLOperand/shape=][|axis|] to |newDimension|.
            1. Set |operand|.{{MLOperand/[[operator]]}} to |operator|.
            1. [=list/Append=] |operand| to |outputs|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/outputs=] to |outputs|.
    1. Return |outputs|.
</details>

<div class="note">
<details open>
  <summary>
    The behavior of this operation can be [EMULATED]
  </summary>
  <pre highlight="js">
    function split(builder, input, splits, options) {
      // This sample shows the case that the splits parameter is an array.
      const outputs = [];
      const inputShape = input.shape;
      const inputRank = inputShape.length;
      let starts = Array(inputRank).fill(0);
      let sizes = inputShape;
      let start = 0;
      for (const size of splits) {
        starts[options.axis] = start;
        sizes[options.axis] = size;
        outputs.push(builder.slice(input, starts, sizes));
        start += size;
      }
      return outputs;
    }
  </pre>
</details>
</div>

### tanh ### {#api-mlgraphbuilder-tanh-method}
Compute the <a href="https://en.wikipedia.org/wiki/Hyperbolic_functions">hyperbolic tangent function</a> of the input tensor. The calculation follows the expression `(exp(2 * x) - 1) / (exp(2 * x) + 1)`.
<script type=idl>
partial interface MLGraphBuilder {
  MLOperand tanh(MLOperand input, optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits tanh;
};
</script>

<div dfn-for="MLGraphBuilder/tanh(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:**
        - an {{MLOperand}}. The output tensor of the same shape as {{MLGraphBuilder/tanh(input, options)/input}}.
</div>

<table id=constraints-tanh class='data' link-for="MLGraphBuilder/tanh(input, options)">
  <caption>Constraints for {{MLGraphBuilder/tanh()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>{{MLOperandDataType/"float32"}}, {{MLOperandDataType/"float16"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/tanh()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>tanh</dfn>
    :: Support limits for operator {{MLGraphBuilder/tanh()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>tanh(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/dataType=] is not one of its [=/allowed data types=] (according to [this table](#constraints-tanh)), then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "tanh" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be [EMULATED]
    </summary>
    <pre highlight="js">
    function tanh(builder, input) {
      return builder.div(
        builder.sub(
          builder.exp(builder.mul(builder.constant(input.dataType, 2), input)),
          builder.constant(input.dataType, 1)),
        builder.add(
          builder.exp(builder.mul(builder.constant(input.dataType, 2), input)),
          builder.constant(input.dataType, 1)));
    }
    </pre>
  </details>
</div>

### tile ### {#api-mlgraphbuilder-tile}
Repeat a tensor the given number of times along each dimension.

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand tile(MLOperand input,
                 sequence<unsigned long> repetitions,
                 optional MLOperatorOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits tile;
};
</script>

<div dfn-for="MLGraphBuilder/tile(input, repetitions, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input N-D tensor.
        - <dfn>repetitions</dfn>: A count per dimension of how many times to repeat that dimension. The [=list/size=] must match the {{MLGraphBuilder/tile(input, repetitions, options)/input}}'s [=MLOperand/rank=], using 1's for any axis that should retain the same size.
        - <dfn>options</dfn>: an optional {{MLOperatorOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The reversed N-D tensor.
</div>

<table id=constraints-tile class='data' link-for="MLGraphBuilder/tile(input, repetitions, options)">
  <caption>Constraints for {{MLGraphBuilder/tile()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following members for {{MLGraphBuilder/tile()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>tile</dfn>
    :: Support limits for operator {{MLGraphBuilder/tile()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>tile(|input|, |repetitions|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |repetitions|'s [=list/size=] is not equal to |input|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
    1. If |repetitions|'s values contain 0's, then [=exception/throw=] a {{TypeError}}.

        Issue(391): If 0-size dimensions are allowed, revise these steps.

    1. Let |outputShape| be a copy of |input|'s [=MLOperand/shape=].
    1. [=list/For each=] |index| in [=the range=] 0 to |outputShape|'s [=list/size=], exclusive:
        1. Set |outputShape|[|index|] to |outputShape|[|index|] * |repetitions|[|index|].
    1. Let |outputDescriptor| be the result of [=creating an MLOperandDescriptor=] given |input|'s [=MLOperand/dataType=] and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given |outputDescriptor|.
        1. Let |operator| be an [=operator=] for the "tile" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

### transpose ### {#api-mlgraphbuilder-transpose}
Permute the dimensions of the input tensor according to {{MLTransposeOptions/permutation}}.

<script type=idl>
dictionary MLTransposeOptions : MLOperatorOptions {
  sequence<[EnforceRange] unsigned long> permutation;
};

partial interface MLGraphBuilder {
  MLOperand transpose(MLOperand input, optional MLTransposeOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits transpose;
};
</script>

{{MLTransposeOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLTransposeOptions>
    : <dfn>permutation</dfn>
    ::
        The values used to permute the output shape.
        The default is [N-1, ..., 0], where N is the [=MLOperand/rank=] of the input tensor, e.g. [2,1,0] for a 3-D tensor.
        These default values cause the output to become a transposed tensor of the input. When specified, the number of values must be the same as the [=MLOperand/rank=] of the input tensor, and the values must be within the range from 0 to N-1 with no duplicates.
</dl>

<div dfn-for="MLGraphBuilder/transpose(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input N-D tensor.
        - <dfn>options</dfn>: an optional {{MLTransposeOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The permuted or transposed N-D tensor.
</div>

<table id=constraints-transpose class='data' link-for="MLGraphBuilder/transpose(input, options)">
  <caption>Constraints for {{MLGraphBuilder/transpose()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/transpose()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>transpose</dfn>
    :: Support limits for operator {{MLGraphBuilder/transpose()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>transpose(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |options|.{{MLTransposeOptions/permutation}} does not [=map/exist=], let |options|.{{MLTransposeOptions/permutation}} be the reversed sequence of all indices for |input|'s [=MLOperand/shape=].
    1. Otherwise if |options|.{{MLTransposeOptions/permutation}} [=map/exists=]:
        1. If its [=list/size=] is not equal to |input|'s [=MLOperand/rank=], then [=exception/throw=] a {{TypeError}}.
        1. If its values are not in [=the range=] 0 to |input|'s [=MLOperand/rank=] exclusive, then [=exception/throw=] a {{TypeError}}.
        1. If it contains duplicate values, then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "transpose" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

### triangular ### {#api-mlgraphbuilder-triangular}
Given a 2-D tensor (matrix), return a 2-D tensor containing either the upper or lower triangular part of the input tensor. If the input tensor has greater than 2 dimensions it is treated as a batch of matrices and the result has the same shape.

<script type=idl>
dictionary MLTriangularOptions : MLOperatorOptions {
  boolean upper = true;
  [EnforceRange] long diagonal = 0;
};

partial interface MLGraphBuilder {
  MLOperand triangular(MLOperand input, optional MLTriangularOptions options = {});
};

partial dictionary MLOpSupportLimits {
  MLSingleInputSupportLimits triangular;
};
</script>

{{MLTriangularOptions}} has the following members:
<dl dfn-type=dict-member dfn-for=MLTriangularOptions>
    : <dfn>upper</dfn>
    ::
        Indicates whether the output the upper or the lower part of the input matrix is retained. True indicates that the upper part is retained.
    : <dfn>diagonal</dfn>
    ::
        Specifies how many diagonals above or below the main diagonals of the input matrix are retained or excluded. A value of 0 means no diagonals other than the main diagonals are affected.
</dl>

<div dfn-for="MLGraphBuilder/triangular(input, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>input</dfn>: an {{MLOperand}}. The input tensor which is at least 2-D.
        - <dfn>options</dfn>: an optional {{MLTriangularOptions}}. The optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output tensor representing a triangular matrix, or batch of matrices which is the same shape as the input.
</div>

<table id=constraints-triangular class='data' link-for="MLGraphBuilder/triangular(input, options)">
  <caption>Constraints for {{MLGraphBuilder/triangular()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{input}}</td>
    <td>[=/any data type|any=]</td>
    <td>2 or greater</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{input}}</td>
    <td>[=/same rank as|same as=] {{input}}</td>
  </tr>
</table>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/triangular()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>triangular</dfn>
    :: Support limits for operator {{MLGraphBuilder/triangular()}}.
</dl>

<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>triangular(|input|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and |input| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If |input|'s [=MLOperand/rank=] is not one of its [=/allowed ranks=] (according to [this table](#constraints-triangular)), then [=exception/throw=] a {{TypeError}}.
    1. *Make graph connections:*
        1. Let |output| be the result of [=copying an MLOperand=] given |input|.
        1. Let |operator| be an [=operator=] for the "triangular" operation, given |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/input=] to |input|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="example">
<details open>
  <summary>
    Examples of how triangular works in different diagonal settings.
  </summary>
  <pre highlight="js">
    // input:
    //   [[7, 1, 2],
    //    [9, 4, 8],
    //    [2, 6, 3]]
    const input = builder.constant(
      {dataType: 'float32', shape: [3, 3]},
      new Float32Array([7, 1, 2, 9, 4, 8, 2, 6, 3]));

    // upper triangular matrix:
    //   [[7, 1, 2],
    //    [0, 4, 8],
    //    [0, 0, 3]]
    const upper = builder.triangular(input);

    // upper triangular matrix with one additional set of diagonals excluded:
    //   [[0, 1, 2],
    //    [0, 0, 8],
    //    [0, 0, 0]]
    const upperPositive = builder.triangular(input, {diagonal: 1});

    // upper triangular matrix with one additional set of diagonals retained:
    //   [[7, 1, 2],
    //    [9, 4, 8],
    //    [0, 6, 3]]
    const upperNegative = builder.triangular(input, {diagonal: -1});

    // lower triangular matrix:
    //   [[7, 0, 0],
    //    [9, 4, 0],
    //    [2, 6, 3]]
    const lower = builder.triangular(input, {upper: false});

    // lower triangular matrix with one additional set of diagonals retained:
    //   [[7, 1, 0],
    //    [9, 4, 8],
    //    [2, 6, 3]]
    const lowerPositive = builder.triangular(input, {upper: false, diagonal: 1});

    // lower triangular matrix with one additional set of diagonals excluded:
    //   [[0, 0, 0],
    //    [9, 0, 0],
    //    [2, 6, 0]]
    const lowerNegative = builder.triangular(input, {upper: false, diagonal: -1})

    // lower triangular matrix with two batches:
    //   [[[7, 0, 0],
    //     [9, 4, 0],
    //     [2, 6, 3]],
    //    [[1, 0, 0],
    //     [4, 5, 0],
    //     [7, 8, 9]]]
    const lowerWithBatches = builder.triangular(input, {upper: false});
  </pre>
</details>
</div>

### where ### {#api-mlgraphbuilder-where}
Select the values from the {{MLGraphBuilder/where(condition, trueValue, falseValue, options)/trueValue}} or the {{MLGraphBuilder/where(condition, trueValue, falseValue, options)/falseValue}} tensor depending on the corresponding values of the {{MLGraphBuilder/where(condition, trueValue, falseValue, options)/condition}} tensor, where non-zero is true and zero is false. The {{MLGraphBuilder/where(condition, trueValue, falseValue, options)/condition}} tensor is often the output of one of the element-wise logical operations.

The operation will be [=broadcast=] according to [[!numpy-broadcasting-rule]]. The input tensors must be [=bidirectionally broadcastable=]. The [=MLOperand/rank=] of the output tensor is the maximum [=MLOperand/rank=] of the input tensors. For each dimension of the output tensor, its size is the maximum size along that dimension of the input tensors.

<script type=idl>
partial interface MLGraphBuilder {
  MLOperand where(MLOperand condition,
                  MLOperand trueValue,
                  MLOperand falseValue,
                  optional MLOperatorOptions options = {});
};

dictionary MLWhereSupportLimits {
  MLTensorLimits condition;
  MLTensorLimits trueValue;
  MLTensorLimits falseValue;
  MLDataTypeLimits output;
};

partial dictionary MLOpSupportLimits {
  MLWhereSupportLimits where;
};
</script>

<div dfn-for="MLGraphBuilder/where(condition, trueValue, falseValue, options)" dfn-type=argument>
    **Arguments:**
        - <dfn>condition</dfn>: an {{MLOperand}}. The condition tensor.
        - <dfn>trueValue</dfn>: an {{MLOperand}}. The tensor from which the value is selected when the condition of the corresponding element is set to true.
        - <dfn>falseValue</dfn>: an {{MLOperand}}. The tensor from which the value is selected when the condition of the corresponding element is set to false.
        - <dfn>options</dfn>: an {{MLOperatorOptions}}. Specifies the optional parameters of the operation.

    **Returns:** an {{MLOperand}}. The output tensor that contains the values selected element-wise from either the {{MLGraphBuilder/where(condition, trueValue, falseValue, options)/trueValue}} or the {{MLGraphBuilder/where(condition, trueValue, falseValue, options)/falseValue}} tensor.
</div>

<table id=constraints-where class='data' link-for="MLGraphBuilder/where(condition, trueValue, falseValue, options)">
  <caption>Constraints for {{MLGraphBuilder/where()}}</caption>
  <thead>
    <tr>
      <th>operand</th>
      <th>[=/allowed data types=]</th>
      <th>[=/allowed ranks=]</th>
    </tr>
  </thead>
  <tr>
    <td>{{condition}}</td>
    <td>{{MLOperandDataType/"uint8"}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>{{trueValue}}</td>
    <td>[=/any data type|any=]</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>{{falseValue}}</td>
    <td>[=/same type as|same as=] {{trueValue}}</td>
    <td>[=/any rank|N=]</td>
  </tr>
  <tr>
    <td>*output*</td>
    <td>[=/same type as|same as=] {{trueValue}}</td>
    <td>maximum of {{condition}}'s [=MLOperand/rank=], {{trueValue}}'s [=MLOperand/rank=] and {{falseValue}}'s [=MLOperand/rank=]</td>
  </tr>
</table>

{{MLWhereSupportLimits}} has the following members:
<dl dfn-type=dict-member dfn-for=MLWhereSupportLimits>
    : <dfn>condition</dfn>
    :: {{MLTensorLimits}} for condition operand.
    : <dfn>trueValue</dfn>
    :: {{MLTensorLimits}} for trueValue operand.
    : <dfn>falseValue</dfn>
    :: {{MLTensorLimits}} for falseValue operand.
    : <dfn>output</dfn>
    :: {{MLDataTypeLimits}} for output operand.
</dl>

{{MLOpSupportLimits}} has the following member for {{MLGraphBuilder/where()}}:
<dl dfn-type=dict-member dfn-for=MLOpSupportLimits>
    : <dfn>where</dfn>
    :: Support limits for operator {{MLGraphBuilder/where()}}.
</dl>


<details open algorithm>
  <summary>
    The <dfn method for=MLGraphBuilder>where(|condition|, |trueValue|, |falseValue|, |options|)</dfn> method steps are:
  </summary>
    1. If [=this=] [=MLGraphBuilder/can not build=], then [=exception/throw=] an "{{InvalidStateError}}" {{DOMException}}.
    1. If [=MLGraphBuilder/validating operand=] with [=this=] and any of |condition|, |trueValue|, and |falseValue| returns false, then [=exception/throw=] a {{TypeError}}.
    1. If the [=MLOperand/dataType=] of any of |condition|, |trueValue|, or |falseValue| is not one of its [=/allowed data types=] (according to [this table](#constraints-where)), then [=exception/throw=] a {{TypeError}}.
    1. Let |outputShape| be the result of [=bidirectionally broadcasting=] |trueValue|'s [=MLOperand/shape=] and |falseValue|'s [=MLOperand/shape=].
        1. If that returns failure, then [=exception/throw=] a {{TypeError}}.
    1. Set |outputShape| to the result of [=bidirectionally broadcasting=] |condition|'s [=MLOperand/shape=] and |outputShape|.
        1. If that returns failure, then [=exception/throw=] a {{TypeError}}.
    1. Let |descriptor| be the result of [=creating an MLOperandDescriptor=] given |trueValue|'s [=MLOperand/dataType=] and |outputShape|.
    1. *Make graph connections:*
        1. Let |output| be the result of [=creating an MLOperand=] given [=this=] and |descriptor|.
        1. Let |operator| be an [=operator=] for the "where" operation, given |condition|, |trueValue|, |falseValue|, and |options|.
        1. Set |output|.{{MLOperand/[[operator]]}} to |operator|.
        1. Set |operator|'s [=operator/inputs=] to |condition|, |trueValue| and |falseValue|.
        1. Set |operator|'s [=operator/output=] to |output|.
    1. Return |output|.
</details>

<div class="note">
  <details open>
    <summary>
    The behavior of this operation can be [EMULATED]
    </summary>
    <pre highlight="js">
    function where(builder, condition, trueValue, falseValue) {
      const c = builder.clamp(condition, {'minValue': 0, 'maxValue': 1});
      builder.add(
        builder.mul(trueValue, builder.cast(c, trueValue.dataType)),
        builder.mul(
          falseValue, builder.cast(builder.logicalNot(c), falseValue.dataType)));
    }
    </pre>
  </details>
</div>



Algorithms {#algorithms}
=====================

## Broadcasting ## {#algorithms-broadcasting}

<dfn>Broadcasting</dfn> describes how WebNN treats tensors with different shapes during graph construction and computation. It is heavily influenced by [[NumPy]] and follows the [[!numpy-broadcasting-rule]]. Loosely speaking, it allows an operation on a smaller tensor to be "broadcast" across the shape of a larger tensor, so that the same data can be applied repeatedly without making copies.

The simplest example is the application of a scalar constant to an N-dimension tensor with element-wise binary operations such as {{MLGraphBuilder/add()}} or {{MLGraphBuilder/mul()}}. Rather than needing to allocate and populate a matching N-dimensional tensor containing multiple copies of the scalar constant, these element-wise operations allow the scalar constant to be used directly, and broadcast the scalar value across the N-dimensional tensor. With the following considerations, the same logic applies to tensors of other dimensions.

The shapes of the input tensors must be compatible. A tensor is [=unidirectionally broadcastable=] to another tensor if the first tensor can be "stretched" by repeating the first tensor along an axis with size 1 or repeating across new dimensions, starting from the last (rightmost) dimension. For example, a *[4]* tensor can be broadcast to a *[5, 4]* tensor by repeating it 5 times. A *[1]* tensor can be broadcast to a [5,4] tensor by repeating it 4 times on the last dimension and 5 times on the preceding dimension. Unidirectional broadcasting is important for operations such as {{MLGraphBuilder/expand()}} where the target tensor shape is explicitly given.

Two tensors are [=bidirectionally broadcastable=] if they can be mutually "stretched" (repeated) across their various dimensions, starting from the last dimension. For example, a *[5,1]* tensor can be bidirectionally broadcast with a *[1,6]* tensor by repeating the first tensor 6 times in the last dimension and the second tensor 5 times in preceding dimension. The result of the operation will be a *[5,6]* tensor. Bidirectional broadcasting is convenient for element-wise operations.

A tensor is [=blockwise broadcastable=] if the all dimensions can be upsampled by integer multiples to the target tensor's shape. For example, a *[4,5]* tensor can be blockwise broadcast up to a *[16,10]* tensor as it is an exact multiple (16 % 4 = 0, 10 % 5 = 0) by repeating every element 4 times in the first dimension and every element 2 times in the last dimension (e.g. values *[1,2,3,4,5]* in the last dimensions would be repeated to *[1,1,2,2,3,3,4,4,5,5]*). However, a *[4,5]* tensor would be incompatible with a *[9,3]* tensor since both dimensions have a nonzero remainder (9 % 4 = 1, 3 % 5 = 3). Blockwise broadcasting is useful for sharing common values in larger blocks to save memory. Both tensors are expected to have the same rank, and the output shape is simply the target tensor's shape which the smaller one is being upsampled to.

Some operations allow broadcasting with special semantics. For example, {{MLGraphBuilder/matmul()}} treats the last two dimensions of the input tensors as the rows and columns of the matrices, and the number of columns in the first matrix must be equal to the number of rows in the second matrix. The matrix multiplication is bidirectionally broadcast across any additional dimensions, treating the input tensors as stacks of matrices to multiply.

<details open algorithm>
<summary>
To <dfn data-lt="unidirectionally broadcasting">unidirectionally broadcast the shapes</dfn> |shapeFrom| and |shapeTo|, perform the following steps. |shapeFrom| and |shapeTo| are [=/lists=] of positive integers, representing the dimensions of tensors, and the steps return a new [=/list=] of positive integers, or failure.
</summary>

1. Let |sizeFrom| be |shapeFrom|'s [=list/size=].
1. Let |sizeTo| be |shapeTo|'s [=list/size=].
1. If |sizeFrom| > |sizeTo|, then return failure.
1. Let |paddedShapeFrom| be a [=list/clone=] of |shapeFrom|.
1. While |paddedShapeFrom|'s [=list/size=] is less than |sizeTo|, [=list/prepend=] 1 to |paddedShapeFrom|.
1. Let |outputShape| be a new [=/list=].
1. [=list/For each=] |index| in [=the range=] 0 to |sizeTo|, exclusive:
    1. Let |dimFrom| be |paddedShapeFrom|[|index|].
    1. Let |dimTo| be |shapeTo|[|index|].
    1. If |dimTo| is not equal to |dimFrom| and |dimFrom| is not equal to 1, then return failure.
    1. [=list/Append=] |dimTo| to |outputShape|.
1. Return |outputShape|.

</details>

<p algorithm>
|shapeFrom| is <dfn>unidirectionally broadcastable</dfn> to |shapeTo| if [=unidirectionally broadcasting=] |shapeFrom| and |shapeTo| does not result in failure.
</p>

<details open algorithm>
<summary>
To <dfn data-lt="bidirectionally broadcasting">bidirectionally broadcast the shapes</dfn> |shapeA| and |shapeB|, perform the following steps. |shapeA| and |shapeB| are [=/lists=] of positive integers, representing the dimensions of tensors, and the steps return a new [=/list=] of positive integers, or failure.
</summary>

1. Let |sizeA| be |shapeA|'s [=list/size=].
1. Let |sizeB| be |shapeB|'s [=list/size=].
1. Let |outputSize| be the maximum of |sizeA| and |sizeB|.
1. Let |paddedA| be a [=list/clone=] of |shapeA|.
1. While |paddedA|'s [=list/size=] is less than |outputSize|, [=list/prepend=] 1 to |paddedA|.
1. Let |paddedB| be a [=list/clone=] of |shapeB|.
1. While |paddedB|'s [=list/size=] is less than |outputSize|, [=list/prepend=] 1 to |paddedB|.
1. Let |outputShape| be a new [=/list=].
1. [=list/For each=] |index| in [=the range=] 0 to |outputSize|, exclusive:
    1. Let |dimA| be |paddedA|[|index|].
    1. Let |dimB| be |paddedB|[|index|].
    1. If |dimA| is not equal to |dimB|, and |dimA| is not equal to 1, and |dimB| is not equal to 1, then return failure.
    1. [=list/Append=] the maximum of |dimA| and |dimB| to |outputShape|.
1. Return |outputShape|.

</details>

<p algorithm>
|shapeA| is <dfn>bidirectionally broadcastable</dfn> to |shapeB| if [=bidirectionally broadcasting=] |shapeA| and |shapeB| does not result in failure.
</p>

<details open algorithm>
<summary>
To <dfn data-lt="blockwise broadcasting">blockwise broadcast the shapes</dfn> |shapeFrom| and |shapeTo|, perform the following steps. |shapeFrom| and |shapeTo| are [=/lists=] of positive integers, representing the dimensions of tensors, and the steps return true or false.
</summary>

1. If |shapeFrom|'s [=list/size=] is not equal to |shapeTo|'s [=list/size=], then return false.
1. [=list/For each=] |index| in [=the range=] 0 to |shapeTo|'s [=list/size=], exclusive:
    1. If |shapeFrom|[|index|] is not exactly divisible into |shapeTo|[|index|], then return false.
1. Return true.

</details>

<p algorithm>
|shapeFrom| is <dfn>blockwise broadcastable</dfn> to |shapeTo| if [=blockwise broadcasting=] |shapeFrom| and |shapeTo| returns true.
</p>

## Casting ## {#algorithms-casting}

Explicit numeric casting is used in algorithms where parameters passed as {{MLNumber}} or {{double}} need to be converted to match the {{MLOperandDataType}} of input or output {{MLOperand}}s.

<details open algorithm="cast">
<summary>
To <dfn>cast</dfn> a number |x| to a given {{MLOperandDataType}} |dataType|, perform the following steps. They return a number.
</summary>

1. Switch on |dataType|:
    <dl class=switch>
        : {{MLOperandDataType/"float32"}}
        :: Return [=ConvertToFloat=](|x|, 32).
        : {{MLOperandDataType/"float16"}}
        :: Return [=ConvertToFloat=](|x|, 16).
        : {{MLOperandDataType/"int64"}}
        :: Return [=ConvertToInt=](|x|, 64, "signed").
        : {{MLOperandDataType/"uint64"}}
        :: Return [=ConvertToInt=](|x|, 64, "unsigned").
        : {{MLOperandDataType/"int32"}}
        :: Return [=ConvertToInt=](|x|, 32, "signed").
        : {{MLOperandDataType/"uint32"}}
        :: Return [=ConvertToInt=](|x|, 32, "signed").
        : {{MLOperandDataType/"int8"}}
        :: Return [=ConvertToInt=](|x|, 8, "signed").
        : {{MLOperandDataType/"uint8"}}
        :: Return [=ConvertToInt=](|x|, 8, "unsigned").
    </dl>

NOTE: The input to [=cast=] is an abstract number with unlimited range and precision, including the special values Infinity, -Infinity and NaN. The output is also an abstract number, but exactly representable as the specified type.

<div algorithm>
The <dfn>ConvertToFloat</dfn>(|x|, |bitLength|) steps are:

1. If |x| is NaN, then return NaN.
1. Switch on |bitLength|:
    <dl class=switch>
        : 32
        ::
            1. Let |upperBound| be 2<sup>128</sup>.
            1. Let |lowerBound| be -2<sup>128</sup>.
            1. Let |S| be the set of [[IEEE-754-2019]] binary32 floating point values except -0, but with the special values |upperBound| and |lowerBound| added.
        : 16
        ::
            1. Let |upperBound| be 2<sup>16</sup>.
            1. Let |lowerBound| be -2<sup>16</sup>.
            1. Let |S| be the set of [[IEEE-754-2019]] binary16 floating point values except -0, but with the special values |upperBound| and |lowerBound| added.
    </dl>
1. Let |y| be the number in |S| that is closest to |x|, selecting the number with an even significand if there are two [=equally close values=]. The two special values |lowerBound| and |upperBound| are considered to have even significands for this purpose.
1. If |y| is |upperBound|, then return +Infinity.
1. If |y| is |lowerBound|, then return -Infinity.
1. If |y| is +0 and |x| is negative, return -0.
1. Return |y|.

NOTE: This is based on a definition in [[WEBIDL]], but extended to cover 16-bit floating point values.

</div>

<div algorithm>
The <dfn>ConvertToInt</dfn>(|x|, |bitLength|, |signedness|) steps are:

1. If |signedness| is "unsigned", then:
    1. Let |lowerBound| be 0.
    1. Let |upperBound| be 2<sup>|bitLength|</sup> - 1.
1. Otherwise:
    1. Let |lowerBound| be -(2<sup>|bitLength| - 1</sup>).
    1. Let |upperBound| be 2<sup>|bitLength| - 1</sup> - 1.
1. If |x| is -0, then set |x| to +0.
1. If |x| is NaN, then return +0.
1. Set |x| to min(max(|x|, |lowerBound|), |upperBound|).
1. Round |x| to the nearest integer, choosing the even integer if it lies halfway between two, and choosing +0 rather than -0.
1. Return |x|.

NOTE: This is based on a definition in [[WEBIDL]] with these differences: 64-bit integers are not treated specially, the input |x| is an abstract number, and clamping is always performed.

</div>

</details>

## Miscellaneous ## {#algorithms-miscellaneous}

<div algorithm>
A [=/list=] |A| is <dfn for=list>equal</dfn> to a [=/list=] |B| if |A|'s [=list/size=] equal's |B|'s [=list/size=] and each [=list/item=] in |A| is equal to the [=list/item=] at the same index in |B|.

Issue(whatwg/infra#664): Remove this when a definition in [[INFRA]] is available.
</div>


Examples {#examples}
=====================

<div class="example">
Given the following build graph:
<pre>
    constant1 ---+
                 +--- Add ---> intermediateOutput1 ---+
    input1    ---+                                    |
                                                      +--- Mul---> output
    constant2 ---+                                    |
                 +--- Add ---> intermediateOutput2 ---+
    input2    ---+
</pre>
<details open>
  <summary>
    The following code implements the graph:
  </summary>
  <pre highlight="js">
    // Use tensors in 4 dimensions.
    const TENSOR_SHAPE = [1, 2, 2, 2];
    const TENSOR_SIZE = 8;

    const context = await navigator.ml.createContext();
    const builder = new MLGraphBuilder(context);

    // Create MLOperandDescriptor object.
    const desc = {
      dataType: 'float32',
      shape: TENSOR_SHAPE
    };

    // constant1 is a constant MLOperand with the value 0.5.
    const constantBuffer1 = new Float32Array(TENSOR_SIZE).fill(0.5);
    const constant1 = builder.constant(desc, constantBuffer1);

    // input1 is one of the input MLOperands. Its value will be set before
    // execution.
    const input1 = builder.input('input1', desc);

    // constant2 is another constant MLOperand with the value 0.5.
    const constantBuffer2 = new Float32Array(TENSOR_SIZE).fill(0.5);
    const constant2 = builder.constant(desc, constantBuffer2);

    // input2 is another input MLOperand. Its value will be set before execution.
    const input2 = builder.input('input2', desc);

    // intermediateOutput1 is the output of the first Add operation.
    const intermediateOutput1 = builder.add(constant1, input1);

    // intermediateOutput2 is the output of the second Add operation.
    const intermediateOutput2 = builder.add(constant2, input2);

    // output is the output MLOperand of the Mul operation.
    const output = builder.mul(intermediateOutput1, intermediateOutput2);
  </pre>
</details>
</div>

Operator Emulation {#emulation}
===============================

*This section is non-normative.*

Operations present in other neural network inference APIs can often be emulated using operations present in WebNN.


## squeeze ## {#emulation-squeeze}

<div class="note">
  <details open>
    <summary>
    The [squeeze](https://pytorch.org/docs/stable/generated/torch.squeeze.html) operation returns a tensor with all specified dimensions of input of size 1 removed. It can be generically implemented using the {{MLGraphBuilder/reshape()}} operation as follows:
    </summary>
    <pre highlight="js">
    function squeeze(builder, input, axes) {
      if (!axes)
        axes = [];
      if (!axes.length)
        input.shape.forEach((item, i) => {
          axes.push(i);
        });
      const shape = Array.from(input.shape);
      for (let axis in axes.sort().reverse())
        if (axis < shape.length && shape[axis] == 1)
          shape.splice(axis, 1);
      return builder.reshape(input, shape);
    }
    </pre>
  </details>
</div>

## unsqueeze ## {#emulation-unsqueeze}

<div class="note">
  <details open>
    <summary>
    The [unsqueeze](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html) operation returns a new tensor with a dimension of size one inserted at the specified position. It can be generically implemented using the {{MLGraphBuilder/reshape()}} operation as follows:
    </summary>
    <pre highlight="js">
    function unsqueeze(builder, input, axes) {
      const shape = Array.from(input.shape);
      for (let axis in axes.sort())
        shape.splice(axis, 0, 1);
      return builder.reshape(input, shape);
    }
    </pre>
  </details>
</div>

## flatten ## {#emulation-flatten}

<div class="note">
  <details open>
    <summary>
    The [flatten](https://pytorch.org/docs/stable/generated/torch.flatten.html) operation reshapes the input into a one-dimensional tensor. It can be generically implemented using the {{MLGraphBuilder/reshape()}} operation as follows:
    </summary>
    <pre highlight="js">
    function flatten(builder, input, axis) {
      if (axis > input.shape.length)
        return input;
      const before = axis.slice(0, axis).reduce((a, b) => a * b, 1);
      const after = axis.slice(axis, input.shape.length).reduce((a, b) => a * b, 1);
      return builder.reshape(input, [before, after]);
    }
    </pre>
  </details>
</div>


# Appendices # {#appendices}

## {{MLOperandDataType}} and {{ArrayBufferView}} compatibility ## {#appendices-mloperanddatatype-arraybufferview-compatibility}

<table class='data'>
  <thead class=stickyheader>
    <tr>
      <th>{{MLOperandDataType}}</th>
      <th>{{ArrayBufferView}}</th>
    </tr>
  </thead>
  <tr>
    <td>{{MLOperandDataType/float32}}</td>
    <td>{{Float32Array}}</td>
  <tr>
    <td>{{MLOperandDataType/float16}}</td>
    <td>{{Float16Array}}</td>
  <tr>
    <td>{{MLOperandDataType/int64}}</td>
    <td>{{BigInt64Array}}</td>
  <tr>
    <td>{{MLOperandDataType/uint64}}</td>
    <td>{{BigUint64Array}}</td>
  <tr>
    <td>{{MLOperandDataType/int32}}</td>
    <td>{{Int32Array}}</td>
  <tr>
    <td>{{MLOperandDataType/uint32}}</td>
    <td>{{Uint32Array}}</td>
  <tr>
    <td>{{MLOperandDataType/int8}}</td>
    <td>{{Int8Array}}</td>
  <tr>
    <td>{{MLOperandDataType/uint8}}</td>
    <td>{{Uint8Array}}</td>
  </tr>
</table>

<p class="note">{{Float16Array}} is at <a href="https://tc39.es/process-document/">ECMA Stage 3</a> signaling its design is finished. Implementers wanting to enable this type ahead native implementations can emulate the type by passing raw bits via {{Uint16Array}}. <a href="https://github.com/webmachinelearning/webnn/issues/373">[Issue webnn#373]</a></p>

<h2 id="acknowledgements">Acknowledgements</h2>

This specification follows the concepts of the Android Neural Networks API C
API.

Thanks to Tomoyuki Shimizu, Ningxin Hu, Zhiqiang Yu and Belem Zhang for the use
cases.

Thanks to Nikhil Thorat, Daniel Smilkov, Ganesan Ramalingam, Rafael Cintron and
Benjamin Poulain for their contributions to the API specification.

Thanks to Sangwhan Moon and the W3C Technical Architecture Group for review of this specification for web architecture fit, design consistency and developer ergonomics.

Thanks to Zoltan Kis for adding algorithms and making navigating this specification a delightful experience. Thanks to Joshua Bell for aligning the specification with modern editorial conventions. Thanks to Ningxin Hu, Lisha Guo, Shiyi Zou, Mingming Xu, Junwei Fu, Bruce Dai and Bin Miao for careful review and comments.

Thanks to W3C Privacy Interest Group for privacy and security review and feedback.

Thanks to Alex Gough and the Chrome Security team for security review and questions.

Thanks to Michal Karzynski for sharing practical guidelines and learnings from ONNX.

Thanks to Kaustubha Govind and Chrome privacy reviewers for feedback and privacy considerations.

Thanks to Jiewei Qian for Chromium implementation review and feedback.

Thanks to Dwayne Robinson, Joshua Lochner and Wanming Lin for their work investigating and providing recommendation for transformer support. Additional thanks to Dwayne and Wanming for providing reviews of operator conformance and web-platform-tests implementation.

Thanks to Feng Dai for his continuous contributions that keep web-platform-tests evolving alongside the specification.
<pre class="biblio">
{
  "Models": {
      "href": "https://github.com/webmachinelearning/webnn/blob/master/op_compatibility/first_wave_models.md",
      "title": "The first-wave models",
      "authors": ["Machine Learning for the Web Community Group"],
      "date": "2020"
  },
  "NumPy": {
    "href": "https://numpy.org/doc/stable/",
    "title": "NumPy",
    "authors": ["The SciPy community"],
    "date": "July 2019"
  },
  "numpy-broadcasting-rule": {
    "href": "https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules",
    "title": "General Broadcasting Rules of NumPy",
    "authors": ["The SciPy community"],
    "date": "July 2019"
  },
  "SSD": {
    "href": "https://arxiv.org/abs/1512.02325",
    "title": "SSD: Single Shot MultiBox Detector",
    "authors": [
      "Wei Liu",
      "Dragomir Anguelov",
      "Dumitru Erhan",
      "Christian Szegedy",
      "Scott Reed",
      "Cheng-Yang Fu",
      "Alexander C. Berg"
    ],
    "date": "December 2016"
  },
  "YOLO": {
    "href": "https://arxiv.org/abs/1506.02640",
    "title": "You Only Look Once: Unified, Real-Time Object Detection",
    "authors": [
      "Joseph Redmon",
      "Santosh Divvala,",
      "Ross Girshick",
      "Ali Farhadi"
    ],
    "date": "May 2016"
  },
  "DeepLabv3+": {
    "href": "https://arxiv.org/abs/1802.02611",
    "title": "Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation",
    "authors": [
      "Liang-Chieh Chen",
      "Yukun Zhu",
      "George Papandreou",
      "Florian Schroff",
      "Hartwig Adam"
    ],
    "date": "August 2018"
  },
  "MaskR-CNN": {
    "href": "https://arxiv.org/abs/1703.06870",
    "title": "Mask R-CNN",
    "authors": [
      "Kaiming He",
      "Georgia Gkioxari",
      "Piotr Dollár",
      "Ross Girshick"
    ],
    "date": "January 2018"
  },
  "SegAny": {
    "href": "https://arxiv.org/abs/2304.02643",
    "title": "Segment Anything",
    "authors": [
      "Alexander Kirillov",
      "Alex Berg",
      "Chloe Rolland",
      "Eric Mintun",
      "Hanzi Mao",
      "Laura Gustafson",
      "Nikhila Ravi",
      "Piotr Dollar",
      "Ross Girshick",
      "Spencer Whitehead",
      "Wan-Yen Lo",
      "Tete Xiao"
    ],
    "date": "April 2023"
  },
  "PoseNet": {
    "href": "https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5",
    "title": "Real-time Human Pose Estimation in the Browser with TensorFlow.js",
    "authors": [
      "Dan Oved"
    ],
    "date": "May 2018"
  },
  "FaceNet": {
    "href": "https://arxiv.org/abs/1503.03832",
    "title": "FaceNet: A Unified Embedding for Face Recognition and Clustering",
    "authors": [
      "Florian Schroff",
      "Dmitry Kalenichenko",
      "James Philbin"
    ],
    "date": "June 2015"
  },
  "FAN": {
    "href": "https://arxiv.org/abs/1703.07332",
    "title": "How far are we from solving the 2D & 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks)",
    "authors": [
      "Adrian Bulat",
      "Georgios Tzimiropoulos"
    ],
    "date": "September 2017"
  },
  "ContextualLoss": {
    "href": "https://arxiv.org/abs/1803.02077",
    "title": "The Contextual Loss for Image Transformation with Non-Aligned Data",
    "authors": [
      "Roey Mechrez",
      "Itamar Talmi",
      "Lihi Zelnik-Manor"
    ],
    "date": "July 2018"
  },
  "PairedCycleGAN": {
    "href": "http://openaccess.thecvf.com/content_cvpr_2018/html/Chang_PairedCycleGAN_Asymmetric_Style_CVPR_2018_paper.html",
    "title": "PairedCycleGAN: Asymmetric Style Transfer for Applying and Removing Makeup",
    "authors": [
      "Huiwen Chang",
      "Jingwan Lu",
      "Fisher Yu",
      "Adam Finkelstein"
    ],
    "date": "June 2018"
  },
  "SRGAN": {
    "href": "https://arxiv.org/abs/1609.04802",
    "title": "Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network",
    "authors": [
      "Christian Ledig",
      "Lucas Theis",
      "Ferenc Huszar",
      "Jose Caballero",
      "Andrew Cunningham",
      "Alejandro Acosta",
      "Andrew Aitken",
      "Alykhan Tejani",
      "Johannes Totz",
      "Zehan Wang",
      "Wenzhe Shi"
    ],
    "date": "May 2017"
  },
  "im2txt": {
    "href": "https://arxiv.org/abs/1609.06647",
    "title": "Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge",
    "authors": [
      "Oriol Vinyals",
      "Alexander Toshev",
      "Samy Bengio",
      "Dumitru Erhan"
    ],
    "date": "September 2016"
  },
  "LDM": {
    "href": "https://arxiv.org/abs/2112.10752",
    "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
    "authors": [
      "Robin Rombach",
      "Andreas Blattmann",
      "Dominik Lorenz",
      "Patrick Esser",
      "Björn Ommer"
    ],
    "date": "April 2022"
  },
  "GNMT": {
    "href": "https://github.com/tensorflow/nmt",
    "title": "Neural Machine Translation (seq2seq) Tutorial",
    "authors": [
      "Minh-Thang Luong",
      "Eugene Brevdo",
      "Rui Zhao"
    ],
    "date": "May 2017"
  },
  "OpenNMT": {
    "href": "https://arxiv.org/abs/1701.02810",
    "title": "OpenNMT: Open-Source Toolkit for Neural Machine Translation",
    "authors": [
      "Guillaume Klein",
      "Yoon Kim",
      "Yuntian Deng",
      "Jean Senellart",
      "Alexander M. Rush"
    ],
    "date": "March 2017"
  },
  "DeepMoji": {
    "href": "https://arxiv.org/abs/1708.00524",
    "title": "Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm",
    "authors": [
      "Bjarke Felbo",
      "Alan Mislove",
      "Anders Søgaard",
      "Iyad Rahwan",
      "Sune Lehmann"
    ],
    "date": "October 2017"
  },
  "Video-Summarization-with-LSTM": {
    "href": "http://www-scf.usc.edu/~zhan355/ke_eccv2016.pdf",
    "title": "Video summarization with long short-term memory",
    "authors": [
      "Ke Zhang",
      "Wei-Lun Chao",
      "Fei Sha",
      "Kristen Grauman"
    ],
    "date": "October 2016"
  },
  "LeakyReLU": {
    "href": "https://pdfs.semanticscholar.org/367f/2c63a6f6a10b3b64b8729d601e69337ee3cc.pdf",
    "title": "Rectifier Nonlinearities Improve Neural Network Acoustic Models",
    "authors": [
      "Andrew L. Maas",
      "Awni Y. Hannun",
      "Andrew Y. Ng"
    ],
    "date": "June 2013"
  },
  "ELU": {
    "href": "https://arxiv.org/abs/1511.07289",
    "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)",
    "authors": [
      "Djork-Arné Clevert",
      "Thomas Unterthiner",
      "Sepp Hochreiter"
    ],
    "date": "February 2016"
  },
  "RNNoise": {
    "href": "https://github.com/xiph/rnnoise",
    "title": "Recurrent neural network for audio noise reduction",
    "authors": [
      "Jean-Marc Valin"
    ],
    "date": "September 2017"
  },
  "Whisper": {
    "href": "https://arxiv.org/abs/2212.04356",
    "title": "Robust Speech Recognition via Large-Scale Weak Supervision",
    "authors": [
      "Alec Radford",
      "Jong Wook Kim",
      "Tao Xu",
      "Greg Brockman",
      "Christine McLeavey",
      "Ilya Sutskever"
    ],
    "date": "December 2022"
  },
  "GRU": {
    "href": "https://arxiv.org/pdf/1406.1078.pdf",
    "title": "Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation",
    "authors": [
      "Kyunghyun Cho",
      "Bart van Merrienboer",
      "Caglar Gulcehre",
      "Dzmitry Bahdanau",
      "Fethi Bougares",
      "Holger Schwenk",
      "Yoshua Bengio"
    ],
    "date": "September 2014"
  },
  "LSTM": {
    "href": "https://doi.org/10.1162/neco.1997.9.8.1735",
    "title": "Long Short-Term Memory",
    "authors": [
      "Sepp Hochreiter",
      "Jürgen Schmidhuber"
    ],
    "date": "November 1997"
  },
  "Batch-Normalization": {
    "href": "https://arxiv.org/abs/1502.03167",
    "title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift",
    "authors": [
      "Sergey Ioffe",
      "Christian Szegedy"
    ],
    "date": "March 2015"
  },
  "Instance-Normalization": {
    "href": "https://arxiv.org/abs/1607.08022",
    "title": "Instance Normalization: The Missing Ingredient for Fast Stylization",
    "authors": [
      "Dmitry Ulyanov",
      "Andrea Vedaldi",
      "Victor Lempitsky"
    ],
    "date": "July 2016"
  },
  "Layer-Normalization": {
    "href": "https://arxiv.org/abs/1607.06450",
    "title": "Layer Normalization",
    "authors": [
      "Jimmy Lei Ba",
      "Jamie Ryan Kiros",
      "Geoffrey E. Hinton"
    ],
    "date": "July 2016"
  },
  "Error-Function": {
    "href": "https://books.google.com/books?id=2CAqsF-RebgC&pg=PA110",
    "title": "Special functions of mathematics for engineers",
    "authors": [
      "Larry C. Andrews"
    ],
    "date": "1998"
  },
  "FaceForensics++": {
    "href": "https://github.com/ondyari/FaceForensics",
    "title": "FaceForensics++",
    "authors": [
      "Andreas Rössler",
      "Davide Cozzolino",
      "Luisa Verdoliva",
      "Christian Riess",
      "Justus Thies",
      "Matthias Nießner"
    ],
    "date": "January 2019"
  },
  "MobileNetV3": {
    "href": "https://arxiv.org/pdf/1905.02244",
    "title": "Searching for MobileNetV3",
    "authors": [
      "Andrew Howard",
      "Mark Sandler",
      "Grace Chu",
      "Liang-Chieh Chen",
      "Bo Chen",
      "Mingxing Tan",
      "Weijun Wang",
      "Yukun Zhu",
      "Ruoming Pang",
      "Vijay Vasudevan",
      "Quoc V. Le",
      "Hartwig Adam"
    ],
    "date": "November 2019"
  },
  "t5-small": {
    "href": "https://jmlr.org/papers/volume21/20-074/20-074.pdf",
    "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
    "authors": [
      "Colin Raffel",
      "Noam Shazeer",
      "Adam Roberts",
      "Katherine Lee",
      "Sharan Narang",
      "Michael Matena",
      "Yanqi Zhou",
      "Wei Li",
      "Peter J. Liu"
    ],
    "date": "June 2020"
  },
  "m2m100_418M": {
    "href": "https://arxiv.org/abs/2010.11125",
    "title": "Beyond English-Centric Multilingual Machine Translation",
    "authors": [
      "Angela Fan",
      "Shruti Bhosale",
      "Holger Schwenk",
      "Zhiyi Ma",
      "Ahmed El-Kishky",
      "Siddharth Goyal",
      "Mandeep Baines",
      "Onur Celebi",
      "Guillaume Wenzek",
      "Vishrav Chaudhary",
      "Naman Goyal",
      "Tom Birch",
      "Vitaliy Liptchinsky",
      "Sergey Edunov",
      "Edouard Grave",
      "Michael Auli",
      "Armand Joulin"
  ],
    "date": "October 2020"
  },
  "gpt2": {
    "href": "https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf",
    "title": "Language Models are Unsupervised Multitask Learners",
    "authors": [
      "Alec Radford",
      "Jeffrey Wu",
      "Rewon Child",
      "David Luan",
      "Dario Amodei",
      "Ilya Sutskever"
    ],
    "date": "February 2019"
  },
  "llama-2-7b": {
    "href": "https://arxiv.org/abs/2307.09288",
    "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models",
    "authors": [
      "Hugo Touvron",
      "Louis Martin",
      "Kevin Stone",
      "Peter Albert",
      "Amjad Almahairi",
      "Yasmine Babaei",
      "Nikolay Bashlykov",
      "Soumya Batra",
      "Prajjwal Bhargava",
      "Shruti Bhosale",
      "Dan Bikel",
      "Lukas Blecher",
      "Cristian Canton Ferrer",
      "Moya Chen",
      "Guillem Cucurull",
      "David Esiobu",
      "Jude Fernandes",
      "Jeremy Fu",
      "Wenyin Fu",
      "Brian Fuller",
      "Cynthia Gao",
      "Vedanuj Goswami",
      "Naman Goyal",
      "Anthony Hartshorn",
      "Saghar Hosseini",
      "Rui Hou",
      "Hakan Inan",
      "Marcin Kardas",
      "Viktor Kerkez",
      "Madian Khabsa",
      "Isabel Kloumann",
      "Artem Korenev",
      "Punit Singh Koura",
      "Marie-Anne Lachaux",
      "Thibaut Lavril",
      "Jenya Lee",
      "Diana Liskovich",
      "Yinghai Lu",
      "Yuning Mao",
      "Xavier Martinet",
      "Todor Mihaylov",
      "Pushkar Mishra",
      "Igor Molybog",
      "Yixin Nie",
      "Andrew Poulton",
      "Jeremy Reizenstein",
      "Rashi Rungta",
      "Kalyan Saladi",
      "Alan Schelten",
      "Ruan Silva",
      "Eric Michael Smith",
      "Ranjan Subramanian",
      "Xiaoqing Ellen Tan",
      "Binh Tang",
      "Ross Taylor",
      "Adina Williams",
      "Jian Xiang Kuan",
      "Puxin Xu",
      "Zheng Yan",
      "Iliyan Zarov",
      "Yuchen Zhang",
      "Angela Fan",
      "Melanie Kambadur",
      "Sharan Narang",
      "Aurelien Rodriguez",
      "Robert Stojnic",
      "Sergey Edunov",
      "Thomas Scialom"
    ],
    "date": "July 2023"
  },
  "Prefix-Sum": {
    "href": "https://en.wikipedia.org/wiki/Prefix_sum",
    "title": "Prefix Sum",
    "authors": ["The Wikipedia community"],
    "date": "January 2025"
  }
}
</pre>
